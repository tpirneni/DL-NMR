{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import dependencies\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Set default plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (30,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize CNN architecture and hyperparameters on dataset of 44 metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of epochs used later in training (this will have to be redefined later......)\n",
    "num_epochs = 500\n",
    "\n",
    "# Name variable used for saving model metrics, name should reflect model used, dataset used, and other information such as # of epochs\n",
    "ModelName = \"CNN_44Met_Optuna_ForManuscript\" + str(num_epochs) +\"ep\"\n",
    "\n",
    "# Set the random seed\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelPerformanceMetrics/') \n",
    "seed = 1 \n",
    "torch.manual_seed(seed)\n",
    "np.save(ModelName + \"_Seed.npy\", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing datasets, validation datasets, and representative example spectra \n",
    "\n",
    "# Switch to directory containing datasets\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/GeneratedDataAndVariables')\n",
    "\n",
    "# Load training data and max value from testing and training datasets\n",
    "spectra = np.load('Dataset44_ExtendedRange_MoreLeftOut_Combined1Distribution_ForManuscript_Spec.npy')\n",
    "conc1 = np.load('Dataset44_ExtendedRange_MoreLeftOut_Combined1Distribution_ForManuscript_Conc.npy')\n",
    "\n",
    "spectraVal = np.load('Dataset44_ExtendedRange_MoreLeftOut_Combined1Distribution_ForManuscript_Val_Spec.npy')\n",
    "concVal = np.load('Dataset44_ExtendedRange_MoreLeftOut_Combined1Distribution_ForManuscript_Val_Conc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU for training.\n"
     ]
    }
   ],
   "source": [
    "## Prepare to switch data from CPU to GPU\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # A CUDA device object\n",
    "    print(\"Using GPU for training.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")           # A CPU object\n",
    "    print(\"CUDA is not available. Using CPU for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up data for testing and training\n",
    "\n",
    "# Split into testing and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectra, conc1, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Tensorize and prepare datasets\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test).float()\n",
    "\n",
    "\n",
    "# Move the input data to the GPU device\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "spectraVal = torch.tensor(spectraVal).float().to(device)   # Confusing names, these spectra are the 5000 spectra generated like the training dataset\n",
    "#ValSpectra = torch.tensor(ValSpectra).float().to(device)   # Confusing names, these spectra are the 10 representative example spectra\n",
    "\n",
    "# Move the target data to the GPU device\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "concVal = torch.tensor(concVal).float().to(device)\n",
    "#ValConc = torch.tensor(ValConc).float().to(device)\n",
    "\n",
    "# More data prep?\n",
    "datasets = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "Test_datasets = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "Val_datasets = torch.utils.data.TensorDataset(spectraVal, concVal)\n",
    "#train_iter = torch.utils.data.DataLoader(datasets, batch_size = 128, shuffle=True)\n",
    "#test_iter = torch.utils.data.DataLoader(Test_datasets, batch_size = 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "del y_test\n",
    "del spectra\n",
    "del conc1\n",
    "del spectraVal\n",
    "del concVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileLoss(nn.Module):\n",
    "    def __init__(self, quantile=0.5):\n",
    "        super(QuantileLoss, self).__init__()\n",
    "        self.quantile = quantile\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        error = y_true - y_pred\n",
    "        loss = torch.mean(torch.max(self.quantile * error, (self.quantile - 1) * error))\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    \n",
    "# MAPE loss function for directly comparing models despite loss function used\n",
    "class MAPELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MAPELoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = torch.mean(torch.abs((y_true - y_pred) / y_true))\n",
    "        return loss * 100  # To get percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 21:58:40,028] A new study created in RDB with name: CNN_Optuna_ForManuscript\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 | Train Loss: 123779.030 | Test Loss: 5162.517 | Test Loss [MAPE]: 429163.339 --time-- 5.798574447631836\n",
      "Epoch 2/500 | Train Loss: 5106.874 | Test Loss: 5162.334 | Test Loss [MAPE]: 450108.679 --time-- 4.2054924964904785\n",
      "Epoch 3/500 | Train Loss: 5106.755 | Test Loss: 5162.389 | Test Loss [MAPE]: 452748.733 --time-- 4.2149834632873535\n",
      "Epoch 4/500 | Train Loss: 5106.983 | Test Loss: 5161.981 | Test Loss [MAPE]: 426240.936 --time-- 4.226120471954346\n",
      "Epoch 5/500 | Train Loss: 5106.918 | Test Loss: 5162.432 | Test Loss [MAPE]: 435016.414 --time-- 4.226314067840576\n",
      "Epoch 6/500 | Train Loss: 5108.415 | Test Loss: 5163.527 | Test Loss [MAPE]: 435418.237 --time-- 4.192160606384277\n",
      "Epoch 7/500 | Train Loss: 5107.464 | Test Loss: 5162.797 | Test Loss [MAPE]: 458230.844 --time-- 4.23551869392395\n",
      "Epoch 8/500 | Train Loss: 5107.382 | Test Loss: 5162.763 | Test Loss [MAPE]: 454800.070 --time-- 4.237369060516357\n",
      "Epoch 9/500 | Train Loss: 5107.264 | Test Loss: 5163.616 | Test Loss [MAPE]: 478566.348 --time-- 4.245995998382568\n",
      "Epoch 10/500 | Train Loss: 5107.418 | Test Loss: 5162.917 | Test Loss [MAPE]: 467459.282 --time-- 4.165467262268066\n",
      "Epoch 11/500 | Train Loss: 5106.786 | Test Loss: 5162.199 | Test Loss [MAPE]: 416686.610 --time-- 4.168936252593994\n",
      "Epoch 12/500 | Train Loss: 5107.137 | Test Loss: 5163.045 | Test Loss [MAPE]: 468047.536 --time-- 4.193880081176758\n",
      "Epoch 13/500 | Train Loss: 5108.046 | Test Loss: 5165.860 | Test Loss [MAPE]: 515997.701 --time-- 4.251062631607056\n",
      "Epoch 14/500 | Train Loss: 5107.876 | Test Loss: 5162.174 | Test Loss [MAPE]: 440253.994 --time-- 4.174416542053223\n",
      "Epoch 15/500 | Train Loss: 5107.247 | Test Loss: 5162.645 | Test Loss [MAPE]: 452478.030 --time-- 4.174314975738525\n",
      "Epoch 16/500 | Train Loss: 5107.349 | Test Loss: 5162.535 | Test Loss [MAPE]: 442156.279 --time-- 4.172884702682495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 21:59:55,042] Trial 0 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5107.315 | Test Loss: 5163.472 | Test Loss [MAPE]: 457806.704 --time-- 4.184074640274048\n",
      "Epoch 1/500 | Train Loss: 174200.981 | Test Loss: 5164.122 | Test Loss [MAPE]: 5816882.144 --time-- 2.5879898071289062\n",
      "Epoch 2/500 | Train Loss: 4613.134 | Test Loss: 4229.693 | Test Loss [MAPE]: 3905282.417 --time-- 2.5410165786743164\n",
      "Epoch 3/500 | Train Loss: 4169.876 | Test Loss: 4119.167 | Test Loss [MAPE]: 2893807.302 --time-- 2.5351552963256836\n",
      "Epoch 4/500 | Train Loss: 4101.899 | Test Loss: 4076.439 | Test Loss [MAPE]: 2335883.608 --time-- 2.5375611782073975\n",
      "Epoch 5/500 | Train Loss: 4037.838 | Test Loss: 4017.628 | Test Loss [MAPE]: 3135208.531 --time-- 2.5352861881256104\n",
      "Epoch 6/500 | Train Loss: 3994.860 | Test Loss: 3983.011 | Test Loss [MAPE]: 3043754.544 --time-- 2.5381650924682617\n",
      "Epoch 7/500 | Train Loss: 3954.501 | Test Loss: 3974.350 | Test Loss [MAPE]: 2484265.388 --time-- 2.5377488136291504\n",
      "Epoch 8/500 | Train Loss: 3910.934 | Test Loss: 3895.837 | Test Loss [MAPE]: 3046804.680 --time-- 2.54142689704895\n",
      "Epoch 9/500 | Train Loss: 3849.205 | Test Loss: 3847.051 | Test Loss [MAPE]: 3577174.323 --time-- 2.5395286083221436\n",
      "Epoch 10/500 | Train Loss: 3816.461 | Test Loss: 3812.210 | Test Loss [MAPE]: 3044575.837 --time-- 2.541957139968872\n",
      "Epoch 11/500 | Train Loss: 3757.625 | Test Loss: 3747.332 | Test Loss [MAPE]: 3673828.241 --time-- 2.5377016067504883\n",
      "Epoch 12/500 | Train Loss: 3693.711 | Test Loss: 3683.548 | Test Loss [MAPE]: 3695077.134 --time-- 2.5400943756103516\n",
      "Epoch 13/500 | Train Loss: 3613.438 | Test Loss: 3568.947 | Test Loss [MAPE]: 3453218.449 --time-- 2.5397934913635254\n",
      "Epoch 14/500 | Train Loss: 3518.257 | Test Loss: 3525.269 | Test Loss [MAPE]: 4371832.051 --time-- 2.5414271354675293\n",
      "Epoch 15/500 | Train Loss: 3427.525 | Test Loss: 3413.718 | Test Loss [MAPE]: 3025006.047 --time-- 2.541857957839966\n",
      "Epoch 16/500 | Train Loss: 3412.721 | Test Loss: 3347.382 | Test Loss [MAPE]: 2559407.594 --time-- 2.5392744541168213\n",
      "Epoch 17/500 | Train Loss: 3281.720 | Test Loss: 3273.303 | Test Loss [MAPE]: 2525549.448 --time-- 2.5404834747314453\n",
      "Epoch 18/500 | Train Loss: 3262.723 | Test Loss: 3260.441 | Test Loss [MAPE]: 2716312.695 --time-- 2.5392394065856934\n",
      "Epoch 19/500 | Train Loss: 3861.597 | Test Loss: 3580.099 | Test Loss [MAPE]: 2827470.153 --time-- 2.540987014770508\n",
      "Epoch 20/500 | Train Loss: 3347.470 | Test Loss: 3275.480 | Test Loss [MAPE]: 3039918.704 --time-- 2.5405824184417725\n",
      "Epoch 21/500 | Train Loss: 3323.049 | Test Loss: 3287.154 | Test Loss [MAPE]: 3410421.022 --time-- 2.5336742401123047\n",
      "Epoch 22/500 | Train Loss: 3171.133 | Test Loss: 3158.655 | Test Loss [MAPE]: 1827936.223 --time-- 2.538559675216675\n",
      "Epoch 23/500 | Train Loss: 3119.379 | Test Loss: 3081.546 | Test Loss [MAPE]: 1841788.227 --time-- 2.5356459617614746\n",
      "Epoch 24/500 | Train Loss: 3093.481 | Test Loss: 3124.867 | Test Loss [MAPE]: 1740936.215 --time-- 2.5419039726257324\n",
      "Epoch 25/500 | Train Loss: 3080.218 | Test Loss: 3099.240 | Test Loss [MAPE]: 1837977.174 --time-- 2.5415191650390625\n",
      "Epoch 26/500 | Train Loss: 3085.490 | Test Loss: 3158.562 | Test Loss [MAPE]: 1883018.175 --time-- 2.5369653701782227\n",
      "Epoch 27/500 | Train Loss: 3031.450 | Test Loss: 3041.269 | Test Loss [MAPE]: 2130713.031 --time-- 2.537324905395508\n",
      "Epoch 28/500 | Train Loss: 3010.377 | Test Loss: 2977.366 | Test Loss [MAPE]: 1900325.568 --time-- 2.5395658016204834\n",
      "Epoch 29/500 | Train Loss: 3009.611 | Test Loss: 3067.089 | Test Loss [MAPE]: 1442991.427 --time-- 2.5369014739990234\n",
      "Epoch 30/500 | Train Loss: 2998.625 | Test Loss: 2941.376 | Test Loss [MAPE]: 1790853.230 --time-- 2.539400100708008\n",
      "Epoch 31/500 | Train Loss: 2961.398 | Test Loss: 3051.637 | Test Loss [MAPE]: 1416113.598 --time-- 2.5343728065490723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:01:17,188] Trial 1 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/500 | Train Loss: 3043.453 | Test Loss: 5077.148 | Test Loss [MAPE]: 550717.549 --time-- 2.5313003063201904\n",
      "Epoch 1/500 | Train Loss: 527902.595 | Test Loss: 5162.457 | Test Loss [MAPE]: 445651.258 --time-- 1.4838082790374756\n",
      "Epoch 2/500 | Train Loss: 5107.077 | Test Loss: 5163.046 | Test Loss [MAPE]: 469048.324 --time-- 1.4959361553192139\n",
      "Epoch 3/500 | Train Loss: 5107.309 | Test Loss: 5163.135 | Test Loss [MAPE]: 434160.252 --time-- 1.504957914352417\n",
      "Epoch 4/500 | Train Loss: 5107.782 | Test Loss: 5162.436 | Test Loss [MAPE]: 441546.607 --time-- 1.4977924823760986\n",
      "Epoch 5/500 | Train Loss: 5108.360 | Test Loss: 5164.897 | Test Loss [MAPE]: 500144.333 --time-- 1.4981741905212402\n",
      "Epoch 6/500 | Train Loss: 5108.791 | Test Loss: 5164.052 | Test Loss [MAPE]: 476823.683 --time-- 1.5003230571746826\n",
      "Epoch 7/500 | Train Loss: 5108.604 | Test Loss: 5162.904 | Test Loss [MAPE]: 449753.811 --time-- 1.5036015510559082\n",
      "Epoch 8/500 | Train Loss: 5109.476 | Test Loss: 5163.578 | Test Loss [MAPE]: 458282.699 --time-- 1.5005040168762207\n",
      "Epoch 9/500 | Train Loss: 5108.763 | Test Loss: 5163.956 | Test Loss [MAPE]: 450336.037 --time-- 1.4999725818634033\n",
      "Epoch 10/500 | Train Loss: 5109.191 | Test Loss: 5166.202 | Test Loss [MAPE]: 529824.207 --time-- 1.4996311664581299\n",
      "Epoch 11/500 | Train Loss: 5109.132 | Test Loss: 5162.982 | Test Loss [MAPE]: 446967.734 --time-- 1.5047237873077393\n",
      "Epoch 12/500 | Train Loss: 5108.682 | Test Loss: 5164.528 | Test Loss [MAPE]: 467888.828 --time-- 1.4966583251953125\n",
      "Epoch 13/500 | Train Loss: 5108.845 | Test Loss: 5164.217 | Test Loss [MAPE]: 467536.783 --time-- 1.500446081161499\n",
      "Epoch 14/500 | Train Loss: 5109.025 | Test Loss: 5163.719 | Test Loss [MAPE]: 449296.171 --time-- 1.4990217685699463\n",
      "Epoch 15/500 | Train Loss: 5107.836 | Test Loss: 5162.538 | Test Loss [MAPE]: 429222.511 --time-- 1.5014822483062744\n",
      "Epoch 16/500 | Train Loss: 5108.520 | Test Loss: 5165.231 | Test Loss [MAPE]: 497585.994 --time-- 1.5087299346923828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:01:43,394] Trial 2 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5109.379 | Test Loss: 5163.712 | Test Loss [MAPE]: 470338.901 --time-- 1.506584644317627\n",
      "Epoch 1/500 | Train Loss: 275369.645 | Test Loss: 5162.173 | Test Loss [MAPE]: 436486.678 --time-- 1.9389111995697021\n",
      "Epoch 2/500 | Train Loss: 5106.547 | Test Loss: 5161.780 | Test Loss [MAPE]: 425371.512 --time-- 1.985368251800537\n",
      "Epoch 3/500 | Train Loss: 5106.506 | Test Loss: 5162.022 | Test Loss [MAPE]: 418550.312 --time-- 1.9803102016448975\n",
      "Epoch 4/500 | Train Loss: 5106.567 | Test Loss: 5162.064 | Test Loss [MAPE]: 419274.229 --time-- 1.989126443862915\n",
      "Epoch 5/500 | Train Loss: 5106.755 | Test Loss: 5162.000 | Test Loss [MAPE]: 422428.240 --time-- 1.980592966079712\n",
      "Epoch 6/500 | Train Loss: 5106.646 | Test Loss: 5162.699 | Test Loss [MAPE]: 418582.036 --time-- 1.9850611686706543\n",
      "Epoch 7/500 | Train Loss: 5106.762 | Test Loss: 5161.898 | Test Loss [MAPE]: 435232.807 --time-- 1.9814226627349854\n",
      "Epoch 8/500 | Train Loss: 5106.782 | Test Loss: 5162.152 | Test Loss [MAPE]: 428140.984 --time-- 1.9849119186401367\n",
      "Epoch 9/500 | Train Loss: 5106.749 | Test Loss: 5162.397 | Test Loss [MAPE]: 421930.596 --time-- 1.9826838970184326\n",
      "Epoch 10/500 | Train Loss: 5106.730 | Test Loss: 5161.990 | Test Loss [MAPE]: 425340.850 --time-- 1.9803342819213867\n",
      "Epoch 11/500 | Train Loss: 5106.690 | Test Loss: 5162.138 | Test Loss [MAPE]: 424645.067 --time-- 1.9811615943908691\n",
      "Epoch 12/500 | Train Loss: 5106.920 | Test Loss: 5162.059 | Test Loss [MAPE]: 432349.106 --time-- 1.982865571975708\n",
      "Epoch 13/500 | Train Loss: 5106.959 | Test Loss: 5162.428 | Test Loss [MAPE]: 455088.257 --time-- 1.9812159538269043\n",
      "Epoch 14/500 | Train Loss: 5107.047 | Test Loss: 5162.218 | Test Loss [MAPE]: 434283.923 --time-- 1.9802744388580322\n",
      "Epoch 15/500 | Train Loss: 5106.847 | Test Loss: 5162.695 | Test Loss [MAPE]: 459121.043 --time-- 1.9841060638427734\n",
      "Epoch 16/500 | Train Loss: 5107.574 | Test Loss: 5162.327 | Test Loss [MAPE]: 438229.715 --time-- 1.9822909832000732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:02:17,887] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.840 | Test Loss: 5162.313 | Test Loss [MAPE]: 448225.596 --time-- 1.9833440780639648\n",
      "Epoch 1/500 | Train Loss: 28445185.343 | Test Loss: 5174.499 | Test Loss [MAPE]: 549446.168 --time-- 11.709767818450928\n",
      "Epoch 2/500 | Train Loss: 5109.019 | Test Loss: 5161.930 | Test Loss [MAPE]: 429440.365 --time-- 12.08596920967102\n",
      "Epoch 3/500 | Train Loss: 5107.157 | Test Loss: 5162.933 | Test Loss [MAPE]: 459776.523 --time-- 12.023315668106079\n",
      "Epoch 4/500 | Train Loss: 5107.191 | Test Loss: 5162.595 | Test Loss [MAPE]: 445012.002 --time-- 12.026752471923828\n",
      "Epoch 5/500 | Train Loss: 5106.961 | Test Loss: 5162.328 | Test Loss [MAPE]: 426446.606 --time-- 12.024506092071533\n",
      "Epoch 6/500 | Train Loss: 5108.158 | Test Loss: 5165.263 | Test Loss [MAPE]: 494969.028 --time-- 12.026630640029907\n",
      "Epoch 7/500 | Train Loss: 5108.637 | Test Loss: 5163.240 | Test Loss [MAPE]: 466380.872 --time-- 12.024399042129517\n",
      "Epoch 8/500 | Train Loss: 5107.252 | Test Loss: 5162.357 | Test Loss [MAPE]: 421462.150 --time-- 12.032756567001343\n",
      "Epoch 9/500 | Train Loss: 5106.948 | Test Loss: 5162.756 | Test Loss [MAPE]: 435978.743 --time-- 12.101020336151123\n",
      "Epoch 10/500 | Train Loss: 5106.887 | Test Loss: 5162.087 | Test Loss [MAPE]: 429318.116 --time-- 12.115882396697998\n",
      "Epoch 11/500 | Train Loss: 5106.869 | Test Loss: 5162.292 | Test Loss [MAPE]: 443280.078 --time-- 12.101526498794556\n",
      "Epoch 12/500 | Train Loss: 5106.856 | Test Loss: 5161.924 | Test Loss [MAPE]: 424467.911 --time-- 12.104672908782959\n",
      "Epoch 13/500 | Train Loss: 5107.358 | Test Loss: 5163.479 | Test Loss [MAPE]: 451644.231 --time-- 12.103479385375977\n",
      "Epoch 14/500 | Train Loss: 5107.744 | Test Loss: 5162.683 | Test Loss [MAPE]: 450573.657 --time-- 12.102421283721924\n",
      "Epoch 15/500 | Train Loss: 5107.138 | Test Loss: 5162.548 | Test Loss [MAPE]: 449592.253 --time-- 12.099238395690918\n",
      "Epoch 16/500 | Train Loss: 5107.111 | Test Loss: 5162.232 | Test Loss [MAPE]: 425000.811 --time-- 12.101284265518188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:05:44,639] Trial 4 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5107.137 | Test Loss: 5162.288 | Test Loss [MAPE]: 435022.875 --time-- 12.102174043655396\n",
      "Epoch 1/500 | Train Loss: 3376639.795 | Test Loss: 4454.423 | Test Loss [MAPE]: 3666548.263 --time-- 1.8297641277313232\n",
      "Epoch 2/500 | Train Loss: 17817.568 | Test Loss: 5162.806 | Test Loss [MAPE]: 442763.257 --time-- 1.7744207382202148\n",
      "Epoch 3/500 | Train Loss: 5107.476 | Test Loss: 5162.230 | Test Loss [MAPE]: 431250.340 --time-- 1.7735927104949951\n",
      "Epoch 4/500 | Train Loss: 5106.875 | Test Loss: 5162.788 | Test Loss [MAPE]: 432850.788 --time-- 1.7827825546264648\n",
      "Epoch 5/500 | Train Loss: 5107.167 | Test Loss: 5161.901 | Test Loss [MAPE]: 428229.698 --time-- 1.7795138359069824\n",
      "Epoch 6/500 | Train Loss: 5106.880 | Test Loss: 5162.165 | Test Loss [MAPE]: 445018.002 --time-- 1.7760851383209229\n",
      "Epoch 7/500 | Train Loss: 5107.084 | Test Loss: 5162.054 | Test Loss [MAPE]: 426767.560 --time-- 1.7744872570037842\n",
      "Epoch 8/500 | Train Loss: 5106.893 | Test Loss: 5162.483 | Test Loss [MAPE]: 423596.876 --time-- 1.7786459922790527\n",
      "Epoch 9/500 | Train Loss: 5107.412 | Test Loss: 5162.667 | Test Loss [MAPE]: 448809.807 --time-- 1.7761898040771484\n",
      "Epoch 10/500 | Train Loss: 5107.327 | Test Loss: 5162.813 | Test Loss [MAPE]: 432171.464 --time-- 1.7792038917541504\n",
      "Epoch 11/500 | Train Loss: 5107.522 | Test Loss: 5162.779 | Test Loss [MAPE]: 431939.626 --time-- 1.7764813899993896\n",
      "Epoch 12/500 | Train Loss: 5107.244 | Test Loss: 5162.541 | Test Loss [MAPE]: 425149.701 --time-- 1.7835872173309326\n",
      "Epoch 13/500 | Train Loss: 5107.683 | Test Loss: 5163.364 | Test Loss [MAPE]: 456506.652 --time-- 1.7769060134887695\n",
      "Epoch 14/500 | Train Loss: 5107.823 | Test Loss: 5162.603 | Test Loss [MAPE]: 425173.000 --time-- 1.782560110092163\n",
      "Epoch 15/500 | Train Loss: 5108.063 | Test Loss: 5163.776 | Test Loss [MAPE]: 448418.808 --time-- 1.777618169784546\n",
      "Epoch 16/500 | Train Loss: 5107.631 | Test Loss: 5162.419 | Test Loss [MAPE]: 427071.904 --time-- 1.7769794464111328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:06:15,508] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5107.687 | Test Loss: 5164.721 | Test Loss [MAPE]: 462865.392 --time-- 1.854783296585083\n",
      "Epoch 1/500 | Train Loss: 6333.758 | Test Loss: 4325.998 | Test Loss [MAPE]: 3762746.421 --time-- 3.8394930362701416\n",
      "Epoch 2/500 | Train Loss: 4227.334 | Test Loss: 4100.021 | Test Loss [MAPE]: 3322463.114 --time-- 3.8141608238220215\n",
      "Epoch 3/500 | Train Loss: 4005.870 | Test Loss: 3878.391 | Test Loss [MAPE]: 3442571.885 --time-- 3.8153302669525146\n",
      "Epoch 4/500 | Train Loss: 3719.293 | Test Loss: 3592.888 | Test Loss [MAPE]: 5332615.757 --time-- 3.815124750137329\n",
      "Epoch 5/500 | Train Loss: 3337.098 | Test Loss: 3176.024 | Test Loss [MAPE]: 4329386.657 --time-- 3.8140413761138916\n",
      "Epoch 6/500 | Train Loss: 2991.297 | Test Loss: 2801.013 | Test Loss [MAPE]: 4615267.206 --time-- 3.8138582706451416\n",
      "Epoch 7/500 | Train Loss: 2779.584 | Test Loss: 2685.731 | Test Loss [MAPE]: 4438669.533 --time-- 3.8199703693389893\n",
      "Epoch 8/500 | Train Loss: 3826.712 | Test Loss: 4337.159 | Test Loss [MAPE]: 3135886.322 --time-- 3.806199073791504\n",
      "Epoch 9/500 | Train Loss: 4345.314 | Test Loss: 3967.369 | Test Loss [MAPE]: 3794297.205 --time-- 3.8175973892211914\n",
      "Epoch 10/500 | Train Loss: 3586.736 | Test Loss: 3163.473 | Test Loss [MAPE]: 5824155.097 --time-- 3.821133852005005\n",
      "Epoch 11/500 | Train Loss: 2829.615 | Test Loss: 2530.645 | Test Loss [MAPE]: 3860409.978 --time-- 3.8242223262786865\n",
      "Epoch 12/500 | Train Loss: 2439.739 | Test Loss: 2432.372 | Test Loss [MAPE]: 3760581.953 --time-- 3.8182711601257324\n",
      "Epoch 13/500 | Train Loss: 17197.378 | Test Loss: 4652.863 | Test Loss [MAPE]: 2094242.378 --time-- 3.811626434326172\n",
      "Epoch 14/500 | Train Loss: 3325.088 | Test Loss: 2504.349 | Test Loss [MAPE]: 4335807.299 --time-- 3.8120641708374023\n",
      "Epoch 15/500 | Train Loss: 2423.759 | Test Loss: 2306.062 | Test Loss [MAPE]: 4241751.393 --time-- 3.812016487121582\n",
      "Epoch 16/500 | Train Loss: 2366.106 | Test Loss: 2837.447 | Test Loss [MAPE]: 4220754.051 --time-- 3.811779737472534\n",
      "Epoch 17/500 | Train Loss: 2436.741 | Test Loss: 2206.462 | Test Loss [MAPE]: 3491656.800 --time-- 3.8119568824768066\n",
      "Epoch 18/500 | Train Loss: 2162.455 | Test Loss: 2063.388 | Test Loss [MAPE]: 3345950.778 --time-- 3.8192813396453857\n",
      "Epoch 19/500 | Train Loss: 2043.228 | Test Loss: 2048.948 | Test Loss [MAPE]: 3202647.633 --time-- 3.813857078552246\n",
      "Epoch 20/500 | Train Loss: 2004.163 | Test Loss: 1969.904 | Test Loss [MAPE]: 2982890.495 --time-- 3.8133342266082764\n",
      "Epoch 21/500 | Train Loss: 1940.225 | Test Loss: 1961.885 | Test Loss [MAPE]: 3147705.352 --time-- 3.8168704509735107\n",
      "Epoch 22/500 | Train Loss: 1929.837 | Test Loss: 2001.757 | Test Loss [MAPE]: 2844881.186 --time-- 3.8120760917663574\n",
      "Epoch 23/500 | Train Loss: 1914.768 | Test Loss: 1962.122 | Test Loss [MAPE]: 2579612.756 --time-- 3.8172202110290527\n",
      "Epoch 24/500 | Train Loss: 1889.237 | Test Loss: 1918.598 | Test Loss [MAPE]: 3225677.479 --time-- 3.8216381072998047\n",
      "Epoch 25/500 | Train Loss: 1834.756 | Test Loss: 1772.461 | Test Loss [MAPE]: 2911835.452 --time-- 3.812530279159546\n",
      "Epoch 26/500 | Train Loss: 1814.412 | Test Loss: 1764.271 | Test Loss [MAPE]: 2667707.173 --time-- 3.8228626251220703\n",
      "Epoch 27/500 | Train Loss: 1832.393 | Test Loss: 1828.104 | Test Loss [MAPE]: 2641413.245 --time-- 3.8170037269592285\n",
      "Epoch 28/500 | Train Loss: 2000.175 | Test Loss: 1835.740 | Test Loss [MAPE]: 2444185.177 --time-- 3.811755657196045\n",
      "Epoch 29/500 | Train Loss: 1796.221 | Test Loss: 1847.106 | Test Loss [MAPE]: 2971497.063 --time-- 3.815044641494751\n",
      "Epoch 30/500 | Train Loss: 1761.543 | Test Loss: 1776.815 | Test Loss [MAPE]: 2614191.605 --time-- 3.8126628398895264\n",
      "Epoch 31/500 | Train Loss: 1804.871 | Test Loss: 1826.689 | Test Loss [MAPE]: 2335885.504 --time-- 3.813880205154419\n",
      "Epoch 32/500 | Train Loss: 1778.845 | Test Loss: 1808.351 | Test Loss [MAPE]: 2299852.780 --time-- 3.815546751022339\n",
      "Epoch 33/500 | Train Loss: 1750.391 | Test Loss: 1825.418 | Test Loss [MAPE]: 2697162.268 --time-- 3.812586545944214\n",
      "Epoch 34/500 | Train Loss: 1737.684 | Test Loss: 1814.252 | Test Loss [MAPE]: 2757797.302 --time-- 3.8161780834198\n",
      "Epoch 35/500 | Train Loss: 1690.131 | Test Loss: 1709.430 | Test Loss [MAPE]: 2621652.372 --time-- 3.8114559650421143\n",
      "Epoch 36/500 | Train Loss: 1699.618 | Test Loss: 1727.275 | Test Loss [MAPE]: 2353695.138 --time-- 3.812851905822754\n",
      "Epoch 37/500 | Train Loss: 1711.879 | Test Loss: 1724.827 | Test Loss [MAPE]: 2584271.743 --time-- 3.8117756843566895\n",
      "Epoch 38/500 | Train Loss: 1695.740 | Test Loss: 1750.591 | Test Loss [MAPE]: 2345318.356 --time-- 3.81878662109375\n",
      "Epoch 39/500 | Train Loss: 1665.126 | Test Loss: 1693.266 | Test Loss [MAPE]: 2473072.633 --time-- 3.8125786781311035\n",
      "Epoch 40/500 | Train Loss: 1649.911 | Test Loss: 1631.212 | Test Loss [MAPE]: 2210826.988 --time-- 3.81445574760437\n",
      "Epoch 41/500 | Train Loss: 1676.741 | Test Loss: 1672.785 | Test Loss [MAPE]: 2435307.636 --time-- 3.8147523403167725\n",
      "Epoch 42/500 | Train Loss: 1635.505 | Test Loss: 1640.946 | Test Loss [MAPE]: 2336928.512 --time-- 3.824434995651245\n",
      "Epoch 43/500 | Train Loss: 1648.466 | Test Loss: 1625.814 | Test Loss [MAPE]: 2489290.499 --time-- 3.815486431121826\n",
      "Epoch 44/500 | Train Loss: 1607.322 | Test Loss: 1682.375 | Test Loss [MAPE]: 2361419.528 --time-- 3.814589738845825\n",
      "Epoch 45/500 | Train Loss: 1620.087 | Test Loss: 1616.097 | Test Loss [MAPE]: 2377642.084 --time-- 3.8114407062530518\n",
      "Epoch 46/500 | Train Loss: 1575.562 | Test Loss: 1677.727 | Test Loss [MAPE]: 2417711.100 --time-- 3.8125288486480713\n",
      "Epoch 47/500 | Train Loss: 1593.449 | Test Loss: 1605.997 | Test Loss [MAPE]: 2331722.189 --time-- 3.81447696685791\n",
      "Epoch 48/500 | Train Loss: 1595.216 | Test Loss: 1587.257 | Test Loss [MAPE]: 1977001.347 --time-- 3.808054208755493\n",
      "Epoch 49/500 | Train Loss: 1594.786 | Test Loss: 1579.253 | Test Loss [MAPE]: 2136748.726 --time-- 3.8130407333374023\n",
      "Epoch 50/500 | Train Loss: 1564.801 | Test Loss: 1580.209 | Test Loss [MAPE]: 1744982.795 --time-- 3.8136415481567383\n",
      "Epoch 51/500 | Train Loss: 1561.501 | Test Loss: 1552.113 | Test Loss [MAPE]: 1903286.901 --time-- 3.8099417686462402\n",
      "Epoch 52/500 | Train Loss: 1599.438 | Test Loss: 1755.236 | Test Loss [MAPE]: 2166988.850 --time-- 3.8081042766571045\n",
      "Epoch 53/500 | Train Loss: 1640.580 | Test Loss: 1662.606 | Test Loss [MAPE]: 2424489.161 --time-- 3.8139986991882324\n",
      "Epoch 54/500 | Train Loss: 1572.919 | Test Loss: 1571.488 | Test Loss [MAPE]: 1971297.405 --time-- 3.8194377422332764\n",
      "Epoch 55/500 | Train Loss: 1539.881 | Test Loss: 1537.572 | Test Loss [MAPE]: 1712718.990 --time-- 3.813964366912842\n",
      "Epoch 56/500 | Train Loss: 1525.605 | Test Loss: 1568.692 | Test Loss [MAPE]: 1935212.049 --time-- 3.81567120552063\n",
      "Epoch 57/500 | Train Loss: 1530.130 | Test Loss: 1579.807 | Test Loss [MAPE]: 1906126.228 --time-- 3.816434860229492\n",
      "Epoch 58/500 | Train Loss: 1546.312 | Test Loss: 1566.704 | Test Loss [MAPE]: 2470212.418 --time-- 3.8161399364471436\n",
      "Epoch 59/500 | Train Loss: 1542.713 | Test Loss: 1688.798 | Test Loss [MAPE]: 2048327.827 --time-- 3.8079142570495605\n",
      "Epoch 60/500 | Train Loss: 1570.308 | Test Loss: 1594.043 | Test Loss [MAPE]: 2218594.317 --time-- 3.8109304904937744\n",
      "Epoch 61/500 | Train Loss: 1551.184 | Test Loss: 1569.307 | Test Loss [MAPE]: 1827748.015 --time-- 3.8114476203918457\n",
      "Epoch 62/500 | Train Loss: 1560.382 | Test Loss: 1524.110 | Test Loss [MAPE]: 2076801.647 --time-- 3.8232035636901855\n",
      "Epoch 63/500 | Train Loss: 1530.204 | Test Loss: 1564.424 | Test Loss [MAPE]: 1821703.746 --time-- 3.8123581409454346\n",
      "Epoch 64/500 | Train Loss: 1513.945 | Test Loss: 1539.216 | Test Loss [MAPE]: 1855436.839 --time-- 3.8146426677703857\n",
      "Epoch 65/500 | Train Loss: 1536.269 | Test Loss: 1536.227 | Test Loss [MAPE]: 2007407.913 --time-- 3.812506675720215\n",
      "Epoch 66/500 | Train Loss: 1538.914 | Test Loss: 1611.906 | Test Loss [MAPE]: 2079301.663 --time-- 3.808155059814453\n",
      "Epoch 67/500 | Train Loss: 1545.558 | Test Loss: 1514.222 | Test Loss [MAPE]: 1884603.999 --time-- 3.81264066696167\n",
      "Epoch 68/500 | Train Loss: 1501.896 | Test Loss: 1528.932 | Test Loss [MAPE]: 1547899.367 --time-- 3.815441608428955\n",
      "Epoch 69/500 | Train Loss: 1587.117 | Test Loss: 1566.573 | Test Loss [MAPE]: 1827922.111 --time-- 3.814943313598633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500 | Train Loss: 1672.989 | Test Loss: 1577.317 | Test Loss [MAPE]: 2001237.847 --time-- 3.80615234375\n",
      "Epoch 71/500 | Train Loss: 1564.149 | Test Loss: 1528.889 | Test Loss [MAPE]: 1939449.222 --time-- 3.811933994293213\n",
      "Epoch 72/500 | Train Loss: 1536.670 | Test Loss: 1525.639 | Test Loss [MAPE]: 2292352.420 --time-- 3.815683603286743\n",
      "Epoch 73/500 | Train Loss: 1512.485 | Test Loss: 1563.296 | Test Loss [MAPE]: 2045318.227 --time-- 3.816364288330078\n",
      "Epoch 74/500 | Train Loss: 1526.618 | Test Loss: 1542.969 | Test Loss [MAPE]: 2025259.068 --time-- 3.813328742980957\n",
      "Epoch 75/500 | Train Loss: 1515.277 | Test Loss: 1507.590 | Test Loss [MAPE]: 2076097.110 --time-- 3.8109993934631348\n",
      "Epoch 76/500 | Train Loss: 1532.648 | Test Loss: 1515.273 | Test Loss [MAPE]: 2032993.513 --time-- 3.8188023567199707\n",
      "Epoch 77/500 | Train Loss: 1530.971 | Test Loss: 1548.415 | Test Loss [MAPE]: 1996912.530 --time-- 3.817645311355591\n",
      "Epoch 78/500 | Train Loss: 1509.423 | Test Loss: 1527.240 | Test Loss [MAPE]: 2001791.288 --time-- 3.823070526123047\n",
      "Epoch 79/500 | Train Loss: 1547.294 | Test Loss: 1643.777 | Test Loss [MAPE]: 2575705.069 --time-- 3.8885326385498047\n",
      "Epoch 80/500 | Train Loss: 1530.957 | Test Loss: 1543.190 | Test Loss [MAPE]: 1842685.705 --time-- 3.810009002685547\n",
      "Epoch 81/500 | Train Loss: 1499.134 | Test Loss: 1520.503 | Test Loss [MAPE]: 1772950.206 --time-- 3.81494402885437\n",
      "Epoch 82/500 | Train Loss: 1526.118 | Test Loss: 1520.996 | Test Loss [MAPE]: 1827364.042 --time-- 3.8131823539733887\n",
      "Epoch 83/500 | Train Loss: 1525.213 | Test Loss: 1586.138 | Test Loss [MAPE]: 1824457.499 --time-- 3.8114988803863525\n",
      "Epoch 84/500 | Train Loss: 1500.101 | Test Loss: 1540.739 | Test Loss [MAPE]: 1973303.354 --time-- 3.8229191303253174\n",
      "Epoch 85/500 | Train Loss: 1515.547 | Test Loss: 1518.186 | Test Loss [MAPE]: 1807462.663 --time-- 3.8124217987060547\n",
      "Epoch 86/500 | Train Loss: 1488.621 | Test Loss: 1506.377 | Test Loss [MAPE]: 1785780.603 --time-- 3.8137519359588623\n",
      "Epoch 87/500 | Train Loss: 1472.045 | Test Loss: 1529.047 | Test Loss [MAPE]: 2301614.196 --time-- 3.8140676021575928\n",
      "Epoch 88/500 | Train Loss: 1488.045 | Test Loss: 1521.806 | Test Loss [MAPE]: 1782495.311 --time-- 3.81166672706604\n",
      "Epoch 89/500 | Train Loss: 1664.528 | Test Loss: 1632.955 | Test Loss [MAPE]: 2419293.577 --time-- 3.8067266941070557\n",
      "Epoch 90/500 | Train Loss: 2599.995 | Test Loss: 2531.240 | Test Loss [MAPE]: 4446679.176 --time-- 3.8047173023223877\n",
      "Epoch 91/500 | Train Loss: 1891.244 | Test Loss: 1557.009 | Test Loss [MAPE]: 2031349.602 --time-- 3.813204288482666\n",
      "Epoch 92/500 | Train Loss: 1604.355 | Test Loss: 1765.796 | Test Loss [MAPE]: 2022892.775 --time-- 3.8351848125457764\n",
      "Epoch 93/500 | Train Loss: 1564.959 | Test Loss: 1500.667 | Test Loss [MAPE]: 2064459.568 --time-- 3.830744504928589\n",
      "Epoch 94/500 | Train Loss: 1498.388 | Test Loss: 1533.306 | Test Loss [MAPE]: 2121915.702 --time-- 3.8115532398223877\n",
      "Epoch 95/500 | Train Loss: 1602.119 | Test Loss: 1562.281 | Test Loss [MAPE]: 1777937.882 --time-- 3.811058521270752\n",
      "Epoch 96/500 | Train Loss: 1510.086 | Test Loss: 1536.466 | Test Loss [MAPE]: 1782410.637 --time-- 3.813887119293213\n",
      "Epoch 97/500 | Train Loss: 1903.701 | Test Loss: 2068.734 | Test Loss [MAPE]: 3272062.454 --time-- 3.8095667362213135\n",
      "Epoch 98/500 | Train Loss: 1637.181 | Test Loss: 1668.767 | Test Loss [MAPE]: 1804147.874 --time-- 3.812653064727783\n",
      "Epoch 99/500 | Train Loss: 1789.580 | Test Loss: 1567.222 | Test Loss [MAPE]: 2242982.243 --time-- 3.8080990314483643\n",
      "Epoch 100/500 | Train Loss: 1492.745 | Test Loss: 1538.502 | Test Loss [MAPE]: 2232020.417 --time-- 3.818730354309082\n",
      "Epoch 101/500 | Train Loss: 1532.856 | Test Loss: 1537.522 | Test Loss [MAPE]: 2378275.406 --time-- 3.8171558380126953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:12:46,565] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500 | Train Loss: 1524.574 | Test Loss: 1556.255 | Test Loss [MAPE]: 2125363.040 --time-- 3.819298505783081\n",
      "Epoch 1/500 | Train Loss: 232907.250 | Test Loss: 5175.352 | Test Loss [MAPE]: 625674.494 --time-- 0.9818665981292725\n",
      "Epoch 2/500 | Train Loss: 5110.281 | Test Loss: 5162.078 | Test Loss [MAPE]: 427628.086 --time-- 0.9789447784423828\n",
      "Epoch 3/500 | Train Loss: 5106.504 | Test Loss: 5161.801 | Test Loss [MAPE]: 422864.826 --time-- 0.9842042922973633\n",
      "Epoch 4/500 | Train Loss: 5106.452 | Test Loss: 5161.751 | Test Loss [MAPE]: 421149.591 --time-- 0.9790139198303223\n",
      "Epoch 5/500 | Train Loss: 5106.471 | Test Loss: 5161.769 | Test Loss [MAPE]: 425859.134 --time-- 0.9813165664672852\n",
      "Epoch 6/500 | Train Loss: 5106.467 | Test Loss: 5161.945 | Test Loss [MAPE]: 434939.996 --time-- 0.9804620742797852\n",
      "Epoch 7/500 | Train Loss: 5106.536 | Test Loss: 5161.809 | Test Loss [MAPE]: 425782.818 --time-- 1.0211491584777832\n",
      "Epoch 8/500 | Train Loss: 5106.501 | Test Loss: 5161.882 | Test Loss [MAPE]: 421503.770 --time-- 1.0070116519927979\n",
      "Epoch 9/500 | Train Loss: 5106.657 | Test Loss: 5162.214 | Test Loss [MAPE]: 415435.252 --time-- 1.0088064670562744\n",
      "Epoch 10/500 | Train Loss: 5106.718 | Test Loss: 5161.913 | Test Loss [MAPE]: 434773.967 --time-- 1.0230293273925781\n",
      "Epoch 11/500 | Train Loss: 5106.554 | Test Loss: 5161.820 | Test Loss [MAPE]: 425873.228 --time-- 1.0179603099822998\n",
      "Epoch 12/500 | Train Loss: 5106.643 | Test Loss: 5162.066 | Test Loss [MAPE]: 423018.027 --time-- 1.0007176399230957\n",
      "Epoch 13/500 | Train Loss: 5106.581 | Test Loss: 5161.931 | Test Loss [MAPE]: 434293.712 --time-- 1.0115232467651367\n",
      "Epoch 14/500 | Train Loss: 5106.716 | Test Loss: 5162.089 | Test Loss [MAPE]: 422171.483 --time-- 1.0180511474609375\n",
      "Epoch 15/500 | Train Loss: 5106.696 | Test Loss: 5162.023 | Test Loss [MAPE]: 428913.042 --time-- 1.0105633735656738\n",
      "Epoch 16/500 | Train Loss: 5106.837 | Test Loss: 5162.476 | Test Loss [MAPE]: 421909.856 --time-- 1.0151164531707764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:13:04,336] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.930 | Test Loss: 5162.132 | Test Loss [MAPE]: 422132.412 --time-- 1.0236849784851074\n",
      "Epoch 1/500 | Train Loss: inf | Test Loss: 5163.557 | Test Loss [MAPE]: 460643.522 --time-- 3.981487512588501\n",
      "Epoch 2/500 | Train Loss: 5107.531 | Test Loss: 5162.032 | Test Loss [MAPE]: 435707.790 --time-- 3.967440128326416\n",
      "Epoch 3/500 | Train Loss: 5106.703 | Test Loss: 5162.513 | Test Loss [MAPE]: 421562.149 --time-- 3.894951820373535\n",
      "Epoch 4/500 | Train Loss: 5106.769 | Test Loss: 5162.055 | Test Loss [MAPE]: 434847.382 --time-- 3.892218828201294\n",
      "Epoch 5/500 | Train Loss: 5106.991 | Test Loss: 5162.116 | Test Loss [MAPE]: 435152.102 --time-- 3.9007201194763184\n",
      "Epoch 6/500 | Train Loss: 5107.237 | Test Loss: 5163.399 | Test Loss [MAPE]: 468622.744 --time-- 3.895195960998535\n",
      "Epoch 7/500 | Train Loss: 5107.873 | Test Loss: 5165.237 | Test Loss [MAPE]: 511455.796 --time-- 3.891817092895508\n",
      "Epoch 8/500 | Train Loss: 5108.611 | Test Loss: 5164.953 | Test Loss [MAPE]: 499818.559 --time-- 3.8853025436401367\n",
      "Epoch 9/500 | Train Loss: 5108.185 | Test Loss: 5162.777 | Test Loss [MAPE]: 435597.291 --time-- 3.891228437423706\n",
      "Epoch 10/500 | Train Loss: 5108.145 | Test Loss: 5164.773 | Test Loss [MAPE]: 483001.520 --time-- 3.914405107498169\n",
      "Epoch 11/500 | Train Loss: 5108.888 | Test Loss: 5167.007 | Test Loss [MAPE]: 517405.228 --time-- 3.8895349502563477\n",
      "Epoch 12/500 | Train Loss: 5110.067 | Test Loss: 5164.096 | Test Loss [MAPE]: 467516.895 --time-- 3.888312578201294\n",
      "Epoch 13/500 | Train Loss: 5109.485 | Test Loss: 5164.649 | Test Loss [MAPE]: 481429.316 --time-- 3.8880598545074463\n",
      "Epoch 14/500 | Train Loss: 5109.249 | Test Loss: 5163.008 | Test Loss [MAPE]: 432137.828 --time-- 3.8860702514648438\n",
      "Epoch 15/500 | Train Loss: 5109.013 | Test Loss: 5165.122 | Test Loss [MAPE]: 480171.861 --time-- 3.8887734413146973\n",
      "Epoch 16/500 | Train Loss: 5109.048 | Test Loss: 5163.455 | Test Loss [MAPE]: 455705.075 --time-- 3.8866729736328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:14:11,257] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5109.012 | Test Loss: 5163.053 | Test Loss [MAPE]: 441948.144 --time-- 3.886324644088745\n",
      "Epoch 1/500 | Train Loss: 33059.729 | Test Loss: 5163.069 | Test Loss [MAPE]: 456442.177 --time-- 3.061591625213623\n",
      "Epoch 2/500 | Train Loss: 6267.808 | Test Loss: 5161.684 | Test Loss [MAPE]: 422810.758 --time-- 3.0647568702697754\n",
      "Epoch 3/500 | Train Loss: 5106.327 | Test Loss: 5161.671 | Test Loss [MAPE]: 422868.887 --time-- 3.078248977661133\n",
      "Epoch 4/500 | Train Loss: 5106.316 | Test Loss: 5161.680 | Test Loss [MAPE]: 422721.695 --time-- 3.0773887634277344\n",
      "Epoch 5/500 | Train Loss: 5106.315 | Test Loss: 5161.694 | Test Loss [MAPE]: 428247.134 --time-- 3.073265314102173\n",
      "Epoch 6/500 | Train Loss: 5106.327 | Test Loss: 5161.683 | Test Loss [MAPE]: 421944.950 --time-- 3.077805995941162\n",
      "Epoch 7/500 | Train Loss: 5106.381 | Test Loss: 5161.709 | Test Loss [MAPE]: 419983.777 --time-- 3.0781424045562744\n",
      "Epoch 8/500 | Train Loss: 5106.335 | Test Loss: 5161.702 | Test Loss [MAPE]: 425268.229 --time-- 3.080744504928589\n",
      "Epoch 9/500 | Train Loss: 5106.333 | Test Loss: 5161.688 | Test Loss [MAPE]: 423832.938 --time-- 3.077730894088745\n",
      "Epoch 10/500 | Train Loss: 5106.338 | Test Loss: 5161.723 | Test Loss [MAPE]: 427570.063 --time-- 3.073967456817627\n",
      "Epoch 11/500 | Train Loss: 5106.344 | Test Loss: 5161.700 | Test Loss [MAPE]: 422721.873 --time-- 3.072600841522217\n",
      "Epoch 12/500 | Train Loss: 5106.351 | Test Loss: 5161.695 | Test Loss [MAPE]: 425667.147 --time-- 3.0753040313720703\n",
      "Epoch 13/500 | Train Loss: 5106.412 | Test Loss: 5161.709 | Test Loss [MAPE]: 427534.670 --time-- 3.0752968788146973\n",
      "Epoch 14/500 | Train Loss: 5106.353 | Test Loss: 5161.778 | Test Loss [MAPE]: 418377.988 --time-- 3.0754811763763428\n",
      "Epoch 15/500 | Train Loss: 5106.374 | Test Loss: 5161.698 | Test Loss [MAPE]: 424472.021 --time-- 3.0740087032318115\n",
      "Epoch 16/500 | Train Loss: 5106.356 | Test Loss: 5161.710 | Test Loss [MAPE]: 427543.399 --time-- 3.0738422870635986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:15:04,657] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.346 | Test Loss: 5161.728 | Test Loss [MAPE]: 426189.179 --time-- 3.074145555496216\n",
      "Epoch 1/500 | Train Loss: 5109.923 | Test Loss: 5161.675 | Test Loss [MAPE]: 423568.143 --time-- 2.2871482372283936\n",
      "Epoch 2/500 | Train Loss: 5106.385 | Test Loss: 5161.722 | Test Loss [MAPE]: 419479.226 --time-- 2.054328203201294\n",
      "Epoch 3/500 | Train Loss: 5106.346 | Test Loss: 5161.700 | Test Loss [MAPE]: 421135.837 --time-- 2.198204755783081\n",
      "Epoch 4/500 | Train Loss: 5106.366 | Test Loss: 5161.708 | Test Loss [MAPE]: 428668.848 --time-- 2.04917049407959\n",
      "Epoch 5/500 | Train Loss: 5106.354 | Test Loss: 5161.738 | Test Loss [MAPE]: 419733.646 --time-- 2.17437744140625\n",
      "Epoch 6/500 | Train Loss: 5106.343 | Test Loss: 5161.721 | Test Loss [MAPE]: 421742.452 --time-- 2.1667046546936035\n",
      "Epoch 7/500 | Train Loss: 5106.349 | Test Loss: 5161.682 | Test Loss [MAPE]: 424793.302 --time-- 2.1791906356811523\n",
      "Epoch 8/500 | Train Loss: 5106.342 | Test Loss: 5161.700 | Test Loss [MAPE]: 422527.503 --time-- 2.1560065746307373\n",
      "Epoch 9/500 | Train Loss: 5106.328 | Test Loss: 5161.701 | Test Loss [MAPE]: 428277.625 --time-- 2.0638515949249268\n",
      "Epoch 10/500 | Train Loss: 5106.352 | Test Loss: 5161.785 | Test Loss [MAPE]: 434678.059 --time-- 2.182710647583008\n",
      "Epoch 11/500 | Train Loss: 5106.332 | Test Loss: 5161.664 | Test Loss [MAPE]: 424339.779 --time-- 1.7944591045379639\n",
      "Epoch 12/500 | Train Loss: 5106.316 | Test Loss: 5161.659 | Test Loss [MAPE]: 423334.699 --time-- 1.7985568046569824\n",
      "Epoch 13/500 | Train Loss: 5106.317 | Test Loss: 5161.660 | Test Loss [MAPE]: 424922.430 --time-- 1.792724370956421\n",
      "Epoch 14/500 | Train Loss: 5106.321 | Test Loss: 5161.612 | Test Loss [MAPE]: 427867.855 --time-- 1.7881731986999512\n",
      "Epoch 15/500 | Train Loss: 5106.259 | Test Loss: 5161.529 | Test Loss [MAPE]: 425471.044 --time-- 1.8028347492218018\n",
      "Epoch 16/500 | Train Loss: 5106.087 | Test Loss: 5161.275 | Test Loss [MAPE]: 435081.698 --time-- 1.7935271263122559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:15:39,280] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5104.909 | Test Loss: 5157.739 | Test Loss [MAPE]: 422349.866 --time-- 1.7953619956970215\n",
      "Epoch 1/500 | Train Loss: 5249.697 | Test Loss: 5161.953 | Test Loss [MAPE]: 431211.194 --time-- 0.9131231307983398\n",
      "Epoch 2/500 | Train Loss: 5106.609 | Test Loss: 5162.042 | Test Loss [MAPE]: 419611.045 --time-- 0.8363251686096191\n",
      "Epoch 3/500 | Train Loss: 5106.918 | Test Loss: 5162.260 | Test Loss [MAPE]: 422192.918 --time-- 0.8372695446014404\n",
      "Epoch 4/500 | Train Loss: 5106.543 | Test Loss: 5161.882 | Test Loss [MAPE]: 432010.288 --time-- 0.8884572982788086\n",
      "Epoch 5/500 | Train Loss: 5106.600 | Test Loss: 5161.813 | Test Loss [MAPE]: 430300.561 --time-- 0.8860671520233154\n",
      "Epoch 6/500 | Train Loss: 5106.484 | Test Loss: 5161.946 | Test Loss [MAPE]: 416419.739 --time-- 0.8830902576446533\n",
      "Epoch 7/500 | Train Loss: 5106.527 | Test Loss: 5161.821 | Test Loss [MAPE]: 425812.271 --time-- 0.8853471279144287\n",
      "Epoch 8/500 | Train Loss: 5106.437 | Test Loss: 5161.831 | Test Loss [MAPE]: 427206.932 --time-- 0.8836076259613037\n",
      "Epoch 9/500 | Train Loss: 5106.466 | Test Loss: 5161.798 | Test Loss [MAPE]: 422854.593 --time-- 0.8826797008514404\n",
      "Epoch 10/500 | Train Loss: 5106.497 | Test Loss: 5161.893 | Test Loss [MAPE]: 417360.128 --time-- 0.8834033012390137\n",
      "Epoch 11/500 | Train Loss: 5106.619 | Test Loss: 5161.828 | Test Loss [MAPE]: 422282.429 --time-- 0.8834645748138428\n",
      "Epoch 12/500 | Train Loss: 5106.554 | Test Loss: 5162.037 | Test Loss [MAPE]: 418878.419 --time-- 0.8859362602233887\n",
      "Epoch 13/500 | Train Loss: 5106.562 | Test Loss: 5161.909 | Test Loss [MAPE]: 431973.976 --time-- 0.8843111991882324\n",
      "Epoch 14/500 | Train Loss: 5106.504 | Test Loss: 5161.792 | Test Loss [MAPE]: 424286.451 --time-- 0.8825716972351074\n",
      "Epoch 15/500 | Train Loss: 5106.503 | Test Loss: 5161.924 | Test Loss [MAPE]: 422237.974 --time-- 0.8842594623565674\n",
      "Epoch 16/500 | Train Loss: 5106.602 | Test Loss: 5161.945 | Test Loss [MAPE]: 421073.447 --time-- 0.8869030475616455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:15:54,831] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.666 | Test Loss: 5161.963 | Test Loss [MAPE]: 417802.769 --time-- 0.8875105381011963\n",
      "Epoch 1/500 | Train Loss: 14043.196 | Test Loss: 4154.228 | Test Loss [MAPE]: 3194392.255 --time-- 1.2124080657958984\n",
      "Epoch 2/500 | Train Loss: 4057.794 | Test Loss: 4008.743 | Test Loss [MAPE]: 3442065.588 --time-- 1.1737632751464844\n",
      "Epoch 3/500 | Train Loss: 3872.889 | Test Loss: 3755.938 | Test Loss [MAPE]: 4381978.776 --time-- 1.1858553886413574\n",
      "Epoch 4/500 | Train Loss: 3588.144 | Test Loss: 3412.423 | Test Loss [MAPE]: 4887329.111 --time-- 1.1763594150543213\n",
      "Epoch 5/500 | Train Loss: 3292.728 | Test Loss: 3153.179 | Test Loss [MAPE]: 5251082.905 --time-- 1.0399608612060547\n",
      "Epoch 6/500 | Train Loss: 3018.344 | Test Loss: 2943.926 | Test Loss [MAPE]: 4367469.755 --time-- 1.0335955619812012\n",
      "Epoch 7/500 | Train Loss: 3421.880 | Test Loss: 3055.549 | Test Loss [MAPE]: 5343334.785 --time-- 1.0400807857513428\n",
      "Epoch 8/500 | Train Loss: 2867.656 | Test Loss: 2779.941 | Test Loss [MAPE]: 4686652.569 --time-- 1.0351378917694092\n",
      "Epoch 9/500 | Train Loss: 2659.256 | Test Loss: 2565.725 | Test Loss [MAPE]: 4486781.779 --time-- 1.039726734161377\n",
      "Epoch 10/500 | Train Loss: 3968.550 | Test Loss: 3920.340 | Test Loss [MAPE]: 6381518.777 --time-- 1.0429813861846924\n",
      "Epoch 11/500 | Train Loss: 3164.456 | Test Loss: 2728.648 | Test Loss [MAPE]: 5118105.301 --time-- 1.0423963069915771\n",
      "Epoch 12/500 | Train Loss: 2662.201 | Test Loss: 2568.431 | Test Loss [MAPE]: 4523025.258 --time-- 1.04193115234375\n",
      "Epoch 13/500 | Train Loss: 2563.834 | Test Loss: 2489.306 | Test Loss [MAPE]: 4211314.276 --time-- 1.0356214046478271\n",
      "Epoch 14/500 | Train Loss: 3957.133 | Test Loss: 3865.857 | Test Loss [MAPE]: 4084999.076 --time-- 1.0402886867523193\n",
      "Epoch 15/500 | Train Loss: 3809.682 | Test Loss: 3600.181 | Test Loss [MAPE]: 3787474.521 --time-- 1.0373191833496094\n",
      "Epoch 16/500 | Train Loss: 3212.659 | Test Loss: 2867.118 | Test Loss [MAPE]: 4126069.352 --time-- 1.038473129272461\n",
      "Epoch 17/500 | Train Loss: 2683.723 | Test Loss: 2564.495 | Test Loss [MAPE]: 3818239.856 --time-- 1.0460896492004395\n",
      "Epoch 18/500 | Train Loss: 2471.246 | Test Loss: 2501.334 | Test Loss [MAPE]: 3583469.317 --time-- 1.0450501441955566\n",
      "Epoch 19/500 | Train Loss: 2417.544 | Test Loss: 2381.582 | Test Loss [MAPE]: 3767936.178 --time-- 1.0429413318634033\n",
      "Epoch 20/500 | Train Loss: 2348.135 | Test Loss: 2299.739 | Test Loss [MAPE]: 2880909.549 --time-- 1.2233202457427979\n",
      "Epoch 21/500 | Train Loss: 2305.837 | Test Loss: 2367.358 | Test Loss [MAPE]: 3863336.715 --time-- 1.3154680728912354\n",
      "Epoch 22/500 | Train Loss: 2283.606 | Test Loss: 2203.231 | Test Loss [MAPE]: 3206971.993 --time-- 1.2982239723205566\n",
      "Epoch 23/500 | Train Loss: 2249.291 | Test Loss: 2201.037 | Test Loss [MAPE]: 3371506.570 --time-- 1.2991259098052979\n",
      "Epoch 24/500 | Train Loss: 2203.534 | Test Loss: 2208.332 | Test Loss [MAPE]: 3023468.549 --time-- 1.2959785461425781\n",
      "Epoch 25/500 | Train Loss: 2186.164 | Test Loss: 2212.532 | Test Loss [MAPE]: 3126253.652 --time-- 1.2368252277374268\n",
      "Epoch 26/500 | Train Loss: 2199.272 | Test Loss: 2132.580 | Test Loss [MAPE]: 2880487.183 --time-- 1.2400338649749756\n",
      "Epoch 27/500 | Train Loss: 2141.065 | Test Loss: 2194.049 | Test Loss [MAPE]: 3707296.085 --time-- 1.3018863201141357\n",
      "Epoch 28/500 | Train Loss: 2124.456 | Test Loss: 2113.522 | Test Loss [MAPE]: 2904325.489 --time-- 1.2921218872070312\n",
      "Epoch 29/500 | Train Loss: 2128.044 | Test Loss: 2140.984 | Test Loss [MAPE]: 3217975.131 --time-- 1.232889175415039\n",
      "Epoch 30/500 | Train Loss: 2097.446 | Test Loss: 2050.101 | Test Loss [MAPE]: 3187411.429 --time-- 1.2960429191589355\n",
      "Epoch 31/500 | Train Loss: 2068.444 | Test Loss: 2061.932 | Test Loss [MAPE]: 2917612.226 --time-- 1.3091990947723389\n",
      "Epoch 32/500 | Train Loss: 2055.062 | Test Loss: 2110.971 | Test Loss [MAPE]: 3813890.758 --time-- 1.3047432899475098\n",
      "Epoch 33/500 | Train Loss: 2013.985 | Test Loss: 1998.157 | Test Loss [MAPE]: 3216935.371 --time-- 1.3207051753997803\n",
      "Epoch 34/500 | Train Loss: 1995.036 | Test Loss: 1993.749 | Test Loss [MAPE]: 2850100.210 --time-- 1.2936885356903076\n",
      "Epoch 35/500 | Train Loss: 1973.404 | Test Loss: 2013.384 | Test Loss [MAPE]: 2653384.853 --time-- 1.3139283657073975\n",
      "Epoch 36/500 | Train Loss: 2008.462 | Test Loss: 2017.542 | Test Loss [MAPE]: 2413325.095 --time-- 1.3110227584838867\n",
      "Epoch 37/500 | Train Loss: 1992.765 | Test Loss: 2635.038 | Test Loss [MAPE]: 2700073.998 --time-- 1.2889037132263184\n",
      "Epoch 38/500 | Train Loss: 2480.357 | Test Loss: 2026.300 | Test Loss [MAPE]: 2689630.163 --time-- 1.2344515323638916\n",
      "Epoch 39/500 | Train Loss: 3059.628 | Test Loss: 2603.303 | Test Loss [MAPE]: 3554203.064 --time-- 1.3325769901275635\n",
      "Epoch 40/500 | Train Loss: 2090.900 | Test Loss: 2045.103 | Test Loss [MAPE]: 3253883.719 --time-- 1.2237613201141357\n",
      "Epoch 41/500 | Train Loss: 2001.188 | Test Loss: 1987.229 | Test Loss [MAPE]: 2702049.041 --time-- 1.3047590255737305\n",
      "Epoch 42/500 | Train Loss: 1982.294 | Test Loss: 1958.891 | Test Loss [MAPE]: 2757542.212 --time-- 1.3131427764892578\n",
      "Epoch 43/500 | Train Loss: 1980.786 | Test Loss: 1984.984 | Test Loss [MAPE]: 3157670.737 --time-- 1.30704927444458\n",
      "Epoch 44/500 | Train Loss: 1971.819 | Test Loss: 1985.598 | Test Loss [MAPE]: 2633469.371 --time-- 1.3062827587127686\n",
      "Epoch 45/500 | Train Loss: 1947.689 | Test Loss: 1999.306 | Test Loss [MAPE]: 2761538.821 --time-- 1.299175500869751\n",
      "Epoch 46/500 | Train Loss: 2090.746 | Test Loss: 3550.317 | Test Loss [MAPE]: 6176610.179 --time-- 1.3056447505950928\n",
      "Epoch 47/500 | Train Loss: 2845.765 | Test Loss: 2191.740 | Test Loss [MAPE]: 2817740.442 --time-- 1.2972564697265625\n",
      "Epoch 48/500 | Train Loss: 2011.748 | Test Loss: 1934.119 | Test Loss [MAPE]: 2272475.545 --time-- 1.2980222702026367\n",
      "Epoch 49/500 | Train Loss: 1980.021 | Test Loss: 2056.163 | Test Loss [MAPE]: 3007723.292 --time-- 1.3168184757232666\n",
      "Epoch 50/500 | Train Loss: 1946.013 | Test Loss: 1925.509 | Test Loss [MAPE]: 2807234.497 --time-- 1.3158621788024902\n",
      "Epoch 51/500 | Train Loss: 1935.606 | Test Loss: 1964.322 | Test Loss [MAPE]: 2350893.235 --time-- 1.3121519088745117\n",
      "Epoch 52/500 | Train Loss: 1927.622 | Test Loss: 1956.112 | Test Loss [MAPE]: 2395832.566 --time-- 1.3090572357177734\n",
      "Epoch 53/500 | Train Loss: 1917.015 | Test Loss: 1921.760 | Test Loss [MAPE]: 2050987.827 --time-- 1.3139889240264893\n",
      "Epoch 54/500 | Train Loss: 1917.219 | Test Loss: 1919.218 | Test Loss [MAPE]: 2451325.410 --time-- 1.3234906196594238\n",
      "Epoch 55/500 | Train Loss: 1924.012 | Test Loss: 1982.199 | Test Loss [MAPE]: 3067569.212 --time-- 1.3023335933685303\n",
      "Epoch 56/500 | Train Loss: 1965.266 | Test Loss: 1993.091 | Test Loss [MAPE]: 2408108.878 --time-- 1.3146002292633057\n",
      "Epoch 57/500 | Train Loss: 1928.300 | Test Loss: 2012.074 | Test Loss [MAPE]: 3252557.270 --time-- 1.304931402206421\n",
      "Epoch 58/500 | Train Loss: 2848.962 | Test Loss: 2917.154 | Test Loss [MAPE]: 3289657.369 --time-- 1.310537338256836\n",
      "Epoch 59/500 | Train Loss: 2221.367 | Test Loss: 1958.717 | Test Loss [MAPE]: 2750263.294 --time-- 1.213775634765625\n",
      "Epoch 60/500 | Train Loss: 1936.043 | Test Loss: 1935.619 | Test Loss [MAPE]: 2381548.077 --time-- 1.3102874755859375\n",
      "Epoch 61/500 | Train Loss: 1953.681 | Test Loss: 1975.765 | Test Loss [MAPE]: 2798225.389 --time-- 1.3005475997924805\n",
      "Epoch 62/500 | Train Loss: 1902.415 | Test Loss: 1918.208 | Test Loss [MAPE]: 2809931.825 --time-- 1.3094944953918457\n",
      "Epoch 63/500 | Train Loss: 1939.395 | Test Loss: 2013.459 | Test Loss [MAPE]: 2464362.769 --time-- 1.3070564270019531\n",
      "Epoch 64/500 | Train Loss: 1907.207 | Test Loss: 1913.021 | Test Loss [MAPE]: 2253208.358 --time-- 1.3039391040802002\n",
      "Epoch 65/500 | Train Loss: 1929.739 | Test Loss: 2013.139 | Test Loss [MAPE]: 2419231.588 --time-- 1.3079204559326172\n",
      "Epoch 66/500 | Train Loss: 1929.352 | Test Loss: 1941.123 | Test Loss [MAPE]: 2474860.036 --time-- 1.3067457675933838\n",
      "Epoch 67/500 | Train Loss: 1953.993 | Test Loss: 2092.775 | Test Loss [MAPE]: 2539958.393 --time-- 1.3152167797088623\n",
      "Epoch 68/500 | Train Loss: 2062.997 | Test Loss: 2169.231 | Test Loss [MAPE]: 3014686.377 --time-- 1.2336311340332031\n",
      "Epoch 69/500 | Train Loss: 1957.074 | Test Loss: 1957.105 | Test Loss [MAPE]: 2428955.359 --time-- 1.2878046035766602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500 | Train Loss: 1914.193 | Test Loss: 1930.929 | Test Loss [MAPE]: 2318172.364 --time-- 1.3112213611602783\n",
      "Epoch 71/500 | Train Loss: 1908.817 | Test Loss: 1935.347 | Test Loss [MAPE]: 2266229.407 --time-- 1.318798303604126\n",
      "Epoch 72/500 | Train Loss: 2387.162 | Test Loss: 3064.068 | Test Loss [MAPE]: 3312828.671 --time-- 1.3012828826904297\n",
      "Epoch 73/500 | Train Loss: 2365.153 | Test Loss: 2092.034 | Test Loss [MAPE]: 2397478.776 --time-- 1.3005917072296143\n",
      "Epoch 74/500 | Train Loss: 2526.919 | Test Loss: 1951.381 | Test Loss [MAPE]: 2529345.203 --time-- 1.3135669231414795\n",
      "Epoch 75/500 | Train Loss: 2058.307 | Test Loss: 1942.452 | Test Loss [MAPE]: 2774936.570 --time-- 1.3127212524414062\n",
      "Epoch 76/500 | Train Loss: 1943.603 | Test Loss: 1922.064 | Test Loss [MAPE]: 2314625.017 --time-- 1.3305168151855469\n",
      "Epoch 77/500 | Train Loss: 1906.550 | Test Loss: 1956.720 | Test Loss [MAPE]: 2934617.232 --time-- 1.3117103576660156\n",
      "Epoch 78/500 | Train Loss: 1910.992 | Test Loss: 1957.613 | Test Loss [MAPE]: 2612764.344 --time-- 1.3224389553070068\n",
      "Epoch 79/500 | Train Loss: 1909.796 | Test Loss: 1939.691 | Test Loss [MAPE]: 2522028.588 --time-- 1.3242030143737793\n",
      "Epoch 80/500 | Train Loss: 1906.016 | Test Loss: 1914.714 | Test Loss [MAPE]: 2591684.571 --time-- 1.3216357231140137\n",
      "Epoch 81/500 | Train Loss: 1874.241 | Test Loss: 1876.342 | Test Loss [MAPE]: 2330499.178 --time-- 1.3011314868927002\n",
      "Epoch 82/500 | Train Loss: 1860.580 | Test Loss: 1901.856 | Test Loss [MAPE]: 2353421.861 --time-- 1.3201289176940918\n",
      "Epoch 83/500 | Train Loss: 1888.438 | Test Loss: 1857.347 | Test Loss [MAPE]: 2474094.223 --time-- 1.3092396259307861\n",
      "Epoch 84/500 | Train Loss: 1888.189 | Test Loss: 1908.948 | Test Loss [MAPE]: 2201914.127 --time-- 1.3175411224365234\n",
      "Epoch 85/500 | Train Loss: 1872.152 | Test Loss: 1897.265 | Test Loss [MAPE]: 2605942.878 --time-- 1.3156776428222656\n",
      "Epoch 86/500 | Train Loss: 1965.030 | Test Loss: 1845.328 | Test Loss [MAPE]: 2301854.805 --time-- 1.3088574409484863\n",
      "Epoch 87/500 | Train Loss: 1870.671 | Test Loss: 1945.133 | Test Loss [MAPE]: 2497880.815 --time-- 1.2896320819854736\n",
      "Epoch 88/500 | Train Loss: 1862.956 | Test Loss: 1859.857 | Test Loss [MAPE]: 2191028.328 --time-- 1.3099822998046875\n",
      "Epoch 89/500 | Train Loss: 1895.910 | Test Loss: 1969.572 | Test Loss [MAPE]: 2103310.609 --time-- 1.2847521305084229\n",
      "Epoch 90/500 | Train Loss: 1863.026 | Test Loss: 1863.194 | Test Loss [MAPE]: 1940839.161 --time-- 1.329040288925171\n",
      "Epoch 91/500 | Train Loss: 1857.161 | Test Loss: 1837.928 | Test Loss [MAPE]: 2248462.909 --time-- 1.3126375675201416\n",
      "Epoch 92/500 | Train Loss: 1834.584 | Test Loss: 1881.768 | Test Loss [MAPE]: 1870513.743 --time-- 1.3229477405548096\n",
      "Epoch 93/500 | Train Loss: 1853.558 | Test Loss: 1811.736 | Test Loss [MAPE]: 2181714.848 --time-- 1.310007095336914\n",
      "Epoch 94/500 | Train Loss: 1840.016 | Test Loss: 1841.247 | Test Loss [MAPE]: 2031651.562 --time-- 1.2886357307434082\n",
      "Epoch 95/500 | Train Loss: 1844.058 | Test Loss: 1828.743 | Test Loss [MAPE]: 2084819.686 --time-- 1.3076839447021484\n",
      "Epoch 96/500 | Train Loss: 1842.059 | Test Loss: 2023.638 | Test Loss [MAPE]: 2158802.878 --time-- 1.3043665885925293\n",
      "Epoch 97/500 | Train Loss: 1863.588 | Test Loss: 1881.488 | Test Loss [MAPE]: 2212705.045 --time-- 1.3282928466796875\n",
      "Epoch 98/500 | Train Loss: 2110.217 | Test Loss: 2078.986 | Test Loss [MAPE]: 3009150.647 --time-- 1.3224964141845703\n",
      "Epoch 99/500 | Train Loss: 2430.144 | Test Loss: 2006.202 | Test Loss [MAPE]: 2348575.467 --time-- 1.3303840160369873\n",
      "Epoch 100/500 | Train Loss: 1885.185 | Test Loss: 1899.503 | Test Loss [MAPE]: 2137708.797 --time-- 1.3071298599243164\n",
      "Epoch 101/500 | Train Loss: 1837.073 | Test Loss: 1901.609 | Test Loss [MAPE]: 1926195.023 --time-- 1.3184051513671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:18:05,085] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500 | Train Loss: 1856.650 | Test Loss: 1878.986 | Test Loss [MAPE]: 2071118.951 --time-- 1.3009443283081055\n",
      "Epoch 1/500 | Train Loss: 5778.444 | Test Loss: 4172.110 | Test Loss [MAPE]: 1830759.060 --time-- 1.526029109954834\n",
      "Epoch 2/500 | Train Loss: 4115.771 | Test Loss: 4104.674 | Test Loss [MAPE]: 1707465.134 --time-- 1.490701675415039\n",
      "Epoch 3/500 | Train Loss: 4036.374 | Test Loss: 4026.124 | Test Loss [MAPE]: 2703391.769 --time-- 1.4990074634552002\n",
      "Epoch 4/500 | Train Loss: 3976.485 | Test Loss: 3958.329 | Test Loss [MAPE]: 2570593.088 --time-- 1.4959492683410645\n",
      "Epoch 5/500 | Train Loss: 3914.745 | Test Loss: 3926.477 | Test Loss [MAPE]: 2367581.940 --time-- 1.5075538158416748\n",
      "Epoch 6/500 | Train Loss: 3861.542 | Test Loss: 3841.211 | Test Loss [MAPE]: 3205385.719 --time-- 1.5282649993896484\n",
      "Epoch 7/500 | Train Loss: 3806.195 | Test Loss: 3778.075 | Test Loss [MAPE]: 2832394.553 --time-- 1.4899070262908936\n",
      "Epoch 8/500 | Train Loss: 3744.248 | Test Loss: 3724.085 | Test Loss [MAPE]: 3125919.919 --time-- 1.495272159576416\n",
      "Epoch 9/500 | Train Loss: 3683.220 | Test Loss: 3683.665 | Test Loss [MAPE]: 3693897.036 --time-- 1.4918277263641357\n",
      "Epoch 10/500 | Train Loss: 3635.190 | Test Loss: 3587.681 | Test Loss [MAPE]: 2975631.006 --time-- 1.3685765266418457\n",
      "Epoch 11/500 | Train Loss: 3590.700 | Test Loss: 4267.765 | Test Loss [MAPE]: 1647516.494 --time-- 1.4912970066070557\n",
      "Epoch 12/500 | Train Loss: 3714.121 | Test Loss: 3975.193 | Test Loss [MAPE]: 1366540.026 --time-- 1.4779813289642334\n",
      "Epoch 13/500 | Train Loss: 3650.021 | Test Loss: 3462.183 | Test Loss [MAPE]: 2491084.117 --time-- 1.5173964500427246\n",
      "Epoch 14/500 | Train Loss: 3433.355 | Test Loss: 3556.607 | Test Loss [MAPE]: 2183867.666 --time-- 1.4808123111724854\n",
      "Epoch 15/500 | Train Loss: 3865.382 | Test Loss: 4032.362 | Test Loss [MAPE]: 2244396.636 --time-- 1.4309492111206055\n",
      "Epoch 16/500 | Train Loss: 3763.823 | Test Loss: 3414.900 | Test Loss [MAPE]: 2454895.788 --time-- 1.470733404159546\n",
      "Epoch 17/500 | Train Loss: 3379.474 | Test Loss: 3308.715 | Test Loss [MAPE]: 1687680.059 --time-- 1.4823293685913086\n",
      "Epoch 18/500 | Train Loss: 3291.255 | Test Loss: 3284.695 | Test Loss [MAPE]: 1652591.792 --time-- 1.4834787845611572\n",
      "Epoch 19/500 | Train Loss: 3276.649 | Test Loss: 3256.575 | Test Loss [MAPE]: 1921861.133 --time-- 1.5153923034667969\n",
      "Epoch 20/500 | Train Loss: 3264.385 | Test Loss: 3254.849 | Test Loss [MAPE]: 1510272.814 --time-- 1.4846396446228027\n",
      "Epoch 21/500 | Train Loss: 3244.186 | Test Loss: 3261.796 | Test Loss [MAPE]: 1712837.146 --time-- 1.4853694438934326\n",
      "Epoch 22/500 | Train Loss: 3252.214 | Test Loss: 3245.303 | Test Loss [MAPE]: 1820997.704 --time-- 1.4806978702545166\n",
      "Epoch 23/500 | Train Loss: 3258.709 | Test Loss: 3286.928 | Test Loss [MAPE]: 1723371.609 --time-- 1.46907377243042\n",
      "Epoch 24/500 | Train Loss: 3243.173 | Test Loss: 3225.694 | Test Loss [MAPE]: 1538913.796 --time-- 1.4807147979736328\n",
      "Epoch 25/500 | Train Loss: 3233.039 | Test Loss: 3251.068 | Test Loss [MAPE]: 1644138.922 --time-- 1.4829373359680176\n",
      "Epoch 26/500 | Train Loss: 3237.036 | Test Loss: 3245.001 | Test Loss [MAPE]: 1436834.570 --time-- 1.4908418655395508\n",
      "Epoch 27/500 | Train Loss: 3234.735 | Test Loss: 3254.572 | Test Loss [MAPE]: 1570428.583 --time-- 1.5124199390411377\n",
      "Epoch 28/500 | Train Loss: 3244.531 | Test Loss: 3288.434 | Test Loss [MAPE]: 1526536.172 --time-- 1.4903879165649414\n",
      "Epoch 29/500 | Train Loss: 3228.859 | Test Loss: 3272.082 | Test Loss [MAPE]: 1826586.899 --time-- 1.4774935245513916\n",
      "Epoch 30/500 | Train Loss: 3220.344 | Test Loss: 3217.486 | Test Loss [MAPE]: 1448858.056 --time-- 1.4769933223724365\n",
      "Epoch 31/500 | Train Loss: 3245.027 | Test Loss: 3234.262 | Test Loss [MAPE]: 1730506.617 --time-- 1.4827640056610107\n",
      "Epoch 32/500 | Train Loss: 3226.557 | Test Loss: 3215.034 | Test Loss [MAPE]: 1730381.910 --time-- 1.4827532768249512\n",
      "Epoch 33/500 | Train Loss: 3245.797 | Test Loss: 3275.938 | Test Loss [MAPE]: 1732167.790 --time-- 1.4801554679870605\n",
      "Epoch 34/500 | Train Loss: 3424.089 | Test Loss: 3640.573 | Test Loss [MAPE]: 1856851.462 --time-- 1.4613432884216309\n",
      "Epoch 35/500 | Train Loss: 3450.235 | Test Loss: 3379.688 | Test Loss [MAPE]: 1832859.230 --time-- 1.4911010265350342\n",
      "Epoch 36/500 | Train Loss: 3274.777 | Test Loss: 3218.452 | Test Loss [MAPE]: 1695882.922 --time-- 1.4853432178497314\n",
      "Epoch 37/500 | Train Loss: 3221.959 | Test Loss: 3236.923 | Test Loss [MAPE]: 1753590.578 --time-- 1.4962289333343506\n",
      "Epoch 38/500 | Train Loss: 3226.605 | Test Loss: 3220.756 | Test Loss [MAPE]: 1750581.693 --time-- 1.4815917015075684\n",
      "Epoch 39/500 | Train Loss: 3221.028 | Test Loss: 3225.957 | Test Loss [MAPE]: 1599243.829 --time-- 1.482454776763916\n",
      "Epoch 40/500 | Train Loss: 3213.438 | Test Loss: 3231.518 | Test Loss [MAPE]: 1473877.631 --time-- 1.5098414421081543\n",
      "Epoch 41/500 | Train Loss: 3213.102 | Test Loss: 3243.057 | Test Loss [MAPE]: 1430516.422 --time-- 1.4923102855682373\n",
      "Epoch 42/500 | Train Loss: 3217.249 | Test Loss: 3221.457 | Test Loss [MAPE]: 1531694.010 --time-- 1.4725704193115234\n",
      "Epoch 43/500 | Train Loss: 3218.690 | Test Loss: 3242.215 | Test Loss [MAPE]: 1548285.553 --time-- 1.4844563007354736\n",
      "Epoch 44/500 | Train Loss: 3215.386 | Test Loss: 3227.389 | Test Loss [MAPE]: 1700921.720 --time-- 1.4890093803405762\n",
      "Epoch 45/500 | Train Loss: 3264.126 | Test Loss: 3213.677 | Test Loss [MAPE]: 1680620.986 --time-- 1.4772770404815674\n",
      "Epoch 46/500 | Train Loss: 3209.214 | Test Loss: 3245.730 | Test Loss [MAPE]: 1848663.311 --time-- 1.4797675609588623\n",
      "Epoch 47/500 | Train Loss: 3223.331 | Test Loss: 3263.210 | Test Loss [MAPE]: 1877112.350 --time-- 1.4743239879608154\n",
      "Epoch 48/500 | Train Loss: 3218.675 | Test Loss: 3217.326 | Test Loss [MAPE]: 1488628.003 --time-- 1.467825174331665\n",
      "Epoch 49/500 | Train Loss: 3207.904 | Test Loss: 3211.144 | Test Loss [MAPE]: 1551049.904 --time-- 1.4987037181854248\n",
      "Epoch 50/500 | Train Loss: 3210.566 | Test Loss: 3202.491 | Test Loss [MAPE]: 1481598.700 --time-- 1.49637770652771\n",
      "Epoch 51/500 | Train Loss: 3206.694 | Test Loss: 3203.735 | Test Loss [MAPE]: 1656729.042 --time-- 1.4810636043548584\n",
      "Epoch 52/500 | Train Loss: 3202.159 | Test Loss: 3218.132 | Test Loss [MAPE]: 1454315.080 --time-- 1.482654094696045\n",
      "Epoch 53/500 | Train Loss: 3216.108 | Test Loss: 3233.979 | Test Loss [MAPE]: 1844769.955 --time-- 1.5187373161315918\n",
      "Epoch 54/500 | Train Loss: 3211.139 | Test Loss: 3351.667 | Test Loss [MAPE]: 1454273.143 --time-- 1.4868643283843994\n",
      "Epoch 55/500 | Train Loss: 3340.866 | Test Loss: 3288.984 | Test Loss [MAPE]: 1852159.284 --time-- 1.4746530055999756\n",
      "Epoch 56/500 | Train Loss: 3233.568 | Test Loss: 3218.134 | Test Loss [MAPE]: 1679902.719 --time-- 1.493009090423584\n",
      "Epoch 57/500 | Train Loss: 3206.857 | Test Loss: 3203.345 | Test Loss [MAPE]: 1678914.464 --time-- 1.4820411205291748\n",
      "Epoch 58/500 | Train Loss: 3207.028 | Test Loss: 3241.304 | Test Loss [MAPE]: 1729631.872 --time-- 1.4826221466064453\n",
      "Epoch 59/500 | Train Loss: 3203.972 | Test Loss: 3228.265 | Test Loss [MAPE]: 1510451.745 --time-- 1.4624245166778564\n",
      "Epoch 60/500 | Train Loss: 3200.572 | Test Loss: 3298.188 | Test Loss [MAPE]: 1582690.994 --time-- 1.47843337059021\n",
      "Epoch 61/500 | Train Loss: 3202.518 | Test Loss: 3221.358 | Test Loss [MAPE]: 1371749.277 --time-- 1.5014493465423584\n",
      "Epoch 62/500 | Train Loss: 3204.397 | Test Loss: 3197.336 | Test Loss [MAPE]: 1544174.243 --time-- 1.4949262142181396\n",
      "Epoch 63/500 | Train Loss: 3206.714 | Test Loss: 3215.443 | Test Loss [MAPE]: 1715089.999 --time-- 1.4811480045318604\n",
      "Epoch 64/500 | Train Loss: 3206.272 | Test Loss: 3215.208 | Test Loss [MAPE]: 1551342.197 --time-- 1.487706184387207\n",
      "Epoch 65/500 | Train Loss: 3206.320 | Test Loss: 3202.460 | Test Loss [MAPE]: 1666119.975 --time-- 1.4242262840270996\n",
      "Epoch 66/500 | Train Loss: 3203.582 | Test Loss: 3215.792 | Test Loss [MAPE]: 1762260.592 --time-- 1.5075807571411133\n",
      "Epoch 67/500 | Train Loss: 3197.253 | Test Loss: 3210.531 | Test Loss [MAPE]: 1553365.269 --time-- 1.4953205585479736\n",
      "Epoch 68/500 | Train Loss: 3197.184 | Test Loss: 3195.991 | Test Loss [MAPE]: 1489099.924 --time-- 1.4813508987426758\n",
      "Epoch 69/500 | Train Loss: 3215.450 | Test Loss: 3209.908 | Test Loss [MAPE]: 1538256.903 --time-- 1.4945063591003418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500 | Train Loss: 3210.759 | Test Loss: 3292.848 | Test Loss [MAPE]: 1146295.940 --time-- 1.4972717761993408\n",
      "Epoch 71/500 | Train Loss: 3221.974 | Test Loss: 3203.425 | Test Loss [MAPE]: 1704955.964 --time-- 1.4400310516357422\n",
      "Epoch 72/500 | Train Loss: 3202.996 | Test Loss: 3212.595 | Test Loss [MAPE]: 1606006.552 --time-- 1.4819068908691406\n",
      "Epoch 73/500 | Train Loss: 3202.944 | Test Loss: 3206.733 | Test Loss [MAPE]: 1595195.571 --time-- 1.4186692237854004\n",
      "Epoch 74/500 | Train Loss: 3201.083 | Test Loss: 3233.912 | Test Loss [MAPE]: 1522228.313 --time-- 1.4748384952545166\n",
      "Epoch 75/500 | Train Loss: 3250.515 | Test Loss: 3238.808 | Test Loss [MAPE]: 1782600.048 --time-- 1.4962577819824219\n",
      "Epoch 76/500 | Train Loss: 3194.322 | Test Loss: 3193.774 | Test Loss [MAPE]: 1638208.004 --time-- 1.4798986911773682\n",
      "Epoch 77/500 | Train Loss: 3197.636 | Test Loss: 3220.228 | Test Loss [MAPE]: 1470390.051 --time-- 1.4820947647094727\n",
      "Epoch 78/500 | Train Loss: 3232.691 | Test Loss: 3226.589 | Test Loss [MAPE]: 1789796.800 --time-- 1.5075345039367676\n",
      "Epoch 79/500 | Train Loss: 3199.504 | Test Loss: 3220.821 | Test Loss [MAPE]: 1566149.319 --time-- 1.5458505153656006\n",
      "Epoch 80/500 | Train Loss: 3210.683 | Test Loss: 3201.848 | Test Loss [MAPE]: 1571198.159 --time-- 1.5543198585510254\n",
      "Epoch 81/500 | Train Loss: 3196.987 | Test Loss: 3201.573 | Test Loss [MAPE]: 1670363.168 --time-- 1.5549798011779785\n",
      "Epoch 82/500 | Train Loss: 3201.874 | Test Loss: 3213.089 | Test Loss [MAPE]: 1684336.394 --time-- 1.553560495376587\n",
      "Epoch 83/500 | Train Loss: 3199.332 | Test Loss: 3214.402 | Test Loss [MAPE]: 1513512.372 --time-- 1.5438816547393799\n",
      "Epoch 84/500 | Train Loss: 3213.200 | Test Loss: 3273.238 | Test Loss [MAPE]: 1357282.419 --time-- 1.561323881149292\n",
      "Epoch 85/500 | Train Loss: 3215.452 | Test Loss: 3215.301 | Test Loss [MAPE]: 1518924.628 --time-- 1.5680241584777832\n",
      "Epoch 86/500 | Train Loss: 3215.316 | Test Loss: 3225.581 | Test Loss [MAPE]: 1689651.740 --time-- 1.5935544967651367\n",
      "Epoch 87/500 | Train Loss: 3201.999 | Test Loss: 3209.708 | Test Loss [MAPE]: 1471621.549 --time-- 1.549525499343872\n",
      "Epoch 88/500 | Train Loss: 3250.304 | Test Loss: 3214.573 | Test Loss [MAPE]: 1720123.144 --time-- 1.5503063201904297\n",
      "Epoch 89/500 | Train Loss: 3200.620 | Test Loss: 3210.064 | Test Loss [MAPE]: 1557900.525 --time-- 1.5529451370239258\n",
      "Epoch 90/500 | Train Loss: 3200.311 | Test Loss: 3260.158 | Test Loss [MAPE]: 1665619.009 --time-- 1.5455772876739502\n",
      "Epoch 91/500 | Train Loss: 3207.036 | Test Loss: 3190.352 | Test Loss [MAPE]: 1647295.339 --time-- 1.5473182201385498\n",
      "Epoch 92/500 | Train Loss: 3194.907 | Test Loss: 3203.236 | Test Loss [MAPE]: 1582499.321 --time-- 1.5668387413024902\n",
      "Epoch 93/500 | Train Loss: 3207.456 | Test Loss: 3233.341 | Test Loss [MAPE]: 1754249.623 --time-- 1.5764405727386475\n",
      "Epoch 94/500 | Train Loss: 3215.693 | Test Loss: 3210.602 | Test Loss [MAPE]: 1615339.897 --time-- 1.5624690055847168\n",
      "Epoch 95/500 | Train Loss: 3194.527 | Test Loss: 3211.702 | Test Loss [MAPE]: 1674659.458 --time-- 1.5393409729003906\n",
      "Epoch 96/500 | Train Loss: 3196.790 | Test Loss: 3227.681 | Test Loss [MAPE]: 1524787.992 --time-- 1.5678560733795166\n",
      "Epoch 97/500 | Train Loss: 3223.331 | Test Loss: 3231.736 | Test Loss [MAPE]: 1736418.150 --time-- 1.5768756866455078\n",
      "Epoch 98/500 | Train Loss: 3197.363 | Test Loss: 3197.361 | Test Loss [MAPE]: 1633532.221 --time-- 1.5598115921020508\n",
      "Epoch 99/500 | Train Loss: 3199.009 | Test Loss: 3200.081 | Test Loss [MAPE]: 1530666.596 --time-- 1.559438943862915\n",
      "Epoch 100/500 | Train Loss: 3192.411 | Test Loss: 3279.724 | Test Loss [MAPE]: 1936932.710 --time-- 1.546546220779419\n",
      "Epoch 101/500 | Train Loss: 3206.431 | Test Loss: 3229.326 | Test Loss [MAPE]: 1530420.078 --time-- 1.4931559562683105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:20:39,859] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500 | Train Loss: 3209.042 | Test Loss: 3226.173 | Test Loss [MAPE]: 1865215.877 --time-- 1.4683549404144287\n",
      "Epoch 1/500 | Train Loss: 5124.171 | Test Loss: 5161.743 | Test Loss [MAPE]: 424025.490 --time-- 1.2387974262237549\n",
      "Epoch 2/500 | Train Loss: 5106.475 | Test Loss: 5161.834 | Test Loss [MAPE]: 419976.899 --time-- 1.2096493244171143\n",
      "Epoch 3/500 | Train Loss: 5106.521 | Test Loss: 5161.919 | Test Loss [MAPE]: 417223.421 --time-- 1.2054228782653809\n",
      "Epoch 4/500 | Train Loss: 5106.499 | Test Loss: 5161.793 | Test Loss [MAPE]: 426961.037 --time-- 1.2347958087921143\n",
      "Epoch 5/500 | Train Loss: 5106.547 | Test Loss: 5161.900 | Test Loss [MAPE]: 421330.266 --time-- 1.1720004081726074\n",
      "Epoch 6/500 | Train Loss: 5106.583 | Test Loss: 5161.837 | Test Loss [MAPE]: 422910.922 --time-- 1.0024938583374023\n",
      "Epoch 7/500 | Train Loss: 5106.569 | Test Loss: 5161.784 | Test Loss [MAPE]: 424480.071 --time-- 0.8824124336242676\n",
      "Epoch 8/500 | Train Loss: 5106.692 | Test Loss: 5161.977 | Test Loss [MAPE]: 438142.251 --time-- 0.8796834945678711\n",
      "Epoch 9/500 | Train Loss: 5106.556 | Test Loss: 5161.871 | Test Loss [MAPE]: 426311.539 --time-- 0.9016327857971191\n",
      "Epoch 10/500 | Train Loss: 5106.656 | Test Loss: 5161.871 | Test Loss [MAPE]: 418287.758 --time-- 0.902907133102417\n",
      "Epoch 11/500 | Train Loss: 5106.525 | Test Loss: 5162.111 | Test Loss [MAPE]: 419577.586 --time-- 0.8806476593017578\n",
      "Epoch 12/500 | Train Loss: 5106.672 | Test Loss: 5161.939 | Test Loss [MAPE]: 433510.408 --time-- 0.8853309154510498\n",
      "Epoch 13/500 | Train Loss: 5106.680 | Test Loss: 5162.092 | Test Loss [MAPE]: 441524.713 --time-- 0.885066032409668\n",
      "Epoch 14/500 | Train Loss: 5106.615 | Test Loss: 5161.883 | Test Loss [MAPE]: 433376.723 --time-- 0.8825664520263672\n",
      "Epoch 15/500 | Train Loss: 5106.656 | Test Loss: 5161.863 | Test Loss [MAPE]: 432491.277 --time-- 0.9202775955200195\n",
      "Epoch 16/500 | Train Loss: 5106.614 | Test Loss: 5161.949 | Test Loss [MAPE]: 423970.109 --time-- 0.9436683654785156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:20:57,423] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.601 | Test Loss: 5162.129 | Test Loss [MAPE]: 418826.472 --time-- 0.9305050373077393\n",
      "Epoch 1/500 | Train Loss: 5886.775 | Test Loss: 4018.707 | Test Loss [MAPE]: 2288249.511 --time-- 2.1609153747558594\n",
      "Epoch 2/500 | Train Loss: 3920.528 | Test Loss: 3825.361 | Test Loss [MAPE]: 3027363.226 --time-- 2.123634099960327\n",
      "Epoch 3/500 | Train Loss: 3805.975 | Test Loss: 3694.250 | Test Loss [MAPE]: 3315746.369 --time-- 2.130964756011963\n",
      "Epoch 4/500 | Train Loss: 3597.227 | Test Loss: 3560.168 | Test Loss [MAPE]: 4361675.641 --time-- 2.124484062194824\n",
      "Epoch 5/500 | Train Loss: 3428.701 | Test Loss: 3337.357 | Test Loss [MAPE]: 2885500.615 --time-- 2.1324243545532227\n",
      "Epoch 6/500 | Train Loss: 3598.818 | Test Loss: 3281.557 | Test Loss [MAPE]: 2449834.564 --time-- 2.121306896209717\n",
      "Epoch 7/500 | Train Loss: 3610.819 | Test Loss: 3365.835 | Test Loss [MAPE]: 2505680.728 --time-- 2.1253602504730225\n",
      "Epoch 8/500 | Train Loss: 4894.091 | Test Loss: 5162.146 | Test Loss [MAPE]: 431206.967 --time-- 2.1253809928894043\n",
      "Epoch 9/500 | Train Loss: 5107.230 | Test Loss: 5162.798 | Test Loss [MAPE]: 457351.880 --time-- 2.118332862854004\n",
      "Epoch 10/500 | Train Loss: 5107.174 | Test Loss: 5162.199 | Test Loss [MAPE]: 429870.496 --time-- 2.131852149963379\n",
      "Epoch 11/500 | Train Loss: 5107.258 | Test Loss: 5162.410 | Test Loss [MAPE]: 440917.745 --time-- 2.1170122623443604\n",
      "Epoch 12/500 | Train Loss: 5107.575 | Test Loss: 5162.481 | Test Loss [MAPE]: 447823.824 --time-- 2.1322171688079834\n",
      "Epoch 13/500 | Train Loss: 5107.607 | Test Loss: 5163.063 | Test Loss [MAPE]: 451223.324 --time-- 2.1242854595184326\n",
      "Epoch 14/500 | Train Loss: 5107.444 | Test Loss: 5162.706 | Test Loss [MAPE]: 431589.023 --time-- 2.131950616836548\n",
      "Epoch 15/500 | Train Loss: 5107.603 | Test Loss: 5162.701 | Test Loss [MAPE]: 439063.085 --time-- 2.135528326034546\n",
      "Epoch 16/500 | Train Loss: 5107.646 | Test Loss: 5163.437 | Test Loss [MAPE]: 476263.474 --time-- 2.12831449508667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:21:34,271] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5107.614 | Test Loss: 5162.553 | Test Loss [MAPE]: 443943.792 --time-- 2.129887342453003\n",
      "Epoch 1/500 | Train Loss: 5186.197 | Test Loss: 5164.015 | Test Loss [MAPE]: 474550.414 --time-- 0.7895426750183105\n",
      "Epoch 2/500 | Train Loss: 5107.176 | Test Loss: 5161.871 | Test Loss [MAPE]: 427517.613 --time-- 0.7115964889526367\n",
      "Epoch 3/500 | Train Loss: 5106.650 | Test Loss: 5161.970 | Test Loss [MAPE]: 431487.191 --time-- 0.6904771327972412\n",
      "Epoch 4/500 | Train Loss: 5106.722 | Test Loss: 5162.019 | Test Loss [MAPE]: 422817.274 --time-- 0.7117805480957031\n",
      "Epoch 5/500 | Train Loss: 5106.674 | Test Loss: 5162.056 | Test Loss [MAPE]: 422115.793 --time-- 0.7119464874267578\n",
      "Epoch 6/500 | Train Loss: 5106.718 | Test Loss: 5162.153 | Test Loss [MAPE]: 423164.174 --time-- 0.7040786743164062\n",
      "Epoch 7/500 | Train Loss: 5106.646 | Test Loss: 5162.195 | Test Loss [MAPE]: 429482.195 --time-- 0.7213294506072998\n",
      "Epoch 8/500 | Train Loss: 5106.725 | Test Loss: 5162.076 | Test Loss [MAPE]: 432311.183 --time-- 0.7255754470825195\n",
      "Epoch 9/500 | Train Loss: 5106.889 | Test Loss: 5162.449 | Test Loss [MAPE]: 454232.507 --time-- 0.7253589630126953\n",
      "Epoch 10/500 | Train Loss: 5106.784 | Test Loss: 5162.046 | Test Loss [MAPE]: 435824.644 --time-- 0.7282750606536865\n",
      "Epoch 11/500 | Train Loss: 5107.507 | Test Loss: 5162.780 | Test Loss [MAPE]: 443034.101 --time-- 0.7118029594421387\n",
      "Epoch 12/500 | Train Loss: 5107.160 | Test Loss: 5163.514 | Test Loss [MAPE]: 437037.813 --time-- 0.7223620414733887\n",
      "Epoch 13/500 | Train Loss: 5107.821 | Test Loss: 5162.874 | Test Loss [MAPE]: 447015.819 --time-- 0.709705114364624\n",
      "Epoch 14/500 | Train Loss: 5107.314 | Test Loss: 5163.598 | Test Loss [MAPE]: 437350.658 --time-- 0.7221992015838623\n",
      "Epoch 15/500 | Train Loss: 5107.509 | Test Loss: 5162.697 | Test Loss [MAPE]: 424982.839 --time-- 0.7097182273864746\n",
      "Epoch 16/500 | Train Loss: 5107.181 | Test Loss: 5162.294 | Test Loss [MAPE]: 434285.054 --time-- 0.7152769565582275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:21:46,988] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5107.138 | Test Loss: 5162.062 | Test Loss [MAPE]: 440016.025 --time-- 0.6469948291778564\n",
      "Epoch 1/500 | Train Loss: 5357.197 | Test Loss: 5162.058 | Test Loss [MAPE]: 415475.575 --time-- 1.3742327690124512\n",
      "Epoch 2/500 | Train Loss: 5106.503 | Test Loss: 5162.121 | Test Loss [MAPE]: 447859.148 --time-- 1.3165807723999023\n",
      "Epoch 3/500 | Train Loss: 5106.495 | Test Loss: 5161.896 | Test Loss [MAPE]: 422901.413 --time-- 1.3127775192260742\n",
      "Epoch 4/500 | Train Loss: 5106.550 | Test Loss: 5161.896 | Test Loss [MAPE]: 424015.071 --time-- 1.3062684535980225\n",
      "Epoch 5/500 | Train Loss: 5106.600 | Test Loss: 5162.008 | Test Loss [MAPE]: 422932.052 --time-- 1.3239080905914307\n",
      "Epoch 6/500 | Train Loss: 5106.570 | Test Loss: 5161.879 | Test Loss [MAPE]: 423728.679 --time-- 1.309119701385498\n",
      "Epoch 7/500 | Train Loss: 5106.609 | Test Loss: 5161.937 | Test Loss [MAPE]: 424789.290 --time-- 1.3099706172943115\n",
      "Epoch 8/500 | Train Loss: 5106.637 | Test Loss: 5161.926 | Test Loss [MAPE]: 431517.793 --time-- 1.3156671524047852\n",
      "Epoch 9/500 | Train Loss: 5106.722 | Test Loss: 5161.997 | Test Loss [MAPE]: 433513.963 --time-- 1.322328805923462\n",
      "Epoch 10/500 | Train Loss: 5106.638 | Test Loss: 5161.855 | Test Loss [MAPE]: 428567.834 --time-- 1.3226089477539062\n",
      "Epoch 11/500 | Train Loss: 5106.716 | Test Loss: 5162.330 | Test Loss [MAPE]: 418860.814 --time-- 1.3190066814422607\n",
      "Epoch 12/500 | Train Loss: 5106.715 | Test Loss: 5162.383 | Test Loss [MAPE]: 417754.245 --time-- 1.3148913383483887\n",
      "Epoch 13/500 | Train Loss: 5106.682 | Test Loss: 5161.918 | Test Loss [MAPE]: 419154.517 --time-- 1.3158855438232422\n",
      "Epoch 14/500 | Train Loss: 5106.737 | Test Loss: 5162.002 | Test Loss [MAPE]: 426339.230 --time-- 1.3274102210998535\n",
      "Epoch 15/500 | Train Loss: 5106.691 | Test Loss: 5162.001 | Test Loss [MAPE]: 427108.446 --time-- 1.3112926483154297\n",
      "Epoch 16/500 | Train Loss: 5106.628 | Test Loss: 5162.102 | Test Loss [MAPE]: 423235.739 --time-- 1.3154783248901367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:22:10,045] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.633 | Test Loss: 5162.546 | Test Loss [MAPE]: 419393.593 --time-- 1.3203728199005127\n",
      "Epoch 1/500 | Train Loss: 13311.139 | Test Loss: 5162.113 | Test Loss [MAPE]: 433332.079 --time-- 1.2607426643371582\n",
      "Epoch 2/500 | Train Loss: 5107.076 | Test Loss: 5162.297 | Test Loss [MAPE]: 428509.560 --time-- 1.2424652576446533\n",
      "Epoch 3/500 | Train Loss: 5107.099 | Test Loss: 5162.164 | Test Loss [MAPE]: 428767.609 --time-- 1.236551284790039\n",
      "Epoch 4/500 | Train Loss: 5107.345 | Test Loss: 5162.353 | Test Loss [MAPE]: 447101.400 --time-- 1.233379602432251\n",
      "Epoch 5/500 | Train Loss: 5107.432 | Test Loss: 5162.543 | Test Loss [MAPE]: 437337.123 --time-- 1.233482837677002\n",
      "Epoch 6/500 | Train Loss: 5107.229 | Test Loss: 5162.507 | Test Loss [MAPE]: 438721.386 --time-- 1.2418270111083984\n",
      "Epoch 7/500 | Train Loss: 5107.754 | Test Loss: 5163.598 | Test Loss [MAPE]: 470876.261 --time-- 1.266796588897705\n",
      "Epoch 8/500 | Train Loss: 5107.573 | Test Loss: 5163.803 | Test Loss [MAPE]: 467561.504 --time-- 1.253124475479126\n",
      "Epoch 9/500 | Train Loss: 5107.606 | Test Loss: 5162.800 | Test Loss [MAPE]: 461315.694 --time-- 1.2306931018829346\n",
      "Epoch 10/500 | Train Loss: 5107.337 | Test Loss: 5162.449 | Test Loss [MAPE]: 438549.486 --time-- 1.2659687995910645\n",
      "Epoch 11/500 | Train Loss: 5107.162 | Test Loss: 5162.365 | Test Loss [MAPE]: 428257.002 --time-- 1.240492582321167\n",
      "Epoch 12/500 | Train Loss: 5107.688 | Test Loss: 5162.585 | Test Loss [MAPE]: 440798.409 --time-- 1.2433984279632568\n",
      "Epoch 13/500 | Train Loss: 5107.251 | Test Loss: 5162.766 | Test Loss [MAPE]: 451226.907 --time-- 1.237360954284668\n",
      "Epoch 14/500 | Train Loss: 5107.391 | Test Loss: 5163.050 | Test Loss [MAPE]: 467815.772 --time-- 1.2317829132080078\n",
      "Epoch 15/500 | Train Loss: 5107.766 | Test Loss: 5162.603 | Test Loss [MAPE]: 424660.776 --time-- 1.2315342426300049\n",
      "Epoch 16/500 | Train Loss: 5107.385 | Test Loss: 5162.535 | Test Loss [MAPE]: 450609.812 --time-- 1.2393081188201904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:22:31,851] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5107.285 | Test Loss: 5162.580 | Test Loss [MAPE]: 435692.536 --time-- 1.2660815715789795\n",
      "Epoch 1/500 | Train Loss: 5126.225 | Test Loss: 5166.323 | Test Loss [MAPE]: 499656.371 --time-- 1.9199483394622803\n",
      "Epoch 2/500 | Train Loss: 5108.125 | Test Loss: 5161.850 | Test Loss [MAPE]: 437063.104 --time-- 1.8740878105163574\n",
      "Epoch 3/500 | Train Loss: 5104.848 | Test Loss: 5156.822 | Test Loss [MAPE]: 439297.616 --time-- 1.875514030456543\n",
      "Epoch 4/500 | Train Loss: 5084.332 | Test Loss: 5086.348 | Test Loss [MAPE]: 918281.855 --time-- 1.8740286827087402\n",
      "Epoch 5/500 | Train Loss: 4856.338 | Test Loss: 4590.730 | Test Loss [MAPE]: 3638549.649 --time-- 1.8837273120880127\n",
      "Epoch 6/500 | Train Loss: 4392.417 | Test Loss: 4254.166 | Test Loss [MAPE]: 3275208.180 --time-- 1.8772590160369873\n",
      "Epoch 7/500 | Train Loss: 4224.756 | Test Loss: 4195.374 | Test Loss [MAPE]: 2484325.849 --time-- 1.8751788139343262\n",
      "Epoch 8/500 | Train Loss: 4189.901 | Test Loss: 4183.385 | Test Loss [MAPE]: 2873105.648 --time-- 1.8740980625152588\n",
      "Epoch 9/500 | Train Loss: 4160.349 | Test Loss: 4154.338 | Test Loss [MAPE]: 2182135.546 --time-- 1.8735847473144531\n",
      "Epoch 10/500 | Train Loss: 4146.671 | Test Loss: 4140.768 | Test Loss [MAPE]: 2022240.997 --time-- 1.8751800060272217\n",
      "Epoch 11/500 | Train Loss: 4131.689 | Test Loss: 4138.388 | Test Loss [MAPE]: 1595038.730 --time-- 1.8764495849609375\n",
      "Epoch 12/500 | Train Loss: 4118.245 | Test Loss: 4122.371 | Test Loss [MAPE]: 2233443.280 --time-- 1.8778769969940186\n",
      "Epoch 13/500 | Train Loss: 4112.643 | Test Loss: 4110.310 | Test Loss [MAPE]: 1692515.385 --time-- 1.8769793510437012\n",
      "Epoch 14/500 | Train Loss: 4097.393 | Test Loss: 4099.639 | Test Loss [MAPE]: 1768846.774 --time-- 1.8760619163513184\n",
      "Epoch 15/500 | Train Loss: 4088.819 | Test Loss: 4090.206 | Test Loss [MAPE]: 1791479.938 --time-- 1.8822765350341797\n",
      "Epoch 16/500 | Train Loss: 4078.255 | Test Loss: 4087.716 | Test Loss [MAPE]: 2244717.680 --time-- 1.8770406246185303\n",
      "Epoch 17/500 | Train Loss: 4069.128 | Test Loss: 4075.903 | Test Loss [MAPE]: 2165058.607 --time-- 1.8787667751312256\n",
      "Epoch 18/500 | Train Loss: 4057.248 | Test Loss: 4062.440 | Test Loss [MAPE]: 2159762.123 --time-- 1.8761589527130127\n",
      "Epoch 19/500 | Train Loss: 4046.561 | Test Loss: 4051.072 | Test Loss [MAPE]: 1886863.838 --time-- 1.8793752193450928\n",
      "Epoch 20/500 | Train Loss: 4034.012 | Test Loss: 4035.316 | Test Loss [MAPE]: 2137622.922 --time-- 1.8791325092315674\n",
      "Epoch 21/500 | Train Loss: 4019.762 | Test Loss: 4020.163 | Test Loss [MAPE]: 2237662.153 --time-- 1.8790702819824219\n",
      "Epoch 22/500 | Train Loss: 4004.291 | Test Loss: 4003.377 | Test Loss [MAPE]: 2306577.845 --time-- 1.876784086227417\n",
      "Epoch 23/500 | Train Loss: 3987.473 | Test Loss: 3985.057 | Test Loss [MAPE]: 2374178.956 --time-- 1.8779644966125488\n",
      "Epoch 24/500 | Train Loss: 3967.561 | Test Loss: 3964.886 | Test Loss [MAPE]: 2459690.398 --time-- 1.8779804706573486\n",
      "Epoch 25/500 | Train Loss: 3946.732 | Test Loss: 3945.311 | Test Loss [MAPE]: 2915724.443 --time-- 1.8791794776916504\n",
      "Epoch 26/500 | Train Loss: 3924.629 | Test Loss: 3920.265 | Test Loss [MAPE]: 2937396.074 --time-- 1.8784313201904297\n",
      "Epoch 27/500 | Train Loss: 3898.269 | Test Loss: 3894.650 | Test Loss [MAPE]: 2940575.133 --time-- 1.8791530132293701\n",
      "Epoch 28/500 | Train Loss: 3870.308 | Test Loss: 3866.721 | Test Loss [MAPE]: 3187788.815 --time-- 1.881181240081787\n",
      "Epoch 29/500 | Train Loss: 3842.970 | Test Loss: 3839.311 | Test Loss [MAPE]: 3443020.835 --time-- 1.8766417503356934\n",
      "Epoch 30/500 | Train Loss: 3812.938 | Test Loss: 3810.367 | Test Loss [MAPE]: 3489844.589 --time-- 1.8759865760803223\n",
      "Epoch 31/500 | Train Loss: 3784.556 | Test Loss: 3785.513 | Test Loss [MAPE]: 3673686.520 --time-- 1.8776590824127197\n",
      "Epoch 32/500 | Train Loss: 3753.853 | Test Loss: 3751.295 | Test Loss [MAPE]: 4012660.724 --time-- 1.8841369152069092\n",
      "Epoch 33/500 | Train Loss: 3723.319 | Test Loss: 3718.955 | Test Loss [MAPE]: 4096500.681 --time-- 1.8831913471221924\n",
      "Epoch 34/500 | Train Loss: 3692.165 | Test Loss: 3689.913 | Test Loss [MAPE]: 4405930.342 --time-- 1.8793020248413086\n",
      "Epoch 35/500 | Train Loss: 3660.856 | Test Loss: 3657.493 | Test Loss [MAPE]: 4477330.533 --time-- 1.8790977001190186\n",
      "Epoch 36/500 | Train Loss: 3630.136 | Test Loss: 3628.042 | Test Loss [MAPE]: 4669453.874 --time-- 1.880014181137085\n",
      "Epoch 37/500 | Train Loss: 3598.126 | Test Loss: 3595.368 | Test Loss [MAPE]: 4968394.070 --time-- 1.879420280456543\n",
      "Epoch 38/500 | Train Loss: 3565.748 | Test Loss: 3562.746 | Test Loss [MAPE]: 5025797.819 --time-- 1.8766748905181885\n",
      "Epoch 39/500 | Train Loss: 3533.906 | Test Loss: 3528.711 | Test Loss [MAPE]: 5062986.233 --time-- 1.878061294555664\n",
      "Epoch 40/500 | Train Loss: 3501.712 | Test Loss: 3496.909 | Test Loss [MAPE]: 5161409.798 --time-- 1.8793156147003174\n",
      "Epoch 41/500 | Train Loss: 3466.565 | Test Loss: 3464.540 | Test Loss [MAPE]: 5394085.321 --time-- 1.8776938915252686\n",
      "Epoch 42/500 | Train Loss: 3432.256 | Test Loss: 3431.414 | Test Loss [MAPE]: 5550487.518 --time-- 1.8799664974212646\n",
      "Epoch 43/500 | Train Loss: 3397.908 | Test Loss: 3392.203 | Test Loss [MAPE]: 5371713.221 --time-- 1.8793151378631592\n",
      "Epoch 44/500 | Train Loss: 3359.352 | Test Loss: 3355.838 | Test Loss [MAPE]: 5838609.583 --time-- 1.8767719268798828\n",
      "Epoch 45/500 | Train Loss: 3317.539 | Test Loss: 3310.266 | Test Loss [MAPE]: 5681670.308 --time-- 1.8782916069030762\n",
      "Epoch 46/500 | Train Loss: 3276.073 | Test Loss: 3266.147 | Test Loss [MAPE]: 5758774.123 --time-- 1.882305383682251\n",
      "Epoch 47/500 | Train Loss: 3231.291 | Test Loss: 3218.937 | Test Loss [MAPE]: 5920626.413 --time-- 1.8801109790802002\n",
      "Epoch 48/500 | Train Loss: 3182.837 | Test Loss: 3165.775 | Test Loss [MAPE]: 5976933.448 --time-- 1.8809559345245361\n",
      "Epoch 49/500 | Train Loss: 3129.199 | Test Loss: 3111.434 | Test Loss [MAPE]: 6058672.569 --time-- 1.8776981830596924\n",
      "Epoch 50/500 | Train Loss: 3073.945 | Test Loss: 3056.064 | Test Loss [MAPE]: 6116956.572 --time-- 1.8786020278930664\n",
      "Epoch 51/500 | Train Loss: 3014.815 | Test Loss: 2996.271 | Test Loss [MAPE]: 5900041.798 --time-- 1.878859519958496\n",
      "Epoch 52/500 | Train Loss: 2958.916 | Test Loss: 2937.459 | Test Loss [MAPE]: 5764648.748 --time-- 1.8805046081542969\n",
      "Epoch 53/500 | Train Loss: 2902.092 | Test Loss: 2883.319 | Test Loss [MAPE]: 5804381.039 --time-- 1.8758959770202637\n",
      "Epoch 54/500 | Train Loss: 2838.601 | Test Loss: 2813.929 | Test Loss [MAPE]: 5667738.137 --time-- 1.877138614654541\n",
      "Epoch 55/500 | Train Loss: 2770.707 | Test Loss: 2749.766 | Test Loss [MAPE]: 5635276.975 --time-- 1.8760945796966553\n",
      "Epoch 56/500 | Train Loss: 2705.266 | Test Loss: 2682.412 | Test Loss [MAPE]: 5484446.920 --time-- 1.8801641464233398\n",
      "Epoch 57/500 | Train Loss: 2641.859 | Test Loss: 2624.776 | Test Loss [MAPE]: 5530019.080 --time-- 1.8788480758666992\n",
      "Epoch 58/500 | Train Loss: 2582.431 | Test Loss: 2570.795 | Test Loss [MAPE]: 5284606.705 --time-- 1.876267910003662\n",
      "Epoch 59/500 | Train Loss: 2528.855 | Test Loss: 2515.541 | Test Loss [MAPE]: 5198368.172 --time-- 1.879173994064331\n",
      "Epoch 60/500 | Train Loss: 2476.145 | Test Loss: 2462.947 | Test Loss [MAPE]: 5049863.952 --time-- 1.8755183219909668\n",
      "Epoch 61/500 | Train Loss: 2427.658 | Test Loss: 2419.589 | Test Loss [MAPE]: 5057663.589 --time-- 1.8816142082214355\n",
      "Epoch 62/500 | Train Loss: 2386.107 | Test Loss: 2380.716 | Test Loss [MAPE]: 4818774.959 --time-- 1.879432201385498\n",
      "Epoch 63/500 | Train Loss: 2338.604 | Test Loss: 2325.714 | Test Loss [MAPE]: 4749377.628 --time-- 1.8780133724212646\n",
      "Epoch 64/500 | Train Loss: 2282.096 | Test Loss: 2270.518 | Test Loss [MAPE]: 4416645.834 --time-- 1.8781483173370361\n",
      "Epoch 65/500 | Train Loss: 2230.736 | Test Loss: 2221.081 | Test Loss [MAPE]: 4548327.537 --time-- 1.8765361309051514\n",
      "Epoch 66/500 | Train Loss: 2183.468 | Test Loss: 2170.129 | Test Loss [MAPE]: 4256420.175 --time-- 1.8785090446472168\n",
      "Epoch 67/500 | Train Loss: 2137.843 | Test Loss: 2129.519 | Test Loss [MAPE]: 4176988.478 --time-- 1.876798152923584\n",
      "Epoch 68/500 | Train Loss: 2099.254 | Test Loss: 2102.522 | Test Loss [MAPE]: 4079123.978 --time-- 1.8761496543884277\n",
      "Epoch 69/500 | Train Loss: 2069.196 | Test Loss: 2073.626 | Test Loss [MAPE]: 4026934.479 --time-- 1.8760566711425781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500 | Train Loss: 2038.216 | Test Loss: 2038.254 | Test Loss [MAPE]: 4009442.981 --time-- 1.878312110900879\n",
      "Epoch 71/500 | Train Loss: 2008.902 | Test Loss: 2014.073 | Test Loss [MAPE]: 3952516.318 --time-- 1.878424882888794\n",
      "Epoch 72/500 | Train Loss: 1985.417 | Test Loss: 1994.262 | Test Loss [MAPE]: 4072550.067 --time-- 1.87693190574646\n",
      "Epoch 73/500 | Train Loss: 1963.005 | Test Loss: 1973.852 | Test Loss [MAPE]: 3926100.389 --time-- 1.877044677734375\n",
      "Epoch 74/500 | Train Loss: 1943.277 | Test Loss: 1956.230 | Test Loss [MAPE]: 3823976.967 --time-- 1.8759500980377197\n",
      "Epoch 75/500 | Train Loss: 1927.349 | Test Loss: 1943.464 | Test Loss [MAPE]: 3747796.737 --time-- 1.8819859027862549\n",
      "Epoch 76/500 | Train Loss: 1911.451 | Test Loss: 1921.822 | Test Loss [MAPE]: 3702337.130 --time-- 1.877901315689087\n",
      "Epoch 77/500 | Train Loss: 1901.529 | Test Loss: 1913.049 | Test Loss [MAPE]: 3745038.434 --time-- 1.8782918453216553\n",
      "Epoch 78/500 | Train Loss: 1885.246 | Test Loss: 1902.995 | Test Loss [MAPE]: 3561712.175 --time-- 1.8800325393676758\n",
      "Epoch 79/500 | Train Loss: 1871.474 | Test Loss: 1879.908 | Test Loss [MAPE]: 3547146.964 --time-- 1.8759417533874512\n",
      "Epoch 80/500 | Train Loss: 1857.797 | Test Loss: 1874.235 | Test Loss [MAPE]: 3643035.459 --time-- 1.8784558773040771\n",
      "Epoch 81/500 | Train Loss: 1850.276 | Test Loss: 1870.389 | Test Loss [MAPE]: 3558059.968 --time-- 1.876166582107544\n",
      "Epoch 82/500 | Train Loss: 1835.042 | Test Loss: 1850.037 | Test Loss [MAPE]: 3647192.998 --time-- 1.8765790462493896\n",
      "Epoch 83/500 | Train Loss: 1821.732 | Test Loss: 1836.100 | Test Loss [MAPE]: 3523908.199 --time-- 1.8789606094360352\n",
      "Epoch 84/500 | Train Loss: 1816.955 | Test Loss: 1832.691 | Test Loss [MAPE]: 3542665.625 --time-- 1.8758721351623535\n",
      "Epoch 85/500 | Train Loss: 1806.273 | Test Loss: 1822.644 | Test Loss [MAPE]: 3482209.370 --time-- 1.876828908920288\n",
      "Epoch 86/500 | Train Loss: 1794.713 | Test Loss: 1823.563 | Test Loss [MAPE]: 3546377.696 --time-- 1.880105972290039\n",
      "Epoch 87/500 | Train Loss: 1788.318 | Test Loss: 1805.080 | Test Loss [MAPE]: 3480482.328 --time-- 1.8772249221801758\n",
      "Epoch 88/500 | Train Loss: 1776.992 | Test Loss: 1789.743 | Test Loss [MAPE]: 3537495.116 --time-- 1.8785278797149658\n",
      "Epoch 89/500 | Train Loss: 1771.472 | Test Loss: 1785.746 | Test Loss [MAPE]: 3477679.035 --time-- 1.8789031505584717\n",
      "Epoch 90/500 | Train Loss: 1759.921 | Test Loss: 1774.142 | Test Loss [MAPE]: 3512652.629 --time-- 1.8827149868011475\n",
      "Epoch 91/500 | Train Loss: 1753.264 | Test Loss: 1771.287 | Test Loss [MAPE]: 3482355.413 --time-- 1.8802454471588135\n",
      "Epoch 92/500 | Train Loss: 1746.398 | Test Loss: 1764.216 | Test Loss [MAPE]: 3390984.016 --time-- 1.8824212551116943\n",
      "Epoch 93/500 | Train Loss: 1740.163 | Test Loss: 1755.509 | Test Loss [MAPE]: 3478447.004 --time-- 1.876988172531128\n",
      "Epoch 94/500 | Train Loss: 1726.609 | Test Loss: 1744.766 | Test Loss [MAPE]: 3409664.612 --time-- 1.878091812133789\n",
      "Epoch 95/500 | Train Loss: 1720.638 | Test Loss: 1744.470 | Test Loss [MAPE]: 3451386.121 --time-- 1.8796977996826172\n",
      "Epoch 96/500 | Train Loss: 1715.309 | Test Loss: 1731.353 | Test Loss [MAPE]: 3367168.588 --time-- 1.8804666996002197\n",
      "Epoch 97/500 | Train Loss: 1707.591 | Test Loss: 1729.059 | Test Loss [MAPE]: 3440963.901 --time-- 1.8791835308074951\n",
      "Epoch 98/500 | Train Loss: 1700.211 | Test Loss: 1718.804 | Test Loss [MAPE]: 3368424.413 --time-- 1.8807775974273682\n",
      "Epoch 99/500 | Train Loss: 1689.448 | Test Loss: 1711.070 | Test Loss [MAPE]: 3412432.629 --time-- 1.8765437602996826\n",
      "Epoch 100/500 | Train Loss: 1686.042 | Test Loss: 1708.608 | Test Loss [MAPE]: 3294474.859 --time-- 1.8784098625183105\n",
      "Epoch 101/500 | Train Loss: 1678.980 | Test Loss: 1698.936 | Test Loss [MAPE]: 3452984.730 --time-- 1.8770079612731934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:25:45,539] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500 | Train Loss: 1669.233 | Test Loss: 1690.421 | Test Loss [MAPE]: 3322981.784 --time-- 1.9091687202453613\n",
      "Epoch 1/500 | Train Loss: 5146.961 | Test Loss: 5163.448 | Test Loss [MAPE]: 541911.216 --time-- 12.990116834640503\n",
      "Epoch 2/500 | Train Loss: 4860.191 | Test Loss: 4369.746 | Test Loss [MAPE]: 3857611.457 --time-- 12.973694324493408\n",
      "Epoch 3/500 | Train Loss: 4210.238 | Test Loss: 4107.671 | Test Loss [MAPE]: 3326618.918 --time-- 12.977248191833496\n",
      "Epoch 4/500 | Train Loss: 4017.951 | Test Loss: 3965.018 | Test Loss [MAPE]: 2860892.183 --time-- 12.980071783065796\n",
      "Epoch 5/500 | Train Loss: 3899.857 | Test Loss: 3845.863 | Test Loss [MAPE]: 4399080.096 --time-- 12.982394218444824\n",
      "Epoch 6/500 | Train Loss: 3778.690 | Test Loss: 3754.502 | Test Loss [MAPE]: 5460774.745 --time-- 13.048043251037598\n",
      "Epoch 7/500 | Train Loss: 3679.370 | Test Loss: 3634.181 | Test Loss [MAPE]: 6213188.270 --time-- 13.01192831993103\n",
      "Epoch 8/500 | Train Loss: 3589.144 | Test Loss: 3575.343 | Test Loss [MAPE]: 6263644.927 --time-- 13.009017705917358\n",
      "Epoch 9/500 | Train Loss: 3514.260 | Test Loss: 3564.633 | Test Loss [MAPE]: 5503536.254 --time-- 13.009931325912476\n",
      "Epoch 10/500 | Train Loss: 3599.759 | Test Loss: 3495.328 | Test Loss [MAPE]: 8002465.122 --time-- 12.993375301361084\n",
      "Epoch 11/500 | Train Loss: 3415.637 | Test Loss: 3371.606 | Test Loss [MAPE]: 7388720.625 --time-- 12.997962236404419\n",
      "Epoch 12/500 | Train Loss: 3334.100 | Test Loss: 3308.668 | Test Loss [MAPE]: 7134457.669 --time-- 12.993677139282227\n",
      "Epoch 13/500 | Train Loss: 3304.080 | Test Loss: 3262.046 | Test Loss [MAPE]: 6817395.350 --time-- 12.997563123703003\n",
      "Epoch 14/500 | Train Loss: 3229.966 | Test Loss: 3252.995 | Test Loss [MAPE]: 6819775.084 --time-- 12.994920015335083\n",
      "Epoch 15/500 | Train Loss: 3193.725 | Test Loss: 3259.927 | Test Loss [MAPE]: 7985064.576 --time-- 12.993796110153198\n",
      "Epoch 16/500 | Train Loss: 3408.869 | Test Loss: 3310.020 | Test Loss [MAPE]: 6300362.550 --time-- 12.987679481506348\n",
      "Epoch 17/500 | Train Loss: 3147.104 | Test Loss: 3080.775 | Test Loss [MAPE]: 7044156.878 --time-- 12.999189853668213\n",
      "Epoch 18/500 | Train Loss: 3066.995 | Test Loss: 3084.906 | Test Loss [MAPE]: 6493220.058 --time-- 12.99847674369812\n",
      "Epoch 19/500 | Train Loss: 3068.706 | Test Loss: 2998.020 | Test Loss [MAPE]: 6437625.565 --time-- 12.994020462036133\n",
      "Epoch 20/500 | Train Loss: 3072.468 | Test Loss: 3018.744 | Test Loss [MAPE]: 6055468.168 --time-- 12.994282722473145\n",
      "Epoch 21/500 | Train Loss: 3000.005 | Test Loss: 3571.679 | Test Loss [MAPE]: 4204047.820 --time-- 13.020368576049805\n",
      "Epoch 22/500 | Train Loss: 3769.246 | Test Loss: 3412.529 | Test Loss [MAPE]: 6039047.760 --time-- 13.00131869316101\n",
      "Epoch 23/500 | Train Loss: 3035.779 | Test Loss: 3224.416 | Test Loss [MAPE]: 5699066.136 --time-- 13.006404876708984\n",
      "Epoch 24/500 | Train Loss: 2926.760 | Test Loss: 2830.571 | Test Loss [MAPE]: 6233213.734 --time-- 13.009902000427246\n",
      "Epoch 25/500 | Train Loss: 2752.719 | Test Loss: 2749.317 | Test Loss [MAPE]: 5857009.779 --time-- 13.025692701339722\n",
      "Epoch 26/500 | Train Loss: 2710.900 | Test Loss: 2683.593 | Test Loss [MAPE]: 5557388.697 --time-- 13.02857255935669\n",
      "Epoch 27/500 | Train Loss: 2637.118 | Test Loss: 2640.474 | Test Loss [MAPE]: 5170023.412 --time-- 13.023005247116089\n",
      "Epoch 28/500 | Train Loss: 2641.255 | Test Loss: 2670.374 | Test Loss [MAPE]: 5063634.554 --time-- 13.027040004730225\n",
      "Epoch 29/500 | Train Loss: 2609.193 | Test Loss: 2607.717 | Test Loss [MAPE]: 4401104.101 --time-- 13.012269973754883\n",
      "Epoch 30/500 | Train Loss: 2628.890 | Test Loss: 2540.115 | Test Loss [MAPE]: 4356346.951 --time-- 13.014847755432129\n",
      "Epoch 31/500 | Train Loss: 2507.785 | Test Loss: 2524.412 | Test Loss [MAPE]: 4518026.242 --time-- 13.021728277206421\n",
      "Epoch 32/500 | Train Loss: 2492.539 | Test Loss: 2498.462 | Test Loss [MAPE]: 4164208.238 --time-- 13.021486282348633\n",
      "Epoch 33/500 | Train Loss: 2458.853 | Test Loss: 2418.685 | Test Loss [MAPE]: 3804221.966 --time-- 13.018310308456421\n",
      "Epoch 34/500 | Train Loss: 2362.965 | Test Loss: 2340.606 | Test Loss [MAPE]: 3491472.927 --time-- 13.017351865768433\n",
      "Epoch 35/500 | Train Loss: 2294.670 | Test Loss: 2265.241 | Test Loss [MAPE]: 3670486.672 --time-- 13.02069616317749\n",
      "Epoch 36/500 | Train Loss: 2458.313 | Test Loss: 2578.283 | Test Loss [MAPE]: 4195571.193 --time-- 13.009963989257812\n",
      "Epoch 37/500 | Train Loss: 2282.393 | Test Loss: 2171.053 | Test Loss [MAPE]: 3141072.458 --time-- 13.017273187637329\n",
      "Epoch 38/500 | Train Loss: 2161.144 | Test Loss: 2223.564 | Test Loss [MAPE]: 3340973.223 --time-- 13.01762342453003\n",
      "Epoch 39/500 | Train Loss: 2165.403 | Test Loss: 2124.394 | Test Loss [MAPE]: 3110044.589 --time-- 13.010620594024658\n",
      "Epoch 40/500 | Train Loss: 2062.329 | Test Loss: 2027.056 | Test Loss [MAPE]: 2793827.664 --time-- 13.01473593711853\n",
      "Epoch 41/500 | Train Loss: 2010.843 | Test Loss: 2114.896 | Test Loss [MAPE]: 2759746.697 --time-- 13.009743928909302\n",
      "Epoch 42/500 | Train Loss: 2000.229 | Test Loss: 2034.129 | Test Loss [MAPE]: 3179899.930 --time-- 13.014339923858643\n",
      "Epoch 43/500 | Train Loss: 1965.765 | Test Loss: 1939.302 | Test Loss [MAPE]: 2834866.887 --time-- 13.011680364608765\n",
      "Epoch 44/500 | Train Loss: 1885.289 | Test Loss: 1877.673 | Test Loss [MAPE]: 2721491.567 --time-- 13.01396656036377\n",
      "Epoch 45/500 | Train Loss: 1836.951 | Test Loss: 1855.177 | Test Loss [MAPE]: 2421945.086 --time-- 13.015235424041748\n",
      "Epoch 46/500 | Train Loss: 1788.596 | Test Loss: 1779.388 | Test Loss [MAPE]: 2071731.309 --time-- 13.01633620262146\n",
      "Epoch 47/500 | Train Loss: 1804.169 | Test Loss: 1826.843 | Test Loss [MAPE]: 2377530.506 --time-- 13.0201096534729\n",
      "Epoch 48/500 | Train Loss: 1773.332 | Test Loss: 1814.290 | Test Loss [MAPE]: 2228900.712 --time-- 13.020037651062012\n",
      "Epoch 49/500 | Train Loss: 1742.869 | Test Loss: 1763.939 | Test Loss [MAPE]: 2282722.751 --time-- 13.019155979156494\n",
      "Epoch 50/500 | Train Loss: 1719.814 | Test Loss: 1776.465 | Test Loss [MAPE]: 2305054.424 --time-- 13.019810199737549\n",
      "Epoch 51/500 | Train Loss: 1735.536 | Test Loss: 1779.548 | Test Loss [MAPE]: 2180148.482 --time-- 13.017938375473022\n",
      "Epoch 52/500 | Train Loss: 1739.074 | Test Loss: 1756.812 | Test Loss [MAPE]: 2072358.943 --time-- 13.021467924118042\n",
      "Epoch 53/500 | Train Loss: 1695.811 | Test Loss: 1688.620 | Test Loss [MAPE]: 1993517.759 --time-- 13.024571180343628\n",
      "Epoch 54/500 | Train Loss: 1689.568 | Test Loss: 1746.455 | Test Loss [MAPE]: 2130400.392 --time-- 13.018170356750488\n",
      "Epoch 55/500 | Train Loss: 1699.224 | Test Loss: 1718.848 | Test Loss [MAPE]: 2009399.062 --time-- 13.023045539855957\n",
      "Epoch 56/500 | Train Loss: 1692.988 | Test Loss: 1733.971 | Test Loss [MAPE]: 2102242.871 --time-- 13.017593622207642\n",
      "Epoch 57/500 | Train Loss: 1683.837 | Test Loss: 1679.248 | Test Loss [MAPE]: 1711948.427 --time-- 13.019360303878784\n",
      "Epoch 58/500 | Train Loss: 1668.860 | Test Loss: 1675.143 | Test Loss [MAPE]: 2113433.600 --time-- 13.013267040252686\n",
      "Epoch 59/500 | Train Loss: 1725.244 | Test Loss: 1786.253 | Test Loss [MAPE]: 2107418.099 --time-- 13.016141414642334\n",
      "Epoch 60/500 | Train Loss: 1693.901 | Test Loss: 1707.052 | Test Loss [MAPE]: 1935769.472 --time-- 12.9698007106781\n",
      "Epoch 61/500 | Train Loss: 1676.492 | Test Loss: 1724.070 | Test Loss [MAPE]: 2155159.938 --time-- 12.963703393936157\n",
      "Epoch 62/500 | Train Loss: 1684.087 | Test Loss: 1688.871 | Test Loss [MAPE]: 1737838.678 --time-- 12.964729309082031\n",
      "Epoch 63/500 | Train Loss: 1673.064 | Test Loss: 1688.845 | Test Loss [MAPE]: 1857882.183 --time-- 12.96824312210083\n",
      "Epoch 64/500 | Train Loss: 1647.733 | Test Loss: 1647.787 | Test Loss [MAPE]: 1769200.660 --time-- 12.981439352035522\n",
      "Epoch 65/500 | Train Loss: 1662.631 | Test Loss: 1670.807 | Test Loss [MAPE]: 1920420.684 --time-- 12.976434469223022\n",
      "Epoch 66/500 | Train Loss: 1656.804 | Test Loss: 1652.496 | Test Loss [MAPE]: 1938361.863 --time-- 12.988768577575684\n",
      "Epoch 67/500 | Train Loss: 1657.717 | Test Loss: 1688.188 | Test Loss [MAPE]: 1859830.853 --time-- 12.967449426651001\n",
      "Epoch 68/500 | Train Loss: 1647.541 | Test Loss: 1642.872 | Test Loss [MAPE]: 2064703.710 --time-- 12.964635372161865\n",
      "Epoch 69/500 | Train Loss: 1620.802 | Test Loss: 1639.707 | Test Loss [MAPE]: 1823743.992 --time-- 12.971039056777954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500 | Train Loss: 1618.485 | Test Loss: 1640.107 | Test Loss [MAPE]: 1854474.275 --time-- 12.974384069442749\n",
      "Epoch 71/500 | Train Loss: 1630.984 | Test Loss: 1647.224 | Test Loss [MAPE]: 2000896.861 --time-- 12.96910047531128\n",
      "Epoch 72/500 | Train Loss: 1619.106 | Test Loss: 1632.011 | Test Loss [MAPE]: 1828091.252 --time-- 12.970428466796875\n",
      "Epoch 73/500 | Train Loss: 1615.321 | Test Loss: 1628.615 | Test Loss [MAPE]: 1700516.538 --time-- 12.967743635177612\n",
      "Epoch 74/500 | Train Loss: 1604.353 | Test Loss: 1630.440 | Test Loss [MAPE]: 2018825.864 --time-- 12.970346689224243\n",
      "Epoch 75/500 | Train Loss: 1596.985 | Test Loss: 1617.722 | Test Loss [MAPE]: 1695666.175 --time-- 12.966891288757324\n",
      "Epoch 76/500 | Train Loss: 1600.780 | Test Loss: 1612.356 | Test Loss [MAPE]: 1822248.206 --time-- 12.971672773361206\n",
      "Epoch 77/500 | Train Loss: 1577.134 | Test Loss: 1624.316 | Test Loss [MAPE]: 1749064.234 --time-- 12.971235513687134\n",
      "Epoch 78/500 | Train Loss: 1606.322 | Test Loss: 1620.267 | Test Loss [MAPE]: 1679306.143 --time-- 12.970886468887329\n",
      "Epoch 79/500 | Train Loss: 1595.298 | Test Loss: 1608.952 | Test Loss [MAPE]: 1819800.382 --time-- 12.969748973846436\n",
      "Epoch 80/500 | Train Loss: 1599.144 | Test Loss: 1628.240 | Test Loss [MAPE]: 2025231.251 --time-- 12.96865463256836\n",
      "Epoch 81/500 | Train Loss: 1597.209 | Test Loss: 1619.693 | Test Loss [MAPE]: 1758105.335 --time-- 12.967362403869629\n",
      "Epoch 82/500 | Train Loss: 1575.199 | Test Loss: 1600.301 | Test Loss [MAPE]: 1772739.435 --time-- 12.966082572937012\n",
      "Epoch 83/500 | Train Loss: 1585.992 | Test Loss: 1619.140 | Test Loss [MAPE]: 1664997.027 --time-- 12.967828512191772\n",
      "Epoch 84/500 | Train Loss: 1579.082 | Test Loss: 1587.518 | Test Loss [MAPE]: 1726508.554 --time-- 12.971105575561523\n",
      "Epoch 85/500 | Train Loss: 1568.999 | Test Loss: 1584.470 | Test Loss [MAPE]: 1702543.736 --time-- 12.972500562667847\n",
      "Epoch 86/500 | Train Loss: 1574.368 | Test Loss: 1629.820 | Test Loss [MAPE]: 1909163.523 --time-- 12.969035148620605\n",
      "Epoch 87/500 | Train Loss: 1589.244 | Test Loss: 1583.286 | Test Loss [MAPE]: 1791318.110 --time-- 12.966784715652466\n",
      "Epoch 88/500 | Train Loss: 1566.681 | Test Loss: 1572.605 | Test Loss [MAPE]: 1795449.799 --time-- 12.966448545455933\n",
      "Epoch 89/500 | Train Loss: 1563.820 | Test Loss: 1572.122 | Test Loss [MAPE]: 1744057.595 --time-- 12.96944546699524\n",
      "Epoch 90/500 | Train Loss: 1573.927 | Test Loss: 1591.370 | Test Loss [MAPE]: 1611607.266 --time-- 12.966732501983643\n",
      "Epoch 91/500 | Train Loss: 1562.139 | Test Loss: 1564.718 | Test Loss [MAPE]: 1873737.455 --time-- 12.96979832649231\n",
      "Epoch 92/500 | Train Loss: 1563.153 | Test Loss: 1581.555 | Test Loss [MAPE]: 1820590.846 --time-- 12.970093727111816\n",
      "Epoch 93/500 | Train Loss: 1550.931 | Test Loss: 1597.520 | Test Loss [MAPE]: 1776048.602 --time-- 12.973560333251953\n",
      "Epoch 94/500 | Train Loss: 1587.987 | Test Loss: 1602.129 | Test Loss [MAPE]: 1812585.256 --time-- 12.971726417541504\n",
      "Epoch 95/500 | Train Loss: 1564.344 | Test Loss: 1583.697 | Test Loss [MAPE]: 1558057.660 --time-- 12.968778371810913\n",
      "Epoch 96/500 | Train Loss: 1539.223 | Test Loss: 1548.055 | Test Loss [MAPE]: 1629819.479 --time-- 12.973808765411377\n",
      "Epoch 97/500 | Train Loss: 1557.691 | Test Loss: 1596.901 | Test Loss [MAPE]: 1900095.992 --time-- 13.029581785202026\n",
      "Epoch 98/500 | Train Loss: 1562.452 | Test Loss: 1566.367 | Test Loss [MAPE]: 1623895.448 --time-- 13.025708436965942\n",
      "Epoch 99/500 | Train Loss: 1603.288 | Test Loss: 1688.712 | Test Loss [MAPE]: 1741068.542 --time-- 13.023410558700562\n",
      "Epoch 100/500 | Train Loss: 1570.937 | Test Loss: 1588.796 | Test Loss [MAPE]: 1691031.825 --time-- 12.974820852279663\n",
      "Epoch 101/500 | Train Loss: 1553.083 | Test Loss: 1560.737 | Test Loss [MAPE]: 1674650.748 --time-- 12.967485189437866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 22:47:53,270] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500 | Train Loss: 1553.305 | Test Loss: 1579.310 | Test Loss [MAPE]: 1598372.525 --time-- 12.999953269958496\n",
      "Epoch 1/500 | Train Loss: 5199.689 | Test Loss: 5162.360 | Test Loss [MAPE]: 442241.952 --time-- 13.02865219116211\n",
      "Epoch 2/500 | Train Loss: 4948.682 | Test Loss: 4405.907 | Test Loss [MAPE]: 3537421.116 --time-- 12.98392391204834\n",
      "Epoch 3/500 | Train Loss: 4040.660 | Test Loss: 3594.559 | Test Loss [MAPE]: 4915909.949 --time-- 12.987643480300903\n",
      "Epoch 4/500 | Train Loss: 3455.499 | Test Loss: 4029.532 | Test Loss [MAPE]: 5398473.348 --time-- 12.990757942199707\n",
      "Epoch 5/500 | Train Loss: 3618.477 | Test Loss: 3152.247 | Test Loss [MAPE]: 5091507.370 --time-- 12.9828462600708\n",
      "Epoch 6/500 | Train Loss: 2503.294 | Test Loss: 2087.909 | Test Loss [MAPE]: 4772470.609 --time-- 12.989060163497925\n",
      "Epoch 7/500 | Train Loss: 1874.039 | Test Loss: 1814.648 | Test Loss [MAPE]: 4296759.101 --time-- 12.996355056762695\n",
      "Epoch 8/500 | Train Loss: 1546.422 | Test Loss: 1443.041 | Test Loss [MAPE]: 3533721.307 --time-- 12.993061542510986\n",
      "Epoch 9/500 | Train Loss: 1338.621 | Test Loss: 1197.983 | Test Loss [MAPE]: 3302174.947 --time-- 12.96215271949768\n",
      "Epoch 10/500 | Train Loss: 1161.850 | Test Loss: 1146.469 | Test Loss [MAPE]: 3278699.663 --time-- 12.959811687469482\n",
      "Epoch 11/500 | Train Loss: 1073.623 | Test Loss: 957.959 | Test Loss [MAPE]: 2546546.195 --time-- 12.960058450698853\n",
      "Epoch 12/500 | Train Loss: 978.893 | Test Loss: 871.435 | Test Loss [MAPE]: 2362365.558 --time-- 13.023372173309326\n",
      "Epoch 13/500 | Train Loss: 950.226 | Test Loss: 986.325 | Test Loss [MAPE]: 2498423.525 --time-- 13.019809246063232\n",
      "Epoch 14/500 | Train Loss: 910.949 | Test Loss: 894.276 | Test Loss [MAPE]: 2467291.523 --time-- 13.017230033874512\n",
      "Epoch 15/500 | Train Loss: 816.403 | Test Loss: 783.613 | Test Loss [MAPE]: 2177494.559 --time-- 13.017461776733398\n",
      "Epoch 16/500 | Train Loss: 756.164 | Test Loss: 926.422 | Test Loss [MAPE]: 2609846.425 --time-- 13.031049013137817\n",
      "Epoch 17/500 | Train Loss: 804.775 | Test Loss: 718.536 | Test Loss [MAPE]: 2051838.141 --time-- 13.024365425109863\n",
      "Epoch 18/500 | Train Loss: 712.387 | Test Loss: 719.147 | Test Loss [MAPE]: 2064686.310 --time-- 13.035824060440063\n",
      "Epoch 19/500 | Train Loss: 640.007 | Test Loss: 727.269 | Test Loss [MAPE]: 2079099.583 --time-- 13.028586387634277\n",
      "Epoch 20/500 | Train Loss: 697.083 | Test Loss: 679.113 | Test Loss [MAPE]: 1946367.031 --time-- 13.018632411956787\n",
      "Epoch 21/500 | Train Loss: 666.946 | Test Loss: 622.668 | Test Loss [MAPE]: 1792175.630 --time-- 13.020880699157715\n",
      "Epoch 22/500 | Train Loss: 616.004 | Test Loss: 613.003 | Test Loss [MAPE]: 1744293.994 --time-- 13.022221565246582\n",
      "Epoch 23/500 | Train Loss: 622.720 | Test Loss: 722.564 | Test Loss [MAPE]: 2104288.950 --time-- 12.972204685211182\n",
      "Epoch 24/500 | Train Loss: 618.991 | Test Loss: 570.203 | Test Loss [MAPE]: 1650408.189 --time-- 12.971582174301147\n",
      "Epoch 25/500 | Train Loss: 581.718 | Test Loss: 732.387 | Test Loss [MAPE]: 2112480.662 --time-- 13.018983840942383\n",
      "Epoch 26/500 | Train Loss: 596.854 | Test Loss: 584.252 | Test Loss [MAPE]: 1687761.150 --time-- 13.020835399627686\n",
      "Epoch 27/500 | Train Loss: 567.566 | Test Loss: 624.671 | Test Loss [MAPE]: 1807774.589 --time-- 13.025134563446045\n",
      "Epoch 28/500 | Train Loss: 574.595 | Test Loss: 573.596 | Test Loss [MAPE]: 1669253.363 --time-- 13.022189855575562\n",
      "Epoch 29/500 | Train Loss: 526.585 | Test Loss: 564.985 | Test Loss [MAPE]: 1675864.130 --time-- 13.02493691444397\n",
      "Epoch 30/500 | Train Loss: 518.057 | Test Loss: 484.232 | Test Loss [MAPE]: 1407525.582 --time-- 13.02261996269226\n",
      "Epoch 31/500 | Train Loss: 496.333 | Test Loss: 460.524 | Test Loss [MAPE]: 1338108.640 --time-- 13.020162582397461\n",
      "Epoch 32/500 | Train Loss: 482.675 | Test Loss: 531.547 | Test Loss [MAPE]: 1556865.775 --time-- 13.02580738067627\n",
      "Epoch 33/500 | Train Loss: 503.735 | Test Loss: 530.238 | Test Loss [MAPE]: 1567760.852 --time-- 13.027424812316895\n",
      "Epoch 34/500 | Train Loss: 518.936 | Test Loss: 601.810 | Test Loss [MAPE]: 1775881.717 --time-- 13.022475481033325\n",
      "Epoch 35/500 | Train Loss: 530.666 | Test Loss: 571.595 | Test Loss [MAPE]: 1711379.278 --time-- 13.024338483810425\n",
      "Epoch 36/500 | Train Loss: 504.203 | Test Loss: 463.036 | Test Loss [MAPE]: 1343737.405 --time-- 13.026204824447632\n",
      "Epoch 37/500 | Train Loss: 478.259 | Test Loss: 492.722 | Test Loss [MAPE]: 1453182.782 --time-- 13.02215576171875\n",
      "Epoch 38/500 | Train Loss: 478.090 | Test Loss: 435.996 | Test Loss [MAPE]: 1263792.132 --time-- 13.02398133277893\n",
      "Epoch 39/500 | Train Loss: 468.280 | Test Loss: 565.321 | Test Loss [MAPE]: 1633919.294 --time-- 13.021324396133423\n",
      "Epoch 40/500 | Train Loss: 461.559 | Test Loss: 530.160 | Test Loss [MAPE]: 1408835.045 --time-- 13.027781248092651\n",
      "Epoch 41/500 | Train Loss: 451.253 | Test Loss: 491.623 | Test Loss [MAPE]: 1474106.444 --time-- 12.989190816879272\n",
      "Epoch 42/500 | Train Loss: 466.463 | Test Loss: 486.833 | Test Loss [MAPE]: 1497927.106 --time-- 13.04765772819519\n",
      "Epoch 43/500 | Train Loss: 442.460 | Test Loss: 439.954 | Test Loss [MAPE]: 1315526.566 --time-- 13.0276460647583\n",
      "Epoch 44/500 | Train Loss: 450.814 | Test Loss: 437.451 | Test Loss [MAPE]: 1358370.989 --time-- 12.999984979629517\n",
      "Epoch 45/500 | Train Loss: 429.954 | Test Loss: 477.130 | Test Loss [MAPE]: 1374796.605 --time-- 12.975847721099854\n",
      "Epoch 46/500 | Train Loss: 449.813 | Test Loss: 467.731 | Test Loss [MAPE]: 1449846.221 --time-- 13.02014708518982\n",
      "Epoch 47/500 | Train Loss: 453.062 | Test Loss: 487.493 | Test Loss [MAPE]: 1405116.636 --time-- 12.978521585464478\n",
      "Epoch 48/500 | Train Loss: 476.595 | Test Loss: 438.406 | Test Loss [MAPE]: 1337095.987 --time-- 12.969776153564453\n",
      "Epoch 49/500 | Train Loss: 439.335 | Test Loss: 483.332 | Test Loss [MAPE]: 1483898.466 --time-- 12.989998817443848\n",
      "Epoch 50/500 | Train Loss: 446.994 | Test Loss: 474.597 | Test Loss [MAPE]: 1415573.890 --time-- 12.973662376403809\n",
      "Epoch 51/500 | Train Loss: 458.605 | Test Loss: 586.084 | Test Loss [MAPE]: 1545839.014 --time-- 12.97252082824707\n",
      "Epoch 52/500 | Train Loss: 417.361 | Test Loss: 434.479 | Test Loss [MAPE]: 1326427.062 --time-- 12.968315362930298\n",
      "Epoch 53/500 | Train Loss: 431.876 | Test Loss: 482.969 | Test Loss [MAPE]: 1418443.550 --time-- 12.969956398010254\n",
      "Epoch 54/500 | Train Loss: 429.065 | Test Loss: 443.641 | Test Loss [MAPE]: 1383544.278 --time-- 12.968865156173706\n",
      "Epoch 55/500 | Train Loss: 444.502 | Test Loss: 451.078 | Test Loss [MAPE]: 1416927.760 --time-- 12.969506025314331\n",
      "Epoch 56/500 | Train Loss: 416.848 | Test Loss: 440.798 | Test Loss [MAPE]: 1375030.297 --time-- 12.967676401138306\n",
      "Epoch 57/500 | Train Loss: 390.768 | Test Loss: 380.804 | Test Loss [MAPE]: 1148554.912 --time-- 12.968588590621948\n",
      "Epoch 58/500 | Train Loss: 393.120 | Test Loss: 377.713 | Test Loss [MAPE]: 1140463.404 --time-- 12.969991683959961\n",
      "Epoch 59/500 | Train Loss: 392.144 | Test Loss: 477.585 | Test Loss [MAPE]: 1487413.566 --time-- 12.972314596176147\n",
      "Epoch 60/500 | Train Loss: 425.963 | Test Loss: 394.314 | Test Loss [MAPE]: 1199379.965 --time-- 12.968719720840454\n",
      "Epoch 61/500 | Train Loss: 386.023 | Test Loss: 434.552 | Test Loss [MAPE]: 1319158.568 --time-- 12.96744418144226\n",
      "Epoch 62/500 | Train Loss: 390.099 | Test Loss: 432.849 | Test Loss [MAPE]: 1361785.088 --time-- 12.968525409698486\n",
      "Epoch 63/500 | Train Loss: 407.551 | Test Loss: 400.811 | Test Loss [MAPE]: 1172821.458 --time-- 12.969245672225952\n",
      "Epoch 64/500 | Train Loss: 407.880 | Test Loss: 407.574 | Test Loss [MAPE]: 1184387.086 --time-- 12.966668367385864\n",
      "Epoch 65/500 | Train Loss: 367.375 | Test Loss: 407.845 | Test Loss [MAPE]: 1269625.901 --time-- 12.971370458602905\n",
      "Epoch 66/500 | Train Loss: 365.066 | Test Loss: 380.713 | Test Loss [MAPE]: 1210790.284 --time-- 12.969648361206055\n",
      "Epoch 67/500 | Train Loss: 382.733 | Test Loss: 374.017 | Test Loss [MAPE]: 1159559.382 --time-- 12.971101522445679\n",
      "Epoch 68/500 | Train Loss: 370.589 | Test Loss: 335.565 | Test Loss [MAPE]: 1052761.885 --time-- 12.969575643539429\n",
      "Epoch 69/500 | Train Loss: 375.886 | Test Loss: 465.972 | Test Loss [MAPE]: 1379772.052 --time-- 12.972477436065674\n",
      "Epoch 70/500 | Train Loss: 378.851 | Test Loss: 377.206 | Test Loss [MAPE]: 1164907.253 --time-- 12.968842029571533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500 | Train Loss: 388.496 | Test Loss: 431.983 | Test Loss [MAPE]: 1305229.010 --time-- 12.96515703201294\n",
      "Epoch 72/500 | Train Loss: 366.461 | Test Loss: 401.673 | Test Loss [MAPE]: 1245998.717 --time-- 12.97086763381958\n",
      "Epoch 73/500 | Train Loss: 362.386 | Test Loss: 411.360 | Test Loss [MAPE]: 1223740.072 --time-- 12.970136642456055\n",
      "Epoch 74/500 | Train Loss: 365.919 | Test Loss: 418.434 | Test Loss [MAPE]: 1303590.109 --time-- 12.96941351890564\n",
      "Epoch 75/500 | Train Loss: 359.184 | Test Loss: 368.951 | Test Loss [MAPE]: 1134401.381 --time-- 12.970195055007935\n",
      "Epoch 76/500 | Train Loss: 360.675 | Test Loss: 380.203 | Test Loss [MAPE]: 1219573.484 --time-- 12.970642566680908\n",
      "Epoch 77/500 | Train Loss: 366.838 | Test Loss: 419.631 | Test Loss [MAPE]: 1284483.730 --time-- 12.968857049942017\n",
      "Epoch 78/500 | Train Loss: 373.699 | Test Loss: 389.017 | Test Loss [MAPE]: 1238703.240 --time-- 12.969889402389526\n",
      "Epoch 79/500 | Train Loss: 347.497 | Test Loss: 360.450 | Test Loss [MAPE]: 1138204.856 --time-- 12.970845460891724\n",
      "Epoch 80/500 | Train Loss: 345.042 | Test Loss: 370.729 | Test Loss [MAPE]: 1178181.942 --time-- 12.965972900390625\n",
      "Epoch 81/500 | Train Loss: 340.076 | Test Loss: 369.305 | Test Loss [MAPE]: 1087597.906 --time-- 12.969783544540405\n",
      "Epoch 82/500 | Train Loss: 355.553 | Test Loss: 360.020 | Test Loss [MAPE]: 1151408.575 --time-- 13.024754285812378\n",
      "Epoch 83/500 | Train Loss: 339.765 | Test Loss: 365.267 | Test Loss [MAPE]: 1139424.480 --time-- 13.027888059616089\n",
      "Epoch 84/500 | Train Loss: 354.009 | Test Loss: 390.027 | Test Loss [MAPE]: 1228806.290 --time-- 13.024890184402466\n",
      "Epoch 85/500 | Train Loss: 355.914 | Test Loss: 375.500 | Test Loss [MAPE]: 1167902.292 --time-- 13.031485557556152\n",
      "Epoch 86/500 | Train Loss: 350.251 | Test Loss: 387.781 | Test Loss [MAPE]: 1179363.629 --time-- 13.024702787399292\n",
      "Epoch 87/500 | Train Loss: 366.616 | Test Loss: 414.780 | Test Loss [MAPE]: 1266777.481 --time-- 13.041604995727539\n",
      "Epoch 88/500 | Train Loss: 337.533 | Test Loss: 383.357 | Test Loss [MAPE]: 1197233.773 --time-- 13.03014087677002\n",
      "Epoch 89/500 | Train Loss: 363.182 | Test Loss: 375.828 | Test Loss [MAPE]: 1190240.413 --time-- 13.025844812393188\n",
      "Epoch 90/500 | Train Loss: 363.290 | Test Loss: 395.300 | Test Loss [MAPE]: 1236572.472 --time-- 13.026478052139282\n",
      "Epoch 91/500 | Train Loss: 368.681 | Test Loss: 334.223 | Test Loss [MAPE]: 1078786.542 --time-- 13.018812417984009\n",
      "Epoch 92/500 | Train Loss: 340.787 | Test Loss: 372.888 | Test Loss [MAPE]: 1152264.292 --time-- 13.020653009414673\n",
      "Epoch 93/500 | Train Loss: 322.179 | Test Loss: 368.627 | Test Loss [MAPE]: 1171853.397 --time-- 13.02817678451538\n",
      "Epoch 94/500 | Train Loss: 350.107 | Test Loss: 398.413 | Test Loss [MAPE]: 1298202.741 --time-- 13.03688097000122\n",
      "Epoch 95/500 | Train Loss: 354.154 | Test Loss: 444.125 | Test Loss [MAPE]: 1013300.304 --time-- 13.026399850845337\n",
      "Epoch 96/500 | Train Loss: 314.555 | Test Loss: 338.362 | Test Loss [MAPE]: 1050709.382 --time-- 13.019329309463501\n",
      "Epoch 97/500 | Train Loss: 354.462 | Test Loss: 329.201 | Test Loss [MAPE]: 1070159.837 --time-- 13.028621673583984\n",
      "Epoch 98/500 | Train Loss: 344.593 | Test Loss: 382.983 | Test Loss [MAPE]: 1218321.016 --time-- 13.026597499847412\n",
      "Epoch 99/500 | Train Loss: 317.117 | Test Loss: 316.873 | Test Loss [MAPE]: 1018488.832 --time-- 13.018016338348389\n",
      "Epoch 100/500 | Train Loss: 338.706 | Test Loss: 363.823 | Test Loss [MAPE]: 1187428.244 --time-- 13.024119853973389\n",
      "Epoch 101/500 | Train Loss: 306.224 | Test Loss: 308.368 | Test Loss [MAPE]: 999199.493 --time-- 13.02347183227539\n",
      "Epoch 102/500 | Train Loss: 307.646 | Test Loss: 368.004 | Test Loss [MAPE]: 1135694.658 --time-- 13.024946451187134\n",
      "Epoch 103/500 | Train Loss: 334.390 | Test Loss: 363.599 | Test Loss [MAPE]: 1148771.723 --time-- 13.02669620513916\n",
      "Epoch 104/500 | Train Loss: 352.941 | Test Loss: 346.004 | Test Loss [MAPE]: 1113768.887 --time-- 12.967463731765747\n",
      "Epoch 105/500 | Train Loss: 308.991 | Test Loss: 329.343 | Test Loss [MAPE]: 1031266.531 --time-- 12.97156047821045\n",
      "Epoch 106/500 | Train Loss: 333.018 | Test Loss: 355.442 | Test Loss [MAPE]: 1065469.503 --time-- 12.96825361251831\n",
      "Epoch 107/500 | Train Loss: 317.237 | Test Loss: 359.145 | Test Loss [MAPE]: 1137618.777 --time-- 12.966564893722534\n",
      "Epoch 108/500 | Train Loss: 330.436 | Test Loss: 344.940 | Test Loss [MAPE]: 1126127.404 --time-- 12.973606824874878\n",
      "Epoch 109/500 | Train Loss: 336.878 | Test Loss: 402.559 | Test Loss [MAPE]: 1191970.291 --time-- 12.98467230796814\n",
      "Epoch 110/500 | Train Loss: 320.055 | Test Loss: 369.694 | Test Loss [MAPE]: 1165580.841 --time-- 12.986830234527588\n",
      "Epoch 111/500 | Train Loss: 298.050 | Test Loss: 323.627 | Test Loss [MAPE]: 1045698.569 --time-- 12.974804401397705\n",
      "Epoch 112/500 | Train Loss: 327.230 | Test Loss: 359.611 | Test Loss [MAPE]: 1074371.266 --time-- 12.97071361541748\n",
      "Epoch 113/500 | Train Loss: 315.653 | Test Loss: 329.887 | Test Loss [MAPE]: 1060909.155 --time-- 12.973560810089111\n",
      "Epoch 114/500 | Train Loss: 293.979 | Test Loss: 363.378 | Test Loss [MAPE]: 1159068.060 --time-- 12.973952770233154\n",
      "Epoch 115/500 | Train Loss: 305.017 | Test Loss: 343.552 | Test Loss [MAPE]: 1080764.098 --time-- 12.99011492729187\n",
      "Epoch 116/500 | Train Loss: 306.809 | Test Loss: 359.656 | Test Loss [MAPE]: 1158188.324 --time-- 12.989248514175415\n",
      "Epoch 117/500 | Train Loss: 308.488 | Test Loss: 293.596 | Test Loss [MAPE]: 971675.885 --time-- 13.044046878814697\n",
      "Epoch 118/500 | Train Loss: 336.092 | Test Loss: 354.349 | Test Loss [MAPE]: 1138175.497 --time-- 13.044384956359863\n",
      "Epoch 119/500 | Train Loss: 342.705 | Test Loss: 399.265 | Test Loss [MAPE]: 1273930.420 --time-- 13.037265300750732\n",
      "Epoch 120/500 | Train Loss: 323.050 | Test Loss: 329.553 | Test Loss [MAPE]: 1082514.050 --time-- 13.039018392562866\n",
      "Epoch 121/500 | Train Loss: 327.279 | Test Loss: 347.651 | Test Loss [MAPE]: 1135180.326 --time-- 13.009992122650146\n",
      "Epoch 122/500 | Train Loss: 329.180 | Test Loss: 362.000 | Test Loss [MAPE]: 1132440.813 --time-- 12.988960981369019\n",
      "Epoch 123/500 | Train Loss: 317.343 | Test Loss: 379.709 | Test Loss [MAPE]: 1215064.241 --time-- 12.989929676055908\n",
      "Epoch 124/500 | Train Loss: 345.110 | Test Loss: 349.297 | Test Loss [MAPE]: 1087276.179 --time-- 12.989465951919556\n",
      "Epoch 125/500 | Train Loss: 316.166 | Test Loss: 339.323 | Test Loss [MAPE]: 1069439.225 --time-- 12.989433288574219\n",
      "Epoch 126/500 | Train Loss: 332.579 | Test Loss: 367.819 | Test Loss [MAPE]: 1187416.392 --time-- 12.987278461456299\n",
      "Epoch 127/500 | Train Loss: 320.511 | Test Loss: 316.739 | Test Loss [MAPE]: 1006743.411 --time-- 12.98865294456482\n",
      "Epoch 128/500 | Train Loss: 311.202 | Test Loss: 348.798 | Test Loss [MAPE]: 1121921.857 --time-- 12.989978075027466\n",
      "Epoch 129/500 | Train Loss: 300.272 | Test Loss: 315.535 | Test Loss [MAPE]: 1007869.336 --time-- 12.98790192604065\n",
      "Epoch 130/500 | Train Loss: 292.874 | Test Loss: 342.266 | Test Loss [MAPE]: 1117454.131 --time-- 12.989648342132568\n",
      "Epoch 131/500 | Train Loss: 296.974 | Test Loss: 381.734 | Test Loss [MAPE]: 1135808.890 --time-- 12.988481283187866\n",
      "Epoch 132/500 | Train Loss: 330.524 | Test Loss: 361.599 | Test Loss [MAPE]: 1155556.439 --time-- 12.994074583053589\n",
      "Epoch 133/500 | Train Loss: 293.428 | Test Loss: 323.110 | Test Loss [MAPE]: 1036324.531 --time-- 12.986621618270874\n",
      "Epoch 134/500 | Train Loss: 298.748 | Test Loss: 336.340 | Test Loss [MAPE]: 1120872.043 --time-- 12.99121618270874\n",
      "Epoch 135/500 | Train Loss: 341.244 | Test Loss: 366.929 | Test Loss [MAPE]: 1128550.992 --time-- 12.986788988113403\n",
      "Epoch 136/500 | Train Loss: 307.083 | Test Loss: 302.022 | Test Loss [MAPE]: 1003522.999 --time-- 12.989150285720825\n",
      "Epoch 137/500 | Train Loss: 272.583 | Test Loss: 334.444 | Test Loss [MAPE]: 1108499.931 --time-- 12.986105680465698\n",
      "Epoch 138/500 | Train Loss: 310.262 | Test Loss: 328.990 | Test Loss [MAPE]: 1050329.842 --time-- 12.990024328231812\n",
      "Epoch 139/500 | Train Loss: 318.018 | Test Loss: 323.474 | Test Loss [MAPE]: 1045197.450 --time-- 12.987734079360962\n",
      "Epoch 140/500 | Train Loss: 302.614 | Test Loss: 307.168 | Test Loss [MAPE]: 1016813.110 --time-- 12.987345218658447\n",
      "Epoch 141/500 | Train Loss: 300.183 | Test Loss: 312.502 | Test Loss [MAPE]: 972396.055 --time-- 12.988288879394531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/500 | Train Loss: 309.595 | Test Loss: 314.700 | Test Loss [MAPE]: 985382.413 --time-- 12.986071586608887\n",
      "Epoch 143/500 | Train Loss: 289.008 | Test Loss: 324.734 | Test Loss [MAPE]: 1073397.714 --time-- 12.988125801086426\n",
      "Epoch 144/500 | Train Loss: 285.170 | Test Loss: 317.928 | Test Loss [MAPE]: 1003977.541 --time-- 12.989612340927124\n",
      "Epoch 145/500 | Train Loss: 289.331 | Test Loss: 300.396 | Test Loss [MAPE]: 973750.708 --time-- 12.986802101135254\n",
      "Epoch 146/500 | Train Loss: 282.730 | Test Loss: 333.971 | Test Loss [MAPE]: 1070550.382 --time-- 12.988817691802979\n",
      "Epoch 147/500 | Train Loss: 285.960 | Test Loss: 308.625 | Test Loss [MAPE]: 976464.884 --time-- 12.991477251052856\n",
      "Epoch 148/500 | Train Loss: 331.974 | Test Loss: 364.675 | Test Loss [MAPE]: 1091018.545 --time-- 12.9888436794281\n",
      "Epoch 149/500 | Train Loss: 303.904 | Test Loss: 263.938 | Test Loss [MAPE]: 848771.631 --time-- 12.985681295394897\n",
      "Epoch 150/500 | Train Loss: 271.795 | Test Loss: 354.259 | Test Loss [MAPE]: 1117816.531 --time-- 12.989284038543701\n",
      "Epoch 151/500 | Train Loss: 273.749 | Test Loss: 341.519 | Test Loss [MAPE]: 1117529.028 --time-- 12.986457347869873\n",
      "Epoch 152/500 | Train Loss: 304.490 | Test Loss: 345.277 | Test Loss [MAPE]: 1092828.490 --time-- 12.992681741714478\n",
      "Epoch 153/500 | Train Loss: 283.056 | Test Loss: 305.363 | Test Loss [MAPE]: 981565.445 --time-- 12.990370035171509\n",
      "Epoch 154/500 | Train Loss: 270.688 | Test Loss: 309.637 | Test Loss [MAPE]: 1038191.932 --time-- 12.990508556365967\n",
      "Epoch 155/500 | Train Loss: 280.401 | Test Loss: 319.211 | Test Loss [MAPE]: 1048390.096 --time-- 12.99397325515747\n",
      "Epoch 156/500 | Train Loss: 327.588 | Test Loss: 432.492 | Test Loss [MAPE]: 1214666.456 --time-- 12.992916584014893\n",
      "Epoch 157/500 | Train Loss: 346.691 | Test Loss: 358.497 | Test Loss [MAPE]: 956542.775 --time-- 12.990893602371216\n",
      "Epoch 158/500 | Train Loss: 289.784 | Test Loss: 309.403 | Test Loss [MAPE]: 1017164.601 --time-- 12.987614631652832\n",
      "Epoch 159/500 | Train Loss: 258.364 | Test Loss: 302.745 | Test Loss [MAPE]: 978373.313 --time-- 12.988742589950562\n",
      "Epoch 160/500 | Train Loss: 262.197 | Test Loss: 281.243 | Test Loss [MAPE]: 857843.422 --time-- 12.98982048034668\n",
      "Epoch 161/500 | Train Loss: 283.701 | Test Loss: 312.730 | Test Loss [MAPE]: 972763.460 --time-- 12.99471926689148\n",
      "Epoch 162/500 | Train Loss: 291.056 | Test Loss: 293.039 | Test Loss [MAPE]: 955355.855 --time-- 12.984687805175781\n",
      "Epoch 163/500 | Train Loss: 280.934 | Test Loss: 314.657 | Test Loss [MAPE]: 1032205.563 --time-- 12.990161895751953\n",
      "Epoch 164/500 | Train Loss: 291.144 | Test Loss: 335.611 | Test Loss [MAPE]: 1018939.880 --time-- 12.991284847259521\n",
      "Epoch 165/500 | Train Loss: 273.308 | Test Loss: 346.122 | Test Loss [MAPE]: 1114782.800 --time-- 12.987706422805786\n",
      "Epoch 166/500 | Train Loss: 276.363 | Test Loss: 311.968 | Test Loss [MAPE]: 936086.540 --time-- 12.99010705947876\n",
      "Epoch 167/500 | Train Loss: 331.720 | Test Loss: 380.936 | Test Loss [MAPE]: 969831.375 --time-- 12.990015983581543\n",
      "Epoch 168/500 | Train Loss: 325.189 | Test Loss: 387.275 | Test Loss [MAPE]: 1008676.966 --time-- 12.986269474029541\n",
      "Epoch 169/500 | Train Loss: 294.186 | Test Loss: 332.682 | Test Loss [MAPE]: 1076709.101 --time-- 12.987709522247314\n",
      "Epoch 170/500 | Train Loss: 266.435 | Test Loss: 293.750 | Test Loss [MAPE]: 954042.290 --time-- 12.986127138137817\n",
      "Epoch 171/500 | Train Loss: 261.927 | Test Loss: 310.278 | Test Loss [MAPE]: 909817.218 --time-- 12.988563060760498\n",
      "Epoch 172/500 | Train Loss: 291.443 | Test Loss: 306.345 | Test Loss [MAPE]: 1001743.598 --time-- 12.988121032714844\n",
      "Epoch 173/500 | Train Loss: 259.710 | Test Loss: 325.233 | Test Loss [MAPE]: 1042786.483 --time-- 12.990071773529053\n",
      "Epoch 174/500 | Train Loss: 286.869 | Test Loss: 314.418 | Test Loss [MAPE]: 1027350.720 --time-- 12.990469932556152\n",
      "Epoch 175/500 | Train Loss: 274.484 | Test Loss: 308.103 | Test Loss [MAPE]: 1016028.375 --time-- 12.993465423583984\n",
      "Epoch 176/500 | Train Loss: 258.962 | Test Loss: 289.093 | Test Loss [MAPE]: 931616.170 --time-- 12.986719131469727\n",
      "Epoch 177/500 | Train Loss: 291.540 | Test Loss: 293.114 | Test Loss [MAPE]: 946604.628 --time-- 12.990530252456665\n",
      "Epoch 178/500 | Train Loss: 279.019 | Test Loss: 305.617 | Test Loss [MAPE]: 911980.581 --time-- 12.987689971923828\n",
      "Epoch 179/500 | Train Loss: 298.713 | Test Loss: 305.219 | Test Loss [MAPE]: 969848.985 --time-- 12.990755319595337\n",
      "Epoch 180/500 | Train Loss: 288.260 | Test Loss: 300.917 | Test Loss [MAPE]: 956746.447 --time-- 12.988191604614258\n",
      "Epoch 181/500 | Train Loss: 272.949 | Test Loss: 347.919 | Test Loss [MAPE]: 1159228.985 --time-- 12.988589525222778\n",
      "Epoch 182/500 | Train Loss: 268.510 | Test Loss: 290.969 | Test Loss [MAPE]: 937126.563 --time-- 12.986485481262207\n",
      "Epoch 183/500 | Train Loss: 281.140 | Test Loss: 338.850 | Test Loss [MAPE]: 1121796.414 --time-- 12.985809087753296\n",
      "Epoch 184/500 | Train Loss: 262.512 | Test Loss: 297.223 | Test Loss [MAPE]: 969800.263 --time-- 12.990836143493652\n",
      "Epoch 185/500 | Train Loss: 262.443 | Test Loss: 308.505 | Test Loss [MAPE]: 947104.413 --time-- 12.993296146392822\n",
      "Epoch 186/500 | Train Loss: 322.690 | Test Loss: 307.739 | Test Loss [MAPE]: 1015917.601 --time-- 12.988013744354248\n",
      "Epoch 187/500 | Train Loss: 332.181 | Test Loss: 434.553 | Test Loss [MAPE]: 971969.923 --time-- 12.986911296844482\n",
      "Epoch 188/500 | Train Loss: 316.775 | Test Loss: 320.431 | Test Loss [MAPE]: 1042639.824 --time-- 12.980574607849121\n",
      "Epoch 189/500 | Train Loss: 278.624 | Test Loss: 280.639 | Test Loss [MAPE]: 936784.748 --time-- 12.985154867172241\n",
      "Epoch 190/500 | Train Loss: 257.678 | Test Loss: 302.156 | Test Loss [MAPE]: 978224.014 --time-- 12.983332395553589\n",
      "Epoch 191/500 | Train Loss: 283.400 | Test Loss: 285.403 | Test Loss [MAPE]: 948724.194 --time-- 12.987273931503296\n",
      "Epoch 192/500 | Train Loss: 260.065 | Test Loss: 282.850 | Test Loss [MAPE]: 925381.283 --time-- 12.986109972000122\n",
      "Epoch 193/500 | Train Loss: 277.703 | Test Loss: 267.201 | Test Loss [MAPE]: 885050.707 --time-- 12.989442586898804\n",
      "Epoch 194/500 | Train Loss: 261.102 | Test Loss: 315.831 | Test Loss [MAPE]: 1010115.667 --time-- 12.986199855804443\n",
      "Epoch 195/500 | Train Loss: 276.569 | Test Loss: 269.724 | Test Loss [MAPE]: 846601.723 --time-- 12.97104287147522\n",
      "Epoch 196/500 | Train Loss: 276.750 | Test Loss: 306.100 | Test Loss [MAPE]: 1017098.939 --time-- 12.966878414154053\n",
      "Epoch 197/500 | Train Loss: 262.401 | Test Loss: 289.355 | Test Loss [MAPE]: 923706.692 --time-- 12.966967105865479\n",
      "Epoch 198/500 | Train Loss: 268.712 | Test Loss: 298.987 | Test Loss [MAPE]: 977110.324 --time-- 12.970011234283447\n",
      "Epoch 199/500 | Train Loss: 288.090 | Test Loss: 308.305 | Test Loss [MAPE]: 1007947.901 --time-- 12.970478773117065\n",
      "Epoch 200/500 | Train Loss: 276.513 | Test Loss: 356.540 | Test Loss [MAPE]: 1154307.882 --time-- 12.970724105834961\n",
      "Epoch 201/500 | Train Loss: 275.932 | Test Loss: 349.036 | Test Loss [MAPE]: 1133842.393 --time-- 12.968560218811035\n",
      "Epoch 202/500 | Train Loss: 258.959 | Test Loss: 259.581 | Test Loss [MAPE]: 882148.596 --time-- 12.965850114822388\n",
      "Epoch 203/500 | Train Loss: 249.066 | Test Loss: 260.342 | Test Loss [MAPE]: 839442.960 --time-- 12.966977596282959\n",
      "Epoch 204/500 | Train Loss: 242.489 | Test Loss: 275.649 | Test Loss [MAPE]: 879818.413 --time-- 12.968214988708496\n",
      "Epoch 205/500 | Train Loss: 266.152 | Test Loss: 290.817 | Test Loss [MAPE]: 967855.548 --time-- 12.969165086746216\n",
      "Epoch 206/500 | Train Loss: 264.168 | Test Loss: 299.098 | Test Loss [MAPE]: 1014137.775 --time-- 12.967291593551636\n",
      "Epoch 207/500 | Train Loss: 292.984 | Test Loss: 309.786 | Test Loss [MAPE]: 971373.198 --time-- 12.970732688903809\n",
      "Epoch 208/500 | Train Loss: 279.522 | Test Loss: 289.397 | Test Loss [MAPE]: 975210.780 --time-- 12.96541428565979\n",
      "Epoch 209/500 | Train Loss: 254.368 | Test Loss: 296.174 | Test Loss [MAPE]: 968969.485 --time-- 12.967486381530762\n",
      "Epoch 210/500 | Train Loss: 241.453 | Test Loss: 287.119 | Test Loss [MAPE]: 937404.814 --time-- 12.97366213798523\n",
      "Epoch 211/500 | Train Loss: 267.172 | Test Loss: 317.233 | Test Loss [MAPE]: 995807.511 --time-- 12.967134237289429\n",
      "Epoch 212/500 | Train Loss: 278.734 | Test Loss: 298.413 | Test Loss [MAPE]: 898214.327 --time-- 12.968316555023193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/500 | Train Loss: 258.760 | Test Loss: 289.553 | Test Loss [MAPE]: 952086.182 --time-- 12.967285633087158\n",
      "Epoch 214/500 | Train Loss: 236.549 | Test Loss: 321.322 | Test Loss [MAPE]: 983243.668 --time-- 12.970680952072144\n",
      "Epoch 215/500 | Train Loss: 238.174 | Test Loss: 281.575 | Test Loss [MAPE]: 921966.981 --time-- 12.973116397857666\n",
      "Epoch 216/500 | Train Loss: 267.725 | Test Loss: 331.682 | Test Loss [MAPE]: 1078790.078 --time-- 13.008623361587524\n",
      "Epoch 217/500 | Train Loss: 275.876 | Test Loss: 297.753 | Test Loss [MAPE]: 950629.834 --time-- 12.999918699264526\n",
      "Epoch 218/500 | Train Loss: 245.067 | Test Loss: 347.408 | Test Loss [MAPE]: 1117813.692 --time-- 13.002183675765991\n",
      "Epoch 219/500 | Train Loss: 261.680 | Test Loss: 271.571 | Test Loss [MAPE]: 880557.757 --time-- 13.0235276222229\n",
      "Epoch 220/500 | Train Loss: 256.974 | Test Loss: 303.569 | Test Loss [MAPE]: 987990.569 --time-- 13.022542953491211\n",
      "Epoch 221/500 | Train Loss: 234.699 | Test Loss: 239.578 | Test Loss [MAPE]: 815690.313 --time-- 13.024831295013428\n",
      "Epoch 222/500 | Train Loss: 250.551 | Test Loss: 282.957 | Test Loss [MAPE]: 926558.589 --time-- 13.024291276931763\n",
      "Epoch 223/500 | Train Loss: 288.686 | Test Loss: 348.928 | Test Loss [MAPE]: 1018477.415 --time-- 13.028713703155518\n",
      "Epoch 224/500 | Train Loss: 285.001 | Test Loss: 311.744 | Test Loss [MAPE]: 986118.544 --time-- 12.965759992599487\n",
      "Epoch 225/500 | Train Loss: 262.573 | Test Loss: 314.793 | Test Loss [MAPE]: 1021557.866 --time-- 12.965760469436646\n",
      "Epoch 226/500 | Train Loss: 269.463 | Test Loss: 276.619 | Test Loss [MAPE]: 900884.085 --time-- 12.966655492782593\n",
      "Epoch 227/500 | Train Loss: 264.927 | Test Loss: 288.478 | Test Loss [MAPE]: 939941.938 --time-- 12.96964430809021\n",
      "Epoch 228/500 | Train Loss: 282.178 | Test Loss: 274.098 | Test Loss [MAPE]: 908346.644 --time-- 12.966108560562134\n",
      "Epoch 229/500 | Train Loss: 261.507 | Test Loss: 278.758 | Test Loss [MAPE]: 921944.480 --time-- 12.966728210449219\n",
      "Epoch 230/500 | Train Loss: 227.451 | Test Loss: 281.682 | Test Loss [MAPE]: 941807.200 --time-- 12.972488403320312\n",
      "Epoch 231/500 | Train Loss: 242.967 | Test Loss: 290.472 | Test Loss [MAPE]: 953960.172 --time-- 12.97567868232727\n",
      "Epoch 232/500 | Train Loss: 262.886 | Test Loss: 327.178 | Test Loss [MAPE]: 1038863.782 --time-- 12.965449094772339\n",
      "Epoch 233/500 | Train Loss: 244.615 | Test Loss: 282.662 | Test Loss [MAPE]: 914171.955 --time-- 12.9668710231781\n",
      "Epoch 234/500 | Train Loss: 229.308 | Test Loss: 289.838 | Test Loss [MAPE]: 980705.232 --time-- 12.970445394515991\n",
      "Epoch 235/500 | Train Loss: 267.340 | Test Loss: 305.913 | Test Loss [MAPE]: 889617.110 --time-- 12.96764087677002\n",
      "Epoch 236/500 | Train Loss: 318.384 | Test Loss: 372.987 | Test Loss [MAPE]: 1182074.201 --time-- 12.967013835906982\n",
      "Epoch 237/500 | Train Loss: 262.408 | Test Loss: 327.210 | Test Loss [MAPE]: 1023639.566 --time-- 12.96479058265686\n",
      "Epoch 238/500 | Train Loss: 262.288 | Test Loss: 309.113 | Test Loss [MAPE]: 807573.843 --time-- 12.966050624847412\n",
      "Epoch 239/500 | Train Loss: 253.985 | Test Loss: 252.527 | Test Loss [MAPE]: 831546.271 --time-- 12.967261552810669\n",
      "Epoch 240/500 | Train Loss: 261.207 | Test Loss: 275.143 | Test Loss [MAPE]: 905341.559 --time-- 13.027241706848145\n",
      "Epoch 241/500 | Train Loss: 239.373 | Test Loss: 274.003 | Test Loss [MAPE]: 904951.952 --time-- 13.019554376602173\n",
      "Epoch 242/500 | Train Loss: 244.671 | Test Loss: 281.872 | Test Loss [MAPE]: 937457.667 --time-- 13.025583028793335\n",
      "Epoch 243/500 | Train Loss: 236.295 | Test Loss: 306.136 | Test Loss [MAPE]: 998701.123 --time-- 13.020521402359009\n",
      "Epoch 244/500 | Train Loss: 309.115 | Test Loss: 294.226 | Test Loss [MAPE]: 892708.670 --time-- 13.040343999862671\n",
      "Epoch 245/500 | Train Loss: 295.063 | Test Loss: 320.055 | Test Loss [MAPE]: 980889.378 --time-- 13.022830724716187\n",
      "Epoch 246/500 | Train Loss: 251.752 | Test Loss: 272.173 | Test Loss [MAPE]: 897727.732 --time-- 13.037701606750488\n",
      "Epoch 247/500 | Train Loss: 240.306 | Test Loss: 301.181 | Test Loss [MAPE]: 909889.702 --time-- 13.020891189575195\n",
      "Epoch 248/500 | Train Loss: 271.379 | Test Loss: 261.051 | Test Loss [MAPE]: 877076.300 --time-- 12.967769622802734\n",
      "Epoch 249/500 | Train Loss: 251.557 | Test Loss: 268.978 | Test Loss [MAPE]: 860276.663 --time-- 12.9645357131958\n",
      "Epoch 250/500 | Train Loss: 238.677 | Test Loss: 265.233 | Test Loss [MAPE]: 893591.013 --time-- 12.972766160964966\n",
      "Epoch 251/500 | Train Loss: 215.548 | Test Loss: 252.304 | Test Loss [MAPE]: 854178.633 --time-- 12.98215937614441\n",
      "Epoch 252/500 | Train Loss: 230.191 | Test Loss: 262.779 | Test Loss [MAPE]: 876945.907 --time-- 12.985085248947144\n",
      "Epoch 253/500 | Train Loss: 232.866 | Test Loss: 266.194 | Test Loss [MAPE]: 864002.358 --time-- 12.965691566467285\n",
      "Epoch 254/500 | Train Loss: 242.396 | Test Loss: 319.446 | Test Loss [MAPE]: 1003635.487 --time-- 12.968113422393799\n",
      "Epoch 255/500 | Train Loss: 255.964 | Test Loss: 298.930 | Test Loss [MAPE]: 1002032.783 --time-- 12.969361782073975\n",
      "Epoch 256/500 | Train Loss: 247.290 | Test Loss: 323.474 | Test Loss [MAPE]: 1079392.849 --time-- 12.967476844787598\n",
      "Epoch 257/500 | Train Loss: 265.334 | Test Loss: 277.979 | Test Loss [MAPE]: 914979.326 --time-- 12.96468210220337\n",
      "Epoch 258/500 | Train Loss: 235.096 | Test Loss: 270.389 | Test Loss [MAPE]: 883839.077 --time-- 12.968226909637451\n",
      "Epoch 259/500 | Train Loss: 240.825 | Test Loss: 260.463 | Test Loss [MAPE]: 880493.340 --time-- 12.969513893127441\n",
      "Epoch 260/500 | Train Loss: 228.778 | Test Loss: 273.527 | Test Loss [MAPE]: 909876.936 --time-- 12.966270446777344\n",
      "Epoch 261/500 | Train Loss: 234.957 | Test Loss: 304.719 | Test Loss [MAPE]: 998411.792 --time-- 12.96720290184021\n",
      "Epoch 262/500 | Train Loss: 246.809 | Test Loss: 271.554 | Test Loss [MAPE]: 905916.831 --time-- 12.972876787185669\n",
      "Epoch 263/500 | Train Loss: 223.516 | Test Loss: 270.730 | Test Loss [MAPE]: 891378.194 --time-- 12.968270778656006\n",
      "Epoch 264/500 | Train Loss: 220.166 | Test Loss: 278.854 | Test Loss [MAPE]: 902124.556 --time-- 12.96946668624878\n",
      "Epoch 265/500 | Train Loss: 227.704 | Test Loss: 289.011 | Test Loss [MAPE]: 929044.441 --time-- 12.970311403274536\n",
      "Epoch 266/500 | Train Loss: 230.866 | Test Loss: 246.547 | Test Loss [MAPE]: 809050.870 --time-- 12.96564245223999\n",
      "Epoch 267/500 | Train Loss: 237.904 | Test Loss: 257.473 | Test Loss [MAPE]: 842191.683 --time-- 12.969807624816895\n",
      "Epoch 268/500 | Train Loss: 229.653 | Test Loss: 274.065 | Test Loss [MAPE]: 898174.653 --time-- 12.966382503509521\n",
      "Epoch 269/500 | Train Loss: 234.640 | Test Loss: 259.831 | Test Loss [MAPE]: 876171.513 --time-- 12.970251083374023\n",
      "Epoch 270/500 | Train Loss: 249.004 | Test Loss: 331.006 | Test Loss [MAPE]: 1017282.718 --time-- 12.969046592712402\n",
      "Epoch 271/500 | Train Loss: 269.547 | Test Loss: 322.231 | Test Loss [MAPE]: 947407.207 --time-- 12.969198226928711\n",
      "Epoch 272/500 | Train Loss: 289.442 | Test Loss: 334.509 | Test Loss [MAPE]: 930714.655 --time-- 12.968516111373901\n",
      "Epoch 273/500 | Train Loss: 258.725 | Test Loss: 282.012 | Test Loss [MAPE]: 893428.666 --time-- 12.965672731399536\n",
      "Epoch 274/500 | Train Loss: 241.118 | Test Loss: 245.857 | Test Loss [MAPE]: 844864.573 --time-- 12.968167781829834\n",
      "Epoch 275/500 | Train Loss: 223.883 | Test Loss: 253.209 | Test Loss [MAPE]: 858045.353 --time-- 12.96341586112976\n",
      "Epoch 276/500 | Train Loss: 236.725 | Test Loss: 262.682 | Test Loss [MAPE]: 870017.302 --time-- 12.965553998947144\n",
      "Epoch 277/500 | Train Loss: 245.737 | Test Loss: 306.552 | Test Loss [MAPE]: 984036.760 --time-- 12.96580171585083\n",
      "Epoch 278/500 | Train Loss: 248.580 | Test Loss: 292.337 | Test Loss [MAPE]: 935165.010 --time-- 12.963547945022583\n",
      "Epoch 279/500 | Train Loss: 243.502 | Test Loss: 289.112 | Test Loss [MAPE]: 966242.309 --time-- 12.963324069976807\n",
      "Epoch 280/500 | Train Loss: 244.984 | Test Loss: 296.982 | Test Loss [MAPE]: 986899.861 --time-- 12.965324401855469\n",
      "Epoch 281/500 | Train Loss: 225.321 | Test Loss: 252.666 | Test Loss [MAPE]: 805873.877 --time-- 12.971976280212402\n",
      "Epoch 282/500 | Train Loss: 238.419 | Test Loss: 309.950 | Test Loss [MAPE]: 1034851.948 --time-- 12.967887878417969\n",
      "Epoch 283/500 | Train Loss: 323.142 | Test Loss: 351.705 | Test Loss [MAPE]: 1011877.326 --time-- 12.961045742034912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/500 | Train Loss: 250.227 | Test Loss: 272.137 | Test Loss [MAPE]: 922484.903 --time-- 12.956325769424438\n",
      "Epoch 285/500 | Train Loss: 240.227 | Test Loss: 269.112 | Test Loss [MAPE]: 910820.522 --time-- 12.963012218475342\n",
      "Epoch 286/500 | Train Loss: 224.499 | Test Loss: 260.948 | Test Loss [MAPE]: 868119.725 --time-- 12.962022542953491\n",
      "Epoch 287/500 | Train Loss: 229.221 | Test Loss: 286.298 | Test Loss [MAPE]: 895021.350 --time-- 12.959336280822754\n",
      "Epoch 288/500 | Train Loss: 230.963 | Test Loss: 265.494 | Test Loss [MAPE]: 883453.690 --time-- 12.96385931968689\n",
      "Epoch 289/500 | Train Loss: 232.496 | Test Loss: 279.539 | Test Loss [MAPE]: 903112.545 --time-- 12.963865041732788\n",
      "Epoch 290/500 | Train Loss: 223.756 | Test Loss: 267.857 | Test Loss [MAPE]: 906335.181 --time-- 12.963210821151733\n",
      "Epoch 291/500 | Train Loss: 227.614 | Test Loss: 274.681 | Test Loss [MAPE]: 908611.677 --time-- 12.962414264678955\n",
      "Epoch 292/500 | Train Loss: 223.085 | Test Loss: 286.005 | Test Loss [MAPE]: 938933.906 --time-- 12.96259331703186\n",
      "Epoch 293/500 | Train Loss: 219.906 | Test Loss: 256.893 | Test Loss [MAPE]: 819944.921 --time-- 12.96462106704712\n",
      "Epoch 294/500 | Train Loss: 209.801 | Test Loss: 255.439 | Test Loss [MAPE]: 860711.579 --time-- 12.965642213821411\n",
      "Epoch 295/500 | Train Loss: 236.198 | Test Loss: 259.929 | Test Loss [MAPE]: 841663.328 --time-- 12.964823722839355\n",
      "Epoch 296/500 | Train Loss: 241.940 | Test Loss: 267.280 | Test Loss [MAPE]: 885146.143 --time-- 12.965981245040894\n",
      "Epoch 297/500 | Train Loss: 269.431 | Test Loss: 264.249 | Test Loss [MAPE]: 859481.555 --time-- 12.962010860443115\n",
      "Epoch 298/500 | Train Loss: 237.874 | Test Loss: 283.526 | Test Loss [MAPE]: 857584.171 --time-- 12.961491584777832\n",
      "Epoch 299/500 | Train Loss: 220.878 | Test Loss: 251.744 | Test Loss [MAPE]: 813554.414 --time-- 13.021878242492676\n",
      "Epoch 300/500 | Train Loss: 222.426 | Test Loss: 281.629 | Test Loss [MAPE]: 930902.802 --time-- 13.020185470581055\n",
      "Epoch 301/500 | Train Loss: 225.395 | Test Loss: 244.372 | Test Loss [MAPE]: 812191.442 --time-- 13.021726369857788\n",
      "Epoch 302/500 | Train Loss: 217.361 | Test Loss: 254.707 | Test Loss [MAPE]: 848824.068 --time-- 13.020756483078003\n",
      "Epoch 303/500 | Train Loss: 218.419 | Test Loss: 294.642 | Test Loss [MAPE]: 953835.561 --time-- 12.965826034545898\n",
      "Epoch 304/500 | Train Loss: 232.887 | Test Loss: 268.664 | Test Loss [MAPE]: 879909.654 --time-- 12.964664459228516\n",
      "Epoch 305/500 | Train Loss: 235.128 | Test Loss: 329.240 | Test Loss [MAPE]: 918217.539 --time-- 12.966045379638672\n",
      "Epoch 306/500 | Train Loss: 217.385 | Test Loss: 230.727 | Test Loss [MAPE]: 743093.115 --time-- 12.962637186050415\n",
      "Epoch 307/500 | Train Loss: 210.428 | Test Loss: 246.814 | Test Loss [MAPE]: 792267.574 --time-- 12.967783212661743\n",
      "Epoch 308/500 | Train Loss: 232.554 | Test Loss: 259.461 | Test Loss [MAPE]: 863176.248 --time-- 12.963667154312134\n",
      "Epoch 309/500 | Train Loss: 221.399 | Test Loss: 267.756 | Test Loss [MAPE]: 889039.105 --time-- 12.965255498886108\n",
      "Epoch 310/500 | Train Loss: 232.916 | Test Loss: 274.796 | Test Loss [MAPE]: 848129.988 --time-- 12.967510461807251\n",
      "Epoch 311/500 | Train Loss: 242.265 | Test Loss: 246.850 | Test Loss [MAPE]: 811799.434 --time-- 12.965240955352783\n",
      "Epoch 312/500 | Train Loss: 224.580 | Test Loss: 320.360 | Test Loss [MAPE]: 845851.552 --time-- 12.963438510894775\n",
      "Epoch 313/500 | Train Loss: 266.497 | Test Loss: 283.019 | Test Loss [MAPE]: 869371.101 --time-- 12.964312314987183\n",
      "Epoch 314/500 | Train Loss: 275.906 | Test Loss: 375.429 | Test Loss [MAPE]: 904041.104 --time-- 12.966601133346558\n",
      "Epoch 315/500 | Train Loss: 280.831 | Test Loss: 289.789 | Test Loss [MAPE]: 817308.377 --time-- 12.963283777236938\n",
      "Epoch 316/500 | Train Loss: 224.747 | Test Loss: 264.347 | Test Loss [MAPE]: 870649.652 --time-- 12.964418649673462\n",
      "Epoch 317/500 | Train Loss: 228.886 | Test Loss: 289.485 | Test Loss [MAPE]: 945590.291 --time-- 12.961174726486206\n",
      "Epoch 318/500 | Train Loss: 300.488 | Test Loss: 427.752 | Test Loss [MAPE]: 1282647.894 --time-- 12.955671310424805\n",
      "Epoch 319/500 | Train Loss: 689.199 | Test Loss: 728.903 | Test Loss [MAPE]: 1930231.089 --time-- 12.944566488265991\n",
      "Epoch 320/500 | Train Loss: 450.754 | Test Loss: 304.944 | Test Loss [MAPE]: 993765.233 --time-- 12.948185682296753\n",
      "Epoch 321/500 | Train Loss: 333.600 | Test Loss: 480.250 | Test Loss [MAPE]: 1220925.905 --time-- 12.945098876953125\n",
      "Epoch 322/500 | Train Loss: 377.434 | Test Loss: 306.013 | Test Loss [MAPE]: 884761.368 --time-- 12.93779444694519\n",
      "Epoch 323/500 | Train Loss: 300.468 | Test Loss: 303.025 | Test Loss [MAPE]: 930724.714 --time-- 12.946510791778564\n",
      "Epoch 324/500 | Train Loss: 329.856 | Test Loss: 330.637 | Test Loss [MAPE]: 938912.072 --time-- 12.940202236175537\n",
      "Epoch 325/500 | Train Loss: 265.433 | Test Loss: 316.416 | Test Loss [MAPE]: 886625.311 --time-- 12.94943642616272\n",
      "Epoch 326/500 | Train Loss: 237.740 | Test Loss: 258.736 | Test Loss [MAPE]: 810053.515 --time-- 12.945688962936401\n",
      "Epoch 327/500 | Train Loss: 217.424 | Test Loss: 246.731 | Test Loss [MAPE]: 797245.166 --time-- 12.951141834259033\n",
      "Epoch 328/500 | Train Loss: 217.736 | Test Loss: 282.515 | Test Loss [MAPE]: 914434.145 --time-- 12.953335762023926\n",
      "Epoch 329/500 | Train Loss: 230.960 | Test Loss: 250.479 | Test Loss [MAPE]: 809789.525 --time-- 13.007791757583618\n",
      "Epoch 330/500 | Train Loss: 228.769 | Test Loss: 341.945 | Test Loss [MAPE]: 894263.795 --time-- 13.005417108535767\n",
      "Epoch 331/500 | Train Loss: 254.117 | Test Loss: 279.242 | Test Loss [MAPE]: 923365.465 --time-- 13.008995532989502\n",
      "Epoch 332/500 | Train Loss: 224.946 | Test Loss: 266.314 | Test Loss [MAPE]: 871243.739 --time-- 13.005549907684326\n",
      "Epoch 333/500 | Train Loss: 213.043 | Test Loss: 256.022 | Test Loss [MAPE]: 754103.933 --time-- 13.02193808555603\n",
      "Epoch 334/500 | Train Loss: 208.224 | Test Loss: 246.929 | Test Loss [MAPE]: 824326.624 --time-- 13.014670848846436\n",
      "Epoch 335/500 | Train Loss: 203.101 | Test Loss: 258.343 | Test Loss [MAPE]: 856495.943 --time-- 12.955379962921143\n",
      "Epoch 336/500 | Train Loss: 213.230 | Test Loss: 244.525 | Test Loss [MAPE]: 802989.834 --time-- 12.958473205566406\n",
      "Epoch 337/500 | Train Loss: 211.987 | Test Loss: 257.960 | Test Loss [MAPE]: 846403.223 --time-- 12.959239959716797\n",
      "Epoch 338/500 | Train Loss: 234.083 | Test Loss: 282.846 | Test Loss [MAPE]: 930510.945 --time-- 12.957845687866211\n",
      "Epoch 339/500 | Train Loss: 223.462 | Test Loss: 272.588 | Test Loss [MAPE]: 896798.906 --time-- 12.959859371185303\n",
      "Epoch 340/500 | Train Loss: 221.297 | Test Loss: 272.077 | Test Loss [MAPE]: 824863.998 --time-- 12.974621772766113\n",
      "Epoch 341/500 | Train Loss: 225.910 | Test Loss: 252.534 | Test Loss [MAPE]: 839618.273 --time-- 12.969082832336426\n",
      "Epoch 342/500 | Train Loss: 225.032 | Test Loss: 266.638 | Test Loss [MAPE]: 862094.995 --time-- 12.951786279678345\n",
      "Epoch 343/500 | Train Loss: 219.746 | Test Loss: 224.117 | Test Loss [MAPE]: 749241.110 --time-- 12.959668397903442\n",
      "Epoch 344/500 | Train Loss: 214.754 | Test Loss: 256.214 | Test Loss [MAPE]: 820318.060 --time-- 12.978672742843628\n",
      "Epoch 345/500 | Train Loss: 226.098 | Test Loss: 264.153 | Test Loss [MAPE]: 813197.354 --time-- 12.958837032318115\n",
      "Epoch 346/500 | Train Loss: 225.286 | Test Loss: 258.097 | Test Loss [MAPE]: 821092.362 --time-- 12.95663571357727\n",
      "Epoch 347/500 | Train Loss: 210.544 | Test Loss: 254.067 | Test Loss [MAPE]: 796477.272 --time-- 12.958169221878052\n",
      "Epoch 348/500 | Train Loss: 218.433 | Test Loss: 255.638 | Test Loss [MAPE]: 866004.530 --time-- 12.956881284713745\n",
      "Epoch 349/500 | Train Loss: 223.527 | Test Loss: 261.362 | Test Loss [MAPE]: 835555.520 --time-- 13.010900974273682\n",
      "Epoch 350/500 | Train Loss: 234.148 | Test Loss: 289.386 | Test Loss [MAPE]: 915984.913 --time-- 13.012544631958008\n",
      "Epoch 351/500 | Train Loss: 221.866 | Test Loss: 259.008 | Test Loss [MAPE]: 856755.694 --time-- 12.991470098495483\n",
      "Epoch 352/500 | Train Loss: 236.183 | Test Loss: 264.460 | Test Loss [MAPE]: 883648.580 --time-- 12.991644859313965\n",
      "Epoch 353/500 | Train Loss: 234.060 | Test Loss: 324.843 | Test Loss [MAPE]: 968384.882 --time-- 12.987182378768921\n",
      "Epoch 354/500 | Train Loss: 244.122 | Test Loss: 250.650 | Test Loss [MAPE]: 813564.126 --time-- 12.985557079315186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500 | Train Loss: 225.138 | Test Loss: 248.207 | Test Loss [MAPE]: 819534.717 --time-- 12.98665165901184\n",
      "Epoch 356/500 | Train Loss: 205.089 | Test Loss: 255.533 | Test Loss [MAPE]: 846905.417 --time-- 12.989108085632324\n",
      "Epoch 357/500 | Train Loss: 222.219 | Test Loss: 260.761 | Test Loss [MAPE]: 870587.148 --time-- 12.991079807281494\n",
      "Epoch 358/500 | Train Loss: 209.055 | Test Loss: 259.025 | Test Loss [MAPE]: 842756.698 --time-- 12.99143385887146\n",
      "Epoch 359/500 | Train Loss: 230.051 | Test Loss: 250.066 | Test Loss [MAPE]: 834919.761 --time-- 12.987959146499634\n",
      "Epoch 360/500 | Train Loss: 218.559 | Test Loss: 251.083 | Test Loss [MAPE]: 823980.322 --time-- 12.986607789993286\n",
      "Epoch 361/500 | Train Loss: 211.037 | Test Loss: 239.482 | Test Loss [MAPE]: 792978.796 --time-- 12.991307020187378\n",
      "Epoch 362/500 | Train Loss: 223.624 | Test Loss: 260.238 | Test Loss [MAPE]: 834221.940 --time-- 12.986042261123657\n",
      "Epoch 363/500 | Train Loss: 215.976 | Test Loss: 245.290 | Test Loss [MAPE]: 830863.177 --time-- 12.98689866065979\n",
      "Epoch 364/500 | Train Loss: 205.613 | Test Loss: 237.272 | Test Loss [MAPE]: 782901.229 --time-- 12.991761445999146\n",
      "Epoch 365/500 | Train Loss: 216.249 | Test Loss: 261.106 | Test Loss [MAPE]: 843474.482 --time-- 12.988477230072021\n",
      "Epoch 366/500 | Train Loss: 212.861 | Test Loss: 258.730 | Test Loss [MAPE]: 857731.458 --time-- 12.98810362815857\n",
      "Epoch 367/500 | Train Loss: 224.439 | Test Loss: 235.714 | Test Loss [MAPE]: 783543.420 --time-- 12.987667083740234\n",
      "Epoch 368/500 | Train Loss: 218.010 | Test Loss: 246.192 | Test Loss [MAPE]: 784990.827 --time-- 12.989676237106323\n",
      "Epoch 369/500 | Train Loss: 205.122 | Test Loss: 233.329 | Test Loss [MAPE]: 776920.902 --time-- 12.9903724193573\n",
      "Epoch 370/500 | Train Loss: 211.164 | Test Loss: 297.275 | Test Loss [MAPE]: 1004687.334 --time-- 12.989555358886719\n",
      "Epoch 371/500 | Train Loss: 236.112 | Test Loss: 265.746 | Test Loss [MAPE]: 879860.879 --time-- 12.985519409179688\n",
      "Epoch 372/500 | Train Loss: 207.201 | Test Loss: 261.445 | Test Loss [MAPE]: 875142.564 --time-- 12.990255117416382\n",
      "Epoch 373/500 | Train Loss: 229.313 | Test Loss: 276.349 | Test Loss [MAPE]: 813959.769 --time-- 12.983083248138428\n",
      "Epoch 374/500 | Train Loss: 231.596 | Test Loss: 269.086 | Test Loss [MAPE]: 901435.140 --time-- 12.95874285697937\n",
      "Epoch 375/500 | Train Loss: 219.929 | Test Loss: 249.685 | Test Loss [MAPE]: 852252.126 --time-- 12.956218957901001\n",
      "Epoch 376/500 | Train Loss: 224.560 | Test Loss: 250.913 | Test Loss [MAPE]: 843553.294 --time-- 12.954853296279907\n",
      "Epoch 377/500 | Train Loss: 216.645 | Test Loss: 246.950 | Test Loss [MAPE]: 832885.434 --time-- 12.957377910614014\n",
      "Epoch 378/500 | Train Loss: 221.228 | Test Loss: 290.288 | Test Loss [MAPE]: 886945.997 --time-- 12.954654455184937\n",
      "Epoch 379/500 | Train Loss: 225.961 | Test Loss: 262.306 | Test Loss [MAPE]: 889980.816 --time-- 12.955893516540527\n",
      "Epoch 380/500 | Train Loss: 218.389 | Test Loss: 326.805 | Test Loss [MAPE]: 867856.432 --time-- 12.95546841621399\n",
      "Epoch 381/500 | Train Loss: 234.104 | Test Loss: 302.078 | Test Loss [MAPE]: 952349.987 --time-- 12.95977234840393\n",
      "Epoch 382/500 | Train Loss: 227.141 | Test Loss: 237.817 | Test Loss [MAPE]: 798533.527 --time-- 12.956292629241943\n",
      "Epoch 383/500 | Train Loss: 199.827 | Test Loss: 242.302 | Test Loss [MAPE]: 793467.754 --time-- 12.959345579147339\n",
      "Epoch 384/500 | Train Loss: 208.518 | Test Loss: 280.270 | Test Loss [MAPE]: 869009.806 --time-- 12.955254554748535\n",
      "Epoch 385/500 | Train Loss: 212.491 | Test Loss: 223.123 | Test Loss [MAPE]: 770151.480 --time-- 12.956437349319458\n",
      "Epoch 386/500 | Train Loss: 197.127 | Test Loss: 235.795 | Test Loss [MAPE]: 795637.320 --time-- 12.95933222770691\n",
      "Epoch 387/500 | Train Loss: 230.871 | Test Loss: 321.905 | Test Loss [MAPE]: 992376.242 --time-- 12.954882860183716\n",
      "Epoch 388/500 | Train Loss: 212.166 | Test Loss: 241.027 | Test Loss [MAPE]: 771469.488 --time-- 12.955779314041138\n",
      "Epoch 389/500 | Train Loss: 232.098 | Test Loss: 376.650 | Test Loss [MAPE]: 1000159.301 --time-- 12.961974143981934\n",
      "Epoch 390/500 | Train Loss: 265.364 | Test Loss: 245.338 | Test Loss [MAPE]: 817786.201 --time-- 12.95294976234436\n",
      "Epoch 391/500 | Train Loss: 238.257 | Test Loss: 241.655 | Test Loss [MAPE]: 802504.735 --time-- 12.957176208496094\n",
      "Epoch 392/500 | Train Loss: 205.266 | Test Loss: 219.877 | Test Loss [MAPE]: 742211.513 --time-- 12.95676565170288\n",
      "Epoch 393/500 | Train Loss: 192.595 | Test Loss: 239.831 | Test Loss [MAPE]: 801415.229 --time-- 12.958004474639893\n",
      "Epoch 394/500 | Train Loss: 198.074 | Test Loss: 251.517 | Test Loss [MAPE]: 817086.117 --time-- 12.959048509597778\n",
      "Epoch 395/500 | Train Loss: 209.912 | Test Loss: 237.257 | Test Loss [MAPE]: 781232.166 --time-- 12.957489252090454\n",
      "Epoch 396/500 | Train Loss: 199.966 | Test Loss: 240.340 | Test Loss [MAPE]: 805275.374 --time-- 12.956435203552246\n",
      "Epoch 397/500 | Train Loss: 216.186 | Test Loss: 257.033 | Test Loss [MAPE]: 789808.834 --time-- 12.956767082214355\n",
      "Epoch 398/500 | Train Loss: 236.312 | Test Loss: 296.241 | Test Loss [MAPE]: 923722.717 --time-- 12.955134391784668\n",
      "Epoch 399/500 | Train Loss: 251.711 | Test Loss: 263.104 | Test Loss [MAPE]: 837497.087 --time-- 13.00693392753601\n",
      "Epoch 400/500 | Train Loss: 205.524 | Test Loss: 245.104 | Test Loss [MAPE]: 824116.516 --time-- 13.014206171035767\n",
      "Epoch 401/500 | Train Loss: 201.192 | Test Loss: 242.872 | Test Loss [MAPE]: 820611.448 --time-- 13.013164043426514\n",
      "Epoch 402/500 | Train Loss: 212.606 | Test Loss: 266.012 | Test Loss [MAPE]: 845503.713 --time-- 13.013234376907349\n",
      "Epoch 403/500 | Train Loss: 212.208 | Test Loss: 248.783 | Test Loss [MAPE]: 834756.255 --time-- 12.955970525741577\n",
      "Epoch 404/500 | Train Loss: 199.921 | Test Loss: 261.060 | Test Loss [MAPE]: 849540.554 --time-- 12.961619138717651\n",
      "Epoch 405/500 | Train Loss: 198.727 | Test Loss: 278.122 | Test Loss [MAPE]: 765024.436 --time-- 12.962546348571777\n",
      "Epoch 406/500 | Train Loss: 230.463 | Test Loss: 250.366 | Test Loss [MAPE]: 818767.365 --time-- 12.959936141967773\n",
      "Epoch 407/500 | Train Loss: 216.370 | Test Loss: 243.425 | Test Loss [MAPE]: 812004.920 --time-- 12.9586501121521\n",
      "Epoch 408/500 | Train Loss: 202.609 | Test Loss: 257.910 | Test Loss [MAPE]: 885149.998 --time-- 12.961085081100464\n",
      "Epoch 409/500 | Train Loss: 207.513 | Test Loss: 250.303 | Test Loss [MAPE]: 826675.998 --time-- 12.961646795272827\n",
      "Epoch 410/500 | Train Loss: 199.205 | Test Loss: 229.972 | Test Loss [MAPE]: 771375.715 --time-- 12.96137547492981\n",
      "Epoch 411/500 | Train Loss: 195.866 | Test Loss: 241.026 | Test Loss [MAPE]: 791080.088 --time-- 12.966763973236084\n",
      "Epoch 412/500 | Train Loss: 215.550 | Test Loss: 234.469 | Test Loss [MAPE]: 808265.102 --time-- 12.959903955459595\n",
      "Epoch 413/500 | Train Loss: 210.533 | Test Loss: 267.619 | Test Loss [MAPE]: 855319.263 --time-- 12.961596488952637\n",
      "Epoch 414/500 | Train Loss: 216.183 | Test Loss: 272.108 | Test Loss [MAPE]: 900627.646 --time-- 12.959187984466553\n",
      "Epoch 415/500 | Train Loss: 223.767 | Test Loss: 257.529 | Test Loss [MAPE]: 792795.918 --time-- 12.962151765823364\n",
      "Epoch 416/500 | Train Loss: 201.396 | Test Loss: 255.017 | Test Loss [MAPE]: 853354.111 --time-- 12.95937705039978\n",
      "Epoch 417/500 | Train Loss: 207.972 | Test Loss: 241.641 | Test Loss [MAPE]: 817512.991 --time-- 12.959596157073975\n",
      "Epoch 418/500 | Train Loss: 249.804 | Test Loss: 245.794 | Test Loss [MAPE]: 832608.005 --time-- 12.959800004959106\n",
      "Epoch 419/500 | Train Loss: 196.759 | Test Loss: 219.751 | Test Loss [MAPE]: 725961.140 --time-- 12.959322214126587\n",
      "Epoch 420/500 | Train Loss: 186.330 | Test Loss: 243.239 | Test Loss [MAPE]: 730862.955 --time-- 12.960115432739258\n",
      "Epoch 421/500 | Train Loss: 189.059 | Test Loss: 236.786 | Test Loss [MAPE]: 798559.460 --time-- 12.961028337478638\n",
      "Epoch 422/500 | Train Loss: 197.355 | Test Loss: 230.080 | Test Loss [MAPE]: 739410.293 --time-- 12.957410097122192\n",
      "Epoch 423/500 | Train Loss: 189.992 | Test Loss: 238.311 | Test Loss [MAPE]: 774175.699 --time-- 12.960092782974243\n",
      "Epoch 424/500 | Train Loss: 208.570 | Test Loss: 250.509 | Test Loss [MAPE]: 844090.540 --time-- 12.962384939193726\n",
      "Epoch 425/500 | Train Loss: 208.356 | Test Loss: 237.155 | Test Loss [MAPE]: 812690.139 --time-- 12.958396434783936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500 | Train Loss: 207.037 | Test Loss: 238.921 | Test Loss [MAPE]: 809959.917 --time-- 12.957247734069824\n",
      "Epoch 427/500 | Train Loss: 206.604 | Test Loss: 231.718 | Test Loss [MAPE]: 759609.320 --time-- 12.962947607040405\n",
      "Epoch 428/500 | Train Loss: 189.664 | Test Loss: 263.440 | Test Loss [MAPE]: 877541.160 --time-- 12.961014032363892\n",
      "Epoch 429/500 | Train Loss: 204.362 | Test Loss: 223.377 | Test Loss [MAPE]: 754147.467 --time-- 12.956543207168579\n",
      "Epoch 430/500 | Train Loss: 183.070 | Test Loss: 257.499 | Test Loss [MAPE]: 734107.118 --time-- 12.9578697681427\n",
      "Epoch 431/500 | Train Loss: 211.246 | Test Loss: 272.817 | Test Loss [MAPE]: 838383.692 --time-- 12.96147894859314\n",
      "Epoch 432/500 | Train Loss: 212.110 | Test Loss: 245.543 | Test Loss [MAPE]: 808821.774 --time-- 12.95884656906128\n",
      "Epoch 433/500 | Train Loss: 205.288 | Test Loss: 250.069 | Test Loss [MAPE]: 805341.749 --time-- 12.961597919464111\n",
      "Epoch 434/500 | Train Loss: 191.559 | Test Loss: 237.895 | Test Loss [MAPE]: 792722.192 --time-- 12.957927942276001\n",
      "Epoch 435/500 | Train Loss: 220.280 | Test Loss: 294.100 | Test Loss [MAPE]: 987660.833 --time-- 12.958327054977417\n",
      "Epoch 436/500 | Train Loss: 284.000 | Test Loss: 251.062 | Test Loss [MAPE]: 839025.420 --time-- 12.953808784484863\n",
      "Epoch 437/500 | Train Loss: 223.420 | Test Loss: 260.702 | Test Loss [MAPE]: 815388.033 --time-- 12.959872245788574\n",
      "Epoch 438/500 | Train Loss: 234.291 | Test Loss: 234.604 | Test Loss [MAPE]: 736174.576 --time-- 12.95876431465149\n",
      "Epoch 439/500 | Train Loss: 193.896 | Test Loss: 219.083 | Test Loss [MAPE]: 737943.469 --time-- 12.95779275894165\n",
      "Epoch 440/500 | Train Loss: 184.634 | Test Loss: 222.939 | Test Loss [MAPE]: 760108.239 --time-- 12.963694095611572\n",
      "Epoch 441/500 | Train Loss: 197.766 | Test Loss: 228.746 | Test Loss [MAPE]: 785909.803 --time-- 12.961540937423706\n",
      "Epoch 442/500 | Train Loss: 186.589 | Test Loss: 216.275 | Test Loss [MAPE]: 721964.127 --time-- 12.963885068893433\n",
      "Epoch 443/500 | Train Loss: 241.632 | Test Loss: 286.223 | Test Loss [MAPE]: 840141.297 --time-- 12.959060192108154\n",
      "Epoch 444/500 | Train Loss: 208.767 | Test Loss: 242.686 | Test Loss [MAPE]: 772430.656 --time-- 12.95910906791687\n",
      "Epoch 445/500 | Train Loss: 200.083 | Test Loss: 270.886 | Test Loss [MAPE]: 796036.582 --time-- 12.959975004196167\n",
      "Epoch 446/500 | Train Loss: 184.215 | Test Loss: 220.345 | Test Loss [MAPE]: 739556.624 --time-- 12.96069073677063\n",
      "Epoch 447/500 | Train Loss: 183.434 | Test Loss: 248.177 | Test Loss [MAPE]: 831274.612 --time-- 12.962775945663452\n",
      "Epoch 448/500 | Train Loss: 213.373 | Test Loss: 253.349 | Test Loss [MAPE]: 819397.666 --time-- 12.964380741119385\n",
      "Epoch 449/500 | Train Loss: 197.318 | Test Loss: 249.032 | Test Loss [MAPE]: 763869.918 --time-- 12.962595462799072\n",
      "Epoch 450/500 | Train Loss: 202.676 | Test Loss: 221.042 | Test Loss [MAPE]: 725117.612 --time-- 12.960071563720703\n",
      "Epoch 451/500 | Train Loss: 191.803 | Test Loss: 221.244 | Test Loss [MAPE]: 736898.905 --time-- 12.957780838012695\n",
      "Epoch 452/500 | Train Loss: 190.384 | Test Loss: 245.798 | Test Loss [MAPE]: 790606.682 --time-- 12.958483934402466\n",
      "Epoch 453/500 | Train Loss: 190.167 | Test Loss: 249.452 | Test Loss [MAPE]: 795987.270 --time-- 12.95992374420166\n",
      "Epoch 454/500 | Train Loss: 212.546 | Test Loss: 246.621 | Test Loss [MAPE]: 787169.439 --time-- 12.962663412094116\n",
      "Epoch 455/500 | Train Loss: 200.568 | Test Loss: 244.912 | Test Loss [MAPE]: 814976.570 --time-- 12.961303472518921\n",
      "Epoch 456/500 | Train Loss: 211.956 | Test Loss: 239.958 | Test Loss [MAPE]: 774191.554 --time-- 12.961225509643555\n",
      "Epoch 457/500 | Train Loss: 194.543 | Test Loss: 235.753 | Test Loss [MAPE]: 775525.063 --time-- 12.95730209350586\n",
      "Epoch 458/500 | Train Loss: 187.913 | Test Loss: 232.434 | Test Loss [MAPE]: 786034.039 --time-- 12.959085464477539\n",
      "Epoch 459/500 | Train Loss: 189.658 | Test Loss: 248.116 | Test Loss [MAPE]: 735669.039 --time-- 12.958988904953003\n",
      "Epoch 460/500 | Train Loss: 201.278 | Test Loss: 246.352 | Test Loss [MAPE]: 835872.006 --time-- 12.964330196380615\n",
      "Epoch 461/500 | Train Loss: 187.608 | Test Loss: 257.173 | Test Loss [MAPE]: 777424.836 --time-- 12.961951971054077\n",
      "Epoch 462/500 | Train Loss: 222.119 | Test Loss: 320.383 | Test Loss [MAPE]: 845884.688 --time-- 12.961253881454468\n",
      "Epoch 463/500 | Train Loss: 208.202 | Test Loss: 244.896 | Test Loss [MAPE]: 781461.202 --time-- 12.961004972457886\n",
      "Epoch 464/500 | Train Loss: 192.943 | Test Loss: 218.073 | Test Loss [MAPE]: 741775.615 --time-- 12.96293330192566\n",
      "Epoch 465/500 | Train Loss: 193.764 | Test Loss: 226.677 | Test Loss [MAPE]: 752535.756 --time-- 12.956808090209961\n",
      "Epoch 466/500 | Train Loss: 178.243 | Test Loss: 219.769 | Test Loss [MAPE]: 755954.614 --time-- 12.958240270614624\n",
      "Epoch 467/500 | Train Loss: 198.621 | Test Loss: 253.415 | Test Loss [MAPE]: 851854.888 --time-- 12.960152626037598\n",
      "Epoch 468/500 | Train Loss: 189.419 | Test Loss: 220.197 | Test Loss [MAPE]: 720741.690 --time-- 12.956806898117065\n",
      "Epoch 469/500 | Train Loss: 197.271 | Test Loss: 261.096 | Test Loss [MAPE]: 788295.483 --time-- 12.957670211791992\n",
      "Epoch 470/500 | Train Loss: 203.872 | Test Loss: 281.834 | Test Loss [MAPE]: 812718.641 --time-- 12.961715698242188\n",
      "Epoch 471/500 | Train Loss: 261.119 | Test Loss: 242.102 | Test Loss [MAPE]: 761863.037 --time-- 12.949238300323486\n",
      "Epoch 472/500 | Train Loss: 213.140 | Test Loss: 268.463 | Test Loss [MAPE]: 830791.316 --time-- 12.957643032073975\n",
      "Epoch 473/500 | Train Loss: 196.644 | Test Loss: 216.124 | Test Loss [MAPE]: 721354.336 --time-- 12.959287405014038\n",
      "Epoch 474/500 | Train Loss: 192.955 | Test Loss: 230.666 | Test Loss [MAPE]: 776906.936 --time-- 12.958487510681152\n",
      "Epoch 475/500 | Train Loss: 185.097 | Test Loss: 248.699 | Test Loss [MAPE]: 813835.086 --time-- 12.95924711227417\n",
      "Epoch 476/500 | Train Loss: 189.049 | Test Loss: 248.390 | Test Loss [MAPE]: 836360.093 --time-- 12.964282035827637\n",
      "Epoch 477/500 | Train Loss: 216.341 | Test Loss: 253.992 | Test Loss [MAPE]: 800117.745 --time-- 12.957720756530762\n",
      "Epoch 478/500 | Train Loss: 209.686 | Test Loss: 217.091 | Test Loss [MAPE]: 727820.709 --time-- 12.956134796142578\n",
      "Epoch 479/500 | Train Loss: 193.222 | Test Loss: 214.403 | Test Loss [MAPE]: 726488.391 --time-- 12.959824085235596\n",
      "Epoch 480/500 | Train Loss: 183.166 | Test Loss: 249.419 | Test Loss [MAPE]: 821515.995 --time-- 12.965030670166016\n",
      "Epoch 481/500 | Train Loss: 207.805 | Test Loss: 234.624 | Test Loss [MAPE]: 787010.295 --time-- 12.961584091186523\n",
      "Epoch 482/500 | Train Loss: 192.142 | Test Loss: 239.232 | Test Loss [MAPE]: 789428.570 --time-- 12.959691286087036\n",
      "Epoch 483/500 | Train Loss: 198.747 | Test Loss: 231.529 | Test Loss [MAPE]: 790520.852 --time-- 12.959470272064209\n",
      "Epoch 484/500 | Train Loss: 192.343 | Test Loss: 227.222 | Test Loss [MAPE]: 765291.562 --time-- 12.961808204650879\n",
      "Epoch 485/500 | Train Loss: 187.650 | Test Loss: 259.622 | Test Loss [MAPE]: 812928.911 --time-- 12.960453748703003\n",
      "Epoch 486/500 | Train Loss: 219.945 | Test Loss: 221.722 | Test Loss [MAPE]: 729074.640 --time-- 12.958645582199097\n",
      "Epoch 487/500 | Train Loss: 202.420 | Test Loss: 255.502 | Test Loss [MAPE]: 858219.766 --time-- 12.957749366760254\n",
      "Epoch 488/500 | Train Loss: 190.930 | Test Loss: 234.944 | Test Loss [MAPE]: 795871.557 --time-- 12.956731796264648\n",
      "Epoch 489/500 | Train Loss: 187.150 | Test Loss: 262.390 | Test Loss [MAPE]: 866003.105 --time-- 12.962112665176392\n",
      "Epoch 490/500 | Train Loss: 194.239 | Test Loss: 246.597 | Test Loss [MAPE]: 760919.828 --time-- 12.956978559494019\n",
      "Epoch 491/500 | Train Loss: 182.934 | Test Loss: 258.752 | Test Loss [MAPE]: 782912.597 --time-- 12.960610628128052\n",
      "Epoch 492/500 | Train Loss: 230.265 | Test Loss: 283.451 | Test Loss [MAPE]: 790405.722 --time-- 12.95512843132019\n",
      "Epoch 493/500 | Train Loss: 198.661 | Test Loss: 218.661 | Test Loss [MAPE]: 730418.526 --time-- 12.956696271896362\n",
      "Epoch 494/500 | Train Loss: 168.664 | Test Loss: 222.540 | Test Loss [MAPE]: 720757.742 --time-- 12.956001281738281\n",
      "Epoch 495/500 | Train Loss: 193.909 | Test Loss: 229.209 | Test Loss [MAPE]: 770474.131 --time-- 12.95731234550476\n",
      "Epoch 496/500 | Train Loss: 183.918 | Test Loss: 225.771 | Test Loss [MAPE]: 767651.505 --time-- 12.95937466621399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/500 | Train Loss: 180.513 | Test Loss: 213.921 | Test Loss [MAPE]: 724861.628 --time-- 13.014082670211792\n",
      "Epoch 498/500 | Train Loss: 178.426 | Test Loss: 242.274 | Test Loss [MAPE]: 757575.953 --time-- 13.0079185962677\n",
      "Epoch 499/500 | Train Loss: 193.415 | Test Loss: 212.191 | Test Loss [MAPE]: 727460.730 --time-- 12.960513830184937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 00:36:12,489] Trial 21 finished with value: 442241.95236206055 and parameters: {'num_conv_layers': 4, 'kernel_size': 7, 'num_channels': 50, 'pooling_type': 'max', 'conv_stride': 1, 'feedforward_size': 114, 'pool_stride': 2, 'learning_rate': 0.002935580311532131, 'reg_strength': 0.0019503487226480208, 'bs': 108}. Best is trial 21 with value: 442241.95236206055.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500 | Train Loss: 183.494 | Test Loss: 225.627 | Test Loss [MAPE]: 694606.450 --time-- 12.960749864578247\n",
      "6498.69282245636\n",
      "Epoch 1/500 | Train Loss: 202504.399 | Test Loss: 5164.570 | Test Loss [MAPE]: 484117.464 --time-- 11.430615186691284\n",
      "Epoch 2/500 | Train Loss: 5106.929 | Test Loss: 5161.712 | Test Loss [MAPE]: 422847.316 --time-- 11.414045810699463\n",
      "Epoch 3/500 | Train Loss: 5106.346 | Test Loss: 5161.720 | Test Loss [MAPE]: 419489.913 --time-- 11.4166100025177\n",
      "Epoch 4/500 | Train Loss: 5106.362 | Test Loss: 5161.689 | Test Loss [MAPE]: 424435.459 --time-- 11.417201280593872\n",
      "Epoch 5/500 | Train Loss: 5106.346 | Test Loss: 5161.732 | Test Loss [MAPE]: 431563.656 --time-- 11.44171404838562\n",
      "Epoch 6/500 | Train Loss: 5106.347 | Test Loss: 5161.754 | Test Loss [MAPE]: 418813.711 --time-- 11.461723566055298\n",
      "Epoch 7/500 | Train Loss: 5106.376 | Test Loss: 5161.690 | Test Loss [MAPE]: 422250.663 --time-- 11.461268901824951\n",
      "Epoch 8/500 | Train Loss: 5106.370 | Test Loss: 5161.738 | Test Loss [MAPE]: 423451.001 --time-- 11.417380809783936\n",
      "Epoch 9/500 | Train Loss: 5106.392 | Test Loss: 5161.739 | Test Loss [MAPE]: 429299.413 --time-- 11.418272495269775\n",
      "Epoch 10/500 | Train Loss: 5106.387 | Test Loss: 5161.750 | Test Loss [MAPE]: 421543.445 --time-- 11.418031454086304\n",
      "Epoch 11/500 | Train Loss: 5106.400 | Test Loss: 5161.733 | Test Loss [MAPE]: 427354.289 --time-- 11.417058229446411\n",
      "Epoch 12/500 | Train Loss: 5106.420 | Test Loss: 5161.816 | Test Loss [MAPE]: 416860.760 --time-- 11.417932271957397\n",
      "Epoch 13/500 | Train Loss: 5106.423 | Test Loss: 5161.702 | Test Loss [MAPE]: 424916.183 --time-- 11.417844295501709\n",
      "Epoch 14/500 | Train Loss: 5106.399 | Test Loss: 5161.922 | Test Loss [MAPE]: 416873.658 --time-- 11.416357040405273\n",
      "Epoch 15/500 | Train Loss: 5106.449 | Test Loss: 5161.769 | Test Loss [MAPE]: 430439.510 --time-- 11.417759895324707\n",
      "Epoch 16/500 | Train Loss: 5106.438 | Test Loss: 5161.788 | Test Loss [MAPE]: 431647.322 --time-- 11.461155414581299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 00:39:27,733] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.448 | Test Loss: 5161.747 | Test Loss [MAPE]: 422131.214 --time-- 11.461019515991211\n",
      "Epoch 1/500 | Train Loss: 6001.660 | Test Loss: 5164.753 | Test Loss [MAPE]: 506345.299 --time-- 12.527381181716919\n",
      "Epoch 2/500 | Train Loss: 5107.326 | Test Loss: 5161.762 | Test Loss [MAPE]: 417199.605 --time-- 12.506397008895874\n",
      "Epoch 3/500 | Train Loss: 5106.344 | Test Loss: 5161.679 | Test Loss [MAPE]: 422325.088 --time-- 12.505140542984009\n",
      "Epoch 4/500 | Train Loss: 5106.307 | Test Loss: 5161.672 | Test Loss [MAPE]: 425487.180 --time-- 12.508030652999878\n",
      "Epoch 5/500 | Train Loss: 5106.309 | Test Loss: 5161.737 | Test Loss [MAPE]: 417519.301 --time-- 12.505151510238647\n",
      "Epoch 6/500 | Train Loss: 5106.330 | Test Loss: 5161.675 | Test Loss [MAPE]: 422580.919 --time-- 12.538773775100708\n",
      "Epoch 7/500 | Train Loss: 5106.310 | Test Loss: 5161.684 | Test Loss [MAPE]: 426156.237 --time-- 12.534169673919678\n",
      "Epoch 8/500 | Train Loss: 5106.345 | Test Loss: 5161.693 | Test Loss [MAPE]: 426341.412 --time-- 12.537640810012817\n",
      "Epoch 9/500 | Train Loss: 5106.354 | Test Loss: 5161.753 | Test Loss [MAPE]: 432583.620 --time-- 12.538381338119507\n",
      "Epoch 10/500 | Train Loss: 5106.330 | Test Loss: 5161.709 | Test Loss [MAPE]: 425012.820 --time-- 12.538625001907349\n",
      "Epoch 11/500 | Train Loss: 5106.341 | Test Loss: 5161.699 | Test Loss [MAPE]: 423313.553 --time-- 12.538250207901001\n",
      "Epoch 12/500 | Train Loss: 5106.338 | Test Loss: 5161.714 | Test Loss [MAPE]: 419874.483 --time-- 12.53508734703064\n",
      "Epoch 13/500 | Train Loss: 5106.341 | Test Loss: 5161.713 | Test Loss [MAPE]: 420987.709 --time-- 12.565989255905151\n",
      "Epoch 14/500 | Train Loss: 5106.339 | Test Loss: 5161.672 | Test Loss [MAPE]: 423728.161 --time-- 12.559362888336182\n",
      "Epoch 15/500 | Train Loss: 5106.351 | Test Loss: 5161.794 | Test Loss [MAPE]: 434734.999 --time-- 12.509737014770508\n",
      "Epoch 16/500 | Train Loss: 5106.358 | Test Loss: 5161.719 | Test Loss [MAPE]: 419265.569 --time-- 12.505673170089722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 00:43:01,468] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.343 | Test Loss: 5161.713 | Test Loss [MAPE]: 426686.057 --time-- 12.508217334747314\n",
      "Epoch 1/500 | Train Loss: 1899794.593 | Test Loss: 5167.078 | Test Loss [MAPE]: 464674.541 --time-- 3.9821910858154297\n",
      "Epoch 2/500 | Train Loss: 5108.094 | Test Loss: 5161.947 | Test Loss [MAPE]: 429089.207 --time-- 3.9434444904327393\n",
      "Epoch 3/500 | Train Loss: 5106.475 | Test Loss: 5161.810 | Test Loss [MAPE]: 425927.792 --time-- 3.944077253341675\n",
      "Epoch 4/500 | Train Loss: 5106.519 | Test Loss: 5161.794 | Test Loss [MAPE]: 421416.428 --time-- 3.9431612491607666\n",
      "Epoch 5/500 | Train Loss: 5106.542 | Test Loss: 5162.211 | Test Loss [MAPE]: 416982.793 --time-- 3.9427120685577393\n",
      "Epoch 6/500 | Train Loss: 5106.655 | Test Loss: 5162.129 | Test Loss [MAPE]: 445360.227 --time-- 3.9421331882476807\n",
      "Epoch 7/500 | Train Loss: 5106.599 | Test Loss: 5161.930 | Test Loss [MAPE]: 425961.360 --time-- 3.9462504386901855\n",
      "Epoch 8/500 | Train Loss: 5106.578 | Test Loss: 5161.938 | Test Loss [MAPE]: 432083.058 --time-- 3.943618059158325\n",
      "Epoch 9/500 | Train Loss: 5106.659 | Test Loss: 5161.877 | Test Loss [MAPE]: 426625.634 --time-- 3.9424524307250977\n",
      "Epoch 10/500 | Train Loss: 5106.602 | Test Loss: 5161.979 | Test Loss [MAPE]: 424169.700 --time-- 3.941197633743286\n",
      "Epoch 11/500 | Train Loss: 5106.681 | Test Loss: 5161.930 | Test Loss [MAPE]: 420243.668 --time-- 3.9477202892303467\n",
      "Epoch 12/500 | Train Loss: 5106.677 | Test Loss: 5161.985 | Test Loss [MAPE]: 436567.256 --time-- 3.9409875869750977\n",
      "Epoch 13/500 | Train Loss: 5106.623 | Test Loss: 5162.059 | Test Loss [MAPE]: 420556.989 --time-- 3.940566062927246\n",
      "Epoch 14/500 | Train Loss: 5106.791 | Test Loss: 5162.251 | Test Loss [MAPE]: 440680.657 --time-- 3.942673921585083\n",
      "Epoch 15/500 | Train Loss: 5106.959 | Test Loss: 5162.065 | Test Loss [MAPE]: 434852.969 --time-- 3.9455442428588867\n",
      "Epoch 16/500 | Train Loss: 5106.774 | Test Loss: 5161.983 | Test Loss [MAPE]: 434118.412 --time-- 3.939737319946289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 00:44:09,181] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.836 | Test Loss: 5162.031 | Test Loss [MAPE]: 433617.699 --time-- 3.944014072418213\n",
      "Epoch 1/500 | Train Loss: 5116.289 | Test Loss: 5161.401 | Test Loss [MAPE]: 432058.519 --time-- 3.2424449920654297\n",
      "Epoch 2/500 | Train Loss: 5094.523 | Test Loss: 5082.731 | Test Loss [MAPE]: 1004465.065 --time-- 3.2104687690734863\n",
      "Epoch 3/500 | Train Loss: 4545.561 | Test Loss: 4239.922 | Test Loss [MAPE]: 1741577.065 --time-- 3.210577964782715\n",
      "Epoch 4/500 | Train Loss: 4195.458 | Test Loss: 4184.025 | Test Loss [MAPE]: 1734333.901 --time-- 3.213456153869629\n",
      "Epoch 5/500 | Train Loss: 4158.232 | Test Loss: 4140.842 | Test Loss [MAPE]: 1945937.673 --time-- 3.2119622230529785\n",
      "Epoch 6/500 | Train Loss: 4120.568 | Test Loss: 4105.148 | Test Loss [MAPE]: 2384112.397 --time-- 3.216533899307251\n",
      "Epoch 7/500 | Train Loss: 4082.926 | Test Loss: 4070.375 | Test Loss [MAPE]: 2702826.125 --time-- 3.2106387615203857\n",
      "Epoch 8/500 | Train Loss: 4026.163 | Test Loss: 4001.398 | Test Loss [MAPE]: 2302718.472 --time-- 3.2171545028686523\n",
      "Epoch 9/500 | Train Loss: 3971.156 | Test Loss: 3956.488 | Test Loss [MAPE]: 2947154.813 --time-- 3.2182745933532715\n",
      "Epoch 10/500 | Train Loss: 3923.211 | Test Loss: 3895.553 | Test Loss [MAPE]: 2880963.117 --time-- 3.213787794113159\n",
      "Epoch 11/500 | Train Loss: 3859.118 | Test Loss: 3842.942 | Test Loss [MAPE]: 3695632.372 --time-- 3.250605821609497\n",
      "Epoch 12/500 | Train Loss: 3804.114 | Test Loss: 3773.189 | Test Loss [MAPE]: 3820437.549 --time-- 3.2600417137145996\n",
      "Epoch 13/500 | Train Loss: 3731.742 | Test Loss: 3707.249 | Test Loss [MAPE]: 4116096.199 --time-- 3.2600090503692627\n",
      "Epoch 14/500 | Train Loss: 3656.915 | Test Loss: 3619.258 | Test Loss [MAPE]: 4481428.321 --time-- 3.2592837810516357\n",
      "Epoch 15/500 | Train Loss: 3567.114 | Test Loss: 3519.327 | Test Loss [MAPE]: 4807347.502 --time-- 3.259652853012085\n",
      "Epoch 16/500 | Train Loss: 3456.332 | Test Loss: 3399.991 | Test Loss [MAPE]: 4786649.648 --time-- 3.2623302936553955\n",
      "Epoch 17/500 | Train Loss: 3343.663 | Test Loss: 3292.172 | Test Loss [MAPE]: 5556258.023 --time-- 3.260892629623413\n",
      "Epoch 18/500 | Train Loss: 3204.411 | Test Loss: 3142.037 | Test Loss [MAPE]: 5082547.933 --time-- 3.265458822250366\n",
      "Epoch 19/500 | Train Loss: 3056.469 | Test Loss: 2981.996 | Test Loss [MAPE]: 5170846.972 --time-- 3.259284496307373\n",
      "Epoch 20/500 | Train Loss: 2878.258 | Test Loss: 2815.945 | Test Loss [MAPE]: 5493423.864 --time-- 3.26304030418396\n",
      "Epoch 21/500 | Train Loss: 2703.323 | Test Loss: 2631.241 | Test Loss [MAPE]: 5061126.765 --time-- 3.260784387588501\n",
      "Epoch 22/500 | Train Loss: 2541.521 | Test Loss: 2490.375 | Test Loss [MAPE]: 4768615.279 --time-- 3.261927843093872\n",
      "Epoch 23/500 | Train Loss: 2416.966 | Test Loss: 2361.338 | Test Loss [MAPE]: 4610235.932 --time-- 3.2656283378601074\n",
      "Epoch 24/500 | Train Loss: 2309.111 | Test Loss: 2271.545 | Test Loss [MAPE]: 4516752.276 --time-- 3.2636659145355225\n",
      "Epoch 25/500 | Train Loss: 2207.012 | Test Loss: 2176.713 | Test Loss [MAPE]: 4206479.850 --time-- 3.260572910308838\n",
      "Epoch 26/500 | Train Loss: 2134.611 | Test Loss: 2117.175 | Test Loss [MAPE]: 4075110.571 --time-- 3.2624261379241943\n",
      "Epoch 27/500 | Train Loss: 2057.119 | Test Loss: 2033.069 | Test Loss [MAPE]: 3924984.670 --time-- 3.2620224952697754\n",
      "Epoch 28/500 | Train Loss: 1989.443 | Test Loss: 1984.111 | Test Loss [MAPE]: 3830168.417 --time-- 3.2627756595611572\n",
      "Epoch 29/500 | Train Loss: 1943.262 | Test Loss: 1926.962 | Test Loss [MAPE]: 3666659.272 --time-- 3.2642829418182373\n",
      "Epoch 30/500 | Train Loss: 1878.559 | Test Loss: 1873.662 | Test Loss [MAPE]: 3550162.354 --time-- 3.262094259262085\n",
      "Epoch 31/500 | Train Loss: 1830.575 | Test Loss: 1817.755 | Test Loss [MAPE]: 3459619.375 --time-- 3.259258985519409\n",
      "Epoch 32/500 | Train Loss: 1791.252 | Test Loss: 1789.198 | Test Loss [MAPE]: 3539636.935 --time-- 3.263014078140259\n",
      "Epoch 33/500 | Train Loss: 1753.232 | Test Loss: 1767.145 | Test Loss [MAPE]: 3680905.367 --time-- 3.263361930847168\n",
      "Epoch 34/500 | Train Loss: 1713.609 | Test Loss: 1704.125 | Test Loss [MAPE]: 3515191.331 --time-- 3.2614858150482178\n",
      "Epoch 35/500 | Train Loss: 1669.349 | Test Loss: 1667.120 | Test Loss [MAPE]: 3307697.576 --time-- 3.2596356868743896\n",
      "Epoch 36/500 | Train Loss: 1635.148 | Test Loss: 1635.365 | Test Loss [MAPE]: 3402712.195 --time-- 3.2611756324768066\n",
      "Epoch 37/500 | Train Loss: 1606.740 | Test Loss: 1602.358 | Test Loss [MAPE]: 3304189.709 --time-- 3.2608494758605957\n",
      "Epoch 38/500 | Train Loss: 1576.882 | Test Loss: 1580.117 | Test Loss [MAPE]: 3210446.275 --time-- 3.258263111114502\n",
      "Epoch 39/500 | Train Loss: 1546.813 | Test Loss: 1533.920 | Test Loss [MAPE]: 3231851.585 --time-- 3.25934100151062\n",
      "Epoch 40/500 | Train Loss: 1507.882 | Test Loss: 1499.909 | Test Loss [MAPE]: 3330051.205 --time-- 3.2621352672576904\n",
      "Epoch 41/500 | Train Loss: 1481.663 | Test Loss: 1497.810 | Test Loss [MAPE]: 3211932.354 --time-- 3.2634835243225098\n",
      "Epoch 42/500 | Train Loss: 1464.313 | Test Loss: 1470.106 | Test Loss [MAPE]: 3221196.774 --time-- 3.260657548904419\n",
      "Epoch 43/500 | Train Loss: 1427.971 | Test Loss: 1446.301 | Test Loss [MAPE]: 3408620.133 --time-- 3.262885570526123\n",
      "Epoch 44/500 | Train Loss: 1414.640 | Test Loss: 1421.827 | Test Loss [MAPE]: 3287691.359 --time-- 3.2619433403015137\n",
      "Epoch 45/500 | Train Loss: 1383.771 | Test Loss: 1389.587 | Test Loss [MAPE]: 3263330.916 --time-- 3.26322078704834\n",
      "Epoch 46/500 | Train Loss: 1359.643 | Test Loss: 1406.059 | Test Loss [MAPE]: 3154556.044 --time-- 3.2623984813690186\n",
      "Epoch 47/500 | Train Loss: 1344.733 | Test Loss: 1351.320 | Test Loss [MAPE]: 3181289.181 --time-- 3.2637274265289307\n",
      "Epoch 48/500 | Train Loss: 1318.961 | Test Loss: 1341.287 | Test Loss [MAPE]: 3226455.558 --time-- 3.2180867195129395\n",
      "Epoch 49/500 | Train Loss: 1295.496 | Test Loss: 1323.232 | Test Loss [MAPE]: 3141359.216 --time-- 3.2158689498901367\n",
      "Epoch 50/500 | Train Loss: 1290.646 | Test Loss: 1322.009 | Test Loss [MAPE]: 3139131.330 --time-- 3.2139155864715576\n",
      "Epoch 51/500 | Train Loss: 1278.107 | Test Loss: 1311.090 | Test Loss [MAPE]: 3033624.017 --time-- 3.217221975326538\n",
      "Epoch 52/500 | Train Loss: 1254.826 | Test Loss: 1272.280 | Test Loss [MAPE]: 2939146.466 --time-- 3.2134320735931396\n",
      "Epoch 53/500 | Train Loss: 1235.991 | Test Loss: 1248.039 | Test Loss [MAPE]: 2973601.909 --time-- 3.219453811645508\n",
      "Epoch 54/500 | Train Loss: 1228.225 | Test Loss: 1250.467 | Test Loss [MAPE]: 2921217.271 --time-- 3.217348575592041\n",
      "Epoch 55/500 | Train Loss: 1213.890 | Test Loss: 1227.167 | Test Loss [MAPE]: 2935876.352 --time-- 3.215259075164795\n",
      "Epoch 56/500 | Train Loss: 1211.989 | Test Loss: 1220.501 | Test Loss [MAPE]: 2929439.412 --time-- 3.213933229446411\n",
      "Epoch 57/500 | Train Loss: 1207.465 | Test Loss: 1225.931 | Test Loss [MAPE]: 2931657.908 --time-- 3.216341257095337\n",
      "Epoch 58/500 | Train Loss: 1186.884 | Test Loss: 1225.233 | Test Loss [MAPE]: 2972128.094 --time-- 3.2142860889434814\n",
      "Epoch 59/500 | Train Loss: 1173.871 | Test Loss: 1184.188 | Test Loss [MAPE]: 2883467.085 --time-- 3.21368145942688\n",
      "Epoch 60/500 | Train Loss: 1163.251 | Test Loss: 1185.910 | Test Loss [MAPE]: 2799592.437 --time-- 3.2902355194091797\n",
      "Epoch 61/500 | Train Loss: 1172.153 | Test Loss: 1177.240 | Test Loss [MAPE]: 2815934.935 --time-- 3.2888219356536865\n",
      "Epoch 62/500 | Train Loss: 1136.193 | Test Loss: 1173.269 | Test Loss [MAPE]: 2855604.811 --time-- 3.287450075149536\n",
      "Epoch 63/500 | Train Loss: 1135.442 | Test Loss: 1151.983 | Test Loss [MAPE]: 2762579.457 --time-- 3.2809958457946777\n",
      "Epoch 64/500 | Train Loss: 1119.769 | Test Loss: 1183.044 | Test Loss [MAPE]: 3083334.298 --time-- 3.282311201095581\n",
      "Epoch 65/500 | Train Loss: 1129.441 | Test Loss: 1137.810 | Test Loss [MAPE]: 2845246.949 --time-- 3.2876784801483154\n",
      "Epoch 66/500 | Train Loss: 1101.522 | Test Loss: 1130.966 | Test Loss [MAPE]: 2865796.637 --time-- 3.282238245010376\n",
      "Epoch 67/500 | Train Loss: 1089.925 | Test Loss: 1110.938 | Test Loss [MAPE]: 2684192.862 --time-- 3.2773971557617188\n",
      "Epoch 68/500 | Train Loss: 1086.336 | Test Loss: 1121.213 | Test Loss [MAPE]: 2809896.711 --time-- 3.2775466442108154\n",
      "Epoch 69/500 | Train Loss: 1079.563 | Test Loss: 1099.294 | Test Loss [MAPE]: 2751975.306 --time-- 3.2808480262756348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500 | Train Loss: 1058.940 | Test Loss: 1068.148 | Test Loss [MAPE]: 2687553.919 --time-- 3.2879879474639893\n",
      "Epoch 71/500 | Train Loss: 1047.778 | Test Loss: 1077.109 | Test Loss [MAPE]: 2707629.769 --time-- 3.2815101146698\n",
      "Epoch 72/500 | Train Loss: 1043.786 | Test Loss: 1053.334 | Test Loss [MAPE]: 2635592.900 --time-- 3.284292459487915\n",
      "Epoch 73/500 | Train Loss: 1036.152 | Test Loss: 1069.846 | Test Loss [MAPE]: 2686214.280 --time-- 3.282442808151245\n",
      "Epoch 74/500 | Train Loss: 1021.395 | Test Loss: 1051.613 | Test Loss [MAPE]: 2731913.315 --time-- 3.2817790508270264\n",
      "Epoch 75/500 | Train Loss: 1019.367 | Test Loss: 1030.296 | Test Loss [MAPE]: 2624313.635 --time-- 3.2844083309173584\n",
      "Epoch 76/500 | Train Loss: 1003.653 | Test Loss: 1050.751 | Test Loss [MAPE]: 2687687.138 --time-- 3.2806484699249268\n",
      "Epoch 77/500 | Train Loss: 1016.423 | Test Loss: 1055.085 | Test Loss [MAPE]: 2675936.468 --time-- 3.2830440998077393\n",
      "Epoch 78/500 | Train Loss: 989.577 | Test Loss: 1012.139 | Test Loss [MAPE]: 2468306.335 --time-- 3.290895462036133\n",
      "Epoch 79/500 | Train Loss: 979.641 | Test Loss: 1009.019 | Test Loss [MAPE]: 2554672.526 --time-- 3.2162420749664307\n",
      "Epoch 80/500 | Train Loss: 976.130 | Test Loss: 1002.912 | Test Loss [MAPE]: 2501945.863 --time-- 3.2157368659973145\n",
      "Epoch 81/500 | Train Loss: 984.483 | Test Loss: 986.891 | Test Loss [MAPE]: 2606173.166 --time-- 3.2188148498535156\n",
      "Epoch 82/500 | Train Loss: 972.928 | Test Loss: 989.914 | Test Loss [MAPE]: 2510843.246 --time-- 3.2189385890960693\n",
      "Epoch 83/500 | Train Loss: 951.173 | Test Loss: 980.383 | Test Loss [MAPE]: 2432419.520 --time-- 3.2188186645507812\n",
      "Epoch 84/500 | Train Loss: 950.099 | Test Loss: 992.004 | Test Loss [MAPE]: 2590760.488 --time-- 3.218888521194458\n",
      "Epoch 85/500 | Train Loss: 956.229 | Test Loss: 969.396 | Test Loss [MAPE]: 2428524.102 --time-- 3.2173593044281006\n",
      "Epoch 86/500 | Train Loss: 946.180 | Test Loss: 968.646 | Test Loss [MAPE]: 2519413.256 --time-- 3.2158610820770264\n",
      "Epoch 87/500 | Train Loss: 931.888 | Test Loss: 952.180 | Test Loss [MAPE]: 2450710.526 --time-- 3.2191689014434814\n",
      "Epoch 88/500 | Train Loss: 920.677 | Test Loss: 944.855 | Test Loss [MAPE]: 2369757.304 --time-- 3.215085029602051\n",
      "Epoch 89/500 | Train Loss: 917.599 | Test Loss: 970.790 | Test Loss [MAPE]: 2592421.150 --time-- 3.2133333683013916\n",
      "Epoch 90/500 | Train Loss: 912.858 | Test Loss: 931.660 | Test Loss [MAPE]: 2340857.278 --time-- 3.2128865718841553\n",
      "Epoch 91/500 | Train Loss: 910.569 | Test Loss: 943.199 | Test Loss [MAPE]: 2458089.474 --time-- 3.2170615196228027\n",
      "Epoch 92/500 | Train Loss: 905.315 | Test Loss: 933.458 | Test Loss [MAPE]: 2294121.489 --time-- 3.2180609703063965\n",
      "Epoch 93/500 | Train Loss: 894.172 | Test Loss: 919.142 | Test Loss [MAPE]: 2350426.303 --time-- 3.2153358459472656\n",
      "Epoch 94/500 | Train Loss: 887.531 | Test Loss: 919.441 | Test Loss [MAPE]: 2429395.045 --time-- 3.216676712036133\n",
      "Epoch 95/500 | Train Loss: 880.353 | Test Loss: 934.070 | Test Loss [MAPE]: 2381065.173 --time-- 3.2156224250793457\n",
      "Epoch 96/500 | Train Loss: 873.735 | Test Loss: 911.442 | Test Loss [MAPE]: 2263592.982 --time-- 3.216308116912842\n",
      "Epoch 97/500 | Train Loss: 869.063 | Test Loss: 900.855 | Test Loss [MAPE]: 2432815.142 --time-- 3.2169878482818604\n",
      "Epoch 98/500 | Train Loss: 869.061 | Test Loss: 905.438 | Test Loss [MAPE]: 2434029.215 --time-- 3.2168071269989014\n",
      "Epoch 99/500 | Train Loss: 860.974 | Test Loss: 895.782 | Test Loss [MAPE]: 2333287.506 --time-- 3.2160282135009766\n",
      "Epoch 100/500 | Train Loss: 860.428 | Test Loss: 895.780 | Test Loss [MAPE]: 2261871.963 --time-- 3.2165865898132324\n",
      "Epoch 101/500 | Train Loss: 854.091 | Test Loss: 892.308 | Test Loss [MAPE]: 2331174.017 --time-- 3.2181122303009033\n",
      "Epoch 102/500 | Train Loss: 849.207 | Test Loss: 869.993 | Test Loss [MAPE]: 2241519.053 --time-- 3.2172865867614746\n",
      "Epoch 103/500 | Train Loss: 846.852 | Test Loss: 880.054 | Test Loss [MAPE]: 2387166.862 --time-- 3.21657395362854\n",
      "Epoch 104/500 | Train Loss: 861.641 | Test Loss: 882.116 | Test Loss [MAPE]: 2167076.059 --time-- 3.2154500484466553\n",
      "Epoch 105/500 | Train Loss: 844.142 | Test Loss: 853.760 | Test Loss [MAPE]: 2186999.597 --time-- 3.2154626846313477\n",
      "Epoch 106/500 | Train Loss: 825.625 | Test Loss: 853.431 | Test Loss [MAPE]: 2335730.940 --time-- 3.215203046798706\n",
      "Epoch 107/500 | Train Loss: 829.464 | Test Loss: 861.801 | Test Loss [MAPE]: 2235948.815 --time-- 3.214138984680176\n",
      "Epoch 108/500 | Train Loss: 820.790 | Test Loss: 853.408 | Test Loss [MAPE]: 2249354.677 --time-- 3.217515230178833\n",
      "Epoch 109/500 | Train Loss: 818.963 | Test Loss: 848.944 | Test Loss [MAPE]: 2207631.551 --time-- 3.2151315212249756\n",
      "Epoch 110/500 | Train Loss: 816.536 | Test Loss: 831.665 | Test Loss [MAPE]: 2103305.201 --time-- 3.220592498779297\n",
      "Epoch 111/500 | Train Loss: 811.675 | Test Loss: 841.838 | Test Loss [MAPE]: 2244181.917 --time-- 3.2250771522521973\n",
      "Epoch 112/500 | Train Loss: 807.091 | Test Loss: 829.722 | Test Loss [MAPE]: 2209258.694 --time-- 3.215538740158081\n",
      "Epoch 113/500 | Train Loss: 798.104 | Test Loss: 819.551 | Test Loss [MAPE]: 2215532.434 --time-- 3.2168493270874023\n",
      "Epoch 114/500 | Train Loss: 797.773 | Test Loss: 838.684 | Test Loss [MAPE]: 2292432.084 --time-- 3.2184536457061768\n",
      "Epoch 115/500 | Train Loss: 795.512 | Test Loss: 826.824 | Test Loss [MAPE]: 2223876.026 --time-- 3.2169125080108643\n",
      "Epoch 116/500 | Train Loss: 795.223 | Test Loss: 812.867 | Test Loss [MAPE]: 2259681.818 --time-- 3.2146761417388916\n",
      "Epoch 117/500 | Train Loss: 786.971 | Test Loss: 805.272 | Test Loss [MAPE]: 2203636.030 --time-- 3.2151012420654297\n",
      "Epoch 118/500 | Train Loss: 773.428 | Test Loss: 800.063 | Test Loss [MAPE]: 2201752.941 --time-- 3.2175419330596924\n",
      "Epoch 119/500 | Train Loss: 776.529 | Test Loss: 799.643 | Test Loss [MAPE]: 2210519.589 --time-- 3.219726324081421\n",
      "Epoch 120/500 | Train Loss: 771.984 | Test Loss: 787.225 | Test Loss [MAPE]: 2195337.210 --time-- 3.2206318378448486\n",
      "Epoch 121/500 | Train Loss: 758.210 | Test Loss: 781.451 | Test Loss [MAPE]: 2178061.086 --time-- 3.2165889739990234\n",
      "Epoch 122/500 | Train Loss: 756.235 | Test Loss: 794.648 | Test Loss [MAPE]: 2169598.434 --time-- 3.2153713703155518\n",
      "Epoch 123/500 | Train Loss: 755.418 | Test Loss: 797.416 | Test Loss [MAPE]: 2209122.763 --time-- 3.2139601707458496\n",
      "Epoch 124/500 | Train Loss: 756.420 | Test Loss: 768.207 | Test Loss [MAPE]: 2144537.512 --time-- 3.2881922721862793\n",
      "Epoch 125/500 | Train Loss: 745.329 | Test Loss: 768.793 | Test Loss [MAPE]: 2123098.381 --time-- 3.286257266998291\n",
      "Epoch 126/500 | Train Loss: 736.152 | Test Loss: 773.876 | Test Loss [MAPE]: 2137838.786 --time-- 3.28265380859375\n",
      "Epoch 127/500 | Train Loss: 742.721 | Test Loss: 761.241 | Test Loss [MAPE]: 2212812.658 --time-- 3.2805702686309814\n",
      "Epoch 128/500 | Train Loss: 746.254 | Test Loss: 777.626 | Test Loss [MAPE]: 2248227.822 --time-- 3.283061981201172\n",
      "Epoch 129/500 | Train Loss: 741.644 | Test Loss: 757.558 | Test Loss [MAPE]: 2138473.085 --time-- 3.28206205368042\n",
      "Epoch 130/500 | Train Loss: 726.034 | Test Loss: 747.817 | Test Loss [MAPE]: 2080800.985 --time-- 3.2541069984436035\n",
      "Epoch 131/500 | Train Loss: 726.911 | Test Loss: 755.152 | Test Loss [MAPE]: 2098856.045 --time-- 3.2165677547454834\n",
      "Epoch 132/500 | Train Loss: 719.242 | Test Loss: 749.081 | Test Loss [MAPE]: 2185938.835 --time-- 3.2178306579589844\n",
      "Epoch 133/500 | Train Loss: 718.760 | Test Loss: 753.768 | Test Loss [MAPE]: 2224276.916 --time-- 3.216115713119507\n",
      "Epoch 134/500 | Train Loss: 717.539 | Test Loss: 753.246 | Test Loss [MAPE]: 2217317.298 --time-- 3.2183542251586914\n",
      "Epoch 135/500 | Train Loss: 716.972 | Test Loss: 744.943 | Test Loss [MAPE]: 2157114.161 --time-- 3.216630458831787\n",
      "Epoch 136/500 | Train Loss: 697.728 | Test Loss: 715.864 | Test Loss [MAPE]: 2105962.638 --time-- 3.2198164463043213\n",
      "Epoch 137/500 | Train Loss: 718.799 | Test Loss: 751.535 | Test Loss [MAPE]: 2267364.065 --time-- 3.2166976928710938\n",
      "Epoch 138/500 | Train Loss: 692.373 | Test Loss: 713.627 | Test Loss [MAPE]: 2128701.512 --time-- 3.218928098678589\n",
      "Epoch 139/500 | Train Loss: 687.646 | Test Loss: 714.031 | Test Loss [MAPE]: 2104793.442 --time-- 3.2162201404571533\n",
      "Epoch 140/500 | Train Loss: 688.308 | Test Loss: 701.188 | Test Loss [MAPE]: 2071295.550 --time-- 3.2213704586029053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/500 | Train Loss: 683.825 | Test Loss: 710.489 | Test Loss [MAPE]: 2118929.741 --time-- 3.2154428958892822\n",
      "Epoch 142/500 | Train Loss: 677.555 | Test Loss: 702.505 | Test Loss [MAPE]: 2153873.139 --time-- 3.2164688110351562\n",
      "Epoch 143/500 | Train Loss: 666.329 | Test Loss: 706.606 | Test Loss [MAPE]: 2039387.527 --time-- 3.216845989227295\n",
      "Epoch 144/500 | Train Loss: 675.984 | Test Loss: 706.045 | Test Loss [MAPE]: 2122917.353 --time-- 3.215440034866333\n",
      "Epoch 145/500 | Train Loss: 681.280 | Test Loss: 720.394 | Test Loss [MAPE]: 2077608.595 --time-- 3.2179834842681885\n",
      "Epoch 146/500 | Train Loss: 670.927 | Test Loss: 706.246 | Test Loss [MAPE]: 2184622.664 --time-- 3.2169148921966553\n",
      "Epoch 147/500 | Train Loss: 657.540 | Test Loss: 702.315 | Test Loss [MAPE]: 2132799.258 --time-- 3.2150793075561523\n",
      "Epoch 148/500 | Train Loss: 650.150 | Test Loss: 670.232 | Test Loss [MAPE]: 2032025.292 --time-- 3.216566801071167\n",
      "Epoch 149/500 | Train Loss: 640.181 | Test Loss: 675.339 | Test Loss [MAPE]: 1953238.447 --time-- 3.2158865928649902\n",
      "Epoch 150/500 | Train Loss: 654.110 | Test Loss: 697.468 | Test Loss [MAPE]: 2218447.024 --time-- 3.2132468223571777\n",
      "Epoch 151/500 | Train Loss: 636.863 | Test Loss: 644.713 | Test Loss [MAPE]: 1976277.114 --time-- 3.2125518321990967\n",
      "Epoch 152/500 | Train Loss: 636.647 | Test Loss: 655.066 | Test Loss [MAPE]: 2036397.163 --time-- 3.211826801300049\n",
      "Epoch 153/500 | Train Loss: 626.663 | Test Loss: 662.080 | Test Loss [MAPE]: 2014547.611 --time-- 3.2145228385925293\n",
      "Epoch 154/500 | Train Loss: 633.357 | Test Loss: 655.374 | Test Loss [MAPE]: 2055663.097 --time-- 3.2110867500305176\n",
      "Epoch 155/500 | Train Loss: 623.515 | Test Loss: 648.616 | Test Loss [MAPE]: 1956892.716 --time-- 3.2151222229003906\n",
      "Epoch 156/500 | Train Loss: 628.976 | Test Loss: 647.955 | Test Loss [MAPE]: 2097230.788 --time-- 3.214473009109497\n",
      "Epoch 157/500 | Train Loss: 622.592 | Test Loss: 636.080 | Test Loss [MAPE]: 1951905.556 --time-- 3.214935541152954\n",
      "Epoch 158/500 | Train Loss: 619.273 | Test Loss: 653.091 | Test Loss [MAPE]: 2028154.548 --time-- 3.2186121940612793\n",
      "Epoch 159/500 | Train Loss: 609.375 | Test Loss: 625.462 | Test Loss [MAPE]: 1949753.887 --time-- 3.2170979976654053\n",
      "Epoch 160/500 | Train Loss: 602.628 | Test Loss: 637.999 | Test Loss [MAPE]: 1998465.364 --time-- 3.216289758682251\n",
      "Epoch 161/500 | Train Loss: 602.927 | Test Loss: 627.797 | Test Loss [MAPE]: 1980359.262 --time-- 3.213412284851074\n",
      "Epoch 162/500 | Train Loss: 611.759 | Test Loss: 636.980 | Test Loss [MAPE]: 2044575.885 --time-- 3.215837240219116\n",
      "Epoch 163/500 | Train Loss: 597.632 | Test Loss: 621.220 | Test Loss [MAPE]: 1980611.096 --time-- 3.284827947616577\n",
      "Epoch 164/500 | Train Loss: 585.145 | Test Loss: 613.599 | Test Loss [MAPE]: 1981391.480 --time-- 3.2857444286346436\n",
      "Epoch 165/500 | Train Loss: 588.279 | Test Loss: 619.689 | Test Loss [MAPE]: 1968917.796 --time-- 3.280752182006836\n",
      "Epoch 166/500 | Train Loss: 590.889 | Test Loss: 606.525 | Test Loss [MAPE]: 1970101.572 --time-- 3.2845780849456787\n",
      "Epoch 167/500 | Train Loss: 579.144 | Test Loss: 607.348 | Test Loss [MAPE]: 1964985.546 --time-- 3.272008180618286\n",
      "Epoch 168/500 | Train Loss: 576.865 | Test Loss: 604.132 | Test Loss [MAPE]: 1931673.481 --time-- 3.280407428741455\n",
      "Epoch 169/500 | Train Loss: 578.981 | Test Loss: 613.522 | Test Loss [MAPE]: 1938915.188 --time-- 3.2915239334106445\n",
      "Epoch 170/500 | Train Loss: 580.060 | Test Loss: 599.885 | Test Loss [MAPE]: 1960766.048 --time-- 3.282660722732544\n",
      "Epoch 171/500 | Train Loss: 578.480 | Test Loss: 630.344 | Test Loss [MAPE]: 2005863.174 --time-- 3.282569408416748\n",
      "Epoch 172/500 | Train Loss: 578.833 | Test Loss: 589.322 | Test Loss [MAPE]: 1902287.109 --time-- 3.2773008346557617\n",
      "Epoch 173/500 | Train Loss: 560.420 | Test Loss: 596.328 | Test Loss [MAPE]: 1901311.391 --time-- 3.280129909515381\n",
      "Epoch 174/500 | Train Loss: 563.383 | Test Loss: 594.438 | Test Loss [MAPE]: 1930570.203 --time-- 3.281517505645752\n",
      "Epoch 175/500 | Train Loss: 567.080 | Test Loss: 588.302 | Test Loss [MAPE]: 1931286.142 --time-- 3.286923885345459\n",
      "Epoch 176/500 | Train Loss: 556.699 | Test Loss: 573.406 | Test Loss [MAPE]: 1884834.352 --time-- 3.2812130451202393\n",
      "Epoch 177/500 | Train Loss: 551.386 | Test Loss: 573.584 | Test Loss [MAPE]: 1894435.729 --time-- 3.2845396995544434\n",
      "Epoch 178/500 | Train Loss: 545.597 | Test Loss: 578.734 | Test Loss [MAPE]: 1912213.855 --time-- 3.2856342792510986\n",
      "Epoch 179/500 | Train Loss: 541.217 | Test Loss: 569.947 | Test Loss [MAPE]: 1902185.587 --time-- 3.2848236560821533\n",
      "Epoch 180/500 | Train Loss: 543.017 | Test Loss: 580.742 | Test Loss [MAPE]: 1882920.354 --time-- 3.284425973892212\n",
      "Epoch 181/500 | Train Loss: 550.667 | Test Loss: 548.630 | Test Loss [MAPE]: 1816258.696 --time-- 3.28479266166687\n",
      "Epoch 182/500 | Train Loss: 536.559 | Test Loss: 567.861 | Test Loss [MAPE]: 1878044.475 --time-- 3.282040596008301\n",
      "Epoch 183/500 | Train Loss: 536.650 | Test Loss: 589.570 | Test Loss [MAPE]: 1969169.009 --time-- 3.2936348915100098\n",
      "Epoch 184/500 | Train Loss: 543.931 | Test Loss: 557.478 | Test Loss [MAPE]: 1813594.190 --time-- 3.2824225425720215\n",
      "Epoch 185/500 | Train Loss: 519.920 | Test Loss: 547.306 | Test Loss [MAPE]: 1819763.922 --time-- 3.297063112258911\n",
      "Epoch 186/500 | Train Loss: 518.241 | Test Loss: 539.466 | Test Loss [MAPE]: 1806126.218 --time-- 3.2879185676574707\n",
      "Epoch 187/500 | Train Loss: 521.954 | Test Loss: 551.698 | Test Loss [MAPE]: 1864093.644 --time-- 3.282097339630127\n",
      "Epoch 188/500 | Train Loss: 530.449 | Test Loss: 558.313 | Test Loss [MAPE]: 1867740.508 --time-- 3.286726713180542\n",
      "Epoch 189/500 | Train Loss: 542.980 | Test Loss: 544.173 | Test Loss [MAPE]: 1798453.146 --time-- 3.283464193344116\n",
      "Epoch 190/500 | Train Loss: 522.312 | Test Loss: 544.568 | Test Loss [MAPE]: 1838596.237 --time-- 3.2862472534179688\n",
      "Epoch 191/500 | Train Loss: 518.709 | Test Loss: 523.083 | Test Loss [MAPE]: 1749611.447 --time-- 3.28208589553833\n",
      "Epoch 192/500 | Train Loss: 511.876 | Test Loss: 532.908 | Test Loss [MAPE]: 1758366.610 --time-- 3.2834904193878174\n",
      "Epoch 193/500 | Train Loss: 519.539 | Test Loss: 544.090 | Test Loss [MAPE]: 1807215.673 --time-- 3.2869110107421875\n",
      "Epoch 194/500 | Train Loss: 512.677 | Test Loss: 555.373 | Test Loss [MAPE]: 1888477.015 --time-- 3.289092540740967\n",
      "Epoch 195/500 | Train Loss: 505.058 | Test Loss: 538.659 | Test Loss [MAPE]: 1791187.362 --time-- 3.275449514389038\n",
      "Epoch 196/500 | Train Loss: 510.456 | Test Loss: 519.592 | Test Loss [MAPE]: 1746091.577 --time-- 3.2760331630706787\n",
      "Epoch 197/500 | Train Loss: 507.243 | Test Loss: 528.639 | Test Loss [MAPE]: 1784454.634 --time-- 3.2779316902160645\n",
      "Epoch 198/500 | Train Loss: 500.597 | Test Loss: 530.290 | Test Loss [MAPE]: 1798935.079 --time-- 3.2804861068725586\n",
      "Epoch 199/500 | Train Loss: 507.761 | Test Loss: 535.415 | Test Loss [MAPE]: 1753690.983 --time-- 3.219560384750366\n",
      "Epoch 200/500 | Train Loss: 506.310 | Test Loss: 521.578 | Test Loss [MAPE]: 1787311.185 --time-- 3.232712507247925\n",
      "Epoch 201/500 | Train Loss: 495.446 | Test Loss: 514.567 | Test Loss [MAPE]: 1731078.413 --time-- 3.2757670879364014\n",
      "Epoch 202/500 | Train Loss: 504.343 | Test Loss: 508.307 | Test Loss [MAPE]: 1737152.271 --time-- 3.2797436714172363\n",
      "Epoch 203/500 | Train Loss: 509.689 | Test Loss: 521.241 | Test Loss [MAPE]: 1761045.057 --time-- 3.2822890281677246\n",
      "Epoch 204/500 | Train Loss: 492.684 | Test Loss: 518.938 | Test Loss [MAPE]: 1731581.376 --time-- 3.2796881198883057\n",
      "Epoch 205/500 | Train Loss: 491.728 | Test Loss: 515.723 | Test Loss [MAPE]: 1742110.646 --time-- 3.275982618331909\n",
      "Epoch 206/500 | Train Loss: 485.609 | Test Loss: 513.760 | Test Loss [MAPE]: 1710678.798 --time-- 3.2822911739349365\n",
      "Epoch 207/500 | Train Loss: 485.019 | Test Loss: 524.776 | Test Loss [MAPE]: 1790740.476 --time-- 3.281956195831299\n",
      "Epoch 208/500 | Train Loss: 495.671 | Test Loss: 534.658 | Test Loss [MAPE]: 1788924.227 --time-- 3.2802376747131348\n",
      "Epoch 209/500 | Train Loss: 503.880 | Test Loss: 520.026 | Test Loss [MAPE]: 1767857.872 --time-- 3.280661106109619\n",
      "Epoch 210/500 | Train Loss: 485.289 | Test Loss: 504.618 | Test Loss [MAPE]: 1715552.145 --time-- 3.290811538696289\n",
      "Epoch 211/500 | Train Loss: 480.272 | Test Loss: 506.562 | Test Loss [MAPE]: 1689482.912 --time-- 3.2786834239959717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/500 | Train Loss: 488.513 | Test Loss: 510.820 | Test Loss [MAPE]: 1689350.335 --time-- 3.2834622859954834\n",
      "Epoch 213/500 | Train Loss: 494.289 | Test Loss: 513.741 | Test Loss [MAPE]: 1747489.808 --time-- 3.277803659439087\n",
      "Epoch 214/500 | Train Loss: 489.305 | Test Loss: 511.658 | Test Loss [MAPE]: 1727660.962 --time-- 3.278002977371216\n",
      "Epoch 215/500 | Train Loss: 475.614 | Test Loss: 491.942 | Test Loss [MAPE]: 1668628.753 --time-- 3.283137559890747\n",
      "Epoch 216/500 | Train Loss: 472.773 | Test Loss: 493.495 | Test Loss [MAPE]: 1681486.063 --time-- 3.218785524368286\n",
      "Epoch 217/500 | Train Loss: 473.366 | Test Loss: 513.536 | Test Loss [MAPE]: 1720751.081 --time-- 3.214416742324829\n",
      "Epoch 218/500 | Train Loss: 474.153 | Test Loss: 507.529 | Test Loss [MAPE]: 1701286.375 --time-- 3.215348482131958\n",
      "Epoch 219/500 | Train Loss: 472.784 | Test Loss: 497.525 | Test Loss [MAPE]: 1694186.550 --time-- 3.2455215454101562\n",
      "Epoch 220/500 | Train Loss: 461.579 | Test Loss: 496.102 | Test Loss [MAPE]: 1667427.810 --time-- 3.2804741859436035\n",
      "Epoch 221/500 | Train Loss: 473.574 | Test Loss: 494.683 | Test Loss [MAPE]: 1673276.442 --time-- 3.2177717685699463\n",
      "Epoch 222/500 | Train Loss: 469.800 | Test Loss: 495.457 | Test Loss [MAPE]: 1702646.467 --time-- 3.220846176147461\n",
      "Epoch 223/500 | Train Loss: 475.820 | Test Loss: 498.441 | Test Loss [MAPE]: 1689130.487 --time-- 3.2204439640045166\n",
      "Epoch 224/500 | Train Loss: 481.429 | Test Loss: 515.240 | Test Loss [MAPE]: 1739639.632 --time-- 3.2164499759674072\n",
      "Epoch 225/500 | Train Loss: 472.314 | Test Loss: 494.428 | Test Loss [MAPE]: 1684058.396 --time-- 3.217137336730957\n",
      "Epoch 226/500 | Train Loss: 470.056 | Test Loss: 514.601 | Test Loss [MAPE]: 1710756.982 --time-- 3.2149620056152344\n",
      "Epoch 227/500 | Train Loss: 470.001 | Test Loss: 496.643 | Test Loss [MAPE]: 1731145.327 --time-- 3.2158939838409424\n",
      "Epoch 228/500 | Train Loss: 473.113 | Test Loss: 498.195 | Test Loss [MAPE]: 1664268.879 --time-- 3.217048168182373\n",
      "Epoch 229/500 | Train Loss: 469.230 | Test Loss: 479.735 | Test Loss [MAPE]: 1629229.706 --time-- 3.214690923690796\n",
      "Epoch 230/500 | Train Loss: 457.734 | Test Loss: 502.701 | Test Loss [MAPE]: 1705366.332 --time-- 3.2186713218688965\n",
      "Epoch 231/500 | Train Loss: 460.179 | Test Loss: 476.775 | Test Loss [MAPE]: 1622954.040 --time-- 3.2166380882263184\n",
      "Epoch 232/500 | Train Loss: 463.223 | Test Loss: 479.111 | Test Loss [MAPE]: 1628630.267 --time-- 3.2177886962890625\n",
      "Epoch 233/500 | Train Loss: 459.615 | Test Loss: 477.453 | Test Loss [MAPE]: 1624920.025 --time-- 3.2225937843322754\n",
      "Epoch 234/500 | Train Loss: 473.649 | Test Loss: 468.690 | Test Loss [MAPE]: 1592811.457 --time-- 3.2274341583251953\n",
      "Epoch 235/500 | Train Loss: 464.263 | Test Loss: 474.131 | Test Loss [MAPE]: 1606240.567 --time-- 3.2156710624694824\n",
      "Epoch 236/500 | Train Loss: 460.361 | Test Loss: 496.802 | Test Loss [MAPE]: 1694893.647 --time-- 3.220914363861084\n",
      "Epoch 237/500 | Train Loss: 455.875 | Test Loss: 471.840 | Test Loss [MAPE]: 1619016.261 --time-- 3.2144103050231934\n",
      "Epoch 238/500 | Train Loss: 450.289 | Test Loss: 483.317 | Test Loss [MAPE]: 1639822.929 --time-- 3.2157363891601562\n",
      "Epoch 239/500 | Train Loss: 451.476 | Test Loss: 466.269 | Test Loss [MAPE]: 1594483.177 --time-- 3.2217071056365967\n",
      "Epoch 240/500 | Train Loss: 451.300 | Test Loss: 485.829 | Test Loss [MAPE]: 1636240.633 --time-- 3.2163426876068115\n",
      "Epoch 241/500 | Train Loss: 457.779 | Test Loss: 482.224 | Test Loss [MAPE]: 1569368.221 --time-- 3.2200570106506348\n",
      "Epoch 242/500 | Train Loss: 449.823 | Test Loss: 465.828 | Test Loss [MAPE]: 1574800.667 --time-- 3.2177305221557617\n",
      "Epoch 243/500 | Train Loss: 448.089 | Test Loss: 465.389 | Test Loss [MAPE]: 1573410.422 --time-- 3.2131733894348145\n",
      "Epoch 244/500 | Train Loss: 447.582 | Test Loss: 475.391 | Test Loss [MAPE]: 1609339.992 --time-- 3.219104766845703\n",
      "Epoch 245/500 | Train Loss: 445.630 | Test Loss: 467.757 | Test Loss [MAPE]: 1571273.811 --time-- 3.2193713188171387\n",
      "Epoch 246/500 | Train Loss: 450.365 | Test Loss: 468.273 | Test Loss [MAPE]: 1589190.647 --time-- 3.2191882133483887\n",
      "Epoch 247/500 | Train Loss: 446.053 | Test Loss: 491.950 | Test Loss [MAPE]: 1679592.870 --time-- 3.2121667861938477\n",
      "Epoch 248/500 | Train Loss: 460.211 | Test Loss: 492.154 | Test Loss [MAPE]: 1669493.448 --time-- 3.2211976051330566\n",
      "Epoch 249/500 | Train Loss: 442.830 | Test Loss: 459.168 | Test Loss [MAPE]: 1564959.734 --time-- 3.2187399864196777\n",
      "Epoch 250/500 | Train Loss: 433.135 | Test Loss: 466.525 | Test Loss [MAPE]: 1587141.882 --time-- 3.2177913188934326\n",
      "Epoch 251/500 | Train Loss: 434.778 | Test Loss: 459.972 | Test Loss [MAPE]: 1570159.892 --time-- 3.216454267501831\n",
      "Epoch 252/500 | Train Loss: 447.397 | Test Loss: 461.875 | Test Loss [MAPE]: 1569728.853 --time-- 3.214853525161743\n",
      "Epoch 253/500 | Train Loss: 442.832 | Test Loss: 455.903 | Test Loss [MAPE]: 1555852.154 --time-- 3.218470335006714\n",
      "Epoch 254/500 | Train Loss: 438.199 | Test Loss: 468.424 | Test Loss [MAPE]: 1581198.583 --time-- 3.2260735034942627\n",
      "Epoch 255/500 | Train Loss: 436.847 | Test Loss: 462.173 | Test Loss [MAPE]: 1557561.203 --time-- 3.2194788455963135\n",
      "Epoch 256/500 | Train Loss: 444.499 | Test Loss: 474.103 | Test Loss [MAPE]: 1586786.836 --time-- 3.2170326709747314\n",
      "Epoch 257/500 | Train Loss: 452.024 | Test Loss: 463.002 | Test Loss [MAPE]: 1574009.858 --time-- 3.2206640243530273\n",
      "Epoch 258/500 | Train Loss: 440.066 | Test Loss: 462.835 | Test Loss [MAPE]: 1569804.472 --time-- 3.213526964187622\n",
      "Epoch 259/500 | Train Loss: 439.529 | Test Loss: 462.612 | Test Loss [MAPE]: 1570022.307 --time-- 3.214881658554077\n",
      "Epoch 260/500 | Train Loss: 434.842 | Test Loss: 479.154 | Test Loss [MAPE]: 1597759.673 --time-- 3.2161307334899902\n",
      "Epoch 261/500 | Train Loss: 436.305 | Test Loss: 466.192 | Test Loss [MAPE]: 1591678.215 --time-- 3.215947389602661\n",
      "Epoch 262/500 | Train Loss: 433.953 | Test Loss: 474.372 | Test Loss [MAPE]: 1611647.798 --time-- 3.2165939807891846\n",
      "Epoch 263/500 | Train Loss: 435.926 | Test Loss: 479.637 | Test Loss [MAPE]: 1627187.999 --time-- 3.215196132659912\n",
      "Epoch 264/500 | Train Loss: 434.606 | Test Loss: 448.040 | Test Loss [MAPE]: 1537208.797 --time-- 3.2146594524383545\n",
      "Epoch 265/500 | Train Loss: 440.307 | Test Loss: 464.975 | Test Loss [MAPE]: 1586628.462 --time-- 3.217341423034668\n",
      "Epoch 266/500 | Train Loss: 428.947 | Test Loss: 449.041 | Test Loss [MAPE]: 1537465.568 --time-- 3.2180023193359375\n",
      "Epoch 267/500 | Train Loss: 425.400 | Test Loss: 455.682 | Test Loss [MAPE]: 1499470.150 --time-- 3.2183034420013428\n",
      "Epoch 268/500 | Train Loss: 424.227 | Test Loss: 447.732 | Test Loss [MAPE]: 1515494.191 --time-- 3.21795654296875\n",
      "Epoch 269/500 | Train Loss: 427.701 | Test Loss: 457.922 | Test Loss [MAPE]: 1547727.469 --time-- 3.2137508392333984\n",
      "Epoch 270/500 | Train Loss: 430.415 | Test Loss: 445.404 | Test Loss [MAPE]: 1524670.840 --time-- 3.217726230621338\n",
      "Epoch 271/500 | Train Loss: 427.517 | Test Loss: 473.440 | Test Loss [MAPE]: 1573253.788 --time-- 3.217586040496826\n",
      "Epoch 272/500 | Train Loss: 429.216 | Test Loss: 448.687 | Test Loss [MAPE]: 1507557.124 --time-- 3.2195589542388916\n",
      "Epoch 273/500 | Train Loss: 414.483 | Test Loss: 436.292 | Test Loss [MAPE]: 1466186.430 --time-- 3.2186923027038574\n",
      "Epoch 274/500 | Train Loss: 423.518 | Test Loss: 466.509 | Test Loss [MAPE]: 1584248.282 --time-- 3.2159371376037598\n",
      "Epoch 275/500 | Train Loss: 440.237 | Test Loss: 439.293 | Test Loss [MAPE]: 1491550.583 --time-- 3.2186007499694824\n",
      "Epoch 276/500 | Train Loss: 416.074 | Test Loss: 452.103 | Test Loss [MAPE]: 1515332.199 --time-- 3.216641426086426\n",
      "Epoch 277/500 | Train Loss: 427.913 | Test Loss: 449.260 | Test Loss [MAPE]: 1501132.727 --time-- 3.215660810470581\n",
      "Epoch 278/500 | Train Loss: 432.459 | Test Loss: 463.456 | Test Loss [MAPE]: 1540035.053 --time-- 3.2142133712768555\n",
      "Epoch 279/500 | Train Loss: 430.851 | Test Loss: 448.385 | Test Loss [MAPE]: 1497729.238 --time-- 3.2175965309143066\n",
      "Epoch 280/500 | Train Loss: 428.809 | Test Loss: 435.552 | Test Loss [MAPE]: 1487901.188 --time-- 3.2151410579681396\n",
      "Epoch 281/500 | Train Loss: 412.128 | Test Loss: 469.589 | Test Loss [MAPE]: 1561982.349 --time-- 3.221790313720703\n",
      "Epoch 282/500 | Train Loss: 425.385 | Test Loss: 444.534 | Test Loss [MAPE]: 1511832.262 --time-- 3.217667818069458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/500 | Train Loss: 412.957 | Test Loss: 446.239 | Test Loss [MAPE]: 1513104.329 --time-- 3.2176084518432617\n",
      "Epoch 284/500 | Train Loss: 421.173 | Test Loss: 433.606 | Test Loss [MAPE]: 1447290.175 --time-- 3.218380928039551\n",
      "Epoch 285/500 | Train Loss: 414.994 | Test Loss: 424.792 | Test Loss [MAPE]: 1451176.389 --time-- 3.2185235023498535\n",
      "Epoch 286/500 | Train Loss: 413.207 | Test Loss: 448.886 | Test Loss [MAPE]: 1518973.900 --time-- 3.2138826847076416\n",
      "Epoch 287/500 | Train Loss: 425.907 | Test Loss: 449.047 | Test Loss [MAPE]: 1511083.504 --time-- 3.215033531188965\n",
      "Epoch 288/500 | Train Loss: 418.624 | Test Loss: 437.927 | Test Loss [MAPE]: 1467927.734 --time-- 3.2164084911346436\n",
      "Epoch 289/500 | Train Loss: 411.040 | Test Loss: 438.883 | Test Loss [MAPE]: 1469495.969 --time-- 3.214586019515991\n",
      "Epoch 290/500 | Train Loss: 407.701 | Test Loss: 443.597 | Test Loss [MAPE]: 1472089.975 --time-- 3.2153542041778564\n",
      "Epoch 291/500 | Train Loss: 418.202 | Test Loss: 441.437 | Test Loss [MAPE]: 1489949.296 --time-- 3.2165071964263916\n",
      "Epoch 292/500 | Train Loss: 421.971 | Test Loss: 432.775 | Test Loss [MAPE]: 1442888.476 --time-- 3.2171971797943115\n",
      "Epoch 293/500 | Train Loss: 405.750 | Test Loss: 429.238 | Test Loss [MAPE]: 1423746.493 --time-- 3.2178125381469727\n",
      "Epoch 294/500 | Train Loss: 407.122 | Test Loss: 438.056 | Test Loss [MAPE]: 1482734.555 --time-- 3.220977544784546\n",
      "Epoch 295/500 | Train Loss: 417.530 | Test Loss: 435.806 | Test Loss [MAPE]: 1487091.839 --time-- 3.2196550369262695\n",
      "Epoch 296/500 | Train Loss: 407.666 | Test Loss: 432.754 | Test Loss [MAPE]: 1444268.124 --time-- 3.216251850128174\n",
      "Epoch 297/500 | Train Loss: 406.509 | Test Loss: 418.884 | Test Loss [MAPE]: 1405178.617 --time-- 3.2137346267700195\n",
      "Epoch 298/500 | Train Loss: 404.603 | Test Loss: 427.280 | Test Loss [MAPE]: 1454744.384 --time-- 3.2171788215637207\n",
      "Epoch 299/500 | Train Loss: 409.693 | Test Loss: 438.225 | Test Loss [MAPE]: 1480998.981 --time-- 3.212916374206543\n",
      "Epoch 300/500 | Train Loss: 404.765 | Test Loss: 412.749 | Test Loss [MAPE]: 1393843.826 --time-- 3.216583013534546\n",
      "Epoch 301/500 | Train Loss: 410.231 | Test Loss: 437.411 | Test Loss [MAPE]: 1485845.720 --time-- 3.216794967651367\n",
      "Epoch 302/500 | Train Loss: 421.503 | Test Loss: 450.927 | Test Loss [MAPE]: 1504753.609 --time-- 3.2169430255889893\n",
      "Epoch 303/500 | Train Loss: 414.195 | Test Loss: 459.002 | Test Loss [MAPE]: 1549440.798 --time-- 3.2153868675231934\n",
      "Epoch 304/500 | Train Loss: 399.618 | Test Loss: 413.208 | Test Loss [MAPE]: 1399534.671 --time-- 3.218930244445801\n",
      "Epoch 305/500 | Train Loss: 393.143 | Test Loss: 423.615 | Test Loss [MAPE]: 1438002.586 --time-- 3.217930555343628\n",
      "Epoch 306/500 | Train Loss: 404.034 | Test Loss: 447.530 | Test Loss [MAPE]: 1499194.409 --time-- 3.2178053855895996\n",
      "Epoch 307/500 | Train Loss: 414.664 | Test Loss: 449.660 | Test Loss [MAPE]: 1500415.654 --time-- 3.2165892124176025\n",
      "Epoch 308/500 | Train Loss: 412.284 | Test Loss: 449.185 | Test Loss [MAPE]: 1495746.535 --time-- 3.2205424308776855\n",
      "Epoch 309/500 | Train Loss: 409.217 | Test Loss: 431.169 | Test Loss [MAPE]: 1457788.245 --time-- 3.2184789180755615\n",
      "Epoch 310/500 | Train Loss: 394.950 | Test Loss: 420.962 | Test Loss [MAPE]: 1438388.307 --time-- 3.219216823577881\n",
      "Epoch 311/500 | Train Loss: 391.045 | Test Loss: 421.098 | Test Loss [MAPE]: 1442564.351 --time-- 3.2145578861236572\n",
      "Epoch 312/500 | Train Loss: 399.605 | Test Loss: 416.069 | Test Loss [MAPE]: 1404714.570 --time-- 3.2149555683135986\n",
      "Epoch 313/500 | Train Loss: 401.251 | Test Loss: 420.346 | Test Loss [MAPE]: 1400660.337 --time-- 3.219465732574463\n",
      "Epoch 314/500 | Train Loss: 402.768 | Test Loss: 428.940 | Test Loss [MAPE]: 1441829.993 --time-- 3.2164437770843506\n",
      "Epoch 315/500 | Train Loss: 391.050 | Test Loss: 400.191 | Test Loss [MAPE]: 1370254.771 --time-- 3.2132859230041504\n",
      "Epoch 316/500 | Train Loss: 399.895 | Test Loss: 437.481 | Test Loss [MAPE]: 1445881.415 --time-- 3.215283155441284\n",
      "Epoch 317/500 | Train Loss: 394.633 | Test Loss: 417.673 | Test Loss [MAPE]: 1397740.378 --time-- 3.214569330215454\n",
      "Epoch 318/500 | Train Loss: 406.492 | Test Loss: 425.133 | Test Loss [MAPE]: 1439109.566 --time-- 3.2133052349090576\n",
      "Epoch 319/500 | Train Loss: 394.660 | Test Loss: 425.647 | Test Loss [MAPE]: 1439076.042 --time-- 3.2180368900299072\n",
      "Epoch 320/500 | Train Loss: 393.371 | Test Loss: 413.733 | Test Loss [MAPE]: 1369555.408 --time-- 3.2136900424957275\n",
      "Epoch 321/500 | Train Loss: 391.721 | Test Loss: 422.463 | Test Loss [MAPE]: 1425009.604 --time-- 3.213635206222534\n",
      "Epoch 322/500 | Train Loss: 391.803 | Test Loss: 439.091 | Test Loss [MAPE]: 1462639.009 --time-- 3.213878631591797\n",
      "Epoch 323/500 | Train Loss: 398.547 | Test Loss: 429.657 | Test Loss [MAPE]: 1434182.446 --time-- 3.2143306732177734\n",
      "Epoch 324/500 | Train Loss: 394.187 | Test Loss: 412.767 | Test Loss [MAPE]: 1375444.627 --time-- 3.215975522994995\n",
      "Epoch 325/500 | Train Loss: 389.441 | Test Loss: 402.551 | Test Loss [MAPE]: 1364008.824 --time-- 3.2174875736236572\n",
      "Epoch 326/500 | Train Loss: 404.849 | Test Loss: 412.746 | Test Loss [MAPE]: 1412394.642 --time-- 3.215000867843628\n",
      "Epoch 327/500 | Train Loss: 395.700 | Test Loss: 412.899 | Test Loss [MAPE]: 1371183.903 --time-- 3.2150516510009766\n",
      "Epoch 328/500 | Train Loss: 397.960 | Test Loss: 413.304 | Test Loss [MAPE]: 1389709.919 --time-- 3.2145087718963623\n",
      "Epoch 329/500 | Train Loss: 389.731 | Test Loss: 419.268 | Test Loss [MAPE]: 1419643.253 --time-- 3.2160606384277344\n",
      "Epoch 330/500 | Train Loss: 393.197 | Test Loss: 442.226 | Test Loss [MAPE]: 1487435.834 --time-- 3.215622901916504\n",
      "Epoch 331/500 | Train Loss: 405.509 | Test Loss: 425.314 | Test Loss [MAPE]: 1434517.643 --time-- 3.284118890762329\n",
      "Epoch 332/500 | Train Loss: 386.871 | Test Loss: 408.961 | Test Loss [MAPE]: 1390080.889 --time-- 3.2170088291168213\n",
      "Epoch 333/500 | Train Loss: 390.316 | Test Loss: 414.855 | Test Loss [MAPE]: 1387149.157 --time-- 3.21750545501709\n",
      "Epoch 334/500 | Train Loss: 387.745 | Test Loss: 406.824 | Test Loss [MAPE]: 1374546.752 --time-- 3.2184174060821533\n",
      "Epoch 335/500 | Train Loss: 393.493 | Test Loss: 422.504 | Test Loss [MAPE]: 1413671.921 --time-- 3.2171127796173096\n",
      "Epoch 336/500 | Train Loss: 383.439 | Test Loss: 404.038 | Test Loss [MAPE]: 1381953.588 --time-- 3.2179758548736572\n",
      "Epoch 337/500 | Train Loss: 392.881 | Test Loss: 417.802 | Test Loss [MAPE]: 1424610.098 --time-- 3.2177579402923584\n",
      "Epoch 338/500 | Train Loss: 389.181 | Test Loss: 423.101 | Test Loss [MAPE]: 1447796.045 --time-- 3.216057062149048\n",
      "Epoch 339/500 | Train Loss: 398.094 | Test Loss: 417.723 | Test Loss [MAPE]: 1401084.139 --time-- 3.215766668319702\n",
      "Epoch 340/500 | Train Loss: 388.855 | Test Loss: 399.119 | Test Loss [MAPE]: 1334059.663 --time-- 3.221691370010376\n",
      "Epoch 341/500 | Train Loss: 376.988 | Test Loss: 410.151 | Test Loss [MAPE]: 1386442.457 --time-- 3.216991424560547\n",
      "Epoch 342/500 | Train Loss: 378.026 | Test Loss: 411.399 | Test Loss [MAPE]: 1390079.637 --time-- 3.213157892227173\n",
      "Epoch 343/500 | Train Loss: 380.851 | Test Loss: 395.260 | Test Loss [MAPE]: 1336267.181 --time-- 3.2177186012268066\n",
      "Epoch 344/500 | Train Loss: 381.759 | Test Loss: 409.829 | Test Loss [MAPE]: 1386889.855 --time-- 3.217010021209717\n",
      "Epoch 345/500 | Train Loss: 385.013 | Test Loss: 405.409 | Test Loss [MAPE]: 1375810.982 --time-- 3.2142670154571533\n",
      "Epoch 346/500 | Train Loss: 392.696 | Test Loss: 422.231 | Test Loss [MAPE]: 1409581.291 --time-- 3.21427059173584\n",
      "Epoch 347/500 | Train Loss: 378.216 | Test Loss: 395.091 | Test Loss [MAPE]: 1343012.029 --time-- 3.219299793243408\n",
      "Epoch 348/500 | Train Loss: 392.403 | Test Loss: 397.311 | Test Loss [MAPE]: 1346955.571 --time-- 3.218167543411255\n",
      "Epoch 349/500 | Train Loss: 372.896 | Test Loss: 400.299 | Test Loss [MAPE]: 1345542.449 --time-- 3.216493606567383\n",
      "Epoch 350/500 | Train Loss: 375.928 | Test Loss: 420.901 | Test Loss [MAPE]: 1415916.209 --time-- 3.213002920150757\n",
      "Epoch 351/500 | Train Loss: 390.806 | Test Loss: 393.777 | Test Loss [MAPE]: 1331948.148 --time-- 3.214033365249634\n",
      "Epoch 352/500 | Train Loss: 380.870 | Test Loss: 402.741 | Test Loss [MAPE]: 1356728.594 --time-- 3.2117788791656494\n",
      "Epoch 353/500 | Train Loss: 380.194 | Test Loss: 411.963 | Test Loss [MAPE]: 1390700.459 --time-- 3.2130377292633057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/500 | Train Loss: 381.522 | Test Loss: 411.828 | Test Loss [MAPE]: 1394472.251 --time-- 3.2152163982391357\n",
      "Epoch 355/500 | Train Loss: 380.729 | Test Loss: 394.328 | Test Loss [MAPE]: 1343534.130 --time-- 3.2167367935180664\n",
      "Epoch 356/500 | Train Loss: 370.320 | Test Loss: 399.094 | Test Loss [MAPE]: 1350009.405 --time-- 3.211063861846924\n",
      "Epoch 357/500 | Train Loss: 371.807 | Test Loss: 419.227 | Test Loss [MAPE]: 1421403.841 --time-- 3.213503122329712\n",
      "Epoch 358/500 | Train Loss: 376.323 | Test Loss: 421.317 | Test Loss [MAPE]: 1403541.309 --time-- 3.2120490074157715\n",
      "Epoch 359/500 | Train Loss: 380.978 | Test Loss: 410.524 | Test Loss [MAPE]: 1402067.249 --time-- 3.2133450508117676\n",
      "Epoch 360/500 | Train Loss: 375.534 | Test Loss: 393.845 | Test Loss [MAPE]: 1328347.233 --time-- 3.2137770652770996\n",
      "Epoch 361/500 | Train Loss: 371.061 | Test Loss: 391.229 | Test Loss [MAPE]: 1327738.763 --time-- 3.211505174636841\n",
      "Epoch 362/500 | Train Loss: 373.475 | Test Loss: 391.671 | Test Loss [MAPE]: 1325230.151 --time-- 3.2152204513549805\n",
      "Epoch 363/500 | Train Loss: 374.949 | Test Loss: 418.367 | Test Loss [MAPE]: 1366681.596 --time-- 3.217780351638794\n",
      "Epoch 364/500 | Train Loss: 371.323 | Test Loss: 396.342 | Test Loss [MAPE]: 1353880.445 --time-- 3.2130250930786133\n",
      "Epoch 365/500 | Train Loss: 371.354 | Test Loss: 408.315 | Test Loss [MAPE]: 1352882.893 --time-- 3.212740659713745\n",
      "Epoch 366/500 | Train Loss: 379.127 | Test Loss: 396.295 | Test Loss [MAPE]: 1333212.782 --time-- 3.2129344940185547\n",
      "Epoch 367/500 | Train Loss: 372.578 | Test Loss: 414.252 | Test Loss [MAPE]: 1393162.559 --time-- 3.2110390663146973\n",
      "Epoch 368/500 | Train Loss: 374.904 | Test Loss: 393.979 | Test Loss [MAPE]: 1342677.788 --time-- 3.2150368690490723\n",
      "Epoch 369/500 | Train Loss: 381.130 | Test Loss: 405.787 | Test Loss [MAPE]: 1337025.912 --time-- 3.214087963104248\n",
      "Epoch 370/500 | Train Loss: 384.446 | Test Loss: 388.299 | Test Loss [MAPE]: 1285257.890 --time-- 3.214169979095459\n",
      "Epoch 371/500 | Train Loss: 371.057 | Test Loss: 412.854 | Test Loss [MAPE]: 1347794.481 --time-- 3.21828556060791\n",
      "Epoch 372/500 | Train Loss: 381.005 | Test Loss: 414.878 | Test Loss [MAPE]: 1391684.734 --time-- 3.215006113052368\n",
      "Epoch 373/500 | Train Loss: 378.836 | Test Loss: 401.478 | Test Loss [MAPE]: 1335573.427 --time-- 3.2130603790283203\n",
      "Epoch 374/500 | Train Loss: 368.553 | Test Loss: 385.747 | Test Loss [MAPE]: 1306889.033 --time-- 3.213066816329956\n",
      "Epoch 375/500 | Train Loss: 373.468 | Test Loss: 400.953 | Test Loss [MAPE]: 1365183.004 --time-- 3.2153403759002686\n",
      "Epoch 376/500 | Train Loss: 367.599 | Test Loss: 397.297 | Test Loss [MAPE]: 1332498.680 --time-- 3.2131099700927734\n",
      "Epoch 377/500 | Train Loss: 361.817 | Test Loss: 400.061 | Test Loss [MAPE]: 1359836.367 --time-- 3.2147364616394043\n",
      "Epoch 378/500 | Train Loss: 381.602 | Test Loss: 399.603 | Test Loss [MAPE]: 1354246.416 --time-- 3.217829942703247\n",
      "Epoch 379/500 | Train Loss: 369.812 | Test Loss: 393.141 | Test Loss [MAPE]: 1336360.342 --time-- 3.214862823486328\n",
      "Epoch 380/500 | Train Loss: 363.624 | Test Loss: 394.375 | Test Loss [MAPE]: 1336627.258 --time-- 3.2170588970184326\n",
      "Epoch 381/500 | Train Loss: 379.373 | Test Loss: 396.061 | Test Loss [MAPE]: 1347266.272 --time-- 3.2163820266723633\n",
      "Epoch 382/500 | Train Loss: 378.135 | Test Loss: 396.167 | Test Loss [MAPE]: 1338075.074 --time-- 3.217808485031128\n",
      "Epoch 383/500 | Train Loss: 370.316 | Test Loss: 407.275 | Test Loss [MAPE]: 1385045.844 --time-- 3.2135140895843506\n",
      "Epoch 384/500 | Train Loss: 365.571 | Test Loss: 405.269 | Test Loss [MAPE]: 1313884.840 --time-- 3.211609363555908\n",
      "Epoch 385/500 | Train Loss: 373.889 | Test Loss: 378.474 | Test Loss [MAPE]: 1268602.241 --time-- 3.2141168117523193\n",
      "Epoch 386/500 | Train Loss: 361.307 | Test Loss: 386.305 | Test Loss [MAPE]: 1278255.543 --time-- 3.214350700378418\n",
      "Epoch 387/500 | Train Loss: 360.193 | Test Loss: 387.699 | Test Loss [MAPE]: 1287258.457 --time-- 3.214292526245117\n",
      "Epoch 388/500 | Train Loss: 359.427 | Test Loss: 381.877 | Test Loss [MAPE]: 1294417.044 --time-- 3.2155444622039795\n",
      "Epoch 389/500 | Train Loss: 369.983 | Test Loss: 398.562 | Test Loss [MAPE]: 1354672.894 --time-- 3.214092254638672\n",
      "Epoch 390/500 | Train Loss: 378.516 | Test Loss: 385.693 | Test Loss [MAPE]: 1263001.195 --time-- 3.2149226665496826\n",
      "Epoch 391/500 | Train Loss: 359.648 | Test Loss: 372.241 | Test Loss [MAPE]: 1249844.825 --time-- 3.2156972885131836\n",
      "Epoch 392/500 | Train Loss: 368.172 | Test Loss: 382.639 | Test Loss [MAPE]: 1293070.593 --time-- 3.216702699661255\n",
      "Epoch 393/500 | Train Loss: 363.914 | Test Loss: 401.074 | Test Loss [MAPE]: 1369373.417 --time-- 3.2151033878326416\n",
      "Epoch 394/500 | Train Loss: 362.063 | Test Loss: 379.940 | Test Loss [MAPE]: 1256311.388 --time-- 3.217867851257324\n",
      "Epoch 395/500 | Train Loss: 354.436 | Test Loss: 368.231 | Test Loss [MAPE]: 1251630.075 --time-- 3.216801643371582\n",
      "Epoch 396/500 | Train Loss: 355.637 | Test Loss: 381.114 | Test Loss [MAPE]: 1279804.048 --time-- 3.214749813079834\n",
      "Epoch 397/500 | Train Loss: 373.440 | Test Loss: 400.854 | Test Loss [MAPE]: 1349759.147 --time-- 3.217451333999634\n",
      "Epoch 398/500 | Train Loss: 371.034 | Test Loss: 396.412 | Test Loss [MAPE]: 1340789.892 --time-- 3.2124412059783936\n",
      "Epoch 399/500 | Train Loss: 363.729 | Test Loss: 384.642 | Test Loss [MAPE]: 1307456.722 --time-- 3.212700605392456\n",
      "Epoch 400/500 | Train Loss: 354.025 | Test Loss: 372.766 | Test Loss [MAPE]: 1257127.105 --time-- 3.215304136276245\n",
      "Epoch 401/500 | Train Loss: 362.714 | Test Loss: 383.480 | Test Loss [MAPE]: 1293172.520 --time-- 3.2148168087005615\n",
      "Epoch 402/500 | Train Loss: 353.425 | Test Loss: 397.637 | Test Loss [MAPE]: 1354915.863 --time-- 3.2138280868530273\n",
      "Epoch 403/500 | Train Loss: 378.065 | Test Loss: 395.938 | Test Loss [MAPE]: 1340538.881 --time-- 3.2130911350250244\n",
      "Epoch 404/500 | Train Loss: 356.471 | Test Loss: 385.169 | Test Loss [MAPE]: 1296505.617 --time-- 3.2156498432159424\n",
      "Epoch 405/500 | Train Loss: 357.479 | Test Loss: 389.874 | Test Loss [MAPE]: 1305500.405 --time-- 3.2153589725494385\n",
      "Epoch 406/500 | Train Loss: 352.320 | Test Loss: 381.075 | Test Loss [MAPE]: 1263567.400 --time-- 3.2191321849823\n",
      "Epoch 407/500 | Train Loss: 359.604 | Test Loss: 378.108 | Test Loss [MAPE]: 1267324.241 --time-- 3.214427947998047\n",
      "Epoch 408/500 | Train Loss: 368.549 | Test Loss: 394.819 | Test Loss [MAPE]: 1323459.106 --time-- 3.215043783187866\n",
      "Epoch 409/500 | Train Loss: 366.967 | Test Loss: 388.020 | Test Loss [MAPE]: 1294487.932 --time-- 3.212437152862549\n",
      "Epoch 410/500 | Train Loss: 356.427 | Test Loss: 369.898 | Test Loss [MAPE]: 1252701.589 --time-- 3.2151355743408203\n",
      "Epoch 411/500 | Train Loss: 357.038 | Test Loss: 388.850 | Test Loss [MAPE]: 1287961.201 --time-- 3.214371681213379\n",
      "Epoch 412/500 | Train Loss: 360.855 | Test Loss: 385.987 | Test Loss [MAPE]: 1306881.958 --time-- 3.21085524559021\n",
      "Epoch 413/500 | Train Loss: 358.387 | Test Loss: 389.622 | Test Loss [MAPE]: 1328181.540 --time-- 3.215176582336426\n",
      "Epoch 414/500 | Train Loss: 357.962 | Test Loss: 372.246 | Test Loss [MAPE]: 1251040.492 --time-- 3.2164430618286133\n",
      "Epoch 415/500 | Train Loss: 349.438 | Test Loss: 385.401 | Test Loss [MAPE]: 1272603.853 --time-- 3.2130472660064697\n",
      "Epoch 416/500 | Train Loss: 360.579 | Test Loss: 381.129 | Test Loss [MAPE]: 1271642.162 --time-- 3.215075969696045\n",
      "Epoch 417/500 | Train Loss: 360.843 | Test Loss: 384.065 | Test Loss [MAPE]: 1283271.038 --time-- 3.2147607803344727\n",
      "Epoch 418/500 | Train Loss: 352.379 | Test Loss: 372.483 | Test Loss [MAPE]: 1265446.214 --time-- 3.2147557735443115\n",
      "Epoch 419/500 | Train Loss: 350.390 | Test Loss: 388.084 | Test Loss [MAPE]: 1320956.654 --time-- 3.2176239490509033\n",
      "Epoch 420/500 | Train Loss: 363.104 | Test Loss: 389.655 | Test Loss [MAPE]: 1318769.021 --time-- 3.214465618133545\n",
      "Epoch 421/500 | Train Loss: 355.100 | Test Loss: 375.032 | Test Loss [MAPE]: 1268430.504 --time-- 3.2161881923675537\n",
      "Epoch 422/500 | Train Loss: 349.017 | Test Loss: 372.837 | Test Loss [MAPE]: 1251281.137 --time-- 3.2162604331970215\n",
      "Epoch 423/500 | Train Loss: 351.864 | Test Loss: 376.235 | Test Loss [MAPE]: 1268692.466 --time-- 3.2143568992614746\n",
      "Epoch 424/500 | Train Loss: 350.409 | Test Loss: 382.118 | Test Loss [MAPE]: 1265635.708 --time-- 3.2164041996002197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/500 | Train Loss: 356.411 | Test Loss: 408.484 | Test Loss [MAPE]: 1391205.837 --time-- 3.2152352333068848\n",
      "Epoch 426/500 | Train Loss: 364.483 | Test Loss: 377.942 | Test Loss [MAPE]: 1283024.081 --time-- 3.2124433517456055\n",
      "Epoch 427/500 | Train Loss: 352.035 | Test Loss: 392.962 | Test Loss [MAPE]: 1320981.153 --time-- 3.2159037590026855\n",
      "Epoch 428/500 | Train Loss: 361.717 | Test Loss: 380.341 | Test Loss [MAPE]: 1299061.186 --time-- 3.211610794067383\n",
      "Epoch 429/500 | Train Loss: 345.794 | Test Loss: 370.341 | Test Loss [MAPE]: 1241615.100 --time-- 3.2149922847747803\n",
      "Epoch 430/500 | Train Loss: 344.588 | Test Loss: 367.783 | Test Loss [MAPE]: 1237523.312 --time-- 3.212700605392456\n",
      "Epoch 431/500 | Train Loss: 349.960 | Test Loss: 377.515 | Test Loss [MAPE]: 1268335.488 --time-- 3.2128496170043945\n",
      "Epoch 432/500 | Train Loss: 347.402 | Test Loss: 382.529 | Test Loss [MAPE]: 1298375.341 --time-- 3.2141058444976807\n",
      "Epoch 433/500 | Train Loss: 345.580 | Test Loss: 362.590 | Test Loss [MAPE]: 1228359.440 --time-- 3.2149696350097656\n",
      "Epoch 434/500 | Train Loss: 349.694 | Test Loss: 364.954 | Test Loss [MAPE]: 1227264.680 --time-- 3.2157108783721924\n",
      "Epoch 435/500 | Train Loss: 345.127 | Test Loss: 371.609 | Test Loss [MAPE]: 1263339.726 --time-- 3.222440242767334\n",
      "Epoch 436/500 | Train Loss: 348.390 | Test Loss: 376.930 | Test Loss [MAPE]: 1254414.575 --time-- 3.2150683403015137\n",
      "Epoch 437/500 | Train Loss: 353.772 | Test Loss: 388.435 | Test Loss [MAPE]: 1272998.525 --time-- 3.2141783237457275\n",
      "Epoch 438/500 | Train Loss: 349.605 | Test Loss: 357.782 | Test Loss [MAPE]: 1216051.197 --time-- 3.218714475631714\n",
      "Epoch 439/500 | Train Loss: 344.558 | Test Loss: 362.312 | Test Loss [MAPE]: 1224390.383 --time-- 3.215487241744995\n",
      "Epoch 440/500 | Train Loss: 348.898 | Test Loss: 368.135 | Test Loss [MAPE]: 1247969.769 --time-- 3.2172486782073975\n",
      "Epoch 441/500 | Train Loss: 344.493 | Test Loss: 370.539 | Test Loss [MAPE]: 1257149.434 --time-- 3.2127437591552734\n",
      "Epoch 442/500 | Train Loss: 350.715 | Test Loss: 373.332 | Test Loss [MAPE]: 1243327.274 --time-- 3.21498441696167\n",
      "Epoch 443/500 | Train Loss: 349.897 | Test Loss: 368.346 | Test Loss [MAPE]: 1230189.399 --time-- 3.215939521789551\n",
      "Epoch 444/500 | Train Loss: 359.414 | Test Loss: 391.808 | Test Loss [MAPE]: 1285656.253 --time-- 3.2140400409698486\n",
      "Epoch 445/500 | Train Loss: 346.723 | Test Loss: 383.146 | Test Loss [MAPE]: 1291528.114 --time-- 3.2135097980499268\n",
      "Epoch 446/500 | Train Loss: 346.562 | Test Loss: 362.265 | Test Loss [MAPE]: 1232558.679 --time-- 3.2162058353424072\n",
      "Epoch 447/500 | Train Loss: 355.939 | Test Loss: 389.891 | Test Loss [MAPE]: 1322196.965 --time-- 3.2138664722442627\n",
      "Epoch 448/500 | Train Loss: 356.996 | Test Loss: 387.732 | Test Loss [MAPE]: 1267610.332 --time-- 3.215967893600464\n",
      "Epoch 449/500 | Train Loss: 355.462 | Test Loss: 365.138 | Test Loss [MAPE]: 1215190.384 --time-- 3.216243028640747\n",
      "Epoch 450/500 | Train Loss: 342.310 | Test Loss: 381.836 | Test Loss [MAPE]: 1275952.081 --time-- 3.2150485515594482\n",
      "Epoch 451/500 | Train Loss: 349.778 | Test Loss: 361.865 | Test Loss [MAPE]: 1195920.907 --time-- 3.2165021896362305\n",
      "Epoch 452/500 | Train Loss: 339.223 | Test Loss: 370.802 | Test Loss [MAPE]: 1272744.301 --time-- 3.219377279281616\n",
      "Epoch 453/500 | Train Loss: 349.503 | Test Loss: 372.184 | Test Loss [MAPE]: 1242320.330 --time-- 3.2168707847595215\n",
      "Epoch 454/500 | Train Loss: 340.663 | Test Loss: 374.743 | Test Loss [MAPE]: 1285919.498 --time-- 3.2163777351379395\n",
      "Epoch 455/500 | Train Loss: 346.904 | Test Loss: 367.860 | Test Loss [MAPE]: 1244182.480 --time-- 3.2129600048065186\n",
      "Epoch 456/500 | Train Loss: 334.511 | Test Loss: 361.274 | Test Loss [MAPE]: 1220216.864 --time-- 3.216012954711914\n",
      "Epoch 457/500 | Train Loss: 349.279 | Test Loss: 403.721 | Test Loss [MAPE]: 1305921.229 --time-- 3.21926212310791\n",
      "Epoch 458/500 | Train Loss: 346.217 | Test Loss: 361.327 | Test Loss [MAPE]: 1211437.041 --time-- 3.215097188949585\n",
      "Epoch 459/500 | Train Loss: 343.237 | Test Loss: 373.136 | Test Loss [MAPE]: 1235864.932 --time-- 3.2157769203186035\n",
      "Epoch 460/500 | Train Loss: 351.206 | Test Loss: 374.876 | Test Loss [MAPE]: 1259310.747 --time-- 3.2142903804779053\n",
      "Epoch 461/500 | Train Loss: 338.517 | Test Loss: 383.424 | Test Loss [MAPE]: 1297373.630 --time-- 3.215559720993042\n",
      "Epoch 462/500 | Train Loss: 348.633 | Test Loss: 365.642 | Test Loss [MAPE]: 1256084.319 --time-- 3.217226505279541\n",
      "Epoch 463/500 | Train Loss: 344.717 | Test Loss: 372.470 | Test Loss [MAPE]: 1249041.614 --time-- 3.2607343196868896\n",
      "Epoch 464/500 | Train Loss: 347.458 | Test Loss: 364.999 | Test Loss [MAPE]: 1214533.363 --time-- 3.2621796131134033\n",
      "Epoch 465/500 | Train Loss: 342.843 | Test Loss: 365.394 | Test Loss [MAPE]: 1215498.857 --time-- 3.2578647136688232\n",
      "Epoch 466/500 | Train Loss: 339.921 | Test Loss: 376.652 | Test Loss [MAPE]: 1278615.221 --time-- 3.262237548828125\n",
      "Epoch 467/500 | Train Loss: 346.311 | Test Loss: 364.835 | Test Loss [MAPE]: 1240424.466 --time-- 3.2609989643096924\n",
      "Epoch 468/500 | Train Loss: 342.372 | Test Loss: 365.597 | Test Loss [MAPE]: 1232778.448 --time-- 3.260232925415039\n",
      "Epoch 469/500 | Train Loss: 337.351 | Test Loss: 367.924 | Test Loss [MAPE]: 1233601.066 --time-- 3.262775421142578\n",
      "Epoch 470/500 | Train Loss: 352.705 | Test Loss: 369.475 | Test Loss [MAPE]: 1209702.325 --time-- 3.2596845626831055\n",
      "Epoch 471/500 | Train Loss: 350.837 | Test Loss: 372.984 | Test Loss [MAPE]: 1249449.489 --time-- 3.262667417526245\n",
      "Epoch 472/500 | Train Loss: 350.649 | Test Loss: 371.598 | Test Loss [MAPE]: 1242110.487 --time-- 3.2610106468200684\n",
      "Epoch 473/500 | Train Loss: 336.884 | Test Loss: 367.898 | Test Loss [MAPE]: 1230648.683 --time-- 3.262802839279175\n",
      "Epoch 474/500 | Train Loss: 322.887 | Test Loss: 350.150 | Test Loss [MAPE]: 1193613.091 --time-- 3.2608799934387207\n",
      "Epoch 475/500 | Train Loss: 334.167 | Test Loss: 358.300 | Test Loss [MAPE]: 1216138.879 --time-- 3.2620527744293213\n",
      "Epoch 476/500 | Train Loss: 339.266 | Test Loss: 368.625 | Test Loss [MAPE]: 1227387.246 --time-- 3.261512517929077\n",
      "Epoch 477/500 | Train Loss: 338.099 | Test Loss: 358.604 | Test Loss [MAPE]: 1209247.472 --time-- 3.259233236312866\n",
      "Epoch 478/500 | Train Loss: 338.011 | Test Loss: 351.365 | Test Loss [MAPE]: 1187652.551 --time-- 3.26017427444458\n",
      "Epoch 479/500 | Train Loss: 337.072 | Test Loss: 354.655 | Test Loss [MAPE]: 1182478.035 --time-- 3.259768486022949\n",
      "Epoch 480/500 | Train Loss: 332.457 | Test Loss: 367.207 | Test Loss [MAPE]: 1248094.572 --time-- 3.259596109390259\n",
      "Epoch 481/500 | Train Loss: 337.246 | Test Loss: 366.341 | Test Loss [MAPE]: 1201675.183 --time-- 3.2572476863861084\n",
      "Epoch 482/500 | Train Loss: 342.592 | Test Loss: 364.582 | Test Loss [MAPE]: 1231796.018 --time-- 3.259591579437256\n",
      "Epoch 483/500 | Train Loss: 332.537 | Test Loss: 345.403 | Test Loss [MAPE]: 1160974.519 --time-- 3.2629752159118652\n",
      "Epoch 484/500 | Train Loss: 344.141 | Test Loss: 348.941 | Test Loss [MAPE]: 1171295.145 --time-- 3.2589058876037598\n",
      "Epoch 485/500 | Train Loss: 336.005 | Test Loss: 357.911 | Test Loss [MAPE]: 1204591.338 --time-- 3.2618472576141357\n",
      "Epoch 486/500 | Train Loss: 342.777 | Test Loss: 379.744 | Test Loss [MAPE]: 1289002.754 --time-- 3.261227607727051\n",
      "Epoch 487/500 | Train Loss: 341.563 | Test Loss: 370.886 | Test Loss [MAPE]: 1209175.558 --time-- 3.2595832347869873\n",
      "Epoch 488/500 | Train Loss: 350.131 | Test Loss: 365.451 | Test Loss [MAPE]: 1234388.789 --time-- 3.2609856128692627\n",
      "Epoch 489/500 | Train Loss: 337.912 | Test Loss: 381.101 | Test Loss [MAPE]: 1255571.035 --time-- 3.2609434127807617\n",
      "Epoch 490/500 | Train Loss: 337.619 | Test Loss: 351.552 | Test Loss [MAPE]: 1175052.281 --time-- 3.2596070766448975\n",
      "Epoch 491/500 | Train Loss: 331.113 | Test Loss: 354.214 | Test Loss [MAPE]: 1187929.455 --time-- 3.2595808506011963\n",
      "Epoch 492/500 | Train Loss: 334.904 | Test Loss: 344.516 | Test Loss [MAPE]: 1159328.652 --time-- 3.2649762630462646\n",
      "Epoch 493/500 | Train Loss: 325.502 | Test Loss: 362.363 | Test Loss [MAPE]: 1201219.909 --time-- 3.2116339206695557\n",
      "Epoch 494/500 | Train Loss: 331.423 | Test Loss: 353.700 | Test Loss [MAPE]: 1207038.605 --time-- 3.2154083251953125\n",
      "Epoch 495/500 | Train Loss: 335.507 | Test Loss: 353.876 | Test Loss [MAPE]: 1177473.455 --time-- 3.213808298110962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500 | Train Loss: 343.882 | Test Loss: 381.117 | Test Loss [MAPE]: 1296162.751 --time-- 3.21337890625\n",
      "Epoch 497/500 | Train Loss: 337.210 | Test Loss: 358.149 | Test Loss [MAPE]: 1197299.819 --time-- 3.2160754203796387\n",
      "Epoch 498/500 | Train Loss: 325.702 | Test Loss: 362.787 | Test Loss [MAPE]: 1220855.731 --time-- 3.2127957344055176\n",
      "Epoch 499/500 | Train Loss: 345.677 | Test Loss: 371.035 | Test Loss [MAPE]: 1247502.997 --time-- 3.212672710418701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 01:11:14,447] Trial 25 finished with value: 432058.5189819336 and parameters: {'num_conv_layers': 4, 'kernel_size': 8, 'num_channels': 40, 'pooling_type': 'max', 'conv_stride': 3, 'feedforward_size': 124, 'pool_stride': 2, 'learning_rate': 0.0005098435550874494, 'reg_strength': 0.0032755728656730897, 'bs': 100}. Best is trial 25 with value: 432058.5189819336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500 | Train Loss: 331.097 | Test Loss: 360.484 | Test Loss [MAPE]: 1223471.008 --time-- 3.2144320011138916\n",
      "1624.8326153755188\n",
      "Epoch 1/500 | Train Loss: 5388.610 | Test Loss: 5161.748 | Test Loss [MAPE]: 425466.093 --time-- 3.232107400894165\n",
      "Epoch 2/500 | Train Loss: 5106.359 | Test Loss: 5161.751 | Test Loss [MAPE]: 430755.171 --time-- 3.1808688640594482\n",
      "Epoch 3/500 | Train Loss: 5106.393 | Test Loss: 5161.739 | Test Loss [MAPE]: 421524.692 --time-- 3.182589292526245\n",
      "Epoch 4/500 | Train Loss: 5106.382 | Test Loss: 5161.734 | Test Loss [MAPE]: 428094.586 --time-- 3.183765172958374\n",
      "Epoch 5/500 | Train Loss: 5106.365 | Test Loss: 5161.725 | Test Loss [MAPE]: 426229.605 --time-- 3.1829657554626465\n",
      "Epoch 6/500 | Train Loss: 5106.436 | Test Loss: 5161.774 | Test Loss [MAPE]: 417241.078 --time-- 3.184457540512085\n",
      "Epoch 7/500 | Train Loss: 5106.484 | Test Loss: 5161.737 | Test Loss [MAPE]: 423238.112 --time-- 3.183802843093872\n",
      "Epoch 8/500 | Train Loss: 5106.416 | Test Loss: 5161.738 | Test Loss [MAPE]: 428964.791 --time-- 3.188039541244507\n",
      "Epoch 9/500 | Train Loss: 5106.415 | Test Loss: 5161.790 | Test Loss [MAPE]: 418485.462 --time-- 3.181863784790039\n",
      "Epoch 10/500 | Train Loss: 5106.440 | Test Loss: 5161.825 | Test Loss [MAPE]: 419941.865 --time-- 3.1825592517852783\n",
      "Epoch 11/500 | Train Loss: 5106.493 | Test Loss: 5161.865 | Test Loss [MAPE]: 425324.970 --time-- 3.178802251815796\n",
      "Epoch 12/500 | Train Loss: 5106.452 | Test Loss: 5161.753 | Test Loss [MAPE]: 426023.853 --time-- 3.182009696960449\n",
      "Epoch 13/500 | Train Loss: 5106.512 | Test Loss: 5161.826 | Test Loss [MAPE]: 424356.200 --time-- 3.1825685501098633\n",
      "Epoch 14/500 | Train Loss: 5106.478 | Test Loss: 5161.790 | Test Loss [MAPE]: 426189.263 --time-- 3.1843113899230957\n",
      "Epoch 15/500 | Train Loss: 5106.495 | Test Loss: 5161.806 | Test Loss [MAPE]: 428950.523 --time-- 3.180986166000366\n",
      "Epoch 16/500 | Train Loss: 5106.470 | Test Loss: 5161.807 | Test Loss [MAPE]: 427589.042 --time-- 3.1821646690368652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 01:12:09,249] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.488 | Test Loss: 5161.875 | Test Loss [MAPE]: 430399.904 --time-- 3.183223247528076\n",
      "Epoch 1/500 | Train Loss: 5351.405 | Test Loss: 5162.112 | Test Loss [MAPE]: 435917.646 --time-- 2.947643518447876\n",
      "Epoch 2/500 | Train Loss: 5106.377 | Test Loss: 5161.673 | Test Loss [MAPE]: 421955.053 --time-- 2.9144551753997803\n",
      "Epoch 3/500 | Train Loss: 5106.319 | Test Loss: 5161.667 | Test Loss [MAPE]: 424165.747 --time-- 2.913477897644043\n",
      "Epoch 4/500 | Train Loss: 5106.325 | Test Loss: 5161.706 | Test Loss [MAPE]: 427275.143 --time-- 2.91514253616333\n",
      "Epoch 5/500 | Train Loss: 5106.340 | Test Loss: 5161.704 | Test Loss [MAPE]: 423287.450 --time-- 2.9159739017486572\n",
      "Epoch 6/500 | Train Loss: 5106.342 | Test Loss: 5161.748 | Test Loss [MAPE]: 418575.387 --time-- 2.9162862300872803\n",
      "Epoch 7/500 | Train Loss: 5106.350 | Test Loss: 5161.721 | Test Loss [MAPE]: 428660.671 --time-- 2.9184072017669678\n",
      "Epoch 8/500 | Train Loss: 5106.368 | Test Loss: 5161.733 | Test Loss [MAPE]: 420974.964 --time-- 2.9171078205108643\n",
      "Epoch 9/500 | Train Loss: 5106.388 | Test Loss: 5161.745 | Test Loss [MAPE]: 426868.434 --time-- 2.917880058288574\n",
      "Epoch 10/500 | Train Loss: 5106.360 | Test Loss: 5161.719 | Test Loss [MAPE]: 425886.448 --time-- 2.9167981147766113\n",
      "Epoch 11/500 | Train Loss: 5106.370 | Test Loss: 5161.716 | Test Loss [MAPE]: 426267.904 --time-- 2.9141807556152344\n",
      "Epoch 12/500 | Train Loss: 5106.357 | Test Loss: 5161.720 | Test Loss [MAPE]: 429642.414 --time-- 2.915703773498535\n",
      "Epoch 13/500 | Train Loss: 5106.374 | Test Loss: 5161.709 | Test Loss [MAPE]: 426298.529 --time-- 2.9175703525543213\n",
      "Epoch 14/500 | Train Loss: 5106.379 | Test Loss: 5161.710 | Test Loss [MAPE]: 422693.322 --time-- 2.9168834686279297\n",
      "Epoch 15/500 | Train Loss: 5106.397 | Test Loss: 5161.733 | Test Loss [MAPE]: 426430.527 --time-- 2.9191231727600098\n",
      "Epoch 16/500 | Train Loss: 5106.393 | Test Loss: 5161.747 | Test Loss [MAPE]: 425893.917 --time-- 2.918513536453247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 01:12:59,482] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.426 | Test Loss: 5161.765 | Test Loss [MAPE]: 427857.800 --time-- 2.914428472518921\n",
      "Epoch 1/500 | Train Loss: 6055.547 | Test Loss: 5162.264 | Test Loss [MAPE]: 449278.314 --time-- 2.0407121181488037\n",
      "Epoch 2/500 | Train Loss: 5106.897 | Test Loss: 5161.885 | Test Loss [MAPE]: 422475.655 --time-- 1.985151767730713\n",
      "Epoch 3/500 | Train Loss: 5106.577 | Test Loss: 5162.180 | Test Loss [MAPE]: 444556.310 --time-- 1.982978343963623\n",
      "Epoch 4/500 | Train Loss: 5107.023 | Test Loss: 5162.221 | Test Loss [MAPE]: 437988.609 --time-- 1.9837315082550049\n",
      "Epoch 5/500 | Train Loss: 5106.765 | Test Loss: 5162.122 | Test Loss [MAPE]: 431473.041 --time-- 1.9830780029296875\n",
      "Epoch 6/500 | Train Loss: 5106.701 | Test Loss: 5162.356 | Test Loss [MAPE]: 423918.337 --time-- 1.9779248237609863\n",
      "Epoch 7/500 | Train Loss: 5106.972 | Test Loss: 5162.002 | Test Loss [MAPE]: 430398.185 --time-- 1.9806489944458008\n",
      "Epoch 8/500 | Train Loss: 5107.409 | Test Loss: 5163.327 | Test Loss [MAPE]: 464178.771 --time-- 1.9811115264892578\n",
      "Epoch 9/500 | Train Loss: 5107.214 | Test Loss: 5162.081 | Test Loss [MAPE]: 429235.984 --time-- 1.9832558631896973\n",
      "Epoch 10/500 | Train Loss: 5107.058 | Test Loss: 5161.987 | Test Loss [MAPE]: 428247.037 --time-- 1.979142665863037\n",
      "Epoch 11/500 | Train Loss: 5106.784 | Test Loss: 5162.076 | Test Loss [MAPE]: 429473.293 --time-- 1.98276948928833\n",
      "Epoch 12/500 | Train Loss: 5106.846 | Test Loss: 5162.331 | Test Loss [MAPE]: 424470.551 --time-- 1.9831359386444092\n",
      "Epoch 13/500 | Train Loss: 5106.951 | Test Loss: 5162.119 | Test Loss [MAPE]: 439663.553 --time-- 1.9784932136535645\n",
      "Epoch 14/500 | Train Loss: 5107.040 | Test Loss: 5162.168 | Test Loss [MAPE]: 437292.281 --time-- 1.9799597263336182\n",
      "Epoch 15/500 | Train Loss: 5106.884 | Test Loss: 5162.224 | Test Loss [MAPE]: 425001.314 --time-- 1.9782254695892334\n",
      "Epoch 16/500 | Train Loss: 5106.884 | Test Loss: 5162.213 | Test Loss [MAPE]: 444606.448 --time-- 1.977900505065918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 01:13:33,860] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5107.030 | Test Loss: 5162.332 | Test Loss [MAPE]: 431096.278 --time-- 1.977238416671753\n",
      "Epoch 1/500 | Train Loss: 6831289.409 | Test Loss: 5162.674 | Test Loss [MAPE]: 429437.551 --time-- 4.02707839012146\n",
      "Epoch 2/500 | Train Loss: 5106.734 | Test Loss: 5162.002 | Test Loss [MAPE]: 420280.739 --time-- 4.024863243103027\n",
      "Epoch 3/500 | Train Loss: 5106.631 | Test Loss: 5161.932 | Test Loss [MAPE]: 435510.781 --time-- 4.026646375656128\n",
      "Epoch 4/500 | Train Loss: 5106.812 | Test Loss: 5161.940 | Test Loss [MAPE]: 429696.242 --time-- 4.027078628540039\n",
      "Epoch 5/500 | Train Loss: 5106.697 | Test Loss: 5161.930 | Test Loss [MAPE]: 421084.343 --time-- 4.0269694328308105\n",
      "Epoch 6/500 | Train Loss: 5106.874 | Test Loss: 5163.446 | Test Loss [MAPE]: 473724.855 --time-- 4.023402690887451\n",
      "Epoch 7/500 | Train Loss: 5107.182 | Test Loss: 5162.187 | Test Loss [MAPE]: 422630.296 --time-- 4.0278000831604\n",
      "Epoch 8/500 | Train Loss: 5106.997 | Test Loss: 5162.139 | Test Loss [MAPE]: 431202.351 --time-- 4.024587631225586\n",
      "Epoch 9/500 | Train Loss: 5106.979 | Test Loss: 5162.682 | Test Loss [MAPE]: 426682.508 --time-- 4.026016712188721\n",
      "Epoch 10/500 | Train Loss: 5107.691 | Test Loss: 5163.139 | Test Loss [MAPE]: 431729.819 --time-- 4.114555597305298\n",
      "Epoch 11/500 | Train Loss: 5107.305 | Test Loss: 5162.457 | Test Loss [MAPE]: 443820.114 --time-- 4.108023643493652\n",
      "Epoch 12/500 | Train Loss: 5107.205 | Test Loss: 5162.367 | Test Loss [MAPE]: 435047.103 --time-- 4.027889251708984\n",
      "Epoch 13/500 | Train Loss: 5107.314 | Test Loss: 5163.434 | Test Loss [MAPE]: 471690.197 --time-- 4.027804613113403\n",
      "Epoch 14/500 | Train Loss: 5107.726 | Test Loss: 5163.639 | Test Loss [MAPE]: 439196.896 --time-- 4.028549432754517\n",
      "Epoch 15/500 | Train Loss: 5107.849 | Test Loss: 5162.582 | Test Loss [MAPE]: 433641.467 --time-- 4.027223110198975\n",
      "Epoch 16/500 | Train Loss: 5107.129 | Test Loss: 5161.986 | Test Loss [MAPE]: 432238.358 --time-- 4.034018039703369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 01:14:43,190] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5107.442 | Test Loss: 5162.170 | Test Loss [MAPE]: 430963.590 --time-- 4.029443740844727\n",
      "Epoch 1/500 | Train Loss: 87858.108 | Test Loss: 5162.126 | Test Loss [MAPE]: 421836.727 --time-- 2.9265573024749756\n",
      "Epoch 2/500 | Train Loss: 5106.547 | Test Loss: 5161.861 | Test Loss [MAPE]: 427985.133 --time-- 2.8817615509033203\n",
      "Epoch 3/500 | Train Loss: 5106.558 | Test Loss: 5161.871 | Test Loss [MAPE]: 428030.995 --time-- 2.884437084197998\n",
      "Epoch 4/500 | Train Loss: 5106.571 | Test Loss: 5161.956 | Test Loss [MAPE]: 419036.167 --time-- 2.878723621368408\n",
      "Epoch 5/500 | Train Loss: 5106.799 | Test Loss: 5162.130 | Test Loss [MAPE]: 444272.895 --time-- 2.8795082569122314\n",
      "Epoch 6/500 | Train Loss: 5106.797 | Test Loss: 5161.985 | Test Loss [MAPE]: 428461.980 --time-- 2.8818318843841553\n",
      "Epoch 7/500 | Train Loss: 5106.596 | Test Loss: 5162.057 | Test Loss [MAPE]: 424429.189 --time-- 2.8777928352355957\n",
      "Epoch 8/500 | Train Loss: 5106.825 | Test Loss: 5162.027 | Test Loss [MAPE]: 423220.955 --time-- 2.879624605178833\n",
      "Epoch 9/500 | Train Loss: 5106.745 | Test Loss: 5162.098 | Test Loss [MAPE]: 441391.466 --time-- 2.8806798458099365\n",
      "Epoch 10/500 | Train Loss: 5106.671 | Test Loss: 5162.023 | Test Loss [MAPE]: 438554.253 --time-- 2.8803064823150635\n",
      "Epoch 11/500 | Train Loss: 5106.935 | Test Loss: 5162.137 | Test Loss [MAPE]: 431222.281 --time-- 2.883485794067383\n",
      "Epoch 12/500 | Train Loss: 5106.799 | Test Loss: 5162.084 | Test Loss [MAPE]: 437497.917 --time-- 2.8795523643493652\n",
      "Epoch 13/500 | Train Loss: 5106.988 | Test Loss: 5163.087 | Test Loss [MAPE]: 468020.086 --time-- 2.8826189041137695\n",
      "Epoch 14/500 | Train Loss: 5107.055 | Test Loss: 5162.199 | Test Loss [MAPE]: 440180.719 --time-- 2.883685827255249\n",
      "Epoch 15/500 | Train Loss: 5106.912 | Test Loss: 5162.101 | Test Loss [MAPE]: 438115.103 --time-- 2.88100528717041\n",
      "Epoch 16/500 | Train Loss: 5106.996 | Test Loss: 5162.381 | Test Loss [MAPE]: 443526.043 --time-- 2.882683038711548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 01:15:32,856] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5107.025 | Test Loss: 5162.390 | Test Loss [MAPE]: 436851.387 --time-- 2.882042646408081\n",
      "Epoch 1/500 | Train Loss: 5154.977 | Test Loss: 5083.180 | Test Loss [MAPE]: 910197.424 --time-- 12.710403203964233\n",
      "Epoch 2/500 | Train Loss: 4467.733 | Test Loss: 4227.443 | Test Loss [MAPE]: 2301402.844 --time-- 12.689192056655884\n",
      "Epoch 3/500 | Train Loss: 4043.622 | Test Loss: 3869.140 | Test Loss [MAPE]: 3643547.130 --time-- 12.68531060218811\n",
      "Epoch 4/500 | Train Loss: 3746.645 | Test Loss: 3502.101 | Test Loss [MAPE]: 6502141.919 --time-- 12.68501091003418\n",
      "Epoch 5/500 | Train Loss: 3326.811 | Test Loss: 2899.112 | Test Loss [MAPE]: 6649696.914 --time-- 12.685498476028442\n",
      "Epoch 6/500 | Train Loss: 3159.370 | Test Loss: 3377.792 | Test Loss [MAPE]: 4709826.735 --time-- 12.687970638275146\n",
      "Epoch 7/500 | Train Loss: 2866.010 | Test Loss: 2497.288 | Test Loss [MAPE]: 5625976.129 --time-- 12.685595750808716\n",
      "Epoch 8/500 | Train Loss: 2261.811 | Test Loss: 2502.306 | Test Loss [MAPE]: 4436036.844 --time-- 12.683217287063599\n",
      "Epoch 9/500 | Train Loss: 2033.414 | Test Loss: 1936.451 | Test Loss [MAPE]: 4649299.491 --time-- 12.686572313308716\n",
      "Epoch 10/500 | Train Loss: 1708.814 | Test Loss: 1491.847 | Test Loss [MAPE]: 3837369.211 --time-- 12.683994054794312\n",
      "Epoch 11/500 | Train Loss: 1372.299 | Test Loss: 1385.382 | Test Loss [MAPE]: 3403033.712 --time-- 12.689863681793213\n",
      "Epoch 12/500 | Train Loss: 1287.845 | Test Loss: 1437.285 | Test Loss [MAPE]: 3095168.509 --time-- 12.690458059310913\n",
      "Epoch 13/500 | Train Loss: 1224.811 | Test Loss: 1029.587 | Test Loss [MAPE]: 2506125.282 --time-- 12.68761682510376\n",
      "Epoch 14/500 | Train Loss: 1060.651 | Test Loss: 1058.595 | Test Loss [MAPE]: 2522049.467 --time-- 12.690248250961304\n",
      "Epoch 15/500 | Train Loss: 1096.795 | Test Loss: 990.120 | Test Loss [MAPE]: 2458431.674 --time-- 12.687862634658813\n",
      "Epoch 16/500 | Train Loss: 939.323 | Test Loss: 829.972 | Test Loss [MAPE]: 2094111.239 --time-- 12.69163703918457\n",
      "Epoch 17/500 | Train Loss: 871.919 | Test Loss: 871.781 | Test Loss [MAPE]: 2263852.850 --time-- 12.695600986480713\n",
      "Epoch 18/500 | Train Loss: 835.733 | Test Loss: 794.632 | Test Loss [MAPE]: 2019396.352 --time-- 12.689597606658936\n",
      "Epoch 19/500 | Train Loss: 758.321 | Test Loss: 863.913 | Test Loss [MAPE]: 2367491.861 --time-- 12.693881273269653\n",
      "Epoch 20/500 | Train Loss: 780.179 | Test Loss: 839.841 | Test Loss [MAPE]: 2429465.658 --time-- 12.693715810775757\n",
      "Epoch 21/500 | Train Loss: 781.060 | Test Loss: 700.899 | Test Loss [MAPE]: 1806090.248 --time-- 12.69168210029602\n",
      "Epoch 22/500 | Train Loss: 751.019 | Test Loss: 670.521 | Test Loss [MAPE]: 1720723.201 --time-- 12.689481496810913\n",
      "Epoch 23/500 | Train Loss: 636.705 | Test Loss: 602.107 | Test Loss [MAPE]: 1775255.197 --time-- 12.693684339523315\n",
      "Epoch 24/500 | Train Loss: 620.713 | Test Loss: 622.801 | Test Loss [MAPE]: 1589236.627 --time-- 12.693166017532349\n",
      "Epoch 25/500 | Train Loss: 655.396 | Test Loss: 635.952 | Test Loss [MAPE]: 1833864.304 --time-- 12.707116603851318\n",
      "Epoch 26/500 | Train Loss: 634.886 | Test Loss: 635.097 | Test Loss [MAPE]: 1799553.123 --time-- 12.715349674224854\n",
      "Epoch 27/500 | Train Loss: 567.438 | Test Loss: 660.986 | Test Loss [MAPE]: 1954094.056 --time-- 12.71552300453186\n",
      "Epoch 28/500 | Train Loss: 613.319 | Test Loss: 680.021 | Test Loss [MAPE]: 1896771.203 --time-- 12.716181993484497\n",
      "Epoch 29/500 | Train Loss: 563.681 | Test Loss: 471.367 | Test Loss [MAPE]: 1293606.747 --time-- 12.711333274841309\n",
      "Epoch 30/500 | Train Loss: 532.024 | Test Loss: 531.012 | Test Loss [MAPE]: 1504119.690 --time-- 12.710967063903809\n",
      "Epoch 31/500 | Train Loss: 570.422 | Test Loss: 532.388 | Test Loss [MAPE]: 1535053.828 --time-- 12.718101263046265\n",
      "Epoch 32/500 | Train Loss: 540.740 | Test Loss: 518.133 | Test Loss [MAPE]: 1432552.632 --time-- 12.71716046333313\n",
      "Epoch 33/500 | Train Loss: 500.450 | Test Loss: 545.267 | Test Loss [MAPE]: 1539518.312 --time-- 12.713178634643555\n",
      "Epoch 34/500 | Train Loss: 544.161 | Test Loss: 600.735 | Test Loss [MAPE]: 1730136.699 --time-- 12.719747543334961\n",
      "Epoch 35/500 | Train Loss: 560.479 | Test Loss: 473.857 | Test Loss [MAPE]: 1349022.170 --time-- 12.720139265060425\n",
      "Epoch 36/500 | Train Loss: 481.505 | Test Loss: 526.776 | Test Loss [MAPE]: 1520743.299 --time-- 12.72098708152771\n",
      "Epoch 37/500 | Train Loss: 492.971 | Test Loss: 460.502 | Test Loss [MAPE]: 1350561.547 --time-- 12.72399353981018\n",
      "Epoch 38/500 | Train Loss: 489.517 | Test Loss: 469.658 | Test Loss [MAPE]: 1358464.029 --time-- 12.717151403427124\n",
      "Epoch 39/500 | Train Loss: 467.780 | Test Loss: 527.830 | Test Loss [MAPE]: 1407472.723 --time-- 12.718100309371948\n",
      "Epoch 40/500 | Train Loss: 465.764 | Test Loss: 488.458 | Test Loss [MAPE]: 1454318.284 --time-- 12.718483686447144\n",
      "Epoch 41/500 | Train Loss: 468.317 | Test Loss: 476.443 | Test Loss [MAPE]: 1420224.453 --time-- 12.771922826766968\n",
      "Epoch 42/500 | Train Loss: 455.295 | Test Loss: 515.825 | Test Loss [MAPE]: 1504027.714 --time-- 12.771337032318115\n",
      "Epoch 43/500 | Train Loss: 448.322 | Test Loss: 471.489 | Test Loss [MAPE]: 1203647.300 --time-- 12.773239374160767\n",
      "Epoch 44/500 | Train Loss: 487.900 | Test Loss: 454.799 | Test Loss [MAPE]: 1332567.894 --time-- 12.77337121963501\n",
      "Epoch 45/500 | Train Loss: 451.184 | Test Loss: 491.470 | Test Loss [MAPE]: 1442073.479 --time-- 12.788441181182861\n",
      "Epoch 46/500 | Train Loss: 461.873 | Test Loss: 499.067 | Test Loss [MAPE]: 1450353.027 --time-- 12.785279273986816\n",
      "Epoch 47/500 | Train Loss: 440.424 | Test Loss: 451.211 | Test Loss [MAPE]: 1333132.536 --time-- 12.784574270248413\n",
      "Epoch 48/500 | Train Loss: 425.525 | Test Loss: 447.080 | Test Loss [MAPE]: 1317733.008 --time-- 12.779788970947266\n",
      "Epoch 49/500 | Train Loss: 426.601 | Test Loss: 433.331 | Test Loss [MAPE]: 1294188.124 --time-- 12.769849061965942\n",
      "Epoch 50/500 | Train Loss: 431.811 | Test Loss: 430.455 | Test Loss [MAPE]: 1296934.415 --time-- 12.778375625610352\n",
      "Epoch 51/500 | Train Loss: 417.836 | Test Loss: 408.497 | Test Loss [MAPE]: 1204420.068 --time-- 12.774025678634644\n",
      "Epoch 52/500 | Train Loss: 423.247 | Test Loss: 410.303 | Test Loss [MAPE]: 1207322.002 --time-- 12.771041870117188\n",
      "Epoch 53/500 | Train Loss: 413.891 | Test Loss: 426.216 | Test Loss [MAPE]: 1243589.826 --time-- 12.776010990142822\n",
      "Epoch 54/500 | Train Loss: 423.604 | Test Loss: 421.750 | Test Loss [MAPE]: 1268346.848 --time-- 12.769089698791504\n",
      "Epoch 55/500 | Train Loss: 396.878 | Test Loss: 429.672 | Test Loss [MAPE]: 1280122.721 --time-- 12.72773814201355\n",
      "Epoch 56/500 | Train Loss: 384.127 | Test Loss: 383.711 | Test Loss [MAPE]: 1158192.751 --time-- 12.725210666656494\n",
      "Epoch 57/500 | Train Loss: 408.262 | Test Loss: 387.888 | Test Loss [MAPE]: 1162970.283 --time-- 12.720429420471191\n",
      "Epoch 58/500 | Train Loss: 400.934 | Test Loss: 434.091 | Test Loss [MAPE]: 1263885.740 --time-- 12.724498271942139\n",
      "Epoch 59/500 | Train Loss: 418.625 | Test Loss: 434.332 | Test Loss [MAPE]: 1249223.268 --time-- 12.71841025352478\n",
      "Epoch 60/500 | Train Loss: 391.824 | Test Loss: 390.887 | Test Loss [MAPE]: 1173061.907 --time-- 12.712209463119507\n",
      "Epoch 61/500 | Train Loss: 411.336 | Test Loss: 398.144 | Test Loss [MAPE]: 1210828.157 --time-- 12.725704669952393\n",
      "Epoch 62/500 | Train Loss: 391.542 | Test Loss: 386.208 | Test Loss [MAPE]: 1141075.065 --time-- 12.72652006149292\n",
      "Epoch 63/500 | Train Loss: 385.109 | Test Loss: 396.850 | Test Loss [MAPE]: 1148867.561 --time-- 12.710194110870361\n",
      "Epoch 64/500 | Train Loss: 386.726 | Test Loss: 398.076 | Test Loss [MAPE]: 1192656.111 --time-- 12.705247640609741\n",
      "Epoch 65/500 | Train Loss: 366.112 | Test Loss: 364.620 | Test Loss [MAPE]: 1083484.546 --time-- 12.710990190505981\n",
      "Epoch 66/500 | Train Loss: 345.710 | Test Loss: 386.685 | Test Loss [MAPE]: 1150736.139 --time-- 12.711724996566772\n",
      "Epoch 67/500 | Train Loss: 355.293 | Test Loss: 408.820 | Test Loss [MAPE]: 1234552.077 --time-- 12.713067293167114\n",
      "Epoch 68/500 | Train Loss: 381.258 | Test Loss: 415.774 | Test Loss [MAPE]: 1246699.083 --time-- 12.710711002349854\n",
      "Epoch 69/500 | Train Loss: 358.461 | Test Loss: 404.265 | Test Loss [MAPE]: 1206896.964 --time-- 12.711323976516724\n",
      "Epoch 70/500 | Train Loss: 377.187 | Test Loss: 410.372 | Test Loss [MAPE]: 1206187.750 --time-- 12.711689472198486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500 | Train Loss: 364.526 | Test Loss: 371.224 | Test Loss [MAPE]: 1130264.811 --time-- 12.709994077682495\n",
      "Epoch 72/500 | Train Loss: 362.836 | Test Loss: 400.023 | Test Loss [MAPE]: 1206823.906 --time-- 12.707224607467651\n",
      "Epoch 73/500 | Train Loss: 363.580 | Test Loss: 429.737 | Test Loss [MAPE]: 1195733.694 --time-- 12.708570957183838\n",
      "Epoch 74/500 | Train Loss: 378.481 | Test Loss: 392.994 | Test Loss [MAPE]: 1188553.154 --time-- 12.708314657211304\n",
      "Epoch 75/500 | Train Loss: 377.613 | Test Loss: 362.753 | Test Loss [MAPE]: 1100160.410 --time-- 12.711695194244385\n",
      "Epoch 76/500 | Train Loss: 349.656 | Test Loss: 386.741 | Test Loss [MAPE]: 1180083.227 --time-- 12.70892071723938\n",
      "Epoch 77/500 | Train Loss: 387.224 | Test Loss: 349.798 | Test Loss [MAPE]: 1059990.674 --time-- 12.70762300491333\n",
      "Epoch 78/500 | Train Loss: 396.407 | Test Loss: 369.707 | Test Loss [MAPE]: 1146670.960 --time-- 12.70263934135437\n",
      "Epoch 79/500 | Train Loss: 363.032 | Test Loss: 361.671 | Test Loss [MAPE]: 1122933.185 --time-- 12.707883596420288\n",
      "Epoch 80/500 | Train Loss: 359.403 | Test Loss: 372.549 | Test Loss [MAPE]: 1142357.976 --time-- 12.70727252960205\n",
      "Epoch 81/500 | Train Loss: 347.929 | Test Loss: 327.239 | Test Loss [MAPE]: 1007106.748 --time-- 12.713746309280396\n",
      "Epoch 82/500 | Train Loss: 345.522 | Test Loss: 363.362 | Test Loss [MAPE]: 1056688.641 --time-- 12.716625690460205\n",
      "Epoch 83/500 | Train Loss: 353.116 | Test Loss: 380.087 | Test Loss [MAPE]: 1145431.794 --time-- 12.709367513656616\n",
      "Epoch 84/500 | Train Loss: 357.025 | Test Loss: 329.240 | Test Loss [MAPE]: 992661.905 --time-- 12.709845304489136\n",
      "Epoch 85/500 | Train Loss: 350.035 | Test Loss: 345.144 | Test Loss [MAPE]: 1045700.318 --time-- 12.715919971466064\n",
      "Epoch 86/500 | Train Loss: 339.566 | Test Loss: 360.138 | Test Loss [MAPE]: 1143239.522 --time-- 12.713179111480713\n",
      "Epoch 87/500 | Train Loss: 345.665 | Test Loss: 353.641 | Test Loss [MAPE]: 1084591.875 --time-- 12.713735342025757\n",
      "Epoch 88/500 | Train Loss: 337.988 | Test Loss: 325.983 | Test Loss [MAPE]: 1008137.924 --time-- 12.711049318313599\n",
      "Epoch 89/500 | Train Loss: 341.526 | Test Loss: 420.052 | Test Loss [MAPE]: 1209081.664 --time-- 12.712230205535889\n",
      "Epoch 90/500 | Train Loss: 334.187 | Test Loss: 363.313 | Test Loss [MAPE]: 1131012.076 --time-- 12.747903823852539\n",
      "Epoch 91/500 | Train Loss: 370.895 | Test Loss: 427.256 | Test Loss [MAPE]: 1309030.769 --time-- 12.746646642684937\n",
      "Epoch 92/500 | Train Loss: 357.965 | Test Loss: 353.503 | Test Loss [MAPE]: 1090573.469 --time-- 12.739863634109497\n",
      "Epoch 93/500 | Train Loss: 343.709 | Test Loss: 329.927 | Test Loss [MAPE]: 1027353.618 --time-- 12.732086896896362\n",
      "Epoch 94/500 | Train Loss: 327.955 | Test Loss: 377.521 | Test Loss [MAPE]: 1185803.252 --time-- 12.76140809059143\n",
      "Epoch 95/500 | Train Loss: 322.104 | Test Loss: 343.644 | Test Loss [MAPE]: 1057638.933 --time-- 12.763356924057007\n",
      "Epoch 96/500 | Train Loss: 318.286 | Test Loss: 392.511 | Test Loss [MAPE]: 1191025.102 --time-- 12.809085845947266\n",
      "Epoch 97/500 | Train Loss: 318.534 | Test Loss: 317.384 | Test Loss [MAPE]: 1004365.311 --time-- 12.711591958999634\n",
      "Epoch 98/500 | Train Loss: 330.668 | Test Loss: 343.619 | Test Loss [MAPE]: 1038387.235 --time-- 12.709831476211548\n",
      "Epoch 99/500 | Train Loss: 333.803 | Test Loss: 414.027 | Test Loss [MAPE]: 1169046.824 --time-- 12.709478855133057\n",
      "Epoch 100/500 | Train Loss: 342.521 | Test Loss: 331.305 | Test Loss [MAPE]: 1024394.497 --time-- 12.71056342124939\n",
      "Epoch 101/500 | Train Loss: 317.735 | Test Loss: 331.747 | Test Loss [MAPE]: 1025443.066 --time-- 12.71016263961792\n",
      "Epoch 102/500 | Train Loss: 312.103 | Test Loss: 311.638 | Test Loss [MAPE]: 979080.792 --time-- 12.706714391708374\n",
      "Epoch 103/500 | Train Loss: 308.851 | Test Loss: 361.590 | Test Loss [MAPE]: 1094295.832 --time-- 12.7101469039917\n",
      "Epoch 104/500 | Train Loss: 313.474 | Test Loss: 345.530 | Test Loss [MAPE]: 1009242.807 --time-- 12.707980632781982\n",
      "Epoch 105/500 | Train Loss: 326.376 | Test Loss: 343.548 | Test Loss [MAPE]: 1090734.287 --time-- 12.707727193832397\n",
      "Epoch 106/500 | Train Loss: 321.290 | Test Loss: 363.123 | Test Loss [MAPE]: 1142129.516 --time-- 12.704824209213257\n",
      "Epoch 107/500 | Train Loss: 322.535 | Test Loss: 315.410 | Test Loss [MAPE]: 1009705.485 --time-- 12.707849979400635\n",
      "Epoch 108/500 | Train Loss: 316.345 | Test Loss: 305.055 | Test Loss [MAPE]: 959669.676 --time-- 12.704143524169922\n",
      "Epoch 109/500 | Train Loss: 333.640 | Test Loss: 384.062 | Test Loss [MAPE]: 1129160.528 --time-- 12.704490184783936\n",
      "Epoch 110/500 | Train Loss: 332.029 | Test Loss: 357.455 | Test Loss [MAPE]: 1029799.238 --time-- 12.702097415924072\n",
      "Epoch 111/500 | Train Loss: 331.965 | Test Loss: 334.889 | Test Loss [MAPE]: 1042858.656 --time-- 12.706395626068115\n",
      "Epoch 112/500 | Train Loss: 314.162 | Test Loss: 313.606 | Test Loss [MAPE]: 949895.120 --time-- 12.709274768829346\n",
      "Epoch 113/500 | Train Loss: 336.519 | Test Loss: 367.155 | Test Loss [MAPE]: 1125710.291 --time-- 12.710266828536987\n",
      "Epoch 114/500 | Train Loss: 321.451 | Test Loss: 352.638 | Test Loss [MAPE]: 1064038.524 --time-- 12.706437826156616\n",
      "Epoch 115/500 | Train Loss: 312.577 | Test Loss: 383.674 | Test Loss [MAPE]: 1186010.205 --time-- 12.711094379425049\n",
      "Epoch 116/500 | Train Loss: 317.712 | Test Loss: 305.910 | Test Loss [MAPE]: 976599.757 --time-- 12.70739197731018\n",
      "Epoch 117/500 | Train Loss: 312.334 | Test Loss: 316.976 | Test Loss [MAPE]: 977182.400 --time-- 12.708550214767456\n",
      "Epoch 118/500 | Train Loss: 314.744 | Test Loss: 299.456 | Test Loss [MAPE]: 931385.884 --time-- 12.706061363220215\n",
      "Epoch 119/500 | Train Loss: 319.592 | Test Loss: 347.832 | Test Loss [MAPE]: 1126211.199 --time-- 12.709271669387817\n",
      "Epoch 120/500 | Train Loss: 343.094 | Test Loss: 356.168 | Test Loss [MAPE]: 1011905.294 --time-- 12.710103988647461\n",
      "Epoch 121/500 | Train Loss: 310.042 | Test Loss: 331.658 | Test Loss [MAPE]: 1057244.484 --time-- 12.709771871566772\n",
      "Epoch 122/500 | Train Loss: 302.718 | Test Loss: 328.514 | Test Loss [MAPE]: 1018720.687 --time-- 12.76301121711731\n",
      "Epoch 123/500 | Train Loss: 311.879 | Test Loss: 348.944 | Test Loss [MAPE]: 1105978.605 --time-- 12.760954856872559\n",
      "Epoch 124/500 | Train Loss: 334.567 | Test Loss: 366.751 | Test Loss [MAPE]: 1157831.624 --time-- 12.76196026802063\n",
      "Epoch 125/500 | Train Loss: 302.823 | Test Loss: 334.683 | Test Loss [MAPE]: 1036471.039 --time-- 12.762540102005005\n",
      "Epoch 126/500 | Train Loss: 304.506 | Test Loss: 323.480 | Test Loss [MAPE]: 1046747.474 --time-- 12.713457822799683\n",
      "Epoch 127/500 | Train Loss: 323.927 | Test Loss: 384.111 | Test Loss [MAPE]: 1229060.486 --time-- 12.707795858383179\n",
      "Epoch 128/500 | Train Loss: 331.484 | Test Loss: 336.043 | Test Loss [MAPE]: 1077073.519 --time-- 12.709199905395508\n",
      "Epoch 129/500 | Train Loss: 301.825 | Test Loss: 324.857 | Test Loss [MAPE]: 1024291.316 --time-- 12.706620693206787\n",
      "Epoch 130/500 | Train Loss: 320.116 | Test Loss: 345.977 | Test Loss [MAPE]: 1069603.370 --time-- 12.709509134292603\n",
      "Epoch 131/500 | Train Loss: 286.448 | Test Loss: 293.160 | Test Loss [MAPE]: 924620.274 --time-- 12.712291479110718\n",
      "Epoch 132/500 | Train Loss: 284.613 | Test Loss: 352.548 | Test Loss [MAPE]: 1109321.923 --time-- 12.713462352752686\n",
      "Epoch 133/500 | Train Loss: 307.328 | Test Loss: 348.526 | Test Loss [MAPE]: 1068003.487 --time-- 12.70633578300476\n",
      "Epoch 134/500 | Train Loss: 304.471 | Test Loss: 283.466 | Test Loss [MAPE]: 872983.247 --time-- 12.710179328918457\n",
      "Epoch 135/500 | Train Loss: 307.667 | Test Loss: 323.632 | Test Loss [MAPE]: 989725.343 --time-- 12.707234859466553\n",
      "Epoch 136/500 | Train Loss: 289.039 | Test Loss: 283.201 | Test Loss [MAPE]: 891317.125 --time-- 12.711457967758179\n",
      "Epoch 137/500 | Train Loss: 293.493 | Test Loss: 344.199 | Test Loss [MAPE]: 1088703.076 --time-- 12.707536220550537\n",
      "Epoch 138/500 | Train Loss: 303.151 | Test Loss: 370.458 | Test Loss [MAPE]: 1119337.880 --time-- 12.7099130153656\n",
      "Epoch 139/500 | Train Loss: 303.360 | Test Loss: 333.256 | Test Loss [MAPE]: 1059703.457 --time-- 12.71086597442627\n",
      "Epoch 140/500 | Train Loss: 312.195 | Test Loss: 321.967 | Test Loss [MAPE]: 1008981.587 --time-- 12.70841932296753\n",
      "Epoch 141/500 | Train Loss: 291.513 | Test Loss: 319.879 | Test Loss [MAPE]: 1005580.492 --time-- 12.707229852676392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/500 | Train Loss: 297.539 | Test Loss: 318.931 | Test Loss [MAPE]: 1023685.284 --time-- 12.712433338165283\n",
      "Epoch 143/500 | Train Loss: 283.165 | Test Loss: 285.952 | Test Loss [MAPE]: 900311.094 --time-- 12.70687747001648\n",
      "Epoch 144/500 | Train Loss: 308.642 | Test Loss: 316.215 | Test Loss [MAPE]: 951090.965 --time-- 12.704389333724976\n",
      "Epoch 145/500 | Train Loss: 280.329 | Test Loss: 311.417 | Test Loss [MAPE]: 1000451.057 --time-- 12.70702600479126\n",
      "Epoch 146/500 | Train Loss: 285.229 | Test Loss: 288.596 | Test Loss [MAPE]: 915524.396 --time-- 12.707323789596558\n",
      "Epoch 147/500 | Train Loss: 287.169 | Test Loss: 313.777 | Test Loss [MAPE]: 914825.632 --time-- 12.700774669647217\n",
      "Epoch 148/500 | Train Loss: 317.455 | Test Loss: 320.019 | Test Loss [MAPE]: 956906.173 --time-- 12.705827951431274\n",
      "Epoch 149/500 | Train Loss: 286.850 | Test Loss: 264.733 | Test Loss [MAPE]: 837550.199 --time-- 12.707812070846558\n",
      "Epoch 150/500 | Train Loss: 271.011 | Test Loss: 293.530 | Test Loss [MAPE]: 920544.258 --time-- 12.7012779712677\n",
      "Epoch 151/500 | Train Loss: 276.312 | Test Loss: 348.947 | Test Loss [MAPE]: 1104213.755 --time-- 12.707843780517578\n",
      "Epoch 152/500 | Train Loss: 292.209 | Test Loss: 363.432 | Test Loss [MAPE]: 1157169.302 --time-- 12.702837944030762\n",
      "Epoch 153/500 | Train Loss: 301.935 | Test Loss: 292.860 | Test Loss [MAPE]: 895288.506 --time-- 12.704224824905396\n",
      "Epoch 154/500 | Train Loss: 294.060 | Test Loss: 360.741 | Test Loss [MAPE]: 1092311.286 --time-- 12.702681064605713\n",
      "Epoch 155/500 | Train Loss: 321.362 | Test Loss: 352.988 | Test Loss [MAPE]: 1069385.395 --time-- 12.702853202819824\n",
      "Epoch 156/500 | Train Loss: 302.182 | Test Loss: 343.163 | Test Loss [MAPE]: 1098142.578 --time-- 12.703893184661865\n",
      "Epoch 157/500 | Train Loss: 282.061 | Test Loss: 307.214 | Test Loss [MAPE]: 979235.126 --time-- 12.69938325881958\n",
      "Epoch 158/500 | Train Loss: 280.678 | Test Loss: 345.705 | Test Loss [MAPE]: 1116259.040 --time-- 12.705305814743042\n",
      "Epoch 159/500 | Train Loss: 299.250 | Test Loss: 280.317 | Test Loss [MAPE]: 873073.868 --time-- 12.708587169647217\n",
      "Epoch 160/500 | Train Loss: 285.879 | Test Loss: 332.871 | Test Loss [MAPE]: 1065145.057 --time-- 12.756656885147095\n",
      "Epoch 161/500 | Train Loss: 288.052 | Test Loss: 309.125 | Test Loss [MAPE]: 958744.550 --time-- 12.760990858078003\n",
      "Epoch 162/500 | Train Loss: 289.989 | Test Loss: 312.202 | Test Loss [MAPE]: 956886.552 --time-- 12.754096984863281\n",
      "Epoch 163/500 | Train Loss: 279.411 | Test Loss: 278.507 | Test Loss [MAPE]: 894997.447 --time-- 12.755306243896484\n",
      "Epoch 164/500 | Train Loss: 294.918 | Test Loss: 320.320 | Test Loss [MAPE]: 1038154.310 --time-- 12.770380973815918\n",
      "Epoch 165/500 | Train Loss: 281.787 | Test Loss: 320.307 | Test Loss [MAPE]: 1002794.712 --time-- 12.774355411529541\n",
      "Epoch 166/500 | Train Loss: 287.668 | Test Loss: 320.015 | Test Loss [MAPE]: 1003912.124 --time-- 12.77049207687378\n",
      "Epoch 167/500 | Train Loss: 291.035 | Test Loss: 336.138 | Test Loss [MAPE]: 1050336.487 --time-- 12.758757829666138\n",
      "Epoch 168/500 | Train Loss: 342.802 | Test Loss: 422.665 | Test Loss [MAPE]: 1060206.538 --time-- 12.756356716156006\n",
      "Epoch 169/500 | Train Loss: 294.237 | Test Loss: 288.327 | Test Loss [MAPE]: 895939.305 --time-- 12.75713562965393\n",
      "Epoch 170/500 | Train Loss: 252.510 | Test Loss: 283.466 | Test Loss [MAPE]: 926919.450 --time-- 12.759252786636353\n",
      "Epoch 171/500 | Train Loss: 262.436 | Test Loss: 291.555 | Test Loss [MAPE]: 949469.651 --time-- 12.753514289855957\n",
      "Epoch 172/500 | Train Loss: 281.364 | Test Loss: 311.644 | Test Loss [MAPE]: 1019684.875 --time-- 12.753773927688599\n",
      "Epoch 173/500 | Train Loss: 280.005 | Test Loss: 315.281 | Test Loss [MAPE]: 1006292.581 --time-- 12.755415916442871\n",
      "Epoch 174/500 | Train Loss: 275.838 | Test Loss: 314.538 | Test Loss [MAPE]: 998862.246 --time-- 12.756883144378662\n",
      "Epoch 175/500 | Train Loss: 275.681 | Test Loss: 281.540 | Test Loss [MAPE]: 894178.926 --time-- 12.760390996932983\n",
      "Epoch 176/500 | Train Loss: 270.118 | Test Loss: 286.058 | Test Loss [MAPE]: 932080.981 --time-- 12.75911808013916\n",
      "Epoch 177/500 | Train Loss: 285.074 | Test Loss: 315.938 | Test Loss [MAPE]: 958122.743 --time-- 12.757215738296509\n",
      "Epoch 178/500 | Train Loss: 277.348 | Test Loss: 317.490 | Test Loss [MAPE]: 1008695.264 --time-- 12.752717018127441\n",
      "Epoch 179/500 | Train Loss: 292.227 | Test Loss: 288.427 | Test Loss [MAPE]: 910455.461 --time-- 12.753546714782715\n",
      "Epoch 180/500 | Train Loss: 265.603 | Test Loss: 269.496 | Test Loss [MAPE]: 881961.313 --time-- 12.759873151779175\n",
      "Epoch 181/500 | Train Loss: 258.806 | Test Loss: 314.791 | Test Loss [MAPE]: 1002776.023 --time-- 12.757330894470215\n",
      "Epoch 182/500 | Train Loss: 284.583 | Test Loss: 316.670 | Test Loss [MAPE]: 993259.629 --time-- 12.751024961471558\n",
      "Epoch 183/500 | Train Loss: 272.613 | Test Loss: 323.198 | Test Loss [MAPE]: 1024320.820 --time-- 12.75790810585022\n",
      "Epoch 184/500 | Train Loss: 269.460 | Test Loss: 291.619 | Test Loss [MAPE]: 959277.522 --time-- 12.757776975631714\n",
      "Epoch 185/500 | Train Loss: 260.738 | Test Loss: 306.063 | Test Loss [MAPE]: 986669.133 --time-- 12.758540391921997\n",
      "Epoch 186/500 | Train Loss: 273.232 | Test Loss: 343.773 | Test Loss [MAPE]: 1110981.927 --time-- 12.759859561920166\n",
      "Epoch 187/500 | Train Loss: 266.388 | Test Loss: 292.513 | Test Loss [MAPE]: 920072.574 --time-- 12.757712125778198\n",
      "Epoch 188/500 | Train Loss: 270.141 | Test Loss: 307.735 | Test Loss [MAPE]: 1002353.878 --time-- 12.758064985275269\n",
      "Epoch 189/500 | Train Loss: 277.039 | Test Loss: 298.041 | Test Loss [MAPE]: 961303.383 --time-- 12.759624481201172\n",
      "Epoch 190/500 | Train Loss: 271.211 | Test Loss: 261.406 | Test Loss [MAPE]: 879277.284 --time-- 12.755392789840698\n",
      "Epoch 191/500 | Train Loss: 248.090 | Test Loss: 303.873 | Test Loss [MAPE]: 975210.805 --time-- 12.758981704711914\n",
      "Epoch 192/500 | Train Loss: 263.138 | Test Loss: 321.923 | Test Loss [MAPE]: 1016791.719 --time-- 12.757039070129395\n",
      "Epoch 193/500 | Train Loss: 281.574 | Test Loss: 323.408 | Test Loss [MAPE]: 955715.085 --time-- 12.755810976028442\n",
      "Epoch 194/500 | Train Loss: 283.377 | Test Loss: 281.639 | Test Loss [MAPE]: 914075.204 --time-- 12.754786491394043\n",
      "Epoch 195/500 | Train Loss: 255.253 | Test Loss: 274.713 | Test Loss [MAPE]: 862152.132 --time-- 12.756184101104736\n",
      "Epoch 196/500 | Train Loss: 249.571 | Test Loss: 284.033 | Test Loss [MAPE]: 917276.256 --time-- 12.760594129562378\n",
      "Epoch 197/500 | Train Loss: 268.445 | Test Loss: 304.759 | Test Loss [MAPE]: 974536.147 --time-- 12.751687288284302\n",
      "Epoch 198/500 | Train Loss: 287.292 | Test Loss: 292.964 | Test Loss [MAPE]: 958465.585 --time-- 12.75824236869812\n",
      "Epoch 199/500 | Train Loss: 272.533 | Test Loss: 327.292 | Test Loss [MAPE]: 977381.487 --time-- 12.759305477142334\n",
      "Epoch 200/500 | Train Loss: 282.687 | Test Loss: 275.644 | Test Loss [MAPE]: 909630.182 --time-- 12.754639625549316\n",
      "Epoch 201/500 | Train Loss: 272.005 | Test Loss: 296.081 | Test Loss [MAPE]: 961558.550 --time-- 12.75483751296997\n",
      "Epoch 202/500 | Train Loss: 278.792 | Test Loss: 278.706 | Test Loss [MAPE]: 891406.371 --time-- 12.756446123123169\n",
      "Epoch 203/500 | Train Loss: 260.780 | Test Loss: 268.691 | Test Loss [MAPE]: 878980.294 --time-- 12.751891613006592\n",
      "Epoch 204/500 | Train Loss: 258.031 | Test Loss: 333.771 | Test Loss [MAPE]: 977134.846 --time-- 12.760915040969849\n",
      "Epoch 205/500 | Train Loss: 274.514 | Test Loss: 274.650 | Test Loss [MAPE]: 887323.338 --time-- 12.760269403457642\n",
      "Epoch 206/500 | Train Loss: 252.048 | Test Loss: 285.065 | Test Loss [MAPE]: 923197.273 --time-- 12.756337881088257\n",
      "Epoch 207/500 | Train Loss: 251.870 | Test Loss: 294.527 | Test Loss [MAPE]: 945715.962 --time-- 12.753321647644043\n",
      "Epoch 208/500 | Train Loss: 267.229 | Test Loss: 324.899 | Test Loss [MAPE]: 996065.308 --time-- 12.761443376541138\n",
      "Epoch 209/500 | Train Loss: 270.777 | Test Loss: 319.156 | Test Loss [MAPE]: 1032165.344 --time-- 12.75004243850708\n",
      "Epoch 210/500 | Train Loss: 259.960 | Test Loss: 299.145 | Test Loss [MAPE]: 952902.134 --time-- 12.755150556564331\n",
      "Epoch 211/500 | Train Loss: 271.261 | Test Loss: 316.249 | Test Loss [MAPE]: 1025489.554 --time-- 12.751168727874756\n",
      "Epoch 212/500 | Train Loss: 270.721 | Test Loss: 305.122 | Test Loss [MAPE]: 992247.344 --time-- 12.70319938659668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/500 | Train Loss: 292.981 | Test Loss: 284.377 | Test Loss [MAPE]: 910819.846 --time-- 12.75480842590332\n",
      "Epoch 214/500 | Train Loss: 255.135 | Test Loss: 277.625 | Test Loss [MAPE]: 896995.655 --time-- 12.760234832763672\n",
      "Epoch 215/500 | Train Loss: 279.606 | Test Loss: 264.153 | Test Loss [MAPE]: 844993.293 --time-- 12.754897117614746\n",
      "Epoch 216/500 | Train Loss: 281.222 | Test Loss: 296.172 | Test Loss [MAPE]: 971433.453 --time-- 12.7475745677948\n",
      "Epoch 217/500 | Train Loss: 266.677 | Test Loss: 296.209 | Test Loss [MAPE]: 910223.026 --time-- 12.757494688034058\n",
      "Epoch 218/500 | Train Loss: 259.832 | Test Loss: 305.257 | Test Loss [MAPE]: 979805.763 --time-- 12.748892784118652\n",
      "Epoch 219/500 | Train Loss: 259.984 | Test Loss: 274.288 | Test Loss [MAPE]: 906750.632 --time-- 12.754355907440186\n",
      "Epoch 220/500 | Train Loss: 281.348 | Test Loss: 329.047 | Test Loss [MAPE]: 950944.755 --time-- 12.750680923461914\n",
      "Epoch 221/500 | Train Loss: 278.908 | Test Loss: 251.325 | Test Loss [MAPE]: 792121.731 --time-- 12.756311655044556\n",
      "Epoch 222/500 | Train Loss: 240.378 | Test Loss: 264.892 | Test Loss [MAPE]: 866559.681 --time-- 12.75763750076294\n",
      "Epoch 223/500 | Train Loss: 245.085 | Test Loss: 280.999 | Test Loss [MAPE]: 914183.011 --time-- 12.754744291305542\n",
      "Epoch 224/500 | Train Loss: 264.090 | Test Loss: 358.931 | Test Loss [MAPE]: 1165571.799 --time-- 12.757331848144531\n",
      "Epoch 225/500 | Train Loss: 261.481 | Test Loss: 239.296 | Test Loss [MAPE]: 788499.592 --time-- 12.755114793777466\n",
      "Epoch 226/500 | Train Loss: 243.920 | Test Loss: 271.572 | Test Loss [MAPE]: 887349.287 --time-- 12.759319305419922\n",
      "Epoch 227/500 | Train Loss: 298.999 | Test Loss: 341.884 | Test Loss [MAPE]: 902537.738 --time-- 12.756104469299316\n",
      "Epoch 228/500 | Train Loss: 262.174 | Test Loss: 292.143 | Test Loss [MAPE]: 947159.009 --time-- 12.75827431678772\n",
      "Epoch 229/500 | Train Loss: 250.422 | Test Loss: 276.062 | Test Loss [MAPE]: 891492.122 --time-- 12.706260919570923\n",
      "Epoch 230/500 | Train Loss: 255.117 | Test Loss: 336.631 | Test Loss [MAPE]: 959800.810 --time-- 12.700106382369995\n",
      "Epoch 231/500 | Train Loss: 277.361 | Test Loss: 302.822 | Test Loss [MAPE]: 1001591.201 --time-- 12.705992698669434\n",
      "Epoch 232/500 | Train Loss: 262.977 | Test Loss: 291.253 | Test Loss [MAPE]: 964513.375 --time-- 12.710318803787231\n",
      "Epoch 233/500 | Train Loss: 253.244 | Test Loss: 282.899 | Test Loss [MAPE]: 914014.423 --time-- 12.70939302444458\n",
      "Epoch 234/500 | Train Loss: 249.095 | Test Loss: 245.088 | Test Loss [MAPE]: 802022.355 --time-- 12.710441827774048\n",
      "Epoch 235/500 | Train Loss: 227.087 | Test Loss: 247.312 | Test Loss [MAPE]: 783747.150 --time-- 12.719577550888062\n",
      "Epoch 236/500 | Train Loss: 260.119 | Test Loss: 323.111 | Test Loss [MAPE]: 1048453.058 --time-- 12.712415933609009\n",
      "Epoch 237/500 | Train Loss: 253.328 | Test Loss: 301.370 | Test Loss [MAPE]: 904906.101 --time-- 12.716924667358398\n",
      "Epoch 238/500 | Train Loss: 274.511 | Test Loss: 259.986 | Test Loss [MAPE]: 805027.797 --time-- 12.702407121658325\n",
      "Epoch 239/500 | Train Loss: 239.035 | Test Loss: 238.262 | Test Loss [MAPE]: 777055.759 --time-- 12.703146934509277\n",
      "Epoch 240/500 | Train Loss: 248.286 | Test Loss: 293.203 | Test Loss [MAPE]: 923512.393 --time-- 12.706171035766602\n",
      "Epoch 241/500 | Train Loss: 266.413 | Test Loss: 240.982 | Test Loss [MAPE]: 799104.340 --time-- 12.70212173461914\n",
      "Epoch 242/500 | Train Loss: 238.113 | Test Loss: 261.401 | Test Loss [MAPE]: 828031.304 --time-- 12.707267045974731\n",
      "Epoch 243/500 | Train Loss: 251.749 | Test Loss: 282.318 | Test Loss [MAPE]: 923864.854 --time-- 12.704594850540161\n",
      "Epoch 244/500 | Train Loss: 253.814 | Test Loss: 268.249 | Test Loss [MAPE]: 859199.738 --time-- 12.705471754074097\n",
      "Epoch 245/500 | Train Loss: 249.449 | Test Loss: 262.004 | Test Loss [MAPE]: 858339.790 --time-- 12.70782470703125\n",
      "Epoch 246/500 | Train Loss: 256.128 | Test Loss: 282.369 | Test Loss [MAPE]: 904747.907 --time-- 12.757630109786987\n",
      "Epoch 247/500 | Train Loss: 270.615 | Test Loss: 293.197 | Test Loss [MAPE]: 925544.348 --time-- 12.753184795379639\n",
      "Epoch 248/500 | Train Loss: 270.970 | Test Loss: 269.474 | Test Loss [MAPE]: 870658.979 --time-- 12.755213975906372\n",
      "Epoch 249/500 | Train Loss: 255.970 | Test Loss: 297.083 | Test Loss [MAPE]: 947490.325 --time-- 12.754710674285889\n",
      "Epoch 250/500 | Train Loss: 248.624 | Test Loss: 290.648 | Test Loss [MAPE]: 927490.721 --time-- 12.759390592575073\n",
      "Epoch 251/500 | Train Loss: 253.852 | Test Loss: 259.578 | Test Loss [MAPE]: 857539.317 --time-- 12.70371699333191\n",
      "Epoch 252/500 | Train Loss: 264.289 | Test Loss: 303.497 | Test Loss [MAPE]: 970872.332 --time-- 12.702489852905273\n",
      "Epoch 253/500 | Train Loss: 255.538 | Test Loss: 280.879 | Test Loss [MAPE]: 886541.493 --time-- 12.705755949020386\n",
      "Epoch 254/500 | Train Loss: 238.638 | Test Loss: 271.571 | Test Loss [MAPE]: 853733.518 --time-- 12.702712297439575\n",
      "Epoch 255/500 | Train Loss: 286.430 | Test Loss: 260.521 | Test Loss [MAPE]: 843915.920 --time-- 12.701981544494629\n",
      "Epoch 256/500 | Train Loss: 282.027 | Test Loss: 265.540 | Test Loss [MAPE]: 824177.182 --time-- 12.748462438583374\n",
      "Epoch 257/500 | Train Loss: 271.709 | Test Loss: 366.514 | Test Loss [MAPE]: 1013101.815 --time-- 12.747679710388184\n",
      "Epoch 258/500 | Train Loss: 311.983 | Test Loss: 283.069 | Test Loss [MAPE]: 908248.673 --time-- 12.73648190498352\n",
      "Epoch 259/500 | Train Loss: 223.182 | Test Loss: 287.582 | Test Loss [MAPE]: 861093.551 --time-- 12.756774663925171\n",
      "Epoch 260/500 | Train Loss: 262.499 | Test Loss: 291.601 | Test Loss [MAPE]: 971736.525 --time-- 12.768019199371338\n",
      "Epoch 261/500 | Train Loss: 233.389 | Test Loss: 244.874 | Test Loss [MAPE]: 779760.863 --time-- 12.773759126663208\n",
      "Epoch 262/500 | Train Loss: 232.930 | Test Loss: 261.093 | Test Loss [MAPE]: 847809.644 --time-- 12.75254774093628\n",
      "Epoch 263/500 | Train Loss: 252.361 | Test Loss: 276.369 | Test Loss [MAPE]: 901790.302 --time-- 12.699083089828491\n",
      "Epoch 264/500 | Train Loss: 240.969 | Test Loss: 284.089 | Test Loss [MAPE]: 916904.421 --time-- 12.699199199676514\n",
      "Epoch 265/500 | Train Loss: 302.948 | Test Loss: 328.081 | Test Loss [MAPE]: 1015622.016 --time-- 12.692479848861694\n",
      "Epoch 266/500 | Train Loss: 241.260 | Test Loss: 252.359 | Test Loss [MAPE]: 821677.306 --time-- 12.695658683776855\n",
      "Epoch 267/500 | Train Loss: 248.327 | Test Loss: 276.616 | Test Loss [MAPE]: 906662.873 --time-- 12.707112789154053\n",
      "Epoch 268/500 | Train Loss: 239.720 | Test Loss: 272.970 | Test Loss [MAPE]: 898457.088 --time-- 12.756876945495605\n",
      "Epoch 269/500 | Train Loss: 249.129 | Test Loss: 309.156 | Test Loss [MAPE]: 1024986.525 --time-- 12.7553391456604\n",
      "Epoch 270/500 | Train Loss: 246.845 | Test Loss: 310.101 | Test Loss [MAPE]: 976171.638 --time-- 12.755752325057983\n",
      "Epoch 271/500 | Train Loss: 260.766 | Test Loss: 359.109 | Test Loss [MAPE]: 1040119.113 --time-- 12.752224922180176\n",
      "Epoch 272/500 | Train Loss: 281.657 | Test Loss: 319.525 | Test Loss [MAPE]: 1036703.820 --time-- 12.756515502929688\n",
      "Epoch 273/500 | Train Loss: 232.395 | Test Loss: 255.003 | Test Loss [MAPE]: 798753.075 --time-- 12.756803750991821\n",
      "Epoch 274/500 | Train Loss: 243.513 | Test Loss: 290.611 | Test Loss [MAPE]: 932951.223 --time-- 12.702123403549194\n",
      "Epoch 275/500 | Train Loss: 238.379 | Test Loss: 271.054 | Test Loss [MAPE]: 899984.099 --time-- 12.703573226928711\n",
      "Epoch 276/500 | Train Loss: 237.421 | Test Loss: 264.283 | Test Loss [MAPE]: 851383.712 --time-- 12.70203423500061\n",
      "Epoch 277/500 | Train Loss: 244.776 | Test Loss: 275.321 | Test Loss [MAPE]: 851335.873 --time-- 12.698992013931274\n",
      "Epoch 278/500 | Train Loss: 252.318 | Test Loss: 266.964 | Test Loss [MAPE]: 852420.966 --time-- 12.702010154724121\n",
      "Epoch 279/500 | Train Loss: 230.143 | Test Loss: 279.291 | Test Loss [MAPE]: 920092.859 --time-- 12.713147640228271\n",
      "Epoch 280/500 | Train Loss: 243.641 | Test Loss: 243.857 | Test Loss [MAPE]: 806289.537 --time-- 12.708580017089844\n",
      "Epoch 281/500 | Train Loss: 256.168 | Test Loss: 290.697 | Test Loss [MAPE]: 912326.239 --time-- 12.702281475067139\n",
      "Epoch 282/500 | Train Loss: 243.961 | Test Loss: 264.951 | Test Loss [MAPE]: 875592.845 --time-- 12.69861364364624\n",
      "Epoch 283/500 | Train Loss: 240.933 | Test Loss: 267.342 | Test Loss [MAPE]: 869803.155 --time-- 12.70383596420288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/500 | Train Loss: 245.168 | Test Loss: 309.049 | Test Loss [MAPE]: 1031368.074 --time-- 12.701637744903564\n",
      "Epoch 285/500 | Train Loss: 269.034 | Test Loss: 278.655 | Test Loss [MAPE]: 950549.746 --time-- 12.69840955734253\n",
      "Epoch 286/500 | Train Loss: 239.969 | Test Loss: 242.783 | Test Loss [MAPE]: 808735.079 --time-- 12.70083236694336\n",
      "Epoch 287/500 | Train Loss: 218.220 | Test Loss: 268.252 | Test Loss [MAPE]: 892486.954 --time-- 12.70474910736084\n",
      "Epoch 288/500 | Train Loss: 240.555 | Test Loss: 315.706 | Test Loss [MAPE]: 914301.696 --time-- 12.702328443527222\n",
      "Epoch 289/500 | Train Loss: 287.358 | Test Loss: 276.542 | Test Loss [MAPE]: 862556.235 --time-- 12.698854923248291\n",
      "Epoch 290/500 | Train Loss: 260.486 | Test Loss: 260.182 | Test Loss [MAPE]: 837597.960 --time-- 12.705363035202026\n",
      "Epoch 291/500 | Train Loss: 225.809 | Test Loss: 301.105 | Test Loss [MAPE]: 985121.242 --time-- 12.70389723777771\n",
      "Epoch 292/500 | Train Loss: 223.374 | Test Loss: 285.108 | Test Loss [MAPE]: 849378.687 --time-- 12.750324487686157\n",
      "Epoch 293/500 | Train Loss: 234.784 | Test Loss: 271.885 | Test Loss [MAPE]: 856803.465 --time-- 12.755414009094238\n",
      "Epoch 294/500 | Train Loss: 241.048 | Test Loss: 279.984 | Test Loss [MAPE]: 860141.645 --time-- 12.704497814178467\n",
      "Epoch 295/500 | Train Loss: 228.625 | Test Loss: 285.929 | Test Loss [MAPE]: 927312.861 --time-- 12.702637195587158\n",
      "Epoch 296/500 | Train Loss: 244.367 | Test Loss: 263.167 | Test Loss [MAPE]: 859672.215 --time-- 12.6991605758667\n",
      "Epoch 297/500 | Train Loss: 238.892 | Test Loss: 305.519 | Test Loss [MAPE]: 965956.126 --time-- 12.699207067489624\n",
      "Epoch 298/500 | Train Loss: 234.926 | Test Loss: 249.870 | Test Loss [MAPE]: 828201.084 --time-- 12.705877542495728\n",
      "Epoch 299/500 | Train Loss: 243.257 | Test Loss: 267.120 | Test Loss [MAPE]: 890740.249 --time-- 12.703133583068848\n",
      "Epoch 300/500 | Train Loss: 235.344 | Test Loss: 283.893 | Test Loss [MAPE]: 921716.302 --time-- 12.698919296264648\n",
      "Epoch 301/500 | Train Loss: 229.428 | Test Loss: 273.194 | Test Loss [MAPE]: 906613.409 --time-- 12.73654556274414\n",
      "Epoch 302/500 | Train Loss: 225.884 | Test Loss: 265.571 | Test Loss [MAPE]: 889922.871 --time-- 12.735443592071533\n",
      "Epoch 303/500 | Train Loss: 262.098 | Test Loss: 359.961 | Test Loss [MAPE]: 1068680.802 --time-- 12.737220287322998\n",
      "Epoch 304/500 | Train Loss: 252.429 | Test Loss: 295.610 | Test Loss [MAPE]: 983705.522 --time-- 12.736517906188965\n",
      "Epoch 305/500 | Train Loss: 240.169 | Test Loss: 270.483 | Test Loss [MAPE]: 895920.619 --time-- 12.727967500686646\n",
      "Epoch 306/500 | Train Loss: 229.884 | Test Loss: 258.841 | Test Loss [MAPE]: 847474.377 --time-- 12.73800277709961\n",
      "Epoch 307/500 | Train Loss: 230.793 | Test Loss: 283.552 | Test Loss [MAPE]: 839793.629 --time-- 12.738370180130005\n",
      "Epoch 308/500 | Train Loss: 242.497 | Test Loss: 282.464 | Test Loss [MAPE]: 959644.468 --time-- 12.730228424072266\n",
      "Epoch 309/500 | Train Loss: 230.036 | Test Loss: 295.023 | Test Loss [MAPE]: 942198.526 --time-- 12.704445362091064\n",
      "Epoch 310/500 | Train Loss: 242.331 | Test Loss: 258.492 | Test Loss [MAPE]: 847376.173 --time-- 12.702738523483276\n",
      "Epoch 311/500 | Train Loss: 229.056 | Test Loss: 265.107 | Test Loss [MAPE]: 892403.588 --time-- 12.700738191604614\n",
      "Epoch 312/500 | Train Loss: 229.991 | Test Loss: 288.862 | Test Loss [MAPE]: 873263.113 --time-- 12.703258752822876\n",
      "Epoch 313/500 | Train Loss: 281.452 | Test Loss: 247.288 | Test Loss [MAPE]: 786235.503 --time-- 12.698675394058228\n",
      "Epoch 314/500 | Train Loss: 212.342 | Test Loss: 291.397 | Test Loss [MAPE]: 857318.017 --time-- 12.703583240509033\n",
      "Epoch 315/500 | Train Loss: 219.922 | Test Loss: 246.721 | Test Loss [MAPE]: 783774.846 --time-- 12.699681520462036\n",
      "Epoch 316/500 | Train Loss: 226.250 | Test Loss: 289.643 | Test Loss [MAPE]: 935926.793 --time-- 12.70248556137085\n",
      "Epoch 317/500 | Train Loss: 243.442 | Test Loss: 228.568 | Test Loss [MAPE]: 765108.904 --time-- 12.698176383972168\n",
      "Epoch 318/500 | Train Loss: 228.546 | Test Loss: 269.170 | Test Loss [MAPE]: 854203.666 --time-- 12.700263500213623\n",
      "Epoch 319/500 | Train Loss: 267.218 | Test Loss: 303.294 | Test Loss [MAPE]: 991856.197 --time-- 12.702892065048218\n",
      "Epoch 320/500 | Train Loss: 241.686 | Test Loss: 291.301 | Test Loss [MAPE]: 953180.184 --time-- 12.699630975723267\n",
      "Epoch 321/500 | Train Loss: 233.714 | Test Loss: 271.534 | Test Loss [MAPE]: 911961.310 --time-- 12.733271837234497\n",
      "Epoch 322/500 | Train Loss: 244.465 | Test Loss: 277.687 | Test Loss [MAPE]: 890273.413 --time-- 12.729820728302002\n",
      "Epoch 323/500 | Train Loss: 225.554 | Test Loss: 237.551 | Test Loss [MAPE]: 789686.827 --time-- 12.735252618789673\n",
      "Epoch 324/500 | Train Loss: 228.734 | Test Loss: 279.209 | Test Loss [MAPE]: 866051.452 --time-- 12.737355470657349\n",
      "Epoch 325/500 | Train Loss: 282.841 | Test Loss: 408.790 | Test Loss [MAPE]: 1002899.711 --time-- 12.725592613220215\n",
      "Epoch 326/500 | Train Loss: 255.071 | Test Loss: 269.644 | Test Loss [MAPE]: 868641.447 --time-- 12.748169898986816\n",
      "Epoch 327/500 | Train Loss: 221.314 | Test Loss: 219.070 | Test Loss [MAPE]: 742776.283 --time-- 12.752190113067627\n",
      "Epoch 328/500 | Train Loss: 212.409 | Test Loss: 280.285 | Test Loss [MAPE]: 835512.291 --time-- 12.754664182662964\n",
      "Epoch 329/500 | Train Loss: 260.939 | Test Loss: 261.870 | Test Loss [MAPE]: 822841.049 --time-- 12.755271434783936\n",
      "Epoch 330/500 | Train Loss: 238.918 | Test Loss: 269.366 | Test Loss [MAPE]: 806541.064 --time-- 12.700450658798218\n",
      "Epoch 331/500 | Train Loss: 239.734 | Test Loss: 276.585 | Test Loss [MAPE]: 909672.176 --time-- 12.696113109588623\n",
      "Epoch 332/500 | Train Loss: 225.244 | Test Loss: 274.649 | Test Loss [MAPE]: 871880.284 --time-- 12.700778484344482\n",
      "Epoch 333/500 | Train Loss: 220.214 | Test Loss: 254.794 | Test Loss [MAPE]: 811155.825 --time-- 12.70406985282898\n",
      "Epoch 334/500 | Train Loss: 223.942 | Test Loss: 256.710 | Test Loss [MAPE]: 830742.487 --time-- 12.696115493774414\n",
      "Epoch 335/500 | Train Loss: 221.831 | Test Loss: 248.780 | Test Loss [MAPE]: 843997.021 --time-- 12.699856519699097\n",
      "Epoch 336/500 | Train Loss: 225.268 | Test Loss: 278.833 | Test Loss [MAPE]: 926131.806 --time-- 12.701792240142822\n",
      "Epoch 337/500 | Train Loss: 243.634 | Test Loss: 259.693 | Test Loss [MAPE]: 832515.267 --time-- 12.699854373931885\n",
      "Epoch 338/500 | Train Loss: 232.037 | Test Loss: 256.869 | Test Loss [MAPE]: 844524.899 --time-- 12.699049949645996\n",
      "Epoch 339/500 | Train Loss: 219.441 | Test Loss: 276.684 | Test Loss [MAPE]: 902655.109 --time-- 12.701587200164795\n",
      "Epoch 340/500 | Train Loss: 240.996 | Test Loss: 259.547 | Test Loss [MAPE]: 855929.884 --time-- 12.699101209640503\n",
      "Epoch 341/500 | Train Loss: 218.867 | Test Loss: 228.386 | Test Loss [MAPE]: 775514.358 --time-- 12.695356607437134\n",
      "Epoch 342/500 | Train Loss: 220.484 | Test Loss: 295.755 | Test Loss [MAPE]: 987281.991 --time-- 12.696022987365723\n",
      "Epoch 343/500 | Train Loss: 221.564 | Test Loss: 277.912 | Test Loss [MAPE]: 851900.704 --time-- 12.70067572593689\n",
      "Epoch 344/500 | Train Loss: 235.792 | Test Loss: 280.156 | Test Loss [MAPE]: 935058.501 --time-- 12.697206974029541\n",
      "Epoch 345/500 | Train Loss: 230.284 | Test Loss: 276.366 | Test Loss [MAPE]: 884742.948 --time-- 12.700451612472534\n",
      "Epoch 346/500 | Train Loss: 223.443 | Test Loss: 219.663 | Test Loss [MAPE]: 749650.575 --time-- 12.70121169090271\n",
      "Epoch 347/500 | Train Loss: 209.746 | Test Loss: 247.853 | Test Loss [MAPE]: 794108.741 --time-- 12.701743125915527\n",
      "Epoch 348/500 | Train Loss: 221.721 | Test Loss: 239.734 | Test Loss [MAPE]: 809691.660 --time-- 12.704951047897339\n",
      "Epoch 349/500 | Train Loss: 196.665 | Test Loss: 214.070 | Test Loss [MAPE]: 738725.375 --time-- 12.704068422317505\n",
      "Epoch 350/500 | Train Loss: 215.309 | Test Loss: 231.003 | Test Loss [MAPE]: 790260.513 --time-- 12.703086376190186\n",
      "Epoch 351/500 | Train Loss: 208.044 | Test Loss: 246.704 | Test Loss [MAPE]: 831882.492 --time-- 12.701704978942871\n",
      "Epoch 352/500 | Train Loss: 218.908 | Test Loss: 291.883 | Test Loss [MAPE]: 970183.280 --time-- 12.707471370697021\n",
      "Epoch 353/500 | Train Loss: 227.525 | Test Loss: 267.595 | Test Loss [MAPE]: 885358.323 --time-- 12.701360940933228\n",
      "Epoch 354/500 | Train Loss: 227.588 | Test Loss: 254.524 | Test Loss [MAPE]: 859156.606 --time-- 12.69936990737915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500 | Train Loss: 211.576 | Test Loss: 253.720 | Test Loss [MAPE]: 859239.212 --time-- 12.697638273239136\n",
      "Epoch 356/500 | Train Loss: 217.183 | Test Loss: 305.560 | Test Loss [MAPE]: 943275.562 --time-- 12.703052043914795\n",
      "Epoch 357/500 | Train Loss: 239.360 | Test Loss: 257.370 | Test Loss [MAPE]: 864426.418 --time-- 12.697265148162842\n",
      "Epoch 358/500 | Train Loss: 238.807 | Test Loss: 273.873 | Test Loss [MAPE]: 923980.468 --time-- 12.704753398895264\n",
      "Epoch 359/500 | Train Loss: 224.805 | Test Loss: 306.832 | Test Loss [MAPE]: 883463.251 --time-- 12.700304746627808\n",
      "Epoch 360/500 | Train Loss: 228.671 | Test Loss: 274.414 | Test Loss [MAPE]: 874141.410 --time-- 12.700674772262573\n",
      "Epoch 361/500 | Train Loss: 217.710 | Test Loss: 270.783 | Test Loss [MAPE]: 813665.491 --time-- 12.70115041732788\n",
      "Epoch 362/500 | Train Loss: 219.797 | Test Loss: 309.029 | Test Loss [MAPE]: 923037.593 --time-- 12.705160856246948\n",
      "Epoch 363/500 | Train Loss: 240.713 | Test Loss: 276.192 | Test Loss [MAPE]: 927654.883 --time-- 12.70007061958313\n",
      "Epoch 364/500 | Train Loss: 216.457 | Test Loss: 265.251 | Test Loss [MAPE]: 841481.168 --time-- 12.701803207397461\n",
      "Epoch 365/500 | Train Loss: 218.077 | Test Loss: 250.711 | Test Loss [MAPE]: 834804.671 --time-- 12.706061363220215\n",
      "Epoch 366/500 | Train Loss: 199.042 | Test Loss: 233.134 | Test Loss [MAPE]: 751195.947 --time-- 12.705930471420288\n",
      "Epoch 367/500 | Train Loss: 232.934 | Test Loss: 246.546 | Test Loss [MAPE]: 801126.493 --time-- 12.701977014541626\n",
      "Epoch 368/500 | Train Loss: 222.462 | Test Loss: 241.582 | Test Loss [MAPE]: 817440.629 --time-- 12.697537183761597\n",
      "Epoch 369/500 | Train Loss: 210.735 | Test Loss: 259.694 | Test Loss [MAPE]: 865108.771 --time-- 12.698466539382935\n",
      "Epoch 370/500 | Train Loss: 214.292 | Test Loss: 248.866 | Test Loss [MAPE]: 836289.539 --time-- 12.696583032608032\n",
      "Epoch 371/500 | Train Loss: 220.861 | Test Loss: 255.298 | Test Loss [MAPE]: 861134.594 --time-- 12.696515321731567\n",
      "Epoch 372/500 | Train Loss: 226.991 | Test Loss: 243.026 | Test Loss [MAPE]: 824307.391 --time-- 12.698900938034058\n",
      "Epoch 373/500 | Train Loss: 220.224 | Test Loss: 251.283 | Test Loss [MAPE]: 826231.618 --time-- 12.697786808013916\n",
      "Epoch 374/500 | Train Loss: 200.394 | Test Loss: 251.330 | Test Loss [MAPE]: 844783.456 --time-- 12.703745365142822\n",
      "Epoch 375/500 | Train Loss: 227.088 | Test Loss: 238.166 | Test Loss [MAPE]: 775326.606 --time-- 12.70040225982666\n",
      "Epoch 376/500 | Train Loss: 243.610 | Test Loss: 240.128 | Test Loss [MAPE]: 810579.643 --time-- 12.700587749481201\n",
      "Epoch 377/500 | Train Loss: 232.486 | Test Loss: 254.895 | Test Loss [MAPE]: 849399.275 --time-- 12.70295763015747\n",
      "Epoch 378/500 | Train Loss: 206.532 | Test Loss: 266.898 | Test Loss [MAPE]: 888749.687 --time-- 12.698261260986328\n",
      "Epoch 379/500 | Train Loss: 207.871 | Test Loss: 253.233 | Test Loss [MAPE]: 844433.453 --time-- 12.700151205062866\n",
      "Epoch 380/500 | Train Loss: 216.911 | Test Loss: 255.945 | Test Loss [MAPE]: 858336.554 --time-- 12.698276042938232\n",
      "Epoch 381/500 | Train Loss: 218.721 | Test Loss: 273.061 | Test Loss [MAPE]: 934266.741 --time-- 12.698530912399292\n",
      "Epoch 382/500 | Train Loss: 223.843 | Test Loss: 268.424 | Test Loss [MAPE]: 902836.433 --time-- 12.699511528015137\n",
      "Epoch 383/500 | Train Loss: 212.735 | Test Loss: 282.843 | Test Loss [MAPE]: 935840.229 --time-- 12.7081778049469\n",
      "Epoch 384/500 | Train Loss: 245.981 | Test Loss: 292.948 | Test Loss [MAPE]: 857614.540 --time-- 12.699074029922485\n",
      "Epoch 385/500 | Train Loss: 206.261 | Test Loss: 242.219 | Test Loss [MAPE]: 765548.986 --time-- 12.699995994567871\n",
      "Epoch 386/500 | Train Loss: 211.216 | Test Loss: 250.324 | Test Loss [MAPE]: 820354.437 --time-- 12.698865413665771\n",
      "Epoch 387/500 | Train Loss: 209.369 | Test Loss: 291.356 | Test Loss [MAPE]: 889398.663 --time-- 12.69819688796997\n",
      "Epoch 388/500 | Train Loss: 218.454 | Test Loss: 259.721 | Test Loss [MAPE]: 836639.072 --time-- 12.701331615447998\n",
      "Epoch 389/500 | Train Loss: 213.817 | Test Loss: 230.357 | Test Loss [MAPE]: 764533.160 --time-- 12.697442293167114\n",
      "Epoch 390/500 | Train Loss: 244.848 | Test Loss: 287.783 | Test Loss [MAPE]: 903773.538 --time-- 12.70243787765503\n",
      "Epoch 391/500 | Train Loss: 212.585 | Test Loss: 267.447 | Test Loss [MAPE]: 907200.626 --time-- 12.696309328079224\n",
      "Epoch 392/500 | Train Loss: 210.531 | Test Loss: 289.226 | Test Loss [MAPE]: 836517.010 --time-- 12.697175025939941\n",
      "Epoch 393/500 | Train Loss: 239.269 | Test Loss: 243.310 | Test Loss [MAPE]: 796111.183 --time-- 12.754866600036621\n",
      "Epoch 394/500 | Train Loss: 210.015 | Test Loss: 228.640 | Test Loss [MAPE]: 775952.713 --time-- 12.753072023391724\n",
      "Epoch 395/500 | Train Loss: 212.969 | Test Loss: 253.316 | Test Loss [MAPE]: 844928.374 --time-- 12.748977661132812\n",
      "Epoch 396/500 | Train Loss: 228.762 | Test Loss: 246.998 | Test Loss [MAPE]: 831789.733 --time-- 12.756030797958374\n",
      "Epoch 397/500 | Train Loss: 204.993 | Test Loss: 249.471 | Test Loss [MAPE]: 834484.098 --time-- 12.75900387763977\n",
      "Epoch 398/500 | Train Loss: 217.485 | Test Loss: 241.156 | Test Loss [MAPE]: 803202.551 --time-- 12.771248579025269\n",
      "Epoch 399/500 | Train Loss: 222.793 | Test Loss: 271.738 | Test Loss [MAPE]: 903845.320 --time-- 12.754201173782349\n",
      "Epoch 400/500 | Train Loss: 220.738 | Test Loss: 255.103 | Test Loss [MAPE]: 858259.935 --time-- 12.756267309188843\n",
      "Epoch 401/500 | Train Loss: 212.480 | Test Loss: 256.089 | Test Loss [MAPE]: 861859.889 --time-- 12.745164632797241\n",
      "Epoch 402/500 | Train Loss: 223.936 | Test Loss: 226.707 | Test Loss [MAPE]: 769956.798 --time-- 12.749674558639526\n",
      "Epoch 403/500 | Train Loss: 203.555 | Test Loss: 240.046 | Test Loss [MAPE]: 806753.770 --time-- 12.74846339225769\n",
      "Epoch 404/500 | Train Loss: 212.595 | Test Loss: 248.999 | Test Loss [MAPE]: 841584.597 --time-- 12.755443096160889\n",
      "Epoch 405/500 | Train Loss: 254.953 | Test Loss: 313.673 | Test Loss [MAPE]: 1114955.111 --time-- 12.7264084815979\n",
      "Epoch 406/500 | Train Loss: 241.803 | Test Loss: 251.371 | Test Loss [MAPE]: 781479.488 --time-- 12.724649429321289\n",
      "Epoch 407/500 | Train Loss: 217.590 | Test Loss: 268.872 | Test Loss [MAPE]: 875481.006 --time-- 12.698714256286621\n",
      "Epoch 408/500 | Train Loss: 223.444 | Test Loss: 266.355 | Test Loss [MAPE]: 839833.901 --time-- 12.702470064163208\n",
      "Epoch 409/500 | Train Loss: 209.090 | Test Loss: 246.703 | Test Loss [MAPE]: 805231.881 --time-- 12.70153260231018\n",
      "Epoch 410/500 | Train Loss: 209.405 | Test Loss: 230.797 | Test Loss [MAPE]: 704689.585 --time-- 12.70858120918274\n",
      "Epoch 411/500 | Train Loss: 236.915 | Test Loss: 237.826 | Test Loss [MAPE]: 761317.505 --time-- 12.756169080734253\n",
      "Epoch 412/500 | Train Loss: 209.154 | Test Loss: 257.833 | Test Loss [MAPE]: 867704.450 --time-- 12.75044059753418\n",
      "Epoch 413/500 | Train Loss: 201.349 | Test Loss: 250.072 | Test Loss [MAPE]: 822358.423 --time-- 12.750477313995361\n",
      "Epoch 414/500 | Train Loss: 238.535 | Test Loss: 265.152 | Test Loss [MAPE]: 874912.883 --time-- 12.749764919281006\n",
      "Epoch 415/500 | Train Loss: 205.648 | Test Loss: 247.401 | Test Loss [MAPE]: 816986.758 --time-- 12.750123977661133\n",
      "Epoch 416/500 | Train Loss: 198.693 | Test Loss: 270.749 | Test Loss [MAPE]: 878342.845 --time-- 12.751770734786987\n",
      "Epoch 417/500 | Train Loss: 244.317 | Test Loss: 227.447 | Test Loss [MAPE]: 741189.142 --time-- 12.694945335388184\n",
      "Epoch 418/500 | Train Loss: 193.654 | Test Loss: 221.608 | Test Loss [MAPE]: 761502.803 --time-- 12.696912288665771\n",
      "Epoch 419/500 | Train Loss: 250.558 | Test Loss: 289.717 | Test Loss [MAPE]: 853509.986 --time-- 12.697572708129883\n",
      "Epoch 420/500 | Train Loss: 297.815 | Test Loss: 269.222 | Test Loss [MAPE]: 844176.759 --time-- 12.690548658370972\n",
      "Epoch 421/500 | Train Loss: 219.294 | Test Loss: 279.548 | Test Loss [MAPE]: 823928.729 --time-- 12.696943283081055\n",
      "Epoch 422/500 | Train Loss: 221.225 | Test Loss: 261.752 | Test Loss [MAPE]: 854339.780 --time-- 12.69727087020874\n",
      "Epoch 423/500 | Train Loss: 196.813 | Test Loss: 242.778 | Test Loss [MAPE]: 812969.432 --time-- 12.705132961273193\n",
      "Epoch 424/500 | Train Loss: 198.539 | Test Loss: 229.616 | Test Loss [MAPE]: 789976.422 --time-- 12.71415090560913\n",
      "Epoch 425/500 | Train Loss: 189.585 | Test Loss: 237.609 | Test Loss [MAPE]: 802766.057 --time-- 12.696370840072632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500 | Train Loss: 230.125 | Test Loss: 313.140 | Test Loss [MAPE]: 973639.085 --time-- 12.694058656692505\n",
      "Epoch 427/500 | Train Loss: 214.535 | Test Loss: 233.208 | Test Loss [MAPE]: 792983.787 --time-- 12.699244260787964\n",
      "Epoch 428/500 | Train Loss: 189.190 | Test Loss: 237.209 | Test Loss [MAPE]: 758648.622 --time-- 12.700570344924927\n",
      "Epoch 429/500 | Train Loss: 215.606 | Test Loss: 263.779 | Test Loss [MAPE]: 877517.578 --time-- 12.694088220596313\n",
      "Epoch 430/500 | Train Loss: 213.104 | Test Loss: 247.264 | Test Loss [MAPE]: 835715.036 --time-- 12.695859432220459\n",
      "Epoch 431/500 | Train Loss: 223.919 | Test Loss: 234.675 | Test Loss [MAPE]: 803851.556 --time-- 12.699582576751709\n",
      "Epoch 432/500 | Train Loss: 208.523 | Test Loss: 244.463 | Test Loss [MAPE]: 824862.002 --time-- 12.70438814163208\n",
      "Epoch 433/500 | Train Loss: 199.726 | Test Loss: 267.492 | Test Loss [MAPE]: 898993.006 --time-- 12.700777530670166\n",
      "Epoch 434/500 | Train Loss: 218.437 | Test Loss: 284.418 | Test Loss [MAPE]: 866244.043 --time-- 12.695747137069702\n",
      "Epoch 435/500 | Train Loss: 224.215 | Test Loss: 250.764 | Test Loss [MAPE]: 852932.756 --time-- 12.69599962234497\n",
      "Epoch 436/500 | Train Loss: 208.280 | Test Loss: 245.858 | Test Loss [MAPE]: 832442.786 --time-- 12.751015186309814\n",
      "Epoch 437/500 | Train Loss: 228.663 | Test Loss: 272.706 | Test Loss [MAPE]: 884041.797 --time-- 12.698490619659424\n",
      "Epoch 438/500 | Train Loss: 217.862 | Test Loss: 248.649 | Test Loss [MAPE]: 795998.444 --time-- 12.698054552078247\n",
      "Epoch 439/500 | Train Loss: 214.717 | Test Loss: 250.641 | Test Loss [MAPE]: 849782.648 --time-- 12.70270299911499\n",
      "Epoch 440/500 | Train Loss: 198.208 | Test Loss: 249.022 | Test Loss [MAPE]: 812771.064 --time-- 12.768561840057373\n",
      "Epoch 441/500 | Train Loss: 203.187 | Test Loss: 274.968 | Test Loss [MAPE]: 870769.118 --time-- 12.70009160041809\n",
      "Epoch 442/500 | Train Loss: 216.332 | Test Loss: 240.399 | Test Loss [MAPE]: 832840.381 --time-- 12.697561025619507\n",
      "Epoch 443/500 | Train Loss: 215.462 | Test Loss: 256.199 | Test Loss [MAPE]: 869265.458 --time-- 12.699382543563843\n",
      "Epoch 444/500 | Train Loss: 204.772 | Test Loss: 250.215 | Test Loss [MAPE]: 828755.222 --time-- 12.699716806411743\n",
      "Epoch 445/500 | Train Loss: 190.456 | Test Loss: 229.155 | Test Loss [MAPE]: 721013.633 --time-- 12.699211835861206\n",
      "Epoch 446/500 | Train Loss: 263.563 | Test Loss: 358.544 | Test Loss [MAPE]: 917254.737 --time-- 12.69745659828186\n",
      "Epoch 447/500 | Train Loss: 294.829 | Test Loss: 331.487 | Test Loss [MAPE]: 1055892.103 --time-- 12.697316646575928\n",
      "Epoch 448/500 | Train Loss: 270.781 | Test Loss: 255.273 | Test Loss [MAPE]: 840169.875 --time-- 12.710781812667847\n",
      "Epoch 449/500 | Train Loss: 201.045 | Test Loss: 210.600 | Test Loss [MAPE]: 713768.453 --time-- 12.754632234573364\n",
      "Epoch 450/500 | Train Loss: 191.634 | Test Loss: 236.837 | Test Loss [MAPE]: 781657.809 --time-- 12.75314712524414\n",
      "Epoch 451/500 | Train Loss: 192.038 | Test Loss: 244.932 | Test Loss [MAPE]: 825881.525 --time-- 12.75063419342041\n",
      "Epoch 452/500 | Train Loss: 200.107 | Test Loss: 256.569 | Test Loss [MAPE]: 852874.542 --time-- 12.755395650863647\n",
      "Epoch 453/500 | Train Loss: 197.704 | Test Loss: 236.134 | Test Loss [MAPE]: 806779.798 --time-- 12.759816646575928\n",
      "Epoch 454/500 | Train Loss: 198.881 | Test Loss: 260.442 | Test Loss [MAPE]: 866512.898 --time-- 12.772216796875\n",
      "Epoch 455/500 | Train Loss: 204.012 | Test Loss: 251.597 | Test Loss [MAPE]: 850818.724 --time-- 12.779995441436768\n",
      "Epoch 456/500 | Train Loss: 203.175 | Test Loss: 268.559 | Test Loss [MAPE]: 861673.641 --time-- 12.75839877128601\n",
      "Epoch 457/500 | Train Loss: 196.470 | Test Loss: 242.497 | Test Loss [MAPE]: 817920.891 --time-- 12.749926090240479\n",
      "Epoch 458/500 | Train Loss: 199.939 | Test Loss: 229.960 | Test Loss [MAPE]: 757058.440 --time-- 12.746891498565674\n",
      "Epoch 459/500 | Train Loss: 191.206 | Test Loss: 248.329 | Test Loss [MAPE]: 795485.718 --time-- 12.699383974075317\n",
      "Epoch 460/500 | Train Loss: 207.647 | Test Loss: 233.114 | Test Loss [MAPE]: 792027.003 --time-- 12.702868461608887\n",
      "Epoch 461/500 | Train Loss: 205.043 | Test Loss: 238.814 | Test Loss [MAPE]: 806265.214 --time-- 12.70018482208252\n",
      "Epoch 462/500 | Train Loss: 205.111 | Test Loss: 233.246 | Test Loss [MAPE]: 772021.996 --time-- 12.70582103729248\n",
      "Epoch 463/500 | Train Loss: 207.182 | Test Loss: 241.123 | Test Loss [MAPE]: 783632.244 --time-- 12.727143287658691\n",
      "Epoch 464/500 | Train Loss: 194.435 | Test Loss: 233.163 | Test Loss [MAPE]: 780908.530 --time-- 12.712474346160889\n",
      "Epoch 465/500 | Train Loss: 207.816 | Test Loss: 234.888 | Test Loss [MAPE]: 784921.321 --time-- 12.697860956192017\n",
      "Epoch 466/500 | Train Loss: 201.927 | Test Loss: 226.212 | Test Loss [MAPE]: 766601.429 --time-- 12.698971033096313\n",
      "Epoch 467/500 | Train Loss: 196.108 | Test Loss: 241.712 | Test Loss [MAPE]: 823607.972 --time-- 12.700871467590332\n",
      "Epoch 468/500 | Train Loss: 223.636 | Test Loss: 330.625 | Test Loss [MAPE]: 785398.047 --time-- 12.696305513381958\n",
      "Epoch 469/500 | Train Loss: 244.052 | Test Loss: 253.642 | Test Loss [MAPE]: 764144.357 --time-- 12.69498348236084\n",
      "Epoch 470/500 | Train Loss: 219.337 | Test Loss: 248.096 | Test Loss [MAPE]: 824850.456 --time-- 12.693119049072266\n",
      "Epoch 471/500 | Train Loss: 205.510 | Test Loss: 248.509 | Test Loss [MAPE]: 800563.730 --time-- 12.699174880981445\n",
      "Epoch 472/500 | Train Loss: 193.686 | Test Loss: 226.643 | Test Loss [MAPE]: 763079.079 --time-- 12.696895837783813\n",
      "Epoch 473/500 | Train Loss: 206.530 | Test Loss: 269.244 | Test Loss [MAPE]: 844778.123 --time-- 12.692358255386353\n",
      "Epoch 474/500 | Train Loss: 208.513 | Test Loss: 232.931 | Test Loss [MAPE]: 785792.371 --time-- 12.695646047592163\n",
      "Epoch 475/500 | Train Loss: 195.818 | Test Loss: 256.346 | Test Loss [MAPE]: 862679.796 --time-- 12.69444751739502\n",
      "Epoch 476/500 | Train Loss: 197.198 | Test Loss: 229.948 | Test Loss [MAPE]: 766424.574 --time-- 12.750188112258911\n",
      "Epoch 477/500 | Train Loss: 192.688 | Test Loss: 223.498 | Test Loss [MAPE]: 760361.102 --time-- 12.752677202224731\n",
      "Epoch 478/500 | Train Loss: 208.329 | Test Loss: 321.364 | Test Loss [MAPE]: 819751.251 --time-- 12.744864702224731\n",
      "Epoch 479/500 | Train Loss: 265.123 | Test Loss: 245.486 | Test Loss [MAPE]: 818258.495 --time-- 12.746609926223755\n",
      "Epoch 480/500 | Train Loss: 214.926 | Test Loss: 279.157 | Test Loss [MAPE]: 911105.275 --time-- 12.697679281234741\n",
      "Epoch 481/500 | Train Loss: 223.280 | Test Loss: 246.201 | Test Loss [MAPE]: 822304.189 --time-- 12.692564964294434\n",
      "Epoch 482/500 | Train Loss: 202.219 | Test Loss: 233.849 | Test Loss [MAPE]: 770291.322 --time-- 12.69618844985962\n",
      "Epoch 483/500 | Train Loss: 189.811 | Test Loss: 223.621 | Test Loss [MAPE]: 751012.263 --time-- 12.696743488311768\n",
      "Epoch 484/500 | Train Loss: 199.787 | Test Loss: 218.859 | Test Loss [MAPE]: 745027.794 --time-- 12.695500135421753\n",
      "Epoch 485/500 | Train Loss: 202.631 | Test Loss: 215.321 | Test Loss [MAPE]: 729915.845 --time-- 12.695834159851074\n",
      "Epoch 486/500 | Train Loss: 202.180 | Test Loss: 243.595 | Test Loss [MAPE]: 817836.029 --time-- 12.698519229888916\n",
      "Epoch 487/500 | Train Loss: 204.530 | Test Loss: 238.702 | Test Loss [MAPE]: 800564.162 --time-- 12.697200059890747\n",
      "Epoch 488/500 | Train Loss: 202.125 | Test Loss: 284.232 | Test Loss [MAPE]: 972703.951 --time-- 12.69872260093689\n",
      "Epoch 489/500 | Train Loss: 214.671 | Test Loss: 215.050 | Test Loss [MAPE]: 708151.423 --time-- 12.696467399597168\n",
      "Epoch 490/500 | Train Loss: 196.584 | Test Loss: 241.903 | Test Loss [MAPE]: 810819.379 --time-- 12.696131706237793\n",
      "Epoch 491/500 | Train Loss: 206.539 | Test Loss: 266.559 | Test Loss [MAPE]: 905869.982 --time-- 12.696832180023193\n",
      "Epoch 492/500 | Train Loss: 209.953 | Test Loss: 273.528 | Test Loss [MAPE]: 921863.767 --time-- 12.69456148147583\n",
      "Epoch 493/500 | Train Loss: 195.702 | Test Loss: 215.744 | Test Loss [MAPE]: 731628.388 --time-- 12.69443964958191\n",
      "Epoch 494/500 | Train Loss: 198.187 | Test Loss: 241.427 | Test Loss [MAPE]: 813376.313 --time-- 12.69454050064087\n",
      "Epoch 495/500 | Train Loss: 197.977 | Test Loss: 233.588 | Test Loss [MAPE]: 796608.864 --time-- 12.692517518997192\n",
      "Epoch 496/500 | Train Loss: 199.472 | Test Loss: 256.287 | Test Loss [MAPE]: 798842.118 --time-- 12.694398641586304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/500 | Train Loss: 307.627 | Test Loss: 416.658 | Test Loss [MAPE]: 939714.392 --time-- 12.69176197052002\n",
      "Epoch 498/500 | Train Loss: 277.076 | Test Loss: 284.104 | Test Loss [MAPE]: 942304.869 --time-- 12.690232038497925\n",
      "Epoch 499/500 | Train Loss: 223.477 | Test Loss: 227.779 | Test Loss [MAPE]: 762881.830 --time-- 12.69098162651062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 03:01:42,378] Trial 31 finished with value: 704689.585149765 and parameters: {'num_conv_layers': 4, 'kernel_size': 7, 'num_channels': 50, 'pooling_type': 'max', 'conv_stride': 1, 'feedforward_size': 111, 'pool_stride': 2, 'learning_rate': 0.0017512845613230862, 'reg_strength': 0.001931731209107105, 'bs': 118}. Best is trial 25 with value: 432058.5189819336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500 | Train Loss: 180.181 | Test Loss: 218.236 | Test Loss [MAPE]: 744666.513 --time-- 12.698678493499756\n",
      "6369.047784328461\n",
      "Epoch 1/500 | Train Loss: 5813.514 | Test Loss: 5164.072 | Test Loss [MAPE]: 491237.184 --time-- 11.31102180480957\n",
      "Epoch 2/500 | Train Loss: 5107.110 | Test Loss: 5161.736 | Test Loss [MAPE]: 420906.968 --time-- 11.287448644638062\n",
      "Epoch 3/500 | Train Loss: 5106.322 | Test Loss: 5161.666 | Test Loss [MAPE]: 423086.849 --time-- 11.289335012435913\n",
      "Epoch 4/500 | Train Loss: 5106.311 | Test Loss: 5161.691 | Test Loss [MAPE]: 425920.033 --time-- 11.291738748550415\n",
      "Epoch 5/500 | Train Loss: 5106.305 | Test Loss: 5161.688 | Test Loss [MAPE]: 421106.662 --time-- 11.291690826416016\n",
      "Epoch 6/500 | Train Loss: 5106.316 | Test Loss: 5161.680 | Test Loss [MAPE]: 423571.502 --time-- 11.293519258499146\n",
      "Epoch 7/500 | Train Loss: 5106.318 | Test Loss: 5161.699 | Test Loss [MAPE]: 419758.873 --time-- 11.293799638748169\n",
      "Epoch 8/500 | Train Loss: 5106.313 | Test Loss: 5161.698 | Test Loss [MAPE]: 424463.343 --time-- 11.305450201034546\n",
      "Epoch 9/500 | Train Loss: 5106.319 | Test Loss: 5161.673 | Test Loss [MAPE]: 422473.576 --time-- 11.299806118011475\n",
      "Epoch 10/500 | Train Loss: 5106.314 | Test Loss: 5161.687 | Test Loss [MAPE]: 426100.056 --time-- 11.299132823944092\n",
      "Epoch 11/500 | Train Loss: 5106.328 | Test Loss: 5161.693 | Test Loss [MAPE]: 419981.193 --time-- 11.294906616210938\n",
      "Epoch 12/500 | Train Loss: 5106.341 | Test Loss: 5161.695 | Test Loss [MAPE]: 426608.546 --time-- 11.248769283294678\n",
      "Epoch 13/500 | Train Loss: 5106.303 | Test Loss: 5161.761 | Test Loss [MAPE]: 417400.077 --time-- 11.249372482299805\n",
      "Epoch 14/500 | Train Loss: 5106.333 | Test Loss: 5161.707 | Test Loss [MAPE]: 427798.117 --time-- 11.24882698059082\n",
      "Epoch 15/500 | Train Loss: 5106.333 | Test Loss: 5161.727 | Test Loss [MAPE]: 427173.183 --time-- 11.264393091201782\n",
      "Epoch 16/500 | Train Loss: 5106.346 | Test Loss: 5161.704 | Test Loss [MAPE]: 425496.941 --time-- 11.26545238494873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 03:04:54,946] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.347 | Test Loss: 5161.680 | Test Loss [MAPE]: 423544.433 --time-- 11.276929140090942\n",
      "Epoch 1/500 | Train Loss: 46044.721 | Test Loss: 5163.230 | Test Loss [MAPE]: 453608.557 --time-- 4.577923059463501\n",
      "Epoch 2/500 | Train Loss: 5106.811 | Test Loss: 5161.727 | Test Loss [MAPE]: 420097.033 --time-- 4.4978344440460205\n",
      "Epoch 3/500 | Train Loss: 5106.377 | Test Loss: 5161.825 | Test Loss [MAPE]: 435447.353 --time-- 4.442608594894409\n",
      "Epoch 4/500 | Train Loss: 5106.356 | Test Loss: 5161.695 | Test Loss [MAPE]: 422519.412 --time-- 4.439053058624268\n",
      "Epoch 5/500 | Train Loss: 5106.369 | Test Loss: 5161.719 | Test Loss [MAPE]: 427307.458 --time-- 4.490106821060181\n",
      "Epoch 6/500 | Train Loss: 5106.392 | Test Loss: 5161.750 | Test Loss [MAPE]: 428295.284 --time-- 4.487300634384155\n",
      "Epoch 7/500 | Train Loss: 5106.440 | Test Loss: 5161.825 | Test Loss [MAPE]: 419016.280 --time-- 4.489310026168823\n",
      "Epoch 8/500 | Train Loss: 5106.457 | Test Loss: 5161.773 | Test Loss [MAPE]: 427161.681 --time-- 4.486379384994507\n",
      "Epoch 9/500 | Train Loss: 5106.418 | Test Loss: 5161.792 | Test Loss [MAPE]: 431669.070 --time-- 4.485887050628662\n",
      "Epoch 10/500 | Train Loss: 5106.416 | Test Loss: 5161.781 | Test Loss [MAPE]: 424355.199 --time-- 4.48773455619812\n",
      "Epoch 11/500 | Train Loss: 5106.423 | Test Loss: 5161.841 | Test Loss [MAPE]: 433480.556 --time-- 4.487603664398193\n",
      "Epoch 12/500 | Train Loss: 5106.456 | Test Loss: 5161.792 | Test Loss [MAPE]: 432212.660 --time-- 4.48609471321106\n",
      "Epoch 13/500 | Train Loss: 5106.519 | Test Loss: 5161.888 | Test Loss [MAPE]: 436151.866 --time-- 4.492074251174927\n",
      "Epoch 14/500 | Train Loss: 5106.449 | Test Loss: 5161.803 | Test Loss [MAPE]: 427474.435 --time-- 4.4868690967559814\n",
      "Epoch 15/500 | Train Loss: 5106.455 | Test Loss: 5161.737 | Test Loss [MAPE]: 425658.456 --time-- 4.484766244888306\n",
      "Epoch 16/500 | Train Loss: 5106.463 | Test Loss: 5161.787 | Test Loss [MAPE]: 424600.672 --time-- 4.488636016845703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 03:06:11,942] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.458 | Test Loss: 5161.814 | Test Loss [MAPE]: 420714.590 --time-- 4.485757350921631\n",
      "Epoch 1/500 | Train Loss: 5108.778 | Test Loss: 5161.687 | Test Loss [MAPE]: 425934.693 --time-- 2.4124093055725098\n",
      "Epoch 2/500 | Train Loss: 5102.278 | Test Loss: 5133.113 | Test Loss [MAPE]: 475860.596 --time-- 2.3123276233673096\n",
      "Epoch 3/500 | Train Loss: 4444.625 | Test Loss: 4200.784 | Test Loss [MAPE]: 2252660.425 --time-- 2.3127362728118896\n",
      "Epoch 4/500 | Train Loss: 4151.860 | Test Loss: 4124.696 | Test Loss [MAPE]: 1250084.849 --time-- 2.31170654296875\n",
      "Epoch 5/500 | Train Loss: 4102.275 | Test Loss: 4045.484 | Test Loss [MAPE]: 1812820.384 --time-- 2.313568592071533\n",
      "Epoch 6/500 | Train Loss: 3997.327 | Test Loss: 3955.607 | Test Loss [MAPE]: 2312710.637 --time-- 2.3125572204589844\n",
      "Epoch 7/500 | Train Loss: 3917.101 | Test Loss: 3873.805 | Test Loss [MAPE]: 2877088.355 --time-- 2.3127996921539307\n",
      "Epoch 8/500 | Train Loss: 3819.935 | Test Loss: 3774.087 | Test Loss [MAPE]: 2886199.316 --time-- 2.3125174045562744\n",
      "Epoch 9/500 | Train Loss: 3699.630 | Test Loss: 3634.702 | Test Loss [MAPE]: 3932407.805 --time-- 2.3126749992370605\n",
      "Epoch 10/500 | Train Loss: 3535.973 | Test Loss: 3436.182 | Test Loss [MAPE]: 5079206.778 --time-- 2.3101155757904053\n",
      "Epoch 11/500 | Train Loss: 3297.947 | Test Loss: 3161.188 | Test Loss [MAPE]: 5432596.567 --time-- 2.313699245452881\n",
      "Epoch 12/500 | Train Loss: 3024.489 | Test Loss: 2893.664 | Test Loss [MAPE]: 5360542.265 --time-- 2.3129141330718994\n",
      "Epoch 13/500 | Train Loss: 2789.603 | Test Loss: 3001.558 | Test Loss [MAPE]: 4234732.695 --time-- 2.317120313644409\n",
      "Epoch 14/500 | Train Loss: 2660.049 | Test Loss: 2537.345 | Test Loss [MAPE]: 5161797.866 --time-- 2.308986186981201\n",
      "Epoch 15/500 | Train Loss: 2425.544 | Test Loss: 2329.055 | Test Loss [MAPE]: 4586034.668 --time-- 2.3108139038085938\n",
      "Epoch 16/500 | Train Loss: 2256.523 | Test Loss: 2216.985 | Test Loss [MAPE]: 4841335.046 --time-- 2.3094706535339355\n",
      "Epoch 17/500 | Train Loss: 2136.201 | Test Loss: 2085.757 | Test Loss [MAPE]: 4298310.744 --time-- 2.3084495067596436\n",
      "Epoch 18/500 | Train Loss: 2036.042 | Test Loss: 2032.929 | Test Loss [MAPE]: 4394521.414 --time-- 2.309271812438965\n",
      "Epoch 19/500 | Train Loss: 1901.948 | Test Loss: 1845.080 | Test Loss [MAPE]: 3802154.041 --time-- 2.30977201461792\n",
      "Epoch 20/500 | Train Loss: 1786.200 | Test Loss: 1865.796 | Test Loss [MAPE]: 3885413.511 --time-- 2.308894395828247\n",
      "Epoch 21/500 | Train Loss: 1752.407 | Test Loss: 1685.312 | Test Loss [MAPE]: 3639316.672 --time-- 2.312333345413208\n",
      "Epoch 22/500 | Train Loss: 1640.891 | Test Loss: 1634.403 | Test Loss [MAPE]: 3370271.595 --time-- 2.3116815090179443\n",
      "Epoch 23/500 | Train Loss: 1597.157 | Test Loss: 1642.380 | Test Loss [MAPE]: 3470868.299 --time-- 2.3109490871429443\n",
      "Epoch 24/500 | Train Loss: 1592.990 | Test Loss: 1543.184 | Test Loss [MAPE]: 3220782.757 --time-- 2.3114044666290283\n",
      "Epoch 25/500 | Train Loss: 1495.596 | Test Loss: 1447.033 | Test Loss [MAPE]: 3219503.043 --time-- 2.310446262359619\n",
      "Epoch 26/500 | Train Loss: 1441.195 | Test Loss: 1554.059 | Test Loss [MAPE]: 3678182.564 --time-- 2.3120691776275635\n",
      "Epoch 27/500 | Train Loss: 1457.723 | Test Loss: 1448.352 | Test Loss [MAPE]: 3180946.144 --time-- 2.310526132583618\n",
      "Epoch 28/500 | Train Loss: 1372.457 | Test Loss: 1395.046 | Test Loss [MAPE]: 3216095.495 --time-- 2.3096275329589844\n",
      "Epoch 29/500 | Train Loss: 1327.322 | Test Loss: 1329.206 | Test Loss [MAPE]: 3134230.381 --time-- 2.309415817260742\n",
      "Epoch 30/500 | Train Loss: 1327.880 | Test Loss: 1334.049 | Test Loss [MAPE]: 3395059.221 --time-- 2.3104491233825684\n",
      "Epoch 31/500 | Train Loss: 1269.569 | Test Loss: 1221.911 | Test Loss [MAPE]: 2983287.799 --time-- 2.308616876602173\n",
      "Epoch 32/500 | Train Loss: 1245.375 | Test Loss: 1233.553 | Test Loss [MAPE]: 3025679.612 --time-- 2.313898801803589\n",
      "Epoch 33/500 | Train Loss: 1259.447 | Test Loss: 1243.646 | Test Loss [MAPE]: 3094977.469 --time-- 2.3074543476104736\n",
      "Epoch 34/500 | Train Loss: 1221.960 | Test Loss: 1228.397 | Test Loss [MAPE]: 3107199.625 --time-- 2.3132307529449463\n",
      "Epoch 35/500 | Train Loss: 1178.638 | Test Loss: 1339.916 | Test Loss [MAPE]: 3394625.103 --time-- 2.310652732849121\n",
      "Epoch 36/500 | Train Loss: 1196.207 | Test Loss: 1173.006 | Test Loss [MAPE]: 2890956.674 --time-- 2.309403896331787\n",
      "Epoch 37/500 | Train Loss: 1139.933 | Test Loss: 1072.068 | Test Loss [MAPE]: 2742836.369 --time-- 2.310389995574951\n",
      "Epoch 38/500 | Train Loss: 1103.623 | Test Loss: 1108.915 | Test Loss [MAPE]: 2854953.467 --time-- 2.3125686645507812\n",
      "Epoch 39/500 | Train Loss: 1094.967 | Test Loss: 1072.782 | Test Loss [MAPE]: 2770984.217 --time-- 2.3093206882476807\n",
      "Epoch 40/500 | Train Loss: 1038.722 | Test Loss: 1032.674 | Test Loss [MAPE]: 2767994.483 --time-- 2.312394380569458\n",
      "Epoch 41/500 | Train Loss: 988.991 | Test Loss: 1107.416 | Test Loss [MAPE]: 2661867.798 --time-- 2.3102402687072754\n",
      "Epoch 42/500 | Train Loss: 1036.799 | Test Loss: 1067.043 | Test Loss [MAPE]: 2839011.267 --time-- 2.3115813732147217\n",
      "Epoch 43/500 | Train Loss: 1016.966 | Test Loss: 1047.380 | Test Loss [MAPE]: 2770610.867 --time-- 2.310642957687378\n",
      "Epoch 44/500 | Train Loss: 1019.143 | Test Loss: 971.018 | Test Loss [MAPE]: 2640639.874 --time-- 2.3117105960845947\n",
      "Epoch 45/500 | Train Loss: 932.083 | Test Loss: 963.857 | Test Loss [MAPE]: 2526342.181 --time-- 2.3102850914001465\n",
      "Epoch 46/500 | Train Loss: 950.289 | Test Loss: 894.143 | Test Loss [MAPE]: 2412121.030 --time-- 2.3108530044555664\n",
      "Epoch 47/500 | Train Loss: 909.271 | Test Loss: 1012.870 | Test Loss [MAPE]: 2765797.799 --time-- 2.311976194381714\n",
      "Epoch 48/500 | Train Loss: 951.550 | Test Loss: 959.729 | Test Loss [MAPE]: 2494807.780 --time-- 2.3095345497131348\n",
      "Epoch 49/500 | Train Loss: 909.326 | Test Loss: 899.582 | Test Loss [MAPE]: 2342230.225 --time-- 2.3106801509857178\n",
      "Epoch 50/500 | Train Loss: 870.853 | Test Loss: 885.098 | Test Loss [MAPE]: 2354884.484 --time-- 2.310352325439453\n",
      "Epoch 51/500 | Train Loss: 886.401 | Test Loss: 896.257 | Test Loss [MAPE]: 2487489.723 --time-- 2.310321807861328\n",
      "Epoch 52/500 | Train Loss: 886.716 | Test Loss: 851.478 | Test Loss [MAPE]: 2465805.338 --time-- 2.310713052749634\n",
      "Epoch 53/500 | Train Loss: 891.166 | Test Loss: 978.865 | Test Loss [MAPE]: 2605120.175 --time-- 2.310106039047241\n",
      "Epoch 54/500 | Train Loss: 831.731 | Test Loss: 793.046 | Test Loss [MAPE]: 2239363.852 --time-- 2.3130745887756348\n",
      "Epoch 55/500 | Train Loss: 795.597 | Test Loss: 895.438 | Test Loss [MAPE]: 2623511.188 --time-- 2.310793399810791\n",
      "Epoch 56/500 | Train Loss: 825.989 | Test Loss: 826.246 | Test Loss [MAPE]: 2298039.653 --time-- 2.31160306930542\n",
      "Epoch 57/500 | Train Loss: 796.055 | Test Loss: 819.934 | Test Loss [MAPE]: 2338996.221 --time-- 2.3118393421173096\n",
      "Epoch 58/500 | Train Loss: 801.350 | Test Loss: 870.251 | Test Loss [MAPE]: 2415430.542 --time-- 2.313720464706421\n",
      "Epoch 59/500 | Train Loss: 777.032 | Test Loss: 823.560 | Test Loss [MAPE]: 2348333.543 --time-- 2.311389684677124\n",
      "Epoch 60/500 | Train Loss: 758.126 | Test Loss: 731.508 | Test Loss [MAPE]: 2104970.090 --time-- 2.3135931491851807\n",
      "Epoch 61/500 | Train Loss: 762.170 | Test Loss: 771.897 | Test Loss [MAPE]: 2288638.414 --time-- 2.310616970062256\n",
      "Epoch 62/500 | Train Loss: 727.086 | Test Loss: 742.074 | Test Loss [MAPE]: 2258210.556 --time-- 2.3087196350097656\n",
      "Epoch 63/500 | Train Loss: 704.641 | Test Loss: 728.544 | Test Loss [MAPE]: 2184902.572 --time-- 2.309051752090454\n",
      "Epoch 64/500 | Train Loss: 719.297 | Test Loss: 689.893 | Test Loss [MAPE]: 1999617.677 --time-- 2.309051513671875\n",
      "Epoch 65/500 | Train Loss: 677.738 | Test Loss: 699.396 | Test Loss [MAPE]: 1983370.577 --time-- 2.310584783554077\n",
      "Epoch 66/500 | Train Loss: 705.846 | Test Loss: 712.825 | Test Loss [MAPE]: 2040502.954 --time-- 2.3112518787384033\n",
      "Epoch 67/500 | Train Loss: 673.062 | Test Loss: 674.063 | Test Loss [MAPE]: 1991834.291 --time-- 2.3121280670166016\n",
      "Epoch 68/500 | Train Loss: 628.553 | Test Loss: 703.248 | Test Loss [MAPE]: 2076446.923 --time-- 2.311565637588501\n",
      "Epoch 69/500 | Train Loss: 653.103 | Test Loss: 703.219 | Test Loss [MAPE]: 2078276.602 --time-- 2.309607744216919\n",
      "Epoch 70/500 | Train Loss: 699.106 | Test Loss: 707.495 | Test Loss [MAPE]: 2052487.458 --time-- 2.3134536743164062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500 | Train Loss: 625.099 | Test Loss: 598.829 | Test Loss [MAPE]: 1825354.216 --time-- 2.3102195262908936\n",
      "Epoch 72/500 | Train Loss: 612.838 | Test Loss: 678.373 | Test Loss [MAPE]: 2016496.771 --time-- 2.3108105659484863\n",
      "Epoch 73/500 | Train Loss: 617.295 | Test Loss: 607.365 | Test Loss [MAPE]: 1806889.759 --time-- 2.3648483753204346\n",
      "Epoch 74/500 | Train Loss: 615.970 | Test Loss: 615.353 | Test Loss [MAPE]: 1921625.824 --time-- 2.370819091796875\n",
      "Epoch 75/500 | Train Loss: 636.999 | Test Loss: 631.625 | Test Loss [MAPE]: 1874772.698 --time-- 2.3657302856445312\n",
      "Epoch 76/500 | Train Loss: 595.052 | Test Loss: 612.376 | Test Loss [MAPE]: 1885729.191 --time-- 2.3607828617095947\n",
      "Epoch 77/500 | Train Loss: 607.137 | Test Loss: 659.480 | Test Loss [MAPE]: 1978154.524 --time-- 2.36232590675354\n",
      "Epoch 78/500 | Train Loss: 603.130 | Test Loss: 681.704 | Test Loss [MAPE]: 2104382.032 --time-- 2.3609931468963623\n",
      "Epoch 79/500 | Train Loss: 617.933 | Test Loss: 605.958 | Test Loss [MAPE]: 1846534.564 --time-- 2.3617844581604004\n",
      "Epoch 80/500 | Train Loss: 581.002 | Test Loss: 611.874 | Test Loss [MAPE]: 1873451.312 --time-- 2.368788242340088\n",
      "Epoch 81/500 | Train Loss: 616.962 | Test Loss: 602.313 | Test Loss [MAPE]: 1855132.330 --time-- 2.3619742393493652\n",
      "Epoch 82/500 | Train Loss: 599.684 | Test Loss: 569.268 | Test Loss [MAPE]: 1760023.473 --time-- 2.3690590858459473\n",
      "Epoch 83/500 | Train Loss: 541.770 | Test Loss: 591.111 | Test Loss [MAPE]: 1754633.255 --time-- 2.3648838996887207\n",
      "Epoch 84/500 | Train Loss: 610.003 | Test Loss: 683.796 | Test Loss [MAPE]: 1962101.662 --time-- 2.3607592582702637\n",
      "Epoch 85/500 | Train Loss: 571.881 | Test Loss: 577.607 | Test Loss [MAPE]: 1798827.591 --time-- 2.3626418113708496\n",
      "Epoch 86/500 | Train Loss: 573.586 | Test Loss: 541.584 | Test Loss [MAPE]: 1692755.022 --time-- 2.3691213130950928\n",
      "Epoch 87/500 | Train Loss: 556.782 | Test Loss: 624.913 | Test Loss [MAPE]: 1929092.194 --time-- 2.3679001331329346\n",
      "Epoch 88/500 | Train Loss: 600.638 | Test Loss: 641.771 | Test Loss [MAPE]: 1860101.596 --time-- 2.365032911300659\n",
      "Epoch 89/500 | Train Loss: 578.239 | Test Loss: 537.499 | Test Loss [MAPE]: 1658439.131 --time-- 2.365713119506836\n",
      "Epoch 90/500 | Train Loss: 549.490 | Test Loss: 631.445 | Test Loss [MAPE]: 1937697.077 --time-- 2.3670308589935303\n",
      "Epoch 91/500 | Train Loss: 569.787 | Test Loss: 562.109 | Test Loss [MAPE]: 1723403.721 --time-- 2.365872859954834\n",
      "Epoch 92/500 | Train Loss: 555.097 | Test Loss: 596.738 | Test Loss [MAPE]: 1811373.099 --time-- 2.3664824962615967\n",
      "Epoch 93/500 | Train Loss: 568.080 | Test Loss: 541.107 | Test Loss [MAPE]: 1701579.713 --time-- 2.3642306327819824\n",
      "Epoch 94/500 | Train Loss: 523.083 | Test Loss: 546.853 | Test Loss [MAPE]: 1675013.206 --time-- 2.3678436279296875\n",
      "Epoch 95/500 | Train Loss: 558.617 | Test Loss: 570.829 | Test Loss [MAPE]: 1767374.816 --time-- 2.367283821105957\n",
      "Epoch 96/500 | Train Loss: 551.309 | Test Loss: 639.251 | Test Loss [MAPE]: 1948315.169 --time-- 2.3634157180786133\n",
      "Epoch 97/500 | Train Loss: 553.239 | Test Loss: 571.712 | Test Loss [MAPE]: 1776663.536 --time-- 2.364027738571167\n",
      "Epoch 98/500 | Train Loss: 515.355 | Test Loss: 578.333 | Test Loss [MAPE]: 1777631.838 --time-- 2.373015880584717\n",
      "Epoch 99/500 | Train Loss: 583.905 | Test Loss: 561.192 | Test Loss [MAPE]: 1690110.019 --time-- 2.365605354309082\n",
      "Epoch 100/500 | Train Loss: 544.679 | Test Loss: 525.882 | Test Loss [MAPE]: 1637758.194 --time-- 2.3670477867126465\n",
      "Epoch 101/500 | Train Loss: 533.106 | Test Loss: 567.802 | Test Loss [MAPE]: 1763500.543 --time-- 2.360811471939087\n",
      "Epoch 102/500 | Train Loss: 540.614 | Test Loss: 532.168 | Test Loss [MAPE]: 1666615.921 --time-- 2.3883492946624756\n",
      "Epoch 103/500 | Train Loss: 498.262 | Test Loss: 499.720 | Test Loss [MAPE]: 1549652.728 --time-- 2.361081123352051\n",
      "Epoch 104/500 | Train Loss: 530.619 | Test Loss: 552.121 | Test Loss [MAPE]: 1709853.774 --time-- 2.372384548187256\n",
      "Epoch 105/500 | Train Loss: 539.215 | Test Loss: 606.729 | Test Loss [MAPE]: 1828587.713 --time-- 2.3151979446411133\n",
      "Epoch 106/500 | Train Loss: 537.180 | Test Loss: 535.832 | Test Loss [MAPE]: 1635054.102 --time-- 2.312558889389038\n",
      "Epoch 107/500 | Train Loss: 505.214 | Test Loss: 555.099 | Test Loss [MAPE]: 1730256.237 --time-- 2.310502529144287\n",
      "Epoch 108/500 | Train Loss: 515.160 | Test Loss: 547.149 | Test Loss [MAPE]: 1677000.216 --time-- 2.312628984451294\n",
      "Epoch 109/500 | Train Loss: 542.578 | Test Loss: 528.758 | Test Loss [MAPE]: 1637293.869 --time-- 2.3133983612060547\n",
      "Epoch 110/500 | Train Loss: 517.103 | Test Loss: 561.694 | Test Loss [MAPE]: 1750937.956 --time-- 2.3131089210510254\n",
      "Epoch 111/500 | Train Loss: 538.100 | Test Loss: 541.044 | Test Loss [MAPE]: 1670609.060 --time-- 2.3141028881073\n",
      "Epoch 112/500 | Train Loss: 527.535 | Test Loss: 509.206 | Test Loss [MAPE]: 1568842.343 --time-- 2.3140456676483154\n",
      "Epoch 113/500 | Train Loss: 507.955 | Test Loss: 569.275 | Test Loss [MAPE]: 1691813.959 --time-- 2.313046932220459\n",
      "Epoch 114/500 | Train Loss: 512.827 | Test Loss: 490.922 | Test Loss [MAPE]: 1546095.019 --time-- 2.3111040592193604\n",
      "Epoch 115/500 | Train Loss: 500.423 | Test Loss: 492.350 | Test Loss [MAPE]: 1539665.635 --time-- 2.313960313796997\n",
      "Epoch 116/500 | Train Loss: 478.678 | Test Loss: 473.574 | Test Loss [MAPE]: 1468592.888 --time-- 2.3127050399780273\n",
      "Epoch 117/500 | Train Loss: 489.332 | Test Loss: 548.572 | Test Loss [MAPE]: 1704673.452 --time-- 2.3105642795562744\n",
      "Epoch 118/500 | Train Loss: 504.577 | Test Loss: 497.709 | Test Loss [MAPE]: 1582775.718 --time-- 2.3163740634918213\n",
      "Epoch 119/500 | Train Loss: 523.726 | Test Loss: 505.534 | Test Loss [MAPE]: 1568011.761 --time-- 2.309234619140625\n",
      "Epoch 120/500 | Train Loss: 516.401 | Test Loss: 518.165 | Test Loss [MAPE]: 1614488.655 --time-- 2.3112142086029053\n",
      "Epoch 121/500 | Train Loss: 511.265 | Test Loss: 487.056 | Test Loss [MAPE]: 1516955.622 --time-- 2.310748815536499\n",
      "Epoch 122/500 | Train Loss: 484.649 | Test Loss: 459.045 | Test Loss [MAPE]: 1425103.521 --time-- 2.312556743621826\n",
      "Epoch 123/500 | Train Loss: 490.445 | Test Loss: 505.995 | Test Loss [MAPE]: 1593055.716 --time-- 2.3132376670837402\n",
      "Epoch 124/500 | Train Loss: 504.961 | Test Loss: 492.565 | Test Loss [MAPE]: 1552368.725 --time-- 2.3107712268829346\n",
      "Epoch 125/500 | Train Loss: 487.552 | Test Loss: 472.111 | Test Loss [MAPE]: 1519051.904 --time-- 2.3156020641326904\n",
      "Epoch 126/500 | Train Loss: 495.281 | Test Loss: 568.422 | Test Loss [MAPE]: 1770183.561 --time-- 2.316110610961914\n",
      "Epoch 127/500 | Train Loss: 498.388 | Test Loss: 492.016 | Test Loss [MAPE]: 1536237.039 --time-- 2.3155667781829834\n",
      "Epoch 128/500 | Train Loss: 481.229 | Test Loss: 526.081 | Test Loss [MAPE]: 1647452.669 --time-- 2.3133280277252197\n",
      "Epoch 129/500 | Train Loss: 486.057 | Test Loss: 449.542 | Test Loss [MAPE]: 1420226.499 --time-- 2.3119730949401855\n",
      "Epoch 130/500 | Train Loss: 472.417 | Test Loss: 502.071 | Test Loss [MAPE]: 1607521.362 --time-- 2.3129875659942627\n",
      "Epoch 131/500 | Train Loss: 484.330 | Test Loss: 480.734 | Test Loss [MAPE]: 1516747.640 --time-- 2.3160858154296875\n",
      "Epoch 132/500 | Train Loss: 471.791 | Test Loss: 511.541 | Test Loss [MAPE]: 1612671.308 --time-- 2.3138749599456787\n",
      "Epoch 133/500 | Train Loss: 481.431 | Test Loss: 550.029 | Test Loss [MAPE]: 1696848.890 --time-- 2.3122763633728027\n",
      "Epoch 134/500 | Train Loss: 503.380 | Test Loss: 505.033 | Test Loss [MAPE]: 1581467.349 --time-- 2.315431833267212\n",
      "Epoch 135/500 | Train Loss: 503.214 | Test Loss: 509.531 | Test Loss [MAPE]: 1554394.520 --time-- 2.313950538635254\n",
      "Epoch 136/500 | Train Loss: 488.119 | Test Loss: 542.836 | Test Loss [MAPE]: 1701183.216 --time-- 2.311777353286743\n",
      "Epoch 137/500 | Train Loss: 483.866 | Test Loss: 540.494 | Test Loss [MAPE]: 1683880.552 --time-- 2.312634229660034\n",
      "Epoch 138/500 | Train Loss: 473.349 | Test Loss: 482.020 | Test Loss [MAPE]: 1526363.244 --time-- 2.3103199005126953\n",
      "Epoch 139/500 | Train Loss: 473.352 | Test Loss: 459.225 | Test Loss [MAPE]: 1473070.244 --time-- 2.3148908615112305\n",
      "Epoch 140/500 | Train Loss: 472.923 | Test Loss: 500.392 | Test Loss [MAPE]: 1591460.983 --time-- 2.3184661865234375\n",
      "Epoch 141/500 | Train Loss: 502.064 | Test Loss: 482.116 | Test Loss [MAPE]: 1522211.440 --time-- 2.312735080718994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/500 | Train Loss: 469.466 | Test Loss: 474.544 | Test Loss [MAPE]: 1484635.426 --time-- 2.3167026042938232\n",
      "Epoch 143/500 | Train Loss: 494.928 | Test Loss: 560.933 | Test Loss [MAPE]: 1749257.799 --time-- 2.313020944595337\n",
      "Epoch 144/500 | Train Loss: 487.489 | Test Loss: 518.604 | Test Loss [MAPE]: 1631646.055 --time-- 2.31307315826416\n",
      "Epoch 145/500 | Train Loss: 482.582 | Test Loss: 452.403 | Test Loss [MAPE]: 1428639.557 --time-- 2.329214572906494\n",
      "Epoch 146/500 | Train Loss: 472.562 | Test Loss: 514.597 | Test Loss [MAPE]: 1609066.301 --time-- 2.3134613037109375\n",
      "Epoch 147/500 | Train Loss: 472.497 | Test Loss: 464.116 | Test Loss [MAPE]: 1453065.820 --time-- 2.3126044273376465\n",
      "Epoch 148/500 | Train Loss: 450.340 | Test Loss: 497.555 | Test Loss [MAPE]: 1544547.483 --time-- 2.311129093170166\n",
      "Epoch 149/500 | Train Loss: 469.815 | Test Loss: 461.230 | Test Loss [MAPE]: 1445416.514 --time-- 2.318000555038452\n",
      "Epoch 150/500 | Train Loss: 467.640 | Test Loss: 498.166 | Test Loss [MAPE]: 1564770.701 --time-- 2.3134918212890625\n",
      "Epoch 151/500 | Train Loss: 468.178 | Test Loss: 480.508 | Test Loss [MAPE]: 1537959.560 --time-- 2.3130881786346436\n",
      "Epoch 152/500 | Train Loss: 466.317 | Test Loss: 455.542 | Test Loss [MAPE]: 1436242.320 --time-- 2.3137238025665283\n",
      "Epoch 153/500 | Train Loss: 436.713 | Test Loss: 451.432 | Test Loss [MAPE]: 1444196.477 --time-- 2.3143458366394043\n",
      "Epoch 154/500 | Train Loss: 465.345 | Test Loss: 464.409 | Test Loss [MAPE]: 1468425.531 --time-- 2.313894748687744\n",
      "Epoch 155/500 | Train Loss: 453.485 | Test Loss: 501.172 | Test Loss [MAPE]: 1593477.891 --time-- 2.3145928382873535\n",
      "Epoch 156/500 | Train Loss: 472.449 | Test Loss: 480.703 | Test Loss [MAPE]: 1533877.855 --time-- 2.3130714893341064\n",
      "Epoch 157/500 | Train Loss: 465.979 | Test Loss: 532.212 | Test Loss [MAPE]: 1636886.312 --time-- 2.3111791610717773\n",
      "Epoch 158/500 | Train Loss: 486.226 | Test Loss: 548.509 | Test Loss [MAPE]: 1678129.026 --time-- 2.3147828578948975\n",
      "Epoch 159/500 | Train Loss: 481.430 | Test Loss: 461.622 | Test Loss [MAPE]: 1437508.073 --time-- 2.313751697540283\n",
      "Epoch 160/500 | Train Loss: 466.040 | Test Loss: 485.302 | Test Loss [MAPE]: 1512095.144 --time-- 2.3164174556732178\n",
      "Epoch 161/500 | Train Loss: 483.614 | Test Loss: 527.143 | Test Loss [MAPE]: 1629683.763 --time-- 2.3122997283935547\n",
      "Epoch 162/500 | Train Loss: 481.313 | Test Loss: 470.145 | Test Loss [MAPE]: 1494054.817 --time-- 2.3163647651672363\n",
      "Epoch 163/500 | Train Loss: 478.292 | Test Loss: 508.809 | Test Loss [MAPE]: 1586168.745 --time-- 2.3094708919525146\n",
      "Epoch 164/500 | Train Loss: 458.864 | Test Loss: 448.254 | Test Loss [MAPE]: 1436659.858 --time-- 2.3126485347747803\n",
      "Epoch 165/500 | Train Loss: 448.119 | Test Loss: 495.918 | Test Loss [MAPE]: 1546316.052 --time-- 2.3130507469177246\n",
      "Epoch 166/500 | Train Loss: 477.873 | Test Loss: 454.821 | Test Loss [MAPE]: 1439967.948 --time-- 2.3141286373138428\n",
      "Epoch 167/500 | Train Loss: 465.438 | Test Loss: 509.826 | Test Loss [MAPE]: 1668327.570 --time-- 2.313434362411499\n",
      "Epoch 168/500 | Train Loss: 460.788 | Test Loss: 434.497 | Test Loss [MAPE]: 1392629.177 --time-- 2.309859275817871\n",
      "Epoch 169/500 | Train Loss: 477.180 | Test Loss: 488.315 | Test Loss [MAPE]: 1522757.529 --time-- 2.3114278316497803\n",
      "Epoch 170/500 | Train Loss: 479.123 | Test Loss: 450.762 | Test Loss [MAPE]: 1450131.994 --time-- 2.3128044605255127\n",
      "Epoch 171/500 | Train Loss: 496.145 | Test Loss: 457.352 | Test Loss [MAPE]: 1471395.761 --time-- 2.3117613792419434\n",
      "Epoch 172/500 | Train Loss: 453.065 | Test Loss: 485.585 | Test Loss [MAPE]: 1561614.360 --time-- 2.3111536502838135\n",
      "Epoch 173/500 | Train Loss: 448.313 | Test Loss: 448.784 | Test Loss [MAPE]: 1394469.429 --time-- 2.3104565143585205\n",
      "Epoch 174/500 | Train Loss: 441.579 | Test Loss: 492.841 | Test Loss [MAPE]: 1544543.879 --time-- 2.31025767326355\n",
      "Epoch 175/500 | Train Loss: 467.256 | Test Loss: 478.926 | Test Loss [MAPE]: 1529208.890 --time-- 2.3126468658447266\n",
      "Epoch 176/500 | Train Loss: 445.167 | Test Loss: 455.842 | Test Loss [MAPE]: 1470075.701 --time-- 2.3139686584472656\n",
      "Epoch 177/500 | Train Loss: 441.833 | Test Loss: 463.076 | Test Loss [MAPE]: 1515525.429 --time-- 2.3110897541046143\n",
      "Epoch 178/500 | Train Loss: 449.681 | Test Loss: 431.436 | Test Loss [MAPE]: 1393554.762 --time-- 2.315284252166748\n",
      "Epoch 179/500 | Train Loss: 443.971 | Test Loss: 455.016 | Test Loss [MAPE]: 1491563.349 --time-- 2.3117258548736572\n",
      "Epoch 180/500 | Train Loss: 436.894 | Test Loss: 433.828 | Test Loss [MAPE]: 1343025.224 --time-- 2.3143880367279053\n",
      "Epoch 181/500 | Train Loss: 448.603 | Test Loss: 454.188 | Test Loss [MAPE]: 1434965.864 --time-- 2.31713604927063\n",
      "Epoch 182/500 | Train Loss: 480.572 | Test Loss: 468.259 | Test Loss [MAPE]: 1508183.471 --time-- 2.312896490097046\n",
      "Epoch 183/500 | Train Loss: 456.553 | Test Loss: 426.008 | Test Loss [MAPE]: 1392099.320 --time-- 2.3134100437164307\n",
      "Epoch 184/500 | Train Loss: 419.516 | Test Loss: 433.967 | Test Loss [MAPE]: 1377823.944 --time-- 2.3118932247161865\n",
      "Epoch 185/500 | Train Loss: 441.156 | Test Loss: 444.383 | Test Loss [MAPE]: 1424745.912 --time-- 2.3113253116607666\n",
      "Epoch 186/500 | Train Loss: 439.111 | Test Loss: 431.738 | Test Loss [MAPE]: 1362333.170 --time-- 2.3143203258514404\n",
      "Epoch 187/500 | Train Loss: 430.355 | Test Loss: 440.197 | Test Loss [MAPE]: 1384967.880 --time-- 2.3137736320495605\n",
      "Epoch 188/500 | Train Loss: 457.016 | Test Loss: 509.770 | Test Loss [MAPE]: 1626248.628 --time-- 2.3130760192871094\n",
      "Epoch 189/500 | Train Loss: 439.630 | Test Loss: 446.503 | Test Loss [MAPE]: 1430390.092 --time-- 2.3101561069488525\n",
      "Epoch 190/500 | Train Loss: 457.300 | Test Loss: 487.505 | Test Loss [MAPE]: 1558149.874 --time-- 2.3162038326263428\n",
      "Epoch 191/500 | Train Loss: 466.508 | Test Loss: 458.045 | Test Loss [MAPE]: 1482475.711 --time-- 2.31208872795105\n",
      "Epoch 192/500 | Train Loss: 426.411 | Test Loss: 415.110 | Test Loss [MAPE]: 1326115.288 --time-- 2.31357741355896\n",
      "Epoch 193/500 | Train Loss: 404.750 | Test Loss: 418.647 | Test Loss [MAPE]: 1322073.237 --time-- 2.312079668045044\n",
      "Epoch 194/500 | Train Loss: 426.298 | Test Loss: 433.952 | Test Loss [MAPE]: 1371002.276 --time-- 2.315157413482666\n",
      "Epoch 195/500 | Train Loss: 443.634 | Test Loss: 441.188 | Test Loss [MAPE]: 1418766.854 --time-- 2.312659502029419\n",
      "Epoch 196/500 | Train Loss: 419.392 | Test Loss: 421.650 | Test Loss [MAPE]: 1368865.214 --time-- 2.312399387359619\n",
      "Epoch 197/500 | Train Loss: 445.232 | Test Loss: 451.174 | Test Loss [MAPE]: 1381406.178 --time-- 2.3139209747314453\n",
      "Epoch 198/500 | Train Loss: 422.882 | Test Loss: 423.970 | Test Loss [MAPE]: 1340286.568 --time-- 2.312251329421997\n",
      "Epoch 199/500 | Train Loss: 401.935 | Test Loss: 429.845 | Test Loss [MAPE]: 1379659.534 --time-- 2.3144092559814453\n",
      "Epoch 200/500 | Train Loss: 425.164 | Test Loss: 461.793 | Test Loss [MAPE]: 1507346.423 --time-- 2.314079523086548\n",
      "Epoch 201/500 | Train Loss: 442.035 | Test Loss: 459.632 | Test Loss [MAPE]: 1478479.803 --time-- 2.310932159423828\n",
      "Epoch 202/500 | Train Loss: 436.213 | Test Loss: 476.270 | Test Loss [MAPE]: 1571484.711 --time-- 2.3615338802337646\n",
      "Epoch 203/500 | Train Loss: 422.494 | Test Loss: 424.547 | Test Loss [MAPE]: 1349558.128 --time-- 2.310570478439331\n",
      "Epoch 204/500 | Train Loss: 435.499 | Test Loss: 488.443 | Test Loss [MAPE]: 1556227.313 --time-- 2.312177896499634\n",
      "Epoch 205/500 | Train Loss: 459.689 | Test Loss: 461.489 | Test Loss [MAPE]: 1455320.714 --time-- 2.31121563911438\n",
      "Epoch 206/500 | Train Loss: 457.617 | Test Loss: 449.051 | Test Loss [MAPE]: 1452240.145 --time-- 2.3120453357696533\n",
      "Epoch 207/500 | Train Loss: 449.839 | Test Loss: 417.835 | Test Loss [MAPE]: 1361246.228 --time-- 2.314831256866455\n",
      "Epoch 208/500 | Train Loss: 444.332 | Test Loss: 442.534 | Test Loss [MAPE]: 1431029.361 --time-- 2.311467170715332\n",
      "Epoch 209/500 | Train Loss: 427.518 | Test Loss: 434.788 | Test Loss [MAPE]: 1409857.978 --time-- 2.311654806137085\n",
      "Epoch 210/500 | Train Loss: 459.888 | Test Loss: 481.258 | Test Loss [MAPE]: 1527273.487 --time-- 2.3132925033569336\n",
      "Epoch 211/500 | Train Loss: 438.225 | Test Loss: 409.075 | Test Loss [MAPE]: 1335629.823 --time-- 2.314305305480957\n",
      "Epoch 212/500 | Train Loss: 433.447 | Test Loss: 473.526 | Test Loss [MAPE]: 1500195.473 --time-- 2.314340829849243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/500 | Train Loss: 418.152 | Test Loss: 422.865 | Test Loss [MAPE]: 1372532.325 --time-- 2.3133132457733154\n",
      "Epoch 214/500 | Train Loss: 418.472 | Test Loss: 446.023 | Test Loss [MAPE]: 1436503.025 --time-- 2.315535306930542\n",
      "Epoch 215/500 | Train Loss: 438.450 | Test Loss: 459.890 | Test Loss [MAPE]: 1464684.600 --time-- 2.3134543895721436\n",
      "Epoch 216/500 | Train Loss: 446.223 | Test Loss: 416.033 | Test Loss [MAPE]: 1352496.229 --time-- 2.313488483428955\n",
      "Epoch 217/500 | Train Loss: 430.621 | Test Loss: 465.699 | Test Loss [MAPE]: 1471820.291 --time-- 2.3111491203308105\n",
      "Epoch 218/500 | Train Loss: 415.503 | Test Loss: 426.290 | Test Loss [MAPE]: 1346570.848 --time-- 2.3146398067474365\n",
      "Epoch 219/500 | Train Loss: 452.866 | Test Loss: 461.279 | Test Loss [MAPE]: 1459557.939 --time-- 2.3135945796966553\n",
      "Epoch 220/500 | Train Loss: 424.537 | Test Loss: 458.086 | Test Loss [MAPE]: 1473019.023 --time-- 2.311194896697998\n",
      "Epoch 221/500 | Train Loss: 434.361 | Test Loss: 474.392 | Test Loss [MAPE]: 1521389.228 --time-- 2.3113880157470703\n",
      "Epoch 222/500 | Train Loss: 430.387 | Test Loss: 445.779 | Test Loss [MAPE]: 1453176.495 --time-- 2.313620090484619\n",
      "Epoch 223/500 | Train Loss: 425.482 | Test Loss: 452.475 | Test Loss [MAPE]: 1479754.336 --time-- 2.3136603832244873\n",
      "Epoch 224/500 | Train Loss: 434.103 | Test Loss: 454.890 | Test Loss [MAPE]: 1478619.979 --time-- 2.3129513263702393\n",
      "Epoch 225/500 | Train Loss: 416.397 | Test Loss: 444.872 | Test Loss [MAPE]: 1400154.509 --time-- 2.312246799468994\n",
      "Epoch 226/500 | Train Loss: 422.790 | Test Loss: 431.380 | Test Loss [MAPE]: 1376315.141 --time-- 2.311638832092285\n",
      "Epoch 227/500 | Train Loss: 423.149 | Test Loss: 452.688 | Test Loss [MAPE]: 1472098.786 --time-- 2.313178539276123\n",
      "Epoch 228/500 | Train Loss: 424.903 | Test Loss: 423.232 | Test Loss [MAPE]: 1359713.835 --time-- 2.3115389347076416\n",
      "Epoch 229/500 | Train Loss: 432.893 | Test Loss: 397.434 | Test Loss [MAPE]: 1312016.142 --time-- 2.313279390335083\n",
      "Epoch 230/500 | Train Loss: 404.315 | Test Loss: 464.370 | Test Loss [MAPE]: 1494818.964 --time-- 2.3129756450653076\n",
      "Epoch 231/500 | Train Loss: 455.255 | Test Loss: 477.451 | Test Loss [MAPE]: 1450447.448 --time-- 2.311647653579712\n",
      "Epoch 232/500 | Train Loss: 427.227 | Test Loss: 453.009 | Test Loss [MAPE]: 1440905.293 --time-- 2.3142969608306885\n",
      "Epoch 233/500 | Train Loss: 449.775 | Test Loss: 463.902 | Test Loss [MAPE]: 1538332.869 --time-- 2.313699960708618\n",
      "Epoch 234/500 | Train Loss: 399.547 | Test Loss: 457.534 | Test Loss [MAPE]: 1472451.900 --time-- 2.313669443130493\n",
      "Epoch 235/500 | Train Loss: 411.593 | Test Loss: 388.144 | Test Loss [MAPE]: 1275384.600 --time-- 2.313119411468506\n",
      "Epoch 236/500 | Train Loss: 409.052 | Test Loss: 486.796 | Test Loss [MAPE]: 1532603.084 --time-- 2.311613082885742\n",
      "Epoch 237/500 | Train Loss: 424.393 | Test Loss: 437.069 | Test Loss [MAPE]: 1420150.254 --time-- 2.3136000633239746\n",
      "Epoch 238/500 | Train Loss: 421.277 | Test Loss: 448.564 | Test Loss [MAPE]: 1469231.823 --time-- 2.312589406967163\n",
      "Epoch 239/500 | Train Loss: 403.261 | Test Loss: 395.454 | Test Loss [MAPE]: 1270622.435 --time-- 2.3129501342773438\n",
      "Epoch 240/500 | Train Loss: 388.401 | Test Loss: 453.835 | Test Loss [MAPE]: 1462482.000 --time-- 2.3121933937072754\n",
      "Epoch 241/500 | Train Loss: 444.805 | Test Loss: 409.498 | Test Loss [MAPE]: 1308861.233 --time-- 2.312631368637085\n",
      "Epoch 242/500 | Train Loss: 419.140 | Test Loss: 459.362 | Test Loss [MAPE]: 1459017.791 --time-- 2.3115313053131104\n",
      "Epoch 243/500 | Train Loss: 431.302 | Test Loss: 449.613 | Test Loss [MAPE]: 1432407.849 --time-- 2.3160316944122314\n",
      "Epoch 244/500 | Train Loss: 412.092 | Test Loss: 427.162 | Test Loss [MAPE]: 1340878.706 --time-- 2.3110744953155518\n",
      "Epoch 245/500 | Train Loss: 405.252 | Test Loss: 464.313 | Test Loss [MAPE]: 1480527.813 --time-- 2.3135619163513184\n",
      "Epoch 246/500 | Train Loss: 415.125 | Test Loss: 460.386 | Test Loss [MAPE]: 1467331.944 --time-- 2.3136074542999268\n",
      "Epoch 247/500 | Train Loss: 436.628 | Test Loss: 443.339 | Test Loss [MAPE]: 1423123.687 --time-- 2.3137528896331787\n",
      "Epoch 248/500 | Train Loss: 397.018 | Test Loss: 423.342 | Test Loss [MAPE]: 1358997.200 --time-- 2.31266713142395\n",
      "Epoch 249/500 | Train Loss: 395.100 | Test Loss: 411.033 | Test Loss [MAPE]: 1294224.268 --time-- 2.3131723403930664\n",
      "Epoch 250/500 | Train Loss: 432.596 | Test Loss: 459.273 | Test Loss [MAPE]: 1475093.090 --time-- 2.3132102489471436\n",
      "Epoch 251/500 | Train Loss: 435.329 | Test Loss: 429.408 | Test Loss [MAPE]: 1403357.237 --time-- 2.313999891281128\n",
      "Epoch 252/500 | Train Loss: 429.379 | Test Loss: 414.692 | Test Loss [MAPE]: 1361021.537 --time-- 2.3128509521484375\n",
      "Epoch 253/500 | Train Loss: 407.413 | Test Loss: 391.941 | Test Loss [MAPE]: 1261397.121 --time-- 2.3105862140655518\n",
      "Epoch 254/500 | Train Loss: 399.655 | Test Loss: 394.848 | Test Loss [MAPE]: 1273958.882 --time-- 2.3148813247680664\n",
      "Epoch 255/500 | Train Loss: 409.995 | Test Loss: 406.555 | Test Loss [MAPE]: 1302857.166 --time-- 2.3119773864746094\n",
      "Epoch 256/500 | Train Loss: 407.884 | Test Loss: 410.515 | Test Loss [MAPE]: 1346832.356 --time-- 2.3110499382019043\n",
      "Epoch 257/500 | Train Loss: 416.303 | Test Loss: 436.448 | Test Loss [MAPE]: 1419160.744 --time-- 2.3128528594970703\n",
      "Epoch 258/500 | Train Loss: 401.245 | Test Loss: 431.705 | Test Loss [MAPE]: 1382942.473 --time-- 2.3134541511535645\n",
      "Epoch 259/500 | Train Loss: 427.618 | Test Loss: 430.104 | Test Loss [MAPE]: 1394191.144 --time-- 2.313214063644409\n",
      "Epoch 260/500 | Train Loss: 405.751 | Test Loss: 463.009 | Test Loss [MAPE]: 1483230.708 --time-- 2.313493013381958\n",
      "Epoch 261/500 | Train Loss: 430.910 | Test Loss: 432.250 | Test Loss [MAPE]: 1413696.225 --time-- 2.312863826751709\n",
      "Epoch 262/500 | Train Loss: 395.831 | Test Loss: 408.283 | Test Loss [MAPE]: 1323135.386 --time-- 2.3129072189331055\n",
      "Epoch 263/500 | Train Loss: 408.649 | Test Loss: 401.802 | Test Loss [MAPE]: 1303839.332 --time-- 2.312605142593384\n",
      "Epoch 264/500 | Train Loss: 389.984 | Test Loss: 363.968 | Test Loss [MAPE]: 1193002.852 --time-- 2.3159635066986084\n",
      "Epoch 265/500 | Train Loss: 420.892 | Test Loss: 432.863 | Test Loss [MAPE]: 1389720.311 --time-- 2.31483793258667\n",
      "Epoch 266/500 | Train Loss: 423.843 | Test Loss: 490.182 | Test Loss [MAPE]: 1535434.560 --time-- 2.3155088424682617\n",
      "Epoch 267/500 | Train Loss: 444.090 | Test Loss: 436.071 | Test Loss [MAPE]: 1414316.680 --time-- 2.3126015663146973\n",
      "Epoch 268/500 | Train Loss: 460.104 | Test Loss: 442.627 | Test Loss [MAPE]: 1432488.813 --time-- 2.315349578857422\n",
      "Epoch 269/500 | Train Loss: 418.070 | Test Loss: 418.816 | Test Loss [MAPE]: 1337749.410 --time-- 2.3116555213928223\n",
      "Epoch 270/500 | Train Loss: 427.397 | Test Loss: 480.747 | Test Loss [MAPE]: 1563920.221 --time-- 2.3183956146240234\n",
      "Epoch 271/500 | Train Loss: 424.143 | Test Loss: 409.407 | Test Loss [MAPE]: 1325430.726 --time-- 2.3140735626220703\n",
      "Epoch 272/500 | Train Loss: 425.227 | Test Loss: 438.704 | Test Loss [MAPE]: 1434977.906 --time-- 2.313345432281494\n",
      "Epoch 273/500 | Train Loss: 399.005 | Test Loss: 438.195 | Test Loss [MAPE]: 1409269.011 --time-- 2.3145101070404053\n",
      "Epoch 274/500 | Train Loss: 411.975 | Test Loss: 422.485 | Test Loss [MAPE]: 1359239.301 --time-- 2.316953420639038\n",
      "Epoch 275/500 | Train Loss: 434.124 | Test Loss: 483.808 | Test Loss [MAPE]: 1539213.498 --time-- 2.3136868476867676\n",
      "Epoch 276/500 | Train Loss: 410.446 | Test Loss: 427.081 | Test Loss [MAPE]: 1368560.299 --time-- 2.313991069793701\n",
      "Epoch 277/500 | Train Loss: 413.462 | Test Loss: 424.743 | Test Loss [MAPE]: 1359738.971 --time-- 2.315155267715454\n",
      "Epoch 278/500 | Train Loss: 398.470 | Test Loss: 440.049 | Test Loss [MAPE]: 1410237.783 --time-- 2.3132095336914062\n",
      "Epoch 279/500 | Train Loss: 385.828 | Test Loss: 384.835 | Test Loss [MAPE]: 1250629.356 --time-- 2.315007448196411\n",
      "Epoch 280/500 | Train Loss: 383.681 | Test Loss: 425.063 | Test Loss [MAPE]: 1385737.980 --time-- 2.3142507076263428\n",
      "Epoch 281/500 | Train Loss: 425.634 | Test Loss: 422.125 | Test Loss [MAPE]: 1386127.681 --time-- 2.313906192779541\n",
      "Epoch 282/500 | Train Loss: 399.538 | Test Loss: 392.817 | Test Loss [MAPE]: 1266079.944 --time-- 2.315211772918701\n",
      "Epoch 283/500 | Train Loss: 395.813 | Test Loss: 395.652 | Test Loss [MAPE]: 1276576.695 --time-- 2.3127501010894775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/500 | Train Loss: 401.848 | Test Loss: 409.799 | Test Loss [MAPE]: 1317475.374 --time-- 2.315687417984009\n",
      "Epoch 285/500 | Train Loss: 371.977 | Test Loss: 348.961 | Test Loss [MAPE]: 1131395.223 --time-- 2.313767194747925\n",
      "Epoch 286/500 | Train Loss: 387.599 | Test Loss: 367.729 | Test Loss [MAPE]: 1212224.266 --time-- 2.3137755393981934\n",
      "Epoch 287/500 | Train Loss: 406.254 | Test Loss: 430.820 | Test Loss [MAPE]: 1404862.339 --time-- 2.3149707317352295\n",
      "Epoch 288/500 | Train Loss: 392.369 | Test Loss: 435.239 | Test Loss [MAPE]: 1441802.442 --time-- 2.3139634132385254\n",
      "Epoch 289/500 | Train Loss: 415.598 | Test Loss: 449.203 | Test Loss [MAPE]: 1438761.813 --time-- 2.3131322860717773\n",
      "Epoch 290/500 | Train Loss: 390.758 | Test Loss: 395.148 | Test Loss [MAPE]: 1283954.810 --time-- 2.3135733604431152\n",
      "Epoch 291/500 | Train Loss: 405.987 | Test Loss: 379.808 | Test Loss [MAPE]: 1272793.017 --time-- 2.315416097640991\n",
      "Epoch 292/500 | Train Loss: 406.492 | Test Loss: 427.062 | Test Loss [MAPE]: 1377253.643 --time-- 2.3175108432769775\n",
      "Epoch 293/500 | Train Loss: 386.142 | Test Loss: 418.972 | Test Loss [MAPE]: 1356374.852 --time-- 2.3153202533721924\n",
      "Epoch 294/500 | Train Loss: 366.978 | Test Loss: 409.567 | Test Loss [MAPE]: 1334987.112 --time-- 2.313830614089966\n",
      "Epoch 295/500 | Train Loss: 395.796 | Test Loss: 400.613 | Test Loss [MAPE]: 1336716.002 --time-- 2.312309741973877\n",
      "Epoch 296/500 | Train Loss: 417.992 | Test Loss: 406.841 | Test Loss [MAPE]: 1335944.126 --time-- 2.3154664039611816\n",
      "Epoch 297/500 | Train Loss: 398.497 | Test Loss: 377.536 | Test Loss [MAPE]: 1233493.278 --time-- 2.3121135234832764\n",
      "Epoch 298/500 | Train Loss: 385.231 | Test Loss: 383.608 | Test Loss [MAPE]: 1251645.845 --time-- 2.3138046264648438\n",
      "Epoch 299/500 | Train Loss: 388.307 | Test Loss: 423.402 | Test Loss [MAPE]: 1378749.493 --time-- 2.3174376487731934\n",
      "Epoch 300/500 | Train Loss: 394.053 | Test Loss: 384.722 | Test Loss [MAPE]: 1257989.747 --time-- 2.3133113384246826\n",
      "Epoch 301/500 | Train Loss: 380.016 | Test Loss: 426.992 | Test Loss [MAPE]: 1402433.100 --time-- 2.313682794570923\n",
      "Epoch 302/500 | Train Loss: 411.034 | Test Loss: 402.314 | Test Loss [MAPE]: 1312556.189 --time-- 2.3128793239593506\n",
      "Epoch 303/500 | Train Loss: 410.963 | Test Loss: 467.618 | Test Loss [MAPE]: 1498928.913 --time-- 2.3157365322113037\n",
      "Epoch 304/500 | Train Loss: 415.438 | Test Loss: 404.220 | Test Loss [MAPE]: 1322657.033 --time-- 2.313857078552246\n",
      "Epoch 305/500 | Train Loss: 409.547 | Test Loss: 423.698 | Test Loss [MAPE]: 1326832.834 --time-- 2.3134653568267822\n",
      "Epoch 306/500 | Train Loss: 384.464 | Test Loss: 361.267 | Test Loss [MAPE]: 1196066.573 --time-- 2.314206600189209\n",
      "Epoch 307/500 | Train Loss: 391.610 | Test Loss: 400.757 | Test Loss [MAPE]: 1297344.984 --time-- 2.313965320587158\n",
      "Epoch 308/500 | Train Loss: 388.619 | Test Loss: 406.485 | Test Loss [MAPE]: 1273665.525 --time-- 2.3178887367248535\n",
      "Epoch 309/500 | Train Loss: 388.695 | Test Loss: 403.816 | Test Loss [MAPE]: 1334495.864 --time-- 2.3170669078826904\n",
      "Epoch 310/500 | Train Loss: 401.017 | Test Loss: 406.155 | Test Loss [MAPE]: 1329602.671 --time-- 2.314354181289673\n",
      "Epoch 311/500 | Train Loss: 413.899 | Test Loss: 426.486 | Test Loss [MAPE]: 1369847.855 --time-- 2.314204692840576\n",
      "Epoch 312/500 | Train Loss: 371.912 | Test Loss: 332.938 | Test Loss [MAPE]: 1109737.464 --time-- 2.3119935989379883\n",
      "Epoch 313/500 | Train Loss: 389.416 | Test Loss: 399.380 | Test Loss [MAPE]: 1297156.150 --time-- 2.313337564468384\n",
      "Epoch 314/500 | Train Loss: 402.076 | Test Loss: 407.891 | Test Loss [MAPE]: 1330459.049 --time-- 2.3145627975463867\n",
      "Epoch 315/500 | Train Loss: 388.105 | Test Loss: 385.196 | Test Loss [MAPE]: 1278778.475 --time-- 2.311718463897705\n",
      "Epoch 316/500 | Train Loss: 382.263 | Test Loss: 359.623 | Test Loss [MAPE]: 1191259.479 --time-- 2.3142600059509277\n",
      "Epoch 317/500 | Train Loss: 388.884 | Test Loss: 419.056 | Test Loss [MAPE]: 1322761.884 --time-- 2.313795566558838\n",
      "Epoch 318/500 | Train Loss: 399.193 | Test Loss: 408.486 | Test Loss [MAPE]: 1310567.674 --time-- 2.3139595985412598\n",
      "Epoch 319/500 | Train Loss: 387.940 | Test Loss: 398.692 | Test Loss [MAPE]: 1299503.706 --time-- 2.316997528076172\n",
      "Epoch 320/500 | Train Loss: 396.738 | Test Loss: 406.040 | Test Loss [MAPE]: 1319316.280 --time-- 2.3149540424346924\n",
      "Epoch 321/500 | Train Loss: 396.549 | Test Loss: 382.651 | Test Loss [MAPE]: 1252014.561 --time-- 2.3148751258850098\n",
      "Epoch 322/500 | Train Loss: 376.757 | Test Loss: 404.043 | Test Loss [MAPE]: 1328164.970 --time-- 2.3120617866516113\n",
      "Epoch 323/500 | Train Loss: 373.737 | Test Loss: 390.039 | Test Loss [MAPE]: 1269079.935 --time-- 2.312469005584717\n",
      "Epoch 324/500 | Train Loss: 389.210 | Test Loss: 399.276 | Test Loss [MAPE]: 1315386.070 --time-- 2.311859607696533\n",
      "Epoch 325/500 | Train Loss: 386.952 | Test Loss: 395.412 | Test Loss [MAPE]: 1281183.946 --time-- 2.3134043216705322\n",
      "Epoch 326/500 | Train Loss: 399.936 | Test Loss: 423.363 | Test Loss [MAPE]: 1391783.459 --time-- 2.312959671020508\n",
      "Epoch 327/500 | Train Loss: 379.099 | Test Loss: 433.478 | Test Loss [MAPE]: 1395731.734 --time-- 2.3141491413116455\n",
      "Epoch 328/500 | Train Loss: 384.206 | Test Loss: 440.784 | Test Loss [MAPE]: 1459879.011 --time-- 2.314671754837036\n",
      "Epoch 329/500 | Train Loss: 374.044 | Test Loss: 433.130 | Test Loss [MAPE]: 1388965.629 --time-- 2.3147997856140137\n",
      "Epoch 330/500 | Train Loss: 384.995 | Test Loss: 440.136 | Test Loss [MAPE]: 1430495.617 --time-- 2.317249298095703\n",
      "Epoch 331/500 | Train Loss: 406.870 | Test Loss: 405.987 | Test Loss [MAPE]: 1337962.526 --time-- 2.3150634765625\n",
      "Epoch 332/500 | Train Loss: 391.203 | Test Loss: 383.876 | Test Loss [MAPE]: 1244045.158 --time-- 2.3171143531799316\n",
      "Epoch 333/500 | Train Loss: 364.777 | Test Loss: 383.506 | Test Loss [MAPE]: 1263577.656 --time-- 2.312619924545288\n",
      "Epoch 334/500 | Train Loss: 379.251 | Test Loss: 392.975 | Test Loss [MAPE]: 1293777.444 --time-- 2.31296443939209\n",
      "Epoch 335/500 | Train Loss: 381.220 | Test Loss: 392.056 | Test Loss [MAPE]: 1276576.094 --time-- 2.3215627670288086\n",
      "Epoch 336/500 | Train Loss: 405.045 | Test Loss: 451.520 | Test Loss [MAPE]: 1403875.749 --time-- 2.318056583404541\n",
      "Epoch 337/500 | Train Loss: 414.291 | Test Loss: 443.289 | Test Loss [MAPE]: 1418615.356 --time-- 2.315061092376709\n",
      "Epoch 338/500 | Train Loss: 391.933 | Test Loss: 377.332 | Test Loss [MAPE]: 1224601.635 --time-- 2.312791109085083\n",
      "Epoch 339/500 | Train Loss: 393.083 | Test Loss: 383.334 | Test Loss [MAPE]: 1237860.559 --time-- 2.313849449157715\n",
      "Epoch 340/500 | Train Loss: 396.559 | Test Loss: 380.005 | Test Loss [MAPE]: 1235064.386 --time-- 2.3173258304595947\n",
      "Epoch 341/500 | Train Loss: 390.612 | Test Loss: 387.188 | Test Loss [MAPE]: 1285406.707 --time-- 2.3168444633483887\n",
      "Epoch 342/500 | Train Loss: 375.094 | Test Loss: 365.098 | Test Loss [MAPE]: 1176217.303 --time-- 2.3142926692962646\n",
      "Epoch 343/500 | Train Loss: 369.175 | Test Loss: 393.288 | Test Loss [MAPE]: 1303135.663 --time-- 2.316373586654663\n",
      "Epoch 344/500 | Train Loss: 369.427 | Test Loss: 413.969 | Test Loss [MAPE]: 1321043.971 --time-- 2.3184468746185303\n",
      "Epoch 345/500 | Train Loss: 368.787 | Test Loss: 389.079 | Test Loss [MAPE]: 1261067.425 --time-- 2.318319797515869\n",
      "Epoch 346/500 | Train Loss: 363.910 | Test Loss: 391.800 | Test Loss [MAPE]: 1295232.939 --time-- 2.314101219177246\n",
      "Epoch 347/500 | Train Loss: 370.298 | Test Loss: 390.916 | Test Loss [MAPE]: 1267995.485 --time-- 2.3144724369049072\n",
      "Epoch 348/500 | Train Loss: 372.407 | Test Loss: 415.070 | Test Loss [MAPE]: 1338383.722 --time-- 2.312594413757324\n",
      "Epoch 349/500 | Train Loss: 388.903 | Test Loss: 434.516 | Test Loss [MAPE]: 1424393.218 --time-- 2.314016342163086\n",
      "Epoch 350/500 | Train Loss: 396.533 | Test Loss: 357.584 | Test Loss [MAPE]: 1188174.790 --time-- 2.3126418590545654\n",
      "Epoch 351/500 | Train Loss: 365.347 | Test Loss: 373.899 | Test Loss [MAPE]: 1226125.367 --time-- 2.3167707920074463\n",
      "Epoch 352/500 | Train Loss: 383.823 | Test Loss: 377.115 | Test Loss [MAPE]: 1234788.813 --time-- 2.3151206970214844\n",
      "Epoch 353/500 | Train Loss: 395.944 | Test Loss: 386.199 | Test Loss [MAPE]: 1278674.109 --time-- 2.314060688018799\n",
      "Epoch 354/500 | Train Loss: 388.732 | Test Loss: 388.980 | Test Loss [MAPE]: 1304082.253 --time-- 2.3157825469970703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500 | Train Loss: 379.839 | Test Loss: 406.448 | Test Loss [MAPE]: 1334938.121 --time-- 2.3169422149658203\n",
      "Epoch 356/500 | Train Loss: 382.414 | Test Loss: 394.423 | Test Loss [MAPE]: 1241463.202 --time-- 2.315443515777588\n",
      "Epoch 357/500 | Train Loss: 373.099 | Test Loss: 381.115 | Test Loss [MAPE]: 1253374.938 --time-- 2.3140904903411865\n",
      "Epoch 358/500 | Train Loss: 386.749 | Test Loss: 381.865 | Test Loss [MAPE]: 1254096.904 --time-- 2.3154776096343994\n",
      "Epoch 359/500 | Train Loss: 358.567 | Test Loss: 381.515 | Test Loss [MAPE]: 1267816.520 --time-- 2.3165745735168457\n",
      "Epoch 360/500 | Train Loss: 363.362 | Test Loss: 353.968 | Test Loss [MAPE]: 1171412.930 --time-- 2.3147919178009033\n",
      "Epoch 361/500 | Train Loss: 364.262 | Test Loss: 375.103 | Test Loss [MAPE]: 1245973.112 --time-- 2.312605142593384\n",
      "Epoch 362/500 | Train Loss: 375.603 | Test Loss: 353.171 | Test Loss [MAPE]: 1162719.683 --time-- 2.313302755355835\n",
      "Epoch 363/500 | Train Loss: 393.879 | Test Loss: 411.391 | Test Loss [MAPE]: 1336943.877 --time-- 2.3151140213012695\n",
      "Epoch 364/500 | Train Loss: 408.286 | Test Loss: 404.077 | Test Loss [MAPE]: 1314161.371 --time-- 2.314713478088379\n",
      "Epoch 365/500 | Train Loss: 378.260 | Test Loss: 384.210 | Test Loss [MAPE]: 1274521.746 --time-- 2.3156685829162598\n",
      "Epoch 366/500 | Train Loss: 365.251 | Test Loss: 390.698 | Test Loss [MAPE]: 1272743.555 --time-- 2.3154072761535645\n",
      "Epoch 367/500 | Train Loss: 381.632 | Test Loss: 368.395 | Test Loss [MAPE]: 1187069.068 --time-- 2.3154680728912354\n",
      "Epoch 368/500 | Train Loss: 366.314 | Test Loss: 361.257 | Test Loss [MAPE]: 1184055.032 --time-- 2.3139708042144775\n",
      "Epoch 369/500 | Train Loss: 380.093 | Test Loss: 402.036 | Test Loss [MAPE]: 1333799.063 --time-- 2.3134500980377197\n",
      "Epoch 370/500 | Train Loss: 386.209 | Test Loss: 429.234 | Test Loss [MAPE]: 1390878.165 --time-- 2.3148515224456787\n",
      "Epoch 371/500 | Train Loss: 374.739 | Test Loss: 384.542 | Test Loss [MAPE]: 1274885.604 --time-- 2.315887451171875\n",
      "Epoch 372/500 | Train Loss: 371.012 | Test Loss: 464.982 | Test Loss [MAPE]: 1502804.010 --time-- 2.3145246505737305\n",
      "Epoch 373/500 | Train Loss: 403.225 | Test Loss: 421.161 | Test Loss [MAPE]: 1364919.211 --time-- 2.3146400451660156\n",
      "Epoch 374/500 | Train Loss: 361.382 | Test Loss: 421.993 | Test Loss [MAPE]: 1364139.017 --time-- 2.3151257038116455\n",
      "Epoch 375/500 | Train Loss: 372.662 | Test Loss: 386.227 | Test Loss [MAPE]: 1300092.897 --time-- 2.3165700435638428\n",
      "Epoch 376/500 | Train Loss: 356.867 | Test Loss: 391.174 | Test Loss [MAPE]: 1280858.471 --time-- 2.3142998218536377\n",
      "Epoch 377/500 | Train Loss: 383.649 | Test Loss: 431.126 | Test Loss [MAPE]: 1369970.840 --time-- 2.3163235187530518\n",
      "Epoch 378/500 | Train Loss: 386.670 | Test Loss: 365.744 | Test Loss [MAPE]: 1221757.149 --time-- 2.3159823417663574\n",
      "Epoch 379/500 | Train Loss: 382.640 | Test Loss: 427.470 | Test Loss [MAPE]: 1369191.059 --time-- 2.313326597213745\n",
      "Epoch 380/500 | Train Loss: 401.881 | Test Loss: 356.712 | Test Loss [MAPE]: 1179652.346 --time-- 2.3165953159332275\n",
      "Epoch 381/500 | Train Loss: 386.318 | Test Loss: 365.744 | Test Loss [MAPE]: 1203621.164 --time-- 2.315033197402954\n",
      "Epoch 382/500 | Train Loss: 402.078 | Test Loss: 382.957 | Test Loss [MAPE]: 1271038.665 --time-- 2.3118748664855957\n",
      "Epoch 383/500 | Train Loss: 383.271 | Test Loss: 379.677 | Test Loss [MAPE]: 1236114.511 --time-- 2.3134005069732666\n",
      "Epoch 384/500 | Train Loss: 372.556 | Test Loss: 351.949 | Test Loss [MAPE]: 1192183.714 --time-- 2.3120639324188232\n",
      "Epoch 385/500 | Train Loss: 361.409 | Test Loss: 374.535 | Test Loss [MAPE]: 1238932.950 --time-- 2.3142025470733643\n",
      "Epoch 386/500 | Train Loss: 361.168 | Test Loss: 385.801 | Test Loss [MAPE]: 1279409.566 --time-- 2.3131613731384277\n",
      "Epoch 387/500 | Train Loss: 392.787 | Test Loss: 403.301 | Test Loss [MAPE]: 1318380.263 --time-- 2.315181255340576\n",
      "Epoch 388/500 | Train Loss: 369.680 | Test Loss: 391.049 | Test Loss [MAPE]: 1295475.844 --time-- 2.3110954761505127\n",
      "Epoch 389/500 | Train Loss: 372.063 | Test Loss: 349.339 | Test Loss [MAPE]: 1152497.316 --time-- 2.312424659729004\n",
      "Epoch 390/500 | Train Loss: 376.677 | Test Loss: 404.553 | Test Loss [MAPE]: 1385012.310 --time-- 2.315685987472534\n",
      "Epoch 391/500 | Train Loss: 369.739 | Test Loss: 377.083 | Test Loss [MAPE]: 1232103.625 --time-- 2.312302350997925\n",
      "Epoch 392/500 | Train Loss: 375.965 | Test Loss: 397.273 | Test Loss [MAPE]: 1296475.050 --time-- 2.3161003589630127\n",
      "Epoch 393/500 | Train Loss: 379.704 | Test Loss: 372.244 | Test Loss [MAPE]: 1240395.867 --time-- 2.3166074752807617\n",
      "Epoch 394/500 | Train Loss: 375.259 | Test Loss: 343.150 | Test Loss [MAPE]: 1140230.263 --time-- 2.315147638320923\n",
      "Epoch 395/500 | Train Loss: 367.650 | Test Loss: 422.219 | Test Loss [MAPE]: 1355850.102 --time-- 2.313493013381958\n",
      "Epoch 396/500 | Train Loss: 381.070 | Test Loss: 386.311 | Test Loss [MAPE]: 1264861.190 --time-- 2.314516544342041\n",
      "Epoch 397/500 | Train Loss: 354.774 | Test Loss: 359.672 | Test Loss [MAPE]: 1187173.978 --time-- 2.312835454940796\n",
      "Epoch 398/500 | Train Loss: 372.531 | Test Loss: 376.862 | Test Loss [MAPE]: 1241065.209 --time-- 2.314926862716675\n",
      "Epoch 399/500 | Train Loss: 382.406 | Test Loss: 426.980 | Test Loss [MAPE]: 1333961.967 --time-- 2.3145952224731445\n",
      "Epoch 400/500 | Train Loss: 388.412 | Test Loss: 393.606 | Test Loss [MAPE]: 1280271.020 --time-- 2.360908031463623\n",
      "Epoch 401/500 | Train Loss: 354.582 | Test Loss: 364.841 | Test Loss [MAPE]: 1225811.449 --time-- 2.358342409133911\n",
      "Epoch 402/500 | Train Loss: 355.429 | Test Loss: 355.089 | Test Loss [MAPE]: 1179023.388 --time-- 2.361093282699585\n",
      "Epoch 403/500 | Train Loss: 356.177 | Test Loss: 424.389 | Test Loss [MAPE]: 1388289.352 --time-- 2.3596014976501465\n",
      "Epoch 404/500 | Train Loss: 372.426 | Test Loss: 410.414 | Test Loss [MAPE]: 1322267.190 --time-- 2.360515832901001\n",
      "Epoch 405/500 | Train Loss: 393.348 | Test Loss: 420.768 | Test Loss [MAPE]: 1343341.345 --time-- 2.3623647689819336\n",
      "Epoch 406/500 | Train Loss: 374.171 | Test Loss: 354.074 | Test Loss [MAPE]: 1176070.863 --time-- 2.3612945079803467\n",
      "Epoch 407/500 | Train Loss: 371.092 | Test Loss: 359.787 | Test Loss [MAPE]: 1195943.244 --time-- 2.359346628189087\n",
      "Epoch 408/500 | Train Loss: 367.269 | Test Loss: 348.586 | Test Loss [MAPE]: 1116768.364 --time-- 2.359825372695923\n",
      "Epoch 409/500 | Train Loss: 364.340 | Test Loss: 320.324 | Test Loss [MAPE]: 1058231.844 --time-- 2.368683338165283\n",
      "Epoch 410/500 | Train Loss: 367.236 | Test Loss: 361.237 | Test Loss [MAPE]: 1193577.393 --time-- 2.363346576690674\n",
      "Epoch 411/500 | Train Loss: 353.437 | Test Loss: 422.998 | Test Loss [MAPE]: 1348854.199 --time-- 2.3597302436828613\n",
      "Epoch 412/500 | Train Loss: 377.408 | Test Loss: 351.751 | Test Loss [MAPE]: 1184467.140 --time-- 2.358919858932495\n",
      "Epoch 413/500 | Train Loss: 368.500 | Test Loss: 374.090 | Test Loss [MAPE]: 1227651.793 --time-- 2.3144900798797607\n",
      "Epoch 414/500 | Train Loss: 372.700 | Test Loss: 383.595 | Test Loss [MAPE]: 1270382.189 --time-- 2.320556402206421\n",
      "Epoch 415/500 | Train Loss: 383.080 | Test Loss: 404.345 | Test Loss [MAPE]: 1316186.261 --time-- 2.316105842590332\n",
      "Epoch 416/500 | Train Loss: 360.256 | Test Loss: 346.275 | Test Loss [MAPE]: 1155222.551 --time-- 2.314521551132202\n",
      "Epoch 417/500 | Train Loss: 368.524 | Test Loss: 387.189 | Test Loss [MAPE]: 1267009.982 --time-- 2.3152244091033936\n",
      "Epoch 418/500 | Train Loss: 389.877 | Test Loss: 414.464 | Test Loss [MAPE]: 1338749.208 --time-- 2.31549072265625\n",
      "Epoch 419/500 | Train Loss: 385.989 | Test Loss: 397.804 | Test Loss [MAPE]: 1273545.999 --time-- 2.315462112426758\n",
      "Epoch 420/500 | Train Loss: 355.750 | Test Loss: 364.442 | Test Loss [MAPE]: 1156757.654 --time-- 2.3154242038726807\n",
      "Epoch 421/500 | Train Loss: 375.829 | Test Loss: 366.382 | Test Loss [MAPE]: 1236890.294 --time-- 2.3145132064819336\n",
      "Epoch 422/500 | Train Loss: 392.262 | Test Loss: 408.101 | Test Loss [MAPE]: 1327050.695 --time-- 2.3155577182769775\n",
      "Epoch 423/500 | Train Loss: 370.072 | Test Loss: 393.142 | Test Loss [MAPE]: 1296337.879 --time-- 2.3146402835845947\n",
      "Epoch 424/500 | Train Loss: 363.363 | Test Loss: 364.330 | Test Loss [MAPE]: 1179506.211 --time-- 2.317573308944702\n",
      "Epoch 425/500 | Train Loss: 369.263 | Test Loss: 395.085 | Test Loss [MAPE]: 1298151.893 --time-- 2.3164103031158447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500 | Train Loss: 371.950 | Test Loss: 359.258 | Test Loss [MAPE]: 1164474.944 --time-- 2.3136816024780273\n",
      "Epoch 427/500 | Train Loss: 365.890 | Test Loss: 353.357 | Test Loss [MAPE]: 1172090.334 --time-- 2.3165128231048584\n",
      "Epoch 428/500 | Train Loss: 354.794 | Test Loss: 366.364 | Test Loss [MAPE]: 1210264.772 --time-- 2.31278395652771\n",
      "Epoch 429/500 | Train Loss: 359.261 | Test Loss: 362.827 | Test Loss [MAPE]: 1154348.039 --time-- 2.311851978302002\n",
      "Epoch 430/500 | Train Loss: 346.728 | Test Loss: 387.880 | Test Loss [MAPE]: 1258776.785 --time-- 2.3162786960601807\n",
      "Epoch 431/500 | Train Loss: 371.726 | Test Loss: 388.621 | Test Loss [MAPE]: 1265507.645 --time-- 2.3150150775909424\n",
      "Epoch 432/500 | Train Loss: 350.127 | Test Loss: 388.105 | Test Loss [MAPE]: 1226446.173 --time-- 2.31351375579834\n",
      "Epoch 433/500 | Train Loss: 364.556 | Test Loss: 405.532 | Test Loss [MAPE]: 1329195.220 --time-- 2.3154842853546143\n",
      "Epoch 434/500 | Train Loss: 366.621 | Test Loss: 370.867 | Test Loss [MAPE]: 1230076.506 --time-- 2.315258264541626\n",
      "Epoch 435/500 | Train Loss: 363.270 | Test Loss: 371.490 | Test Loss [MAPE]: 1225265.412 --time-- 2.3150267601013184\n",
      "Epoch 436/500 | Train Loss: 344.852 | Test Loss: 339.949 | Test Loss [MAPE]: 1130569.350 --time-- 2.31461763381958\n",
      "Epoch 437/500 | Train Loss: 351.327 | Test Loss: 367.279 | Test Loss [MAPE]: 1191861.868 --time-- 2.3154478073120117\n",
      "Epoch 438/500 | Train Loss: 345.313 | Test Loss: 383.807 | Test Loss [MAPE]: 1267367.915 --time-- 2.312471628189087\n",
      "Epoch 439/500 | Train Loss: 385.332 | Test Loss: 378.726 | Test Loss [MAPE]: 1287888.440 --time-- 2.312776803970337\n",
      "Epoch 440/500 | Train Loss: 366.636 | Test Loss: 372.568 | Test Loss [MAPE]: 1204107.423 --time-- 2.3124351501464844\n",
      "Epoch 441/500 | Train Loss: 340.209 | Test Loss: 369.769 | Test Loss [MAPE]: 1223018.950 --time-- 2.313429117202759\n",
      "Epoch 442/500 | Train Loss: 360.135 | Test Loss: 356.925 | Test Loss [MAPE]: 1175098.435 --time-- 2.3145480155944824\n",
      "Epoch 443/500 | Train Loss: 355.709 | Test Loss: 342.251 | Test Loss [MAPE]: 1128421.224 --time-- 2.3146448135375977\n",
      "Epoch 444/500 | Train Loss: 377.024 | Test Loss: 399.124 | Test Loss [MAPE]: 1303804.180 --time-- 2.3164782524108887\n",
      "Epoch 445/500 | Train Loss: 380.333 | Test Loss: 401.835 | Test Loss [MAPE]: 1316619.091 --time-- 2.3153488636016846\n",
      "Epoch 446/500 | Train Loss: 374.610 | Test Loss: 403.199 | Test Loss [MAPE]: 1308878.100 --time-- 2.3149290084838867\n",
      "Epoch 447/500 | Train Loss: 386.430 | Test Loss: 330.666 | Test Loss [MAPE]: 1108679.667 --time-- 2.3171472549438477\n",
      "Epoch 448/500 | Train Loss: 340.529 | Test Loss: 340.237 | Test Loss [MAPE]: 1125730.367 --time-- 2.316316604614258\n",
      "Epoch 449/500 | Train Loss: 371.129 | Test Loss: 388.807 | Test Loss [MAPE]: 1263215.934 --time-- 2.3166003227233887\n",
      "Epoch 450/500 | Train Loss: 367.336 | Test Loss: 383.024 | Test Loss [MAPE]: 1267930.139 --time-- 2.3137736320495605\n",
      "Epoch 451/500 | Train Loss: 347.494 | Test Loss: 359.533 | Test Loss [MAPE]: 1190223.658 --time-- 2.3170323371887207\n",
      "Epoch 452/500 | Train Loss: 355.987 | Test Loss: 348.253 | Test Loss [MAPE]: 1141344.709 --time-- 2.3183956146240234\n",
      "Epoch 453/500 | Train Loss: 365.385 | Test Loss: 351.777 | Test Loss [MAPE]: 1180893.555 --time-- 2.313962697982788\n",
      "Epoch 454/500 | Train Loss: 335.346 | Test Loss: 349.505 | Test Loss [MAPE]: 1173533.655 --time-- 2.3159103393554688\n",
      "Epoch 455/500 | Train Loss: 352.561 | Test Loss: 397.933 | Test Loss [MAPE]: 1294138.460 --time-- 2.316108226776123\n",
      "Epoch 456/500 | Train Loss: 362.910 | Test Loss: 369.733 | Test Loss [MAPE]: 1220055.928 --time-- 2.3172531127929688\n",
      "Epoch 457/500 | Train Loss: 364.743 | Test Loss: 363.262 | Test Loss [MAPE]: 1188208.269 --time-- 2.314880132675171\n",
      "Epoch 458/500 | Train Loss: 374.034 | Test Loss: 376.843 | Test Loss [MAPE]: 1194871.996 --time-- 2.317809581756592\n",
      "Epoch 459/500 | Train Loss: 382.331 | Test Loss: 413.018 | Test Loss [MAPE]: 1359849.121 --time-- 2.316263198852539\n",
      "Epoch 460/500 | Train Loss: 359.601 | Test Loss: 357.667 | Test Loss [MAPE]: 1194422.177 --time-- 2.315911054611206\n",
      "Epoch 461/500 | Train Loss: 337.139 | Test Loss: 385.096 | Test Loss [MAPE]: 1271386.188 --time-- 2.31369948387146\n",
      "Epoch 462/500 | Train Loss: 369.673 | Test Loss: 424.813 | Test Loss [MAPE]: 1397241.163 --time-- 2.314741373062134\n",
      "Epoch 463/500 | Train Loss: 381.779 | Test Loss: 371.897 | Test Loss [MAPE]: 1191806.328 --time-- 2.3173184394836426\n",
      "Epoch 464/500 | Train Loss: 333.045 | Test Loss: 363.370 | Test Loss [MAPE]: 1199022.614 --time-- 2.315946340560913\n",
      "Epoch 465/500 | Train Loss: 352.605 | Test Loss: 366.320 | Test Loss [MAPE]: 1203217.493 --time-- 2.315624713897705\n",
      "Epoch 466/500 | Train Loss: 370.712 | Test Loss: 404.590 | Test Loss [MAPE]: 1342890.893 --time-- 2.315697193145752\n",
      "Epoch 467/500 | Train Loss: 362.687 | Test Loss: 382.084 | Test Loss [MAPE]: 1241225.665 --time-- 2.3154752254486084\n",
      "Epoch 468/500 | Train Loss: 365.138 | Test Loss: 356.233 | Test Loss [MAPE]: 1176306.717 --time-- 2.3162050247192383\n",
      "Epoch 469/500 | Train Loss: 356.086 | Test Loss: 375.006 | Test Loss [MAPE]: 1223076.956 --time-- 2.316310167312622\n",
      "Epoch 470/500 | Train Loss: 350.314 | Test Loss: 327.124 | Test Loss [MAPE]: 1068812.122 --time-- 2.315683603286743\n",
      "Epoch 471/500 | Train Loss: 356.756 | Test Loss: 351.261 | Test Loss [MAPE]: 1171888.546 --time-- 2.3164565563201904\n",
      "Epoch 472/500 | Train Loss: 358.852 | Test Loss: 394.098 | Test Loss [MAPE]: 1298199.302 --time-- 2.3154516220092773\n",
      "Epoch 473/500 | Train Loss: 354.215 | Test Loss: 349.920 | Test Loss [MAPE]: 1141939.287 --time-- 2.3126611709594727\n",
      "Epoch 474/500 | Train Loss: 364.041 | Test Loss: 415.474 | Test Loss [MAPE]: 1264520.768 --time-- 2.317094326019287\n",
      "Epoch 475/500 | Train Loss: 379.478 | Test Loss: 399.868 | Test Loss [MAPE]: 1301682.347 --time-- 2.3148648738861084\n",
      "Epoch 476/500 | Train Loss: 355.210 | Test Loss: 357.885 | Test Loss [MAPE]: 1193984.826 --time-- 2.3169353008270264\n",
      "Epoch 477/500 | Train Loss: 349.820 | Test Loss: 321.245 | Test Loss [MAPE]: 1058107.165 --time-- 2.3145744800567627\n",
      "Epoch 478/500 | Train Loss: 327.805 | Test Loss: 328.099 | Test Loss [MAPE]: 1106605.905 --time-- 2.3169925212860107\n",
      "Epoch 479/500 | Train Loss: 354.086 | Test Loss: 379.001 | Test Loss [MAPE]: 1266279.455 --time-- 2.3164756298065186\n",
      "Epoch 480/500 | Train Loss: 381.375 | Test Loss: 352.328 | Test Loss [MAPE]: 1158649.784 --time-- 2.3146941661834717\n",
      "Epoch 481/500 | Train Loss: 353.411 | Test Loss: 355.529 | Test Loss [MAPE]: 1182982.191 --time-- 2.3173186779022217\n",
      "Epoch 482/500 | Train Loss: 353.924 | Test Loss: 352.196 | Test Loss [MAPE]: 1169147.121 --time-- 2.3203115463256836\n",
      "Epoch 483/500 | Train Loss: 358.703 | Test Loss: 364.993 | Test Loss [MAPE]: 1192127.550 --time-- 2.31561541557312\n",
      "Epoch 484/500 | Train Loss: 324.480 | Test Loss: 378.963 | Test Loss [MAPE]: 1250283.514 --time-- 2.313676357269287\n",
      "Epoch 485/500 | Train Loss: 361.026 | Test Loss: 373.477 | Test Loss [MAPE]: 1252865.703 --time-- 2.314462900161743\n",
      "Epoch 486/500 | Train Loss: 354.791 | Test Loss: 381.520 | Test Loss [MAPE]: 1256084.482 --time-- 2.3159337043762207\n",
      "Epoch 487/500 | Train Loss: 366.107 | Test Loss: 351.334 | Test Loss [MAPE]: 1163639.991 --time-- 2.3146326541900635\n",
      "Epoch 488/500 | Train Loss: 357.541 | Test Loss: 373.492 | Test Loss [MAPE]: 1221398.438 --time-- 2.318725109100342\n",
      "Epoch 489/500 | Train Loss: 349.154 | Test Loss: 369.597 | Test Loss [MAPE]: 1238174.526 --time-- 2.3121237754821777\n",
      "Epoch 490/500 | Train Loss: 340.709 | Test Loss: 344.516 | Test Loss [MAPE]: 1118073.351 --time-- 2.3143136501312256\n",
      "Epoch 491/500 | Train Loss: 354.390 | Test Loss: 395.855 | Test Loss [MAPE]: 1289579.045 --time-- 2.3136487007141113\n",
      "Epoch 492/500 | Train Loss: 371.624 | Test Loss: 384.373 | Test Loss [MAPE]: 1265714.435 --time-- 2.3169264793395996\n",
      "Epoch 493/500 | Train Loss: 348.789 | Test Loss: 380.708 | Test Loss [MAPE]: 1253137.051 --time-- 2.314918279647827\n",
      "Epoch 494/500 | Train Loss: 354.451 | Test Loss: 372.542 | Test Loss [MAPE]: 1236133.966 --time-- 2.3129348754882812\n",
      "Epoch 495/500 | Train Loss: 339.267 | Test Loss: 333.287 | Test Loss [MAPE]: 1114030.483 --time-- 2.318235397338867\n",
      "Epoch 496/500 | Train Loss: 342.842 | Test Loss: 343.802 | Test Loss [MAPE]: 1158228.168 --time-- 2.3162355422973633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/500 | Train Loss: 348.900 | Test Loss: 403.894 | Test Loss [MAPE]: 1321308.128 --time-- 2.3175830841064453\n",
      "Epoch 498/500 | Train Loss: 363.308 | Test Loss: 414.536 | Test Loss [MAPE]: 1339370.238 --time-- 2.3151257038116455\n",
      "Epoch 499/500 | Train Loss: 363.809 | Test Loss: 405.358 | Test Loss [MAPE]: 1299509.274 --time-- 2.3146238327026367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 03:25:40,175] Trial 34 finished with value: 425934.69303131104 and parameters: {'num_conv_layers': 4, 'kernel_size': 4, 'num_channels': 43, 'pooling_type': 'avg', 'conv_stride': 3, 'feedforward_size': 133, 'pool_stride': 2, 'learning_rate': 0.003929192280135453, 'reg_strength': 0.002719907925190405, 'bs': 119}. Best is trial 34 with value: 425934.69303131104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500 | Train Loss: 344.089 | Test Loss: 369.985 | Test Loss [MAPE]: 1212169.643 --time-- 2.3129186630249023\n",
      "1167.848581314087\n",
      "Epoch 1/500 | Train Loss: 5109.603 | Test Loss: 5161.969 | Test Loss [MAPE]: 434023.248 --time-- 2.3476359844207764\n",
      "Epoch 2/500 | Train Loss: 5092.306 | Test Loss: 4967.664 | Test Loss [MAPE]: 1284178.451 --time-- 2.3041763305664062\n",
      "Epoch 3/500 | Train Loss: 4347.099 | Test Loss: 4234.694 | Test Loss [MAPE]: 1667841.890 --time-- 2.305039167404175\n",
      "Epoch 4/500 | Train Loss: 4175.618 | Test Loss: 4132.119 | Test Loss [MAPE]: 1885716.415 --time-- 2.306291103363037\n",
      "Epoch 5/500 | Train Loss: 4092.074 | Test Loss: 4065.819 | Test Loss [MAPE]: 2916843.382 --time-- 2.3069918155670166\n",
      "Epoch 6/500 | Train Loss: 4049.468 | Test Loss: 3999.794 | Test Loss [MAPE]: 2318849.498 --time-- 2.305736541748047\n",
      "Epoch 7/500 | Train Loss: 3971.291 | Test Loss: 3952.207 | Test Loss [MAPE]: 2571702.838 --time-- 2.3052990436553955\n",
      "Epoch 8/500 | Train Loss: 3913.040 | Test Loss: 3885.601 | Test Loss [MAPE]: 2893763.209 --time-- 2.3047871589660645\n",
      "Epoch 9/500 | Train Loss: 3842.151 | Test Loss: 3813.010 | Test Loss [MAPE]: 3493304.331 --time-- 2.3083181381225586\n",
      "Epoch 10/500 | Train Loss: 3761.054 | Test Loss: 3722.991 | Test Loss [MAPE]: 3799904.656 --time-- 2.3054568767547607\n",
      "Epoch 11/500 | Train Loss: 3662.217 | Test Loss: 3593.531 | Test Loss [MAPE]: 4709419.026 --time-- 2.3041770458221436\n",
      "Epoch 12/500 | Train Loss: 3529.009 | Test Loss: 3449.246 | Test Loss [MAPE]: 4907975.845 --time-- 2.3028104305267334\n",
      "Epoch 13/500 | Train Loss: 3373.085 | Test Loss: 3397.203 | Test Loss [MAPE]: 6377483.203 --time-- 2.303591251373291\n",
      "Epoch 14/500 | Train Loss: 3359.406 | Test Loss: 3369.649 | Test Loss [MAPE]: 4121228.755 --time-- 2.305588483810425\n",
      "Epoch 15/500 | Train Loss: 3120.004 | Test Loss: 2976.667 | Test Loss [MAPE]: 5608666.409 --time-- 2.309868097305298\n",
      "Epoch 16/500 | Train Loss: 2850.091 | Test Loss: 2777.379 | Test Loss [MAPE]: 5400491.252 --time-- 2.3045973777770996\n",
      "Epoch 17/500 | Train Loss: 2675.876 | Test Loss: 2617.426 | Test Loss [MAPE]: 5234697.679 --time-- 2.304098606109619\n",
      "Epoch 18/500 | Train Loss: 2566.743 | Test Loss: 2557.343 | Test Loss [MAPE]: 4874494.575 --time-- 2.3562099933624268\n",
      "Epoch 19/500 | Train Loss: 2452.573 | Test Loss: 2405.518 | Test Loss [MAPE]: 4552129.782 --time-- 2.3645620346069336\n",
      "Epoch 20/500 | Train Loss: 2406.019 | Test Loss: 2378.510 | Test Loss [MAPE]: 4873757.430 --time-- 2.356768846511841\n",
      "Epoch 21/500 | Train Loss: 2274.027 | Test Loss: 2261.842 | Test Loss [MAPE]: 4852950.965 --time-- 2.35837721824646\n",
      "Epoch 22/500 | Train Loss: 2188.248 | Test Loss: 2159.579 | Test Loss [MAPE]: 4274329.662 --time-- 2.3561995029449463\n",
      "Epoch 23/500 | Train Loss: 2171.536 | Test Loss: 2070.228 | Test Loss [MAPE]: 4417380.546 --time-- 2.351562738418579\n",
      "Epoch 24/500 | Train Loss: 2015.753 | Test Loss: 2000.982 | Test Loss [MAPE]: 3974562.407 --time-- 2.3607401847839355\n",
      "Epoch 25/500 | Train Loss: 1987.819 | Test Loss: 1960.193 | Test Loss [MAPE]: 4223008.734 --time-- 2.3584327697753906\n",
      "Epoch 26/500 | Train Loss: 1925.841 | Test Loss: 1886.825 | Test Loss [MAPE]: 4126268.274 --time-- 2.3604319095611572\n",
      "Epoch 27/500 | Train Loss: 1848.624 | Test Loss: 1868.784 | Test Loss [MAPE]: 3972328.957 --time-- 2.355567216873169\n",
      "Epoch 28/500 | Train Loss: 1759.976 | Test Loss: 1759.810 | Test Loss [MAPE]: 3865822.458 --time-- 2.358891248703003\n",
      "Epoch 29/500 | Train Loss: 1738.622 | Test Loss: 1740.253 | Test Loss [MAPE]: 3649332.834 --time-- 2.374297618865967\n",
      "Epoch 30/500 | Train Loss: 1701.527 | Test Loss: 1612.095 | Test Loss [MAPE]: 3528952.764 --time-- 2.3517918586730957\n",
      "Epoch 31/500 | Train Loss: 1595.306 | Test Loss: 1606.200 | Test Loss [MAPE]: 3422081.379 --time-- 2.3504245281219482\n",
      "Epoch 32/500 | Train Loss: 1599.850 | Test Loss: 1632.547 | Test Loss [MAPE]: 3708051.337 --time-- 2.3487861156463623\n",
      "Epoch 33/500 | Train Loss: 1503.061 | Test Loss: 1505.488 | Test Loss [MAPE]: 3291629.884 --time-- 2.349735975265503\n",
      "Epoch 34/500 | Train Loss: 1516.449 | Test Loss: 1479.057 | Test Loss [MAPE]: 3449661.957 --time-- 2.3040828704833984\n",
      "Epoch 35/500 | Train Loss: 1406.689 | Test Loss: 1424.774 | Test Loss [MAPE]: 3279902.011 --time-- 2.3032891750335693\n",
      "Epoch 36/500 | Train Loss: 1359.431 | Test Loss: 1368.857 | Test Loss [MAPE]: 3272597.974 --time-- 2.302011489868164\n",
      "Epoch 37/500 | Train Loss: 1328.859 | Test Loss: 1262.265 | Test Loss [MAPE]: 3010576.582 --time-- 2.302370309829712\n",
      "Epoch 38/500 | Train Loss: 1258.644 | Test Loss: 1369.508 | Test Loss [MAPE]: 3238536.175 --time-- 2.3047356605529785\n",
      "Epoch 39/500 | Train Loss: 1304.180 | Test Loss: 1338.878 | Test Loss [MAPE]: 3246906.103 --time-- 2.305600881576538\n",
      "Epoch 40/500 | Train Loss: 1197.035 | Test Loss: 1223.420 | Test Loss [MAPE]: 3063796.769 --time-- 2.306088447570801\n",
      "Epoch 41/500 | Train Loss: 1202.098 | Test Loss: 1183.367 | Test Loss [MAPE]: 2809954.778 --time-- 2.3045079708099365\n",
      "Epoch 42/500 | Train Loss: 1165.335 | Test Loss: 1138.998 | Test Loss [MAPE]: 2759357.862 --time-- 2.325960159301758\n",
      "Epoch 43/500 | Train Loss: 1119.314 | Test Loss: 1119.694 | Test Loss [MAPE]: 2860779.890 --time-- 2.336031198501587\n",
      "Epoch 44/500 | Train Loss: 1118.435 | Test Loss: 1146.851 | Test Loss [MAPE]: 2755586.655 --time-- 2.3369216918945312\n",
      "Epoch 45/500 | Train Loss: 1113.754 | Test Loss: 1092.154 | Test Loss [MAPE]: 2849657.534 --time-- 2.333282232284546\n",
      "Epoch 46/500 | Train Loss: 1075.530 | Test Loss: 1067.000 | Test Loss [MAPE]: 2735639.534 --time-- 2.334866762161255\n",
      "Epoch 47/500 | Train Loss: 1069.467 | Test Loss: 1048.775 | Test Loss [MAPE]: 2668936.628 --time-- 2.3338565826416016\n",
      "Epoch 48/500 | Train Loss: 1049.129 | Test Loss: 1080.866 | Test Loss [MAPE]: 2800374.349 --time-- 2.3366050720214844\n",
      "Epoch 49/500 | Train Loss: 1041.131 | Test Loss: 1035.637 | Test Loss [MAPE]: 2625720.884 --time-- 2.333252429962158\n",
      "Epoch 50/500 | Train Loss: 1038.327 | Test Loss: 1123.035 | Test Loss [MAPE]: 2586634.215 --time-- 2.3336305618286133\n",
      "Epoch 51/500 | Train Loss: 1016.450 | Test Loss: 1048.301 | Test Loss [MAPE]: 2629872.229 --time-- 2.33415150642395\n",
      "Epoch 52/500 | Train Loss: 993.715 | Test Loss: 1028.157 | Test Loss [MAPE]: 2532457.089 --time-- 2.3347456455230713\n",
      "Epoch 53/500 | Train Loss: 1030.125 | Test Loss: 1022.462 | Test Loss [MAPE]: 2602050.146 --time-- 2.3335604667663574\n",
      "Epoch 54/500 | Train Loss: 1010.958 | Test Loss: 988.656 | Test Loss [MAPE]: 2408963.214 --time-- 2.3331966400146484\n",
      "Epoch 55/500 | Train Loss: 962.536 | Test Loss: 936.265 | Test Loss [MAPE]: 2421688.770 --time-- 2.3340861797332764\n",
      "Epoch 56/500 | Train Loss: 926.918 | Test Loss: 919.619 | Test Loss [MAPE]: 2362248.351 --time-- 2.336710214614868\n",
      "Epoch 57/500 | Train Loss: 906.439 | Test Loss: 983.589 | Test Loss [MAPE]: 2357827.844 --time-- 2.33585262298584\n",
      "Epoch 58/500 | Train Loss: 959.676 | Test Loss: 979.262 | Test Loss [MAPE]: 2558192.994 --time-- 2.3340539932250977\n",
      "Epoch 59/500 | Train Loss: 920.590 | Test Loss: 922.249 | Test Loss [MAPE]: 2475978.207 --time-- 2.3340909481048584\n",
      "Epoch 60/500 | Train Loss: 908.280 | Test Loss: 1004.523 | Test Loss [MAPE]: 2605937.216 --time-- 2.3329854011535645\n",
      "Epoch 61/500 | Train Loss: 900.608 | Test Loss: 929.119 | Test Loss [MAPE]: 2450222.565 --time-- 2.3341851234436035\n",
      "Epoch 62/500 | Train Loss: 870.277 | Test Loss: 858.023 | Test Loss [MAPE]: 2204992.274 --time-- 2.3310086727142334\n",
      "Epoch 63/500 | Train Loss: 831.707 | Test Loss: 878.137 | Test Loss [MAPE]: 2257464.106 --time-- 2.33422589302063\n",
      "Epoch 64/500 | Train Loss: 828.857 | Test Loss: 840.845 | Test Loss [MAPE]: 2316120.939 --time-- 2.334721565246582\n",
      "Epoch 65/500 | Train Loss: 847.300 | Test Loss: 888.769 | Test Loss [MAPE]: 2422948.976 --time-- 2.3344430923461914\n",
      "Epoch 66/500 | Train Loss: 806.417 | Test Loss: 780.663 | Test Loss [MAPE]: 2082530.756 --time-- 2.334961414337158\n",
      "Epoch 67/500 | Train Loss: 820.257 | Test Loss: 881.171 | Test Loss [MAPE]: 2482204.164 --time-- 2.3346378803253174\n",
      "Epoch 68/500 | Train Loss: 822.330 | Test Loss: 756.561 | Test Loss [MAPE]: 2046322.729 --time-- 2.3349990844726562\n",
      "Epoch 69/500 | Train Loss: 774.643 | Test Loss: 772.321 | Test Loss [MAPE]: 2102325.334 --time-- 2.3335800170898438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500 | Train Loss: 779.328 | Test Loss: 752.816 | Test Loss [MAPE]: 2035069.475 --time-- 2.3337998390197754\n",
      "Epoch 71/500 | Train Loss: 749.639 | Test Loss: 790.127 | Test Loss [MAPE]: 2262065.781 --time-- 2.3339462280273438\n",
      "Epoch 72/500 | Train Loss: 745.222 | Test Loss: 743.463 | Test Loss [MAPE]: 2044789.657 --time-- 2.336857318878174\n",
      "Epoch 73/500 | Train Loss: 731.822 | Test Loss: 792.430 | Test Loss [MAPE]: 2271959.968 --time-- 2.338005542755127\n",
      "Epoch 74/500 | Train Loss: 760.185 | Test Loss: 802.983 | Test Loss [MAPE]: 2254591.125 --time-- 2.3349874019622803\n",
      "Epoch 75/500 | Train Loss: 755.991 | Test Loss: 780.805 | Test Loss [MAPE]: 2148224.862 --time-- 2.3347158432006836\n",
      "Epoch 76/500 | Train Loss: 739.439 | Test Loss: 728.647 | Test Loss [MAPE]: 2029040.209 --time-- 2.334585428237915\n",
      "Epoch 77/500 | Train Loss: 703.526 | Test Loss: 657.925 | Test Loss [MAPE]: 1906256.878 --time-- 2.331820249557495\n",
      "Epoch 78/500 | Train Loss: 684.881 | Test Loss: 754.781 | Test Loss [MAPE]: 2139628.943 --time-- 2.333878517150879\n",
      "Epoch 79/500 | Train Loss: 704.037 | Test Loss: 692.104 | Test Loss [MAPE]: 1911488.541 --time-- 2.392127275466919\n",
      "Epoch 80/500 | Train Loss: 682.234 | Test Loss: 688.207 | Test Loss [MAPE]: 1965811.075 --time-- 2.391221523284912\n",
      "Epoch 81/500 | Train Loss: 673.056 | Test Loss: 725.748 | Test Loss [MAPE]: 2070208.334 --time-- 2.3943843841552734\n",
      "Epoch 82/500 | Train Loss: 649.127 | Test Loss: 630.058 | Test Loss [MAPE]: 1781465.057 --time-- 2.3932530879974365\n",
      "Epoch 83/500 | Train Loss: 657.601 | Test Loss: 680.286 | Test Loss [MAPE]: 1943080.665 --time-- 2.389805316925049\n",
      "Epoch 84/500 | Train Loss: 671.101 | Test Loss: 671.268 | Test Loss [MAPE]: 1901777.101 --time-- 2.393002510070801\n",
      "Epoch 85/500 | Train Loss: 641.246 | Test Loss: 633.412 | Test Loss [MAPE]: 1817636.404 --time-- 2.3916406631469727\n",
      "Epoch 86/500 | Train Loss: 623.745 | Test Loss: 588.335 | Test Loss [MAPE]: 1708362.017 --time-- 2.3903021812438965\n",
      "Epoch 87/500 | Train Loss: 617.563 | Test Loss: 678.615 | Test Loss [MAPE]: 1992371.216 --time-- 2.3940751552581787\n",
      "Epoch 88/500 | Train Loss: 634.471 | Test Loss: 633.262 | Test Loss [MAPE]: 1853189.458 --time-- 2.394646406173706\n",
      "Epoch 89/500 | Train Loss: 608.596 | Test Loss: 622.303 | Test Loss [MAPE]: 1834547.797 --time-- 2.3875107765197754\n",
      "Epoch 90/500 | Train Loss: 605.404 | Test Loss: 602.429 | Test Loss [MAPE]: 1787626.251 --time-- 2.3959290981292725\n",
      "Epoch 91/500 | Train Loss: 596.085 | Test Loss: 644.039 | Test Loss [MAPE]: 1866484.480 --time-- 2.3924472332000732\n",
      "Epoch 92/500 | Train Loss: 625.130 | Test Loss: 625.457 | Test Loss [MAPE]: 1862755.603 --time-- 2.3960671424865723\n",
      "Epoch 93/500 | Train Loss: 594.832 | Test Loss: 591.665 | Test Loss [MAPE]: 1744253.104 --time-- 2.395451784133911\n",
      "Epoch 94/500 | Train Loss: 569.144 | Test Loss: 608.216 | Test Loss [MAPE]: 1820481.006 --time-- 2.3891043663024902\n",
      "Epoch 95/500 | Train Loss: 591.127 | Test Loss: 621.430 | Test Loss [MAPE]: 1826659.600 --time-- 2.3994979858398438\n",
      "Epoch 96/500 | Train Loss: 609.404 | Test Loss: 574.794 | Test Loss [MAPE]: 1716130.427 --time-- 2.3982436656951904\n",
      "Epoch 97/500 | Train Loss: 594.065 | Test Loss: 740.080 | Test Loss [MAPE]: 2081364.740 --time-- 2.4025511741638184\n",
      "Epoch 98/500 | Train Loss: 568.798 | Test Loss: 564.614 | Test Loss [MAPE]: 1690358.397 --time-- 2.3922786712646484\n",
      "Epoch 99/500 | Train Loss: 562.734 | Test Loss: 525.894 | Test Loss [MAPE]: 1613569.117 --time-- 2.4006941318511963\n",
      "Epoch 100/500 | Train Loss: 574.650 | Test Loss: 597.214 | Test Loss [MAPE]: 1829570.983 --time-- 2.390831708908081\n",
      "Epoch 101/500 | Train Loss: 544.151 | Test Loss: 556.465 | Test Loss [MAPE]: 1680406.331 --time-- 2.3947267532348633\n",
      "Epoch 102/500 | Train Loss: 526.788 | Test Loss: 590.323 | Test Loss [MAPE]: 1772492.215 --time-- 2.3923025131225586\n",
      "Epoch 103/500 | Train Loss: 545.336 | Test Loss: 544.650 | Test Loss [MAPE]: 1633833.167 --time-- 2.3958818912506104\n",
      "Epoch 104/500 | Train Loss: 512.613 | Test Loss: 520.472 | Test Loss [MAPE]: 1588287.097 --time-- 2.405736207962036\n",
      "Epoch 105/500 | Train Loss: 525.987 | Test Loss: 501.166 | Test Loss [MAPE]: 1512639.973 --time-- 2.387110710144043\n",
      "Epoch 106/500 | Train Loss: 508.596 | Test Loss: 565.664 | Test Loss [MAPE]: 1722964.832 --time-- 2.395587682723999\n",
      "Epoch 107/500 | Train Loss: 516.449 | Test Loss: 502.852 | Test Loss [MAPE]: 1526926.420 --time-- 2.3967392444610596\n",
      "Epoch 108/500 | Train Loss: 534.585 | Test Loss: 580.995 | Test Loss [MAPE]: 1789018.580 --time-- 2.393440008163452\n",
      "Epoch 109/500 | Train Loss: 510.896 | Test Loss: 538.630 | Test Loss [MAPE]: 1708617.585 --time-- 2.4102461338043213\n",
      "Epoch 110/500 | Train Loss: 517.562 | Test Loss: 513.324 | Test Loss [MAPE]: 1558568.951 --time-- 2.3914291858673096\n",
      "Epoch 111/500 | Train Loss: 496.773 | Test Loss: 517.679 | Test Loss [MAPE]: 1598110.760 --time-- 2.3981893062591553\n",
      "Epoch 112/500 | Train Loss: 538.032 | Test Loss: 557.118 | Test Loss [MAPE]: 1727350.886 --time-- 2.392038106918335\n",
      "Epoch 113/500 | Train Loss: 541.291 | Test Loss: 527.755 | Test Loss [MAPE]: 1628402.513 --time-- 2.3973145484924316\n",
      "Epoch 114/500 | Train Loss: 505.659 | Test Loss: 532.256 | Test Loss [MAPE]: 1609916.614 --time-- 2.396719217300415\n",
      "Epoch 115/500 | Train Loss: 475.170 | Test Loss: 489.104 | Test Loss [MAPE]: 1513295.877 --time-- 2.332998514175415\n",
      "Epoch 116/500 | Train Loss: 486.423 | Test Loss: 494.272 | Test Loss [MAPE]: 1512739.511 --time-- 2.333728313446045\n",
      "Epoch 117/500 | Train Loss: 507.843 | Test Loss: 491.029 | Test Loss [MAPE]: 1516442.918 --time-- 2.3321449756622314\n",
      "Epoch 118/500 | Train Loss: 519.425 | Test Loss: 532.050 | Test Loss [MAPE]: 1640911.120 --time-- 2.330314874649048\n",
      "Epoch 119/500 | Train Loss: 504.584 | Test Loss: 522.207 | Test Loss [MAPE]: 1589728.714 --time-- 2.3340578079223633\n",
      "Epoch 120/500 | Train Loss: 527.958 | Test Loss: 568.532 | Test Loss [MAPE]: 1735587.801 --time-- 2.3296830654144287\n",
      "Epoch 121/500 | Train Loss: 516.580 | Test Loss: 500.249 | Test Loss [MAPE]: 1526905.650 --time-- 2.3354761600494385\n",
      "Epoch 122/500 | Train Loss: 466.979 | Test Loss: 463.789 | Test Loss [MAPE]: 1441783.963 --time-- 2.334320545196533\n",
      "Epoch 123/500 | Train Loss: 479.015 | Test Loss: 469.905 | Test Loss [MAPE]: 1458408.576 --time-- 2.332764148712158\n",
      "Epoch 124/500 | Train Loss: 517.309 | Test Loss: 490.139 | Test Loss [MAPE]: 1491949.465 --time-- 2.3326587677001953\n",
      "Epoch 125/500 | Train Loss: 498.626 | Test Loss: 563.660 | Test Loss [MAPE]: 1701792.553 --time-- 2.331408739089966\n",
      "Epoch 126/500 | Train Loss: 512.754 | Test Loss: 523.176 | Test Loss [MAPE]: 1629008.129 --time-- 2.333496570587158\n",
      "Epoch 127/500 | Train Loss: 522.166 | Test Loss: 528.741 | Test Loss [MAPE]: 1601170.560 --time-- 2.332198143005371\n",
      "Epoch 128/500 | Train Loss: 486.427 | Test Loss: 473.581 | Test Loss [MAPE]: 1471808.322 --time-- 2.3325111865997314\n",
      "Epoch 129/500 | Train Loss: 474.029 | Test Loss: 492.538 | Test Loss [MAPE]: 1503755.540 --time-- 2.335094928741455\n",
      "Epoch 130/500 | Train Loss: 470.506 | Test Loss: 492.066 | Test Loss [MAPE]: 1531118.476 --time-- 2.334789991378784\n",
      "Epoch 131/500 | Train Loss: 479.024 | Test Loss: 453.706 | Test Loss [MAPE]: 1404689.517 --time-- 2.3333678245544434\n",
      "Epoch 132/500 | Train Loss: 487.408 | Test Loss: 474.857 | Test Loss [MAPE]: 1421513.186 --time-- 2.3337435722351074\n",
      "Epoch 133/500 | Train Loss: 428.846 | Test Loss: 436.979 | Test Loss [MAPE]: 1361554.289 --time-- 2.332916021347046\n",
      "Epoch 134/500 | Train Loss: 470.705 | Test Loss: 477.694 | Test Loss [MAPE]: 1487063.454 --time-- 2.3358213901519775\n",
      "Epoch 135/500 | Train Loss: 481.380 | Test Loss: 487.634 | Test Loss [MAPE]: 1522145.783 --time-- 2.3307955265045166\n",
      "Epoch 136/500 | Train Loss: 482.327 | Test Loss: 520.090 | Test Loss [MAPE]: 1604361.589 --time-- 2.336958169937134\n",
      "Epoch 137/500 | Train Loss: 493.993 | Test Loss: 483.461 | Test Loss [MAPE]: 1509286.418 --time-- 2.3331820964813232\n",
      "Epoch 138/500 | Train Loss: 457.085 | Test Loss: 493.355 | Test Loss [MAPE]: 1548222.243 --time-- 2.330939769744873\n",
      "Epoch 139/500 | Train Loss: 484.558 | Test Loss: 512.249 | Test Loss [MAPE]: 1589763.452 --time-- 2.3328185081481934\n",
      "Epoch 140/500 | Train Loss: 499.686 | Test Loss: 475.566 | Test Loss [MAPE]: 1498585.301 --time-- 2.3322818279266357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/500 | Train Loss: 486.412 | Test Loss: 547.785 | Test Loss [MAPE]: 1693514.629 --time-- 2.334310293197632\n",
      "Epoch 142/500 | Train Loss: 456.023 | Test Loss: 471.919 | Test Loss [MAPE]: 1470698.715 --time-- 2.332972764968872\n",
      "Epoch 143/500 | Train Loss: 465.022 | Test Loss: 491.600 | Test Loss [MAPE]: 1526045.333 --time-- 2.331226348876953\n",
      "Epoch 144/500 | Train Loss: 481.447 | Test Loss: 499.173 | Test Loss [MAPE]: 1559436.796 --time-- 2.391688823699951\n",
      "Epoch 145/500 | Train Loss: 463.199 | Test Loss: 448.471 | Test Loss [MAPE]: 1385474.681 --time-- 2.395911455154419\n",
      "Epoch 146/500 | Train Loss: 435.735 | Test Loss: 417.387 | Test Loss [MAPE]: 1300168.619 --time-- 2.396073579788208\n",
      "Epoch 147/500 | Train Loss: 442.556 | Test Loss: 479.034 | Test Loss [MAPE]: 1506554.860 --time-- 2.3897807598114014\n",
      "Epoch 148/500 | Train Loss: 477.407 | Test Loss: 550.562 | Test Loss [MAPE]: 1650516.676 --time-- 2.395212411880493\n",
      "Epoch 149/500 | Train Loss: 466.679 | Test Loss: 449.966 | Test Loss [MAPE]: 1412414.872 --time-- 2.387011766433716\n",
      "Epoch 150/500 | Train Loss: 455.667 | Test Loss: 486.673 | Test Loss [MAPE]: 1508425.613 --time-- 2.3936290740966797\n",
      "Epoch 151/500 | Train Loss: 444.207 | Test Loss: 506.076 | Test Loss [MAPE]: 1598136.863 --time-- 2.3881988525390625\n",
      "Epoch 152/500 | Train Loss: 463.825 | Test Loss: 490.716 | Test Loss [MAPE]: 1527385.483 --time-- 2.3895423412323\n",
      "Epoch 153/500 | Train Loss: 444.730 | Test Loss: 465.847 | Test Loss [MAPE]: 1445645.003 --time-- 2.387244701385498\n",
      "Epoch 154/500 | Train Loss: 466.199 | Test Loss: 458.807 | Test Loss [MAPE]: 1456449.565 --time-- 2.3946967124938965\n",
      "Epoch 155/500 | Train Loss: 450.490 | Test Loss: 486.658 | Test Loss [MAPE]: 1506489.228 --time-- 2.3913369178771973\n",
      "Epoch 156/500 | Train Loss: 441.207 | Test Loss: 444.671 | Test Loss [MAPE]: 1379087.175 --time-- 2.393416404724121\n",
      "Epoch 157/500 | Train Loss: 453.522 | Test Loss: 451.325 | Test Loss [MAPE]: 1407635.693 --time-- 2.388718366622925\n",
      "Epoch 158/500 | Train Loss: 456.416 | Test Loss: 515.417 | Test Loss [MAPE]: 1612328.720 --time-- 2.3925023078918457\n",
      "Epoch 159/500 | Train Loss: 482.530 | Test Loss: 505.518 | Test Loss [MAPE]: 1562038.881 --time-- 2.3929619789123535\n",
      "Epoch 160/500 | Train Loss: 447.283 | Test Loss: 464.698 | Test Loss [MAPE]: 1491683.187 --time-- 2.391343116760254\n",
      "Epoch 161/500 | Train Loss: 428.282 | Test Loss: 479.731 | Test Loss [MAPE]: 1520703.558 --time-- 2.3916943073272705\n",
      "Epoch 162/500 | Train Loss: 467.123 | Test Loss: 430.968 | Test Loss [MAPE]: 1302628.346 --time-- 2.392446279525757\n",
      "Epoch 163/500 | Train Loss: 435.749 | Test Loss: 473.106 | Test Loss [MAPE]: 1473124.292 --time-- 2.38948655128479\n",
      "Epoch 164/500 | Train Loss: 472.132 | Test Loss: 471.332 | Test Loss [MAPE]: 1470303.655 --time-- 2.395761013031006\n",
      "Epoch 165/500 | Train Loss: 460.852 | Test Loss: 434.134 | Test Loss [MAPE]: 1363955.273 --time-- 2.3872478008270264\n",
      "Epoch 166/500 | Train Loss: 417.488 | Test Loss: 443.243 | Test Loss [MAPE]: 1376576.626 --time-- 2.3975465297698975\n",
      "Epoch 167/500 | Train Loss: 422.017 | Test Loss: 415.973 | Test Loss [MAPE]: 1324328.897 --time-- 2.390721321105957\n",
      "Epoch 168/500 | Train Loss: 439.759 | Test Loss: 426.620 | Test Loss [MAPE]: 1335329.479 --time-- 2.3905913829803467\n",
      "Epoch 169/500 | Train Loss: 422.676 | Test Loss: 469.770 | Test Loss [MAPE]: 1460405.147 --time-- 2.3371403217315674\n",
      "Epoch 170/500 | Train Loss: 438.509 | Test Loss: 448.886 | Test Loss [MAPE]: 1410755.861 --time-- 2.3351235389709473\n",
      "Epoch 171/500 | Train Loss: 471.305 | Test Loss: 484.832 | Test Loss [MAPE]: 1529474.804 --time-- 2.335257053375244\n",
      "Epoch 172/500 | Train Loss: 455.078 | Test Loss: 464.429 | Test Loss [MAPE]: 1408165.766 --time-- 2.338657855987549\n",
      "Epoch 173/500 | Train Loss: 435.614 | Test Loss: 420.567 | Test Loss [MAPE]: 1349969.969 --time-- 2.3338842391967773\n",
      "Epoch 174/500 | Train Loss: 407.003 | Test Loss: 475.748 | Test Loss [MAPE]: 1501633.331 --time-- 2.33443284034729\n",
      "Epoch 175/500 | Train Loss: 432.809 | Test Loss: 443.059 | Test Loss [MAPE]: 1389575.994 --time-- 2.3359954357147217\n",
      "Epoch 176/500 | Train Loss: 424.615 | Test Loss: 449.844 | Test Loss [MAPE]: 1388506.785 --time-- 2.3351447582244873\n",
      "Epoch 177/500 | Train Loss: 448.036 | Test Loss: 422.410 | Test Loss [MAPE]: 1306394.688 --time-- 2.3341176509857178\n",
      "Epoch 178/500 | Train Loss: 409.766 | Test Loss: 425.595 | Test Loss [MAPE]: 1341190.007 --time-- 2.3348796367645264\n",
      "Epoch 179/500 | Train Loss: 430.271 | Test Loss: 427.818 | Test Loss [MAPE]: 1338090.300 --time-- 2.334784746170044\n",
      "Epoch 180/500 | Train Loss: 442.936 | Test Loss: 454.992 | Test Loss [MAPE]: 1438861.286 --time-- 2.332796335220337\n",
      "Epoch 181/500 | Train Loss: 406.935 | Test Loss: 420.479 | Test Loss [MAPE]: 1340563.341 --time-- 2.3370697498321533\n",
      "Epoch 182/500 | Train Loss: 421.875 | Test Loss: 481.350 | Test Loss [MAPE]: 1530669.319 --time-- 2.3340871334075928\n",
      "Epoch 183/500 | Train Loss: 460.828 | Test Loss: 458.703 | Test Loss [MAPE]: 1456644.776 --time-- 2.3352200984954834\n",
      "Epoch 184/500 | Train Loss: 425.280 | Test Loss: 456.336 | Test Loss [MAPE]: 1456275.660 --time-- 2.3341689109802246\n",
      "Epoch 185/500 | Train Loss: 418.900 | Test Loss: 452.410 | Test Loss [MAPE]: 1431445.919 --time-- 2.3336939811706543\n",
      "Epoch 186/500 | Train Loss: 402.589 | Test Loss: 454.074 | Test Loss [MAPE]: 1412116.568 --time-- 2.3334038257598877\n",
      "Epoch 187/500 | Train Loss: 425.115 | Test Loss: 460.970 | Test Loss [MAPE]: 1431758.372 --time-- 2.3329989910125732\n",
      "Epoch 188/500 | Train Loss: 433.742 | Test Loss: 443.137 | Test Loss [MAPE]: 1380440.455 --time-- 2.33549427986145\n",
      "Epoch 189/500 | Train Loss: 418.745 | Test Loss: 434.903 | Test Loss [MAPE]: 1352684.319 --time-- 2.3357715606689453\n",
      "Epoch 190/500 | Train Loss: 426.939 | Test Loss: 419.572 | Test Loss [MAPE]: 1321525.236 --time-- 2.336989641189575\n",
      "Epoch 191/500 | Train Loss: 428.988 | Test Loss: 442.337 | Test Loss [MAPE]: 1374560.448 --time-- 2.333997964859009\n",
      "Epoch 192/500 | Train Loss: 421.780 | Test Loss: 435.638 | Test Loss [MAPE]: 1359279.560 --time-- 2.3363304138183594\n",
      "Epoch 193/500 | Train Loss: 437.562 | Test Loss: 464.840 | Test Loss [MAPE]: 1480580.795 --time-- 2.347362518310547\n",
      "Epoch 194/500 | Train Loss: 424.460 | Test Loss: 463.320 | Test Loss [MAPE]: 1443335.076 --time-- 2.3410868644714355\n",
      "Epoch 195/500 | Train Loss: 446.186 | Test Loss: 447.997 | Test Loss [MAPE]: 1422634.059 --time-- 2.336082696914673\n",
      "Epoch 196/500 | Train Loss: 416.313 | Test Loss: 445.905 | Test Loss [MAPE]: 1405346.008 --time-- 2.3351027965545654\n",
      "Epoch 197/500 | Train Loss: 419.224 | Test Loss: 476.307 | Test Loss [MAPE]: 1484563.369 --time-- 2.337764024734497\n",
      "Epoch 198/500 | Train Loss: 452.732 | Test Loss: 419.093 | Test Loss [MAPE]: 1336815.712 --time-- 2.3368587493896484\n",
      "Epoch 199/500 | Train Loss: 399.093 | Test Loss: 417.291 | Test Loss [MAPE]: 1304289.922 --time-- 2.334660053253174\n",
      "Epoch 200/500 | Train Loss: 432.759 | Test Loss: 512.058 | Test Loss [MAPE]: 1583980.889 --time-- 2.3390872478485107\n",
      "Epoch 201/500 | Train Loss: 458.833 | Test Loss: 448.764 | Test Loss [MAPE]: 1415098.450 --time-- 2.335845708847046\n",
      "Epoch 202/500 | Train Loss: 432.839 | Test Loss: 461.524 | Test Loss [MAPE]: 1383115.112 --time-- 2.3322503566741943\n",
      "Epoch 203/500 | Train Loss: 424.345 | Test Loss: 411.771 | Test Loss [MAPE]: 1294167.272 --time-- 2.332773447036743\n",
      "Epoch 204/500 | Train Loss: 396.792 | Test Loss: 426.762 | Test Loss [MAPE]: 1319714.012 --time-- 2.338841676712036\n",
      "Epoch 205/500 | Train Loss: 411.853 | Test Loss: 380.844 | Test Loss [MAPE]: 1195114.836 --time-- 2.336810827255249\n",
      "Epoch 206/500 | Train Loss: 384.485 | Test Loss: 400.731 | Test Loss [MAPE]: 1282023.104 --time-- 2.3351328372955322\n",
      "Epoch 207/500 | Train Loss: 409.468 | Test Loss: 451.135 | Test Loss [MAPE]: 1395242.044 --time-- 2.3358500003814697\n",
      "Epoch 208/500 | Train Loss: 392.747 | Test Loss: 371.872 | Test Loss [MAPE]: 1192917.805 --time-- 2.3317553997039795\n",
      "Epoch 209/500 | Train Loss: 412.738 | Test Loss: 441.111 | Test Loss [MAPE]: 1400100.118 --time-- 2.333601474761963\n",
      "Epoch 210/500 | Train Loss: 414.672 | Test Loss: 399.893 | Test Loss [MAPE]: 1292798.979 --time-- 2.335819959640503\n",
      "Epoch 211/500 | Train Loss: 400.921 | Test Loss: 404.679 | Test Loss [MAPE]: 1289786.706 --time-- 2.3370981216430664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/500 | Train Loss: 412.814 | Test Loss: 419.402 | Test Loss [MAPE]: 1335646.595 --time-- 2.33516526222229\n",
      "Epoch 213/500 | Train Loss: 411.378 | Test Loss: 424.475 | Test Loss [MAPE]: 1362174.933 --time-- 2.3381412029266357\n",
      "Epoch 214/500 | Train Loss: 415.065 | Test Loss: 429.490 | Test Loss [MAPE]: 1384813.637 --time-- 2.3389928340911865\n",
      "Epoch 215/500 | Train Loss: 401.585 | Test Loss: 396.322 | Test Loss [MAPE]: 1267600.713 --time-- 2.334421157836914\n",
      "Epoch 216/500 | Train Loss: 408.667 | Test Loss: 485.913 | Test Loss [MAPE]: 1520516.823 --time-- 2.3372764587402344\n",
      "Epoch 217/500 | Train Loss: 425.631 | Test Loss: 401.482 | Test Loss [MAPE]: 1287540.415 --time-- 2.335157871246338\n",
      "Epoch 218/500 | Train Loss: 403.887 | Test Loss: 428.616 | Test Loss [MAPE]: 1339412.316 --time-- 2.3359265327453613\n",
      "Epoch 219/500 | Train Loss: 403.581 | Test Loss: 424.431 | Test Loss [MAPE]: 1332367.612 --time-- 2.335157871246338\n",
      "Epoch 220/500 | Train Loss: 391.060 | Test Loss: 389.175 | Test Loss [MAPE]: 1265155.134 --time-- 2.334660768508911\n",
      "Epoch 221/500 | Train Loss: 408.460 | Test Loss: 445.201 | Test Loss [MAPE]: 1410319.521 --time-- 2.3361527919769287\n",
      "Epoch 222/500 | Train Loss: 398.359 | Test Loss: 433.874 | Test Loss [MAPE]: 1360123.175 --time-- 2.3326194286346436\n",
      "Epoch 223/500 | Train Loss: 388.193 | Test Loss: 424.904 | Test Loss [MAPE]: 1321579.759 --time-- 2.3346409797668457\n",
      "Epoch 224/500 | Train Loss: 385.648 | Test Loss: 374.816 | Test Loss [MAPE]: 1185099.790 --time-- 2.34456467628479\n",
      "Epoch 225/500 | Train Loss: 385.642 | Test Loss: 402.831 | Test Loss [MAPE]: 1276183.679 --time-- 2.33583664894104\n",
      "Epoch 226/500 | Train Loss: 408.097 | Test Loss: 413.235 | Test Loss [MAPE]: 1287136.485 --time-- 2.334636688232422\n",
      "Epoch 227/500 | Train Loss: 410.055 | Test Loss: 395.085 | Test Loss [MAPE]: 1288002.790 --time-- 2.332543134689331\n",
      "Epoch 228/500 | Train Loss: 395.034 | Test Loss: 422.226 | Test Loss [MAPE]: 1336243.397 --time-- 2.3325693607330322\n",
      "Epoch 229/500 | Train Loss: 413.875 | Test Loss: 409.562 | Test Loss [MAPE]: 1290494.614 --time-- 2.3322033882141113\n",
      "Epoch 230/500 | Train Loss: 409.991 | Test Loss: 420.135 | Test Loss [MAPE]: 1320095.900 --time-- 2.334420919418335\n",
      "Epoch 231/500 | Train Loss: 401.535 | Test Loss: 392.541 | Test Loss [MAPE]: 1247200.075 --time-- 2.333969831466675\n",
      "Epoch 232/500 | Train Loss: 395.694 | Test Loss: 406.197 | Test Loss [MAPE]: 1263894.490 --time-- 2.334261655807495\n",
      "Epoch 233/500 | Train Loss: 401.544 | Test Loss: 395.775 | Test Loss [MAPE]: 1281652.832 --time-- 2.334564208984375\n",
      "Epoch 234/500 | Train Loss: 385.687 | Test Loss: 421.034 | Test Loss [MAPE]: 1333458.967 --time-- 2.3332953453063965\n",
      "Epoch 235/500 | Train Loss: 395.784 | Test Loss: 406.952 | Test Loss [MAPE]: 1286068.207 --time-- 2.3359835147857666\n",
      "Epoch 236/500 | Train Loss: 391.125 | Test Loss: 449.081 | Test Loss [MAPE]: 1424819.181 --time-- 2.3328919410705566\n",
      "Epoch 237/500 | Train Loss: 412.847 | Test Loss: 494.312 | Test Loss [MAPE]: 1539174.605 --time-- 2.333449602127075\n",
      "Epoch 238/500 | Train Loss: 425.865 | Test Loss: 380.101 | Test Loss [MAPE]: 1206768.026 --time-- 2.337484359741211\n",
      "Epoch 239/500 | Train Loss: 380.871 | Test Loss: 420.534 | Test Loss [MAPE]: 1301302.243 --time-- 2.333270311355591\n",
      "Epoch 240/500 | Train Loss: 407.741 | Test Loss: 452.434 | Test Loss [MAPE]: 1441619.556 --time-- 2.3320462703704834\n",
      "Epoch 241/500 | Train Loss: 419.789 | Test Loss: 423.268 | Test Loss [MAPE]: 1338261.590 --time-- 2.3346431255340576\n",
      "Epoch 242/500 | Train Loss: 410.543 | Test Loss: 411.864 | Test Loss [MAPE]: 1300891.860 --time-- 2.3331778049468994\n",
      "Epoch 243/500 | Train Loss: 391.041 | Test Loss: 382.187 | Test Loss [MAPE]: 1226871.300 --time-- 2.3339145183563232\n",
      "Epoch 244/500 | Train Loss: 403.709 | Test Loss: 395.422 | Test Loss [MAPE]: 1268387.283 --time-- 2.3339293003082275\n",
      "Epoch 245/500 | Train Loss: 378.302 | Test Loss: 380.912 | Test Loss [MAPE]: 1224702.711 --time-- 2.332195997238159\n",
      "Epoch 246/500 | Train Loss: 371.164 | Test Loss: 370.279 | Test Loss [MAPE]: 1172596.072 --time-- 2.3332102298736572\n",
      "Epoch 247/500 | Train Loss: 380.284 | Test Loss: 394.575 | Test Loss [MAPE]: 1234064.372 --time-- 2.3375868797302246\n",
      "Epoch 248/500 | Train Loss: 370.329 | Test Loss: 413.996 | Test Loss [MAPE]: 1311925.624 --time-- 2.337102174758911\n",
      "Epoch 249/500 | Train Loss: 394.686 | Test Loss: 396.332 | Test Loss [MAPE]: 1275430.921 --time-- 2.3362224102020264\n",
      "Epoch 250/500 | Train Loss: 378.942 | Test Loss: 431.507 | Test Loss [MAPE]: 1363442.145 --time-- 2.3361051082611084\n",
      "Epoch 251/500 | Train Loss: 394.307 | Test Loss: 397.153 | Test Loss [MAPE]: 1268950.016 --time-- 2.33445405960083\n",
      "Epoch 252/500 | Train Loss: 383.495 | Test Loss: 436.840 | Test Loss [MAPE]: 1357076.751 --time-- 2.335636615753174\n",
      "Epoch 253/500 | Train Loss: 398.383 | Test Loss: 400.889 | Test Loss [MAPE]: 1269303.555 --time-- 2.331132650375366\n",
      "Epoch 254/500 | Train Loss: 369.136 | Test Loss: 397.177 | Test Loss [MAPE]: 1270839.339 --time-- 2.334590196609497\n",
      "Epoch 255/500 | Train Loss: 381.025 | Test Loss: 412.401 | Test Loss [MAPE]: 1280812.777 --time-- 2.3324615955352783\n",
      "Epoch 256/500 | Train Loss: 392.937 | Test Loss: 416.573 | Test Loss [MAPE]: 1344751.042 --time-- 2.3430120944976807\n",
      "Epoch 257/500 | Train Loss: 401.851 | Test Loss: 407.826 | Test Loss [MAPE]: 1323772.047 --time-- 2.3372886180877686\n",
      "Epoch 258/500 | Train Loss: 390.699 | Test Loss: 413.780 | Test Loss [MAPE]: 1325137.439 --time-- 2.337066411972046\n",
      "Epoch 259/500 | Train Loss: 388.713 | Test Loss: 402.189 | Test Loss [MAPE]: 1269132.747 --time-- 2.334886312484741\n",
      "Epoch 260/500 | Train Loss: 401.115 | Test Loss: 441.126 | Test Loss [MAPE]: 1409760.574 --time-- 2.3347787857055664\n",
      "Epoch 261/500 | Train Loss: 414.207 | Test Loss: 434.399 | Test Loss [MAPE]: 1418272.719 --time-- 2.3332090377807617\n",
      "Epoch 262/500 | Train Loss: 390.354 | Test Loss: 379.454 | Test Loss [MAPE]: 1220517.971 --time-- 2.3332290649414062\n",
      "Epoch 263/500 | Train Loss: 388.656 | Test Loss: 401.760 | Test Loss [MAPE]: 1261854.496 --time-- 2.3349015712738037\n",
      "Epoch 264/500 | Train Loss: 374.148 | Test Loss: 393.978 | Test Loss [MAPE]: 1274881.521 --time-- 2.334975004196167\n",
      "Epoch 265/500 | Train Loss: 390.628 | Test Loss: 409.613 | Test Loss [MAPE]: 1312196.427 --time-- 2.335627794265747\n",
      "Epoch 266/500 | Train Loss: 389.313 | Test Loss: 404.190 | Test Loss [MAPE]: 1259144.632 --time-- 2.334578037261963\n",
      "Epoch 267/500 | Train Loss: 375.175 | Test Loss: 392.686 | Test Loss [MAPE]: 1275742.832 --time-- 2.3353657722473145\n",
      "Epoch 268/500 | Train Loss: 366.941 | Test Loss: 390.963 | Test Loss [MAPE]: 1243501.383 --time-- 2.3939499855041504\n",
      "Epoch 269/500 | Train Loss: 375.807 | Test Loss: 354.691 | Test Loss [MAPE]: 1152107.218 --time-- 2.3957056999206543\n",
      "Epoch 270/500 | Train Loss: 373.359 | Test Loss: 404.772 | Test Loss [MAPE]: 1286700.043 --time-- 2.394414186477661\n",
      "Epoch 271/500 | Train Loss: 387.731 | Test Loss: 394.574 | Test Loss [MAPE]: 1261527.562 --time-- 2.390251636505127\n",
      "Epoch 272/500 | Train Loss: 411.660 | Test Loss: 405.822 | Test Loss [MAPE]: 1308334.372 --time-- 2.40055775642395\n",
      "Epoch 273/500 | Train Loss: 364.589 | Test Loss: 389.458 | Test Loss [MAPE]: 1264765.101 --time-- 2.3941280841827393\n",
      "Epoch 274/500 | Train Loss: 380.835 | Test Loss: 425.661 | Test Loss [MAPE]: 1346350.582 --time-- 2.395679473876953\n",
      "Epoch 275/500 | Train Loss: 406.518 | Test Loss: 435.219 | Test Loss [MAPE]: 1384887.844 --time-- 2.3960320949554443\n",
      "Epoch 276/500 | Train Loss: 395.670 | Test Loss: 400.610 | Test Loss [MAPE]: 1276650.745 --time-- 2.3958609104156494\n",
      "Epoch 277/500 | Train Loss: 365.012 | Test Loss: 375.742 | Test Loss [MAPE]: 1191114.133 --time-- 2.3982715606689453\n",
      "Epoch 278/500 | Train Loss: 377.068 | Test Loss: 437.780 | Test Loss [MAPE]: 1370660.336 --time-- 2.3953845500946045\n",
      "Epoch 279/500 | Train Loss: 398.137 | Test Loss: 362.307 | Test Loss [MAPE]: 1157911.379 --time-- 2.3941192626953125\n",
      "Epoch 280/500 | Train Loss: 371.365 | Test Loss: 414.901 | Test Loss [MAPE]: 1309408.997 --time-- 2.392591714859009\n",
      "Epoch 281/500 | Train Loss: 365.383 | Test Loss: 385.619 | Test Loss [MAPE]: 1253508.456 --time-- 2.3950538635253906\n",
      "Epoch 282/500 | Train Loss: 366.601 | Test Loss: 382.606 | Test Loss [MAPE]: 1228950.602 --time-- 2.3961517810821533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/500 | Train Loss: 365.036 | Test Loss: 359.817 | Test Loss [MAPE]: 1160630.818 --time-- 2.396125078201294\n",
      "Epoch 284/500 | Train Loss: 371.859 | Test Loss: 401.998 | Test Loss [MAPE]: 1277463.483 --time-- 2.391460418701172\n",
      "Epoch 285/500 | Train Loss: 377.699 | Test Loss: 399.229 | Test Loss [MAPE]: 1307488.157 --time-- 2.3936989307403564\n",
      "Epoch 286/500 | Train Loss: 387.502 | Test Loss: 360.332 | Test Loss [MAPE]: 1149710.918 --time-- 2.394320487976074\n",
      "Epoch 287/500 | Train Loss: 361.526 | Test Loss: 373.755 | Test Loss [MAPE]: 1205202.314 --time-- 2.3952248096466064\n",
      "Epoch 288/500 | Train Loss: 382.585 | Test Loss: 451.625 | Test Loss [MAPE]: 1434137.043 --time-- 2.3935041427612305\n",
      "Epoch 289/500 | Train Loss: 386.728 | Test Loss: 380.080 | Test Loss [MAPE]: 1213817.156 --time-- 2.3999059200286865\n",
      "Epoch 290/500 | Train Loss: 370.139 | Test Loss: 379.263 | Test Loss [MAPE]: 1219993.731 --time-- 2.3538811206817627\n",
      "Epoch 291/500 | Train Loss: 376.786 | Test Loss: 380.197 | Test Loss [MAPE]: 1197475.107 --time-- 2.3526084423065186\n",
      "Epoch 292/500 | Train Loss: 390.724 | Test Loss: 346.477 | Test Loss [MAPE]: 1133353.750 --time-- 2.350800037384033\n",
      "Epoch 293/500 | Train Loss: 360.517 | Test Loss: 366.351 | Test Loss [MAPE]: 1192565.413 --time-- 2.354935646057129\n",
      "Epoch 294/500 | Train Loss: 370.915 | Test Loss: 356.632 | Test Loss [MAPE]: 1132264.666 --time-- 2.350489854812622\n",
      "Epoch 295/500 | Train Loss: 372.006 | Test Loss: 354.819 | Test Loss [MAPE]: 1162813.929 --time-- 2.3515422344207764\n",
      "Epoch 296/500 | Train Loss: 356.300 | Test Loss: 369.810 | Test Loss [MAPE]: 1186306.852 --time-- 2.353806495666504\n",
      "Epoch 297/500 | Train Loss: 362.209 | Test Loss: 377.805 | Test Loss [MAPE]: 1209393.155 --time-- 2.3512675762176514\n",
      "Epoch 298/500 | Train Loss: 362.985 | Test Loss: 383.147 | Test Loss [MAPE]: 1202680.210 --time-- 2.3505191802978516\n",
      "Epoch 299/500 | Train Loss: 359.003 | Test Loss: 353.621 | Test Loss [MAPE]: 1150149.141 --time-- 2.3507542610168457\n",
      "Epoch 300/500 | Train Loss: 342.886 | Test Loss: 340.856 | Test Loss [MAPE]: 1113084.482 --time-- 2.351223945617676\n",
      "Epoch 301/500 | Train Loss: 355.143 | Test Loss: 394.568 | Test Loss [MAPE]: 1289545.513 --time-- 2.3529608249664307\n",
      "Epoch 302/500 | Train Loss: 394.394 | Test Loss: 420.144 | Test Loss [MAPE]: 1374928.981 --time-- 2.3517208099365234\n",
      "Epoch 303/500 | Train Loss: 361.697 | Test Loss: 333.526 | Test Loss [MAPE]: 1081192.296 --time-- 2.351510763168335\n",
      "Epoch 304/500 | Train Loss: 354.087 | Test Loss: 423.935 | Test Loss [MAPE]: 1349588.307 --time-- 2.3521578311920166\n",
      "Epoch 305/500 | Train Loss: 372.666 | Test Loss: 409.459 | Test Loss [MAPE]: 1298953.984 --time-- 2.3531293869018555\n",
      "Epoch 306/500 | Train Loss: 384.908 | Test Loss: 402.514 | Test Loss [MAPE]: 1300231.016 --time-- 2.3513925075531006\n",
      "Epoch 307/500 | Train Loss: 393.405 | Test Loss: 424.208 | Test Loss [MAPE]: 1344668.988 --time-- 2.351658344268799\n",
      "Epoch 308/500 | Train Loss: 377.581 | Test Loss: 351.994 | Test Loss [MAPE]: 1167209.824 --time-- 2.351419687271118\n",
      "Epoch 309/500 | Train Loss: 342.870 | Test Loss: 371.439 | Test Loss [MAPE]: 1183490.365 --time-- 2.353147029876709\n",
      "Epoch 310/500 | Train Loss: 376.668 | Test Loss: 398.874 | Test Loss [MAPE]: 1301403.684 --time-- 2.3516743183135986\n",
      "Epoch 311/500 | Train Loss: 371.760 | Test Loss: 382.256 | Test Loss [MAPE]: 1234132.960 --time-- 2.352844715118408\n",
      "Epoch 312/500 | Train Loss: 373.987 | Test Loss: 375.074 | Test Loss [MAPE]: 1251546.773 --time-- 2.350700616836548\n",
      "Epoch 313/500 | Train Loss: 338.425 | Test Loss: 355.989 | Test Loss [MAPE]: 1138277.012 --time-- 2.354120969772339\n",
      "Epoch 314/500 | Train Loss: 372.350 | Test Loss: 374.807 | Test Loss [MAPE]: 1172588.734 --time-- 2.3519158363342285\n",
      "Epoch 315/500 | Train Loss: 366.642 | Test Loss: 371.877 | Test Loss [MAPE]: 1214352.378 --time-- 2.351511240005493\n",
      "Epoch 316/500 | Train Loss: 345.100 | Test Loss: 361.271 | Test Loss [MAPE]: 1153937.459 --time-- 2.352067470550537\n",
      "Epoch 317/500 | Train Loss: 352.026 | Test Loss: 357.677 | Test Loss [MAPE]: 1167107.234 --time-- 2.351940155029297\n",
      "Epoch 318/500 | Train Loss: 345.488 | Test Loss: 360.747 | Test Loss [MAPE]: 1184421.060 --time-- 2.35160231590271\n",
      "Epoch 319/500 | Train Loss: 377.846 | Test Loss: 388.064 | Test Loss [MAPE]: 1247765.068 --time-- 2.355079412460327\n",
      "Epoch 320/500 | Train Loss: 361.576 | Test Loss: 352.037 | Test Loss [MAPE]: 1165667.092 --time-- 2.3507325649261475\n",
      "Epoch 321/500 | Train Loss: 354.217 | Test Loss: 400.933 | Test Loss [MAPE]: 1289164.305 --time-- 2.350820302963257\n",
      "Epoch 322/500 | Train Loss: 372.758 | Test Loss: 396.771 | Test Loss [MAPE]: 1271064.583 --time-- 2.305089235305786\n",
      "Epoch 323/500 | Train Loss: 366.098 | Test Loss: 379.373 | Test Loss [MAPE]: 1233080.246 --time-- 2.3010454177856445\n",
      "Epoch 324/500 | Train Loss: 371.697 | Test Loss: 413.758 | Test Loss [MAPE]: 1323264.128 --time-- 2.3043837547302246\n",
      "Epoch 325/500 | Train Loss: 382.329 | Test Loss: 408.164 | Test Loss [MAPE]: 1302201.513 --time-- 2.3049659729003906\n",
      "Epoch 326/500 | Train Loss: 372.103 | Test Loss: 416.306 | Test Loss [MAPE]: 1269768.362 --time-- 2.304225206375122\n",
      "Epoch 327/500 | Train Loss: 365.215 | Test Loss: 371.068 | Test Loss [MAPE]: 1180568.784 --time-- 2.307213306427002\n",
      "Epoch 328/500 | Train Loss: 359.617 | Test Loss: 349.763 | Test Loss [MAPE]: 1142040.342 --time-- 2.3055875301361084\n",
      "Epoch 329/500 | Train Loss: 345.696 | Test Loss: 365.755 | Test Loss [MAPE]: 1179552.761 --time-- 2.3066935539245605\n",
      "Epoch 330/500 | Train Loss: 358.055 | Test Loss: 359.552 | Test Loss [MAPE]: 1183581.637 --time-- 2.305743932723999\n",
      "Epoch 331/500 | Train Loss: 372.586 | Test Loss: 400.757 | Test Loss [MAPE]: 1276179.683 --time-- 2.30900239944458\n",
      "Epoch 332/500 | Train Loss: 363.937 | Test Loss: 369.732 | Test Loss [MAPE]: 1178156.970 --time-- 2.3060147762298584\n",
      "Epoch 333/500 | Train Loss: 361.463 | Test Loss: 396.070 | Test Loss [MAPE]: 1215724.190 --time-- 2.308825969696045\n",
      "Epoch 334/500 | Train Loss: 378.627 | Test Loss: 385.637 | Test Loss [MAPE]: 1230015.576 --time-- 2.306835651397705\n",
      "Epoch 335/500 | Train Loss: 376.646 | Test Loss: 376.058 | Test Loss [MAPE]: 1213752.936 --time-- 2.3063762187957764\n",
      "Epoch 336/500 | Train Loss: 365.366 | Test Loss: 402.623 | Test Loss [MAPE]: 1299046.230 --time-- 2.3061435222625732\n",
      "Epoch 337/500 | Train Loss: 349.380 | Test Loss: 351.711 | Test Loss [MAPE]: 1154748.314 --time-- 2.304743528366089\n",
      "Epoch 338/500 | Train Loss: 347.720 | Test Loss: 375.578 | Test Loss [MAPE]: 1261507.226 --time-- 2.3062267303466797\n",
      "Epoch 339/500 | Train Loss: 341.837 | Test Loss: 345.450 | Test Loss [MAPE]: 1135757.226 --time-- 2.3054118156433105\n",
      "Epoch 340/500 | Train Loss: 356.719 | Test Loss: 371.248 | Test Loss [MAPE]: 1204550.338 --time-- 2.3041560649871826\n",
      "Epoch 341/500 | Train Loss: 365.128 | Test Loss: 365.003 | Test Loss [MAPE]: 1193735.083 --time-- 2.3027496337890625\n",
      "Epoch 342/500 | Train Loss: 358.326 | Test Loss: 354.269 | Test Loss [MAPE]: 1168473.915 --time-- 2.3037326335906982\n",
      "Epoch 343/500 | Train Loss: 346.060 | Test Loss: 360.559 | Test Loss [MAPE]: 1151207.516 --time-- 2.3033688068389893\n",
      "Epoch 344/500 | Train Loss: 337.966 | Test Loss: 393.127 | Test Loss [MAPE]: 1273257.056 --time-- 2.304713010787964\n",
      "Epoch 345/500 | Train Loss: 374.441 | Test Loss: 377.864 | Test Loss [MAPE]: 1248997.637 --time-- 2.306039571762085\n",
      "Epoch 346/500 | Train Loss: 365.829 | Test Loss: 373.454 | Test Loss [MAPE]: 1207360.342 --time-- 2.30619740486145\n",
      "Epoch 347/500 | Train Loss: 346.919 | Test Loss: 335.578 | Test Loss [MAPE]: 1117395.322 --time-- 2.3066694736480713\n",
      "Epoch 348/500 | Train Loss: 350.261 | Test Loss: 386.997 | Test Loss [MAPE]: 1228601.766 --time-- 2.306720018386841\n",
      "Epoch 349/500 | Train Loss: 379.565 | Test Loss: 411.623 | Test Loss [MAPE]: 1322830.012 --time-- 2.3059659004211426\n",
      "Epoch 350/500 | Train Loss: 358.146 | Test Loss: 385.294 | Test Loss [MAPE]: 1242528.434 --time-- 2.3030498027801514\n",
      "Epoch 351/500 | Train Loss: 366.286 | Test Loss: 372.570 | Test Loss [MAPE]: 1232012.450 --time-- 2.303097724914551\n",
      "Epoch 352/500 | Train Loss: 364.037 | Test Loss: 377.973 | Test Loss [MAPE]: 1201129.536 --time-- 2.303640842437744\n",
      "Epoch 353/500 | Train Loss: 347.624 | Test Loss: 377.527 | Test Loss [MAPE]: 1225103.243 --time-- 2.3069961071014404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/500 | Train Loss: 347.743 | Test Loss: 352.815 | Test Loss [MAPE]: 1156849.903 --time-- 2.303321361541748\n",
      "Epoch 355/500 | Train Loss: 334.517 | Test Loss: 340.172 | Test Loss [MAPE]: 1118723.623 --time-- 2.3067166805267334\n",
      "Epoch 356/500 | Train Loss: 352.525 | Test Loss: 360.231 | Test Loss [MAPE]: 1183004.888 --time-- 2.3038082122802734\n",
      "Epoch 357/500 | Train Loss: 353.248 | Test Loss: 349.182 | Test Loss [MAPE]: 1144026.454 --time-- 2.3059613704681396\n",
      "Epoch 358/500 | Train Loss: 344.930 | Test Loss: 355.740 | Test Loss [MAPE]: 1154167.388 --time-- 2.3051764965057373\n",
      "Epoch 359/500 | Train Loss: 359.639 | Test Loss: 352.813 | Test Loss [MAPE]: 1141663.300 --time-- 2.30452299118042\n",
      "Epoch 360/500 | Train Loss: 359.038 | Test Loss: 450.783 | Test Loss [MAPE]: 1458157.461 --time-- 2.303162097930908\n",
      "Epoch 361/500 | Train Loss: 359.358 | Test Loss: 348.849 | Test Loss [MAPE]: 1132380.772 --time-- 2.304608106613159\n",
      "Epoch 362/500 | Train Loss: 323.480 | Test Loss: 358.448 | Test Loss [MAPE]: 1156751.872 --time-- 2.306305170059204\n",
      "Epoch 363/500 | Train Loss: 340.960 | Test Loss: 377.780 | Test Loss [MAPE]: 1239202.841 --time-- 2.3040449619293213\n",
      "Epoch 364/500 | Train Loss: 364.677 | Test Loss: 375.450 | Test Loss [MAPE]: 1224294.094 --time-- 2.3051958084106445\n",
      "Epoch 365/500 | Train Loss: 361.433 | Test Loss: 336.090 | Test Loss [MAPE]: 1090591.475 --time-- 2.3041303157806396\n",
      "Epoch 366/500 | Train Loss: 359.237 | Test Loss: 343.394 | Test Loss [MAPE]: 1141420.271 --time-- 2.3046720027923584\n",
      "Epoch 367/500 | Train Loss: 373.905 | Test Loss: 404.044 | Test Loss [MAPE]: 1290189.596 --time-- 2.3034327030181885\n",
      "Epoch 368/500 | Train Loss: 374.181 | Test Loss: 341.750 | Test Loss [MAPE]: 1132465.024 --time-- 2.3051979541778564\n",
      "Epoch 369/500 | Train Loss: 358.344 | Test Loss: 373.233 | Test Loss [MAPE]: 1209214.340 --time-- 2.304276466369629\n",
      "Epoch 370/500 | Train Loss: 353.747 | Test Loss: 378.356 | Test Loss [MAPE]: 1251713.486 --time-- 2.3028151988983154\n",
      "Epoch 371/500 | Train Loss: 345.046 | Test Loss: 339.036 | Test Loss [MAPE]: 1092274.311 --time-- 2.305919647216797\n",
      "Epoch 372/500 | Train Loss: 339.539 | Test Loss: 327.193 | Test Loss [MAPE]: 1062415.674 --time-- 2.3038039207458496\n",
      "Epoch 373/500 | Train Loss: 353.302 | Test Loss: 375.511 | Test Loss [MAPE]: 1224376.042 --time-- 2.3012948036193848\n",
      "Epoch 374/500 | Train Loss: 340.445 | Test Loss: 369.938 | Test Loss [MAPE]: 1233092.837 --time-- 2.3085944652557373\n",
      "Epoch 375/500 | Train Loss: 372.808 | Test Loss: 384.540 | Test Loss [MAPE]: 1250473.459 --time-- 2.353623151779175\n",
      "Epoch 376/500 | Train Loss: 356.066 | Test Loss: 398.018 | Test Loss [MAPE]: 1296863.700 --time-- 2.358189582824707\n",
      "Epoch 377/500 | Train Loss: 353.939 | Test Loss: 385.983 | Test Loss [MAPE]: 1226077.793 --time-- 2.304866313934326\n",
      "Epoch 378/500 | Train Loss: 364.258 | Test Loss: 411.334 | Test Loss [MAPE]: 1320163.838 --time-- 2.3057565689086914\n",
      "Epoch 379/500 | Train Loss: 346.307 | Test Loss: 347.239 | Test Loss [MAPE]: 1140992.955 --time-- 2.3046600818634033\n",
      "Epoch 380/500 | Train Loss: 353.754 | Test Loss: 349.914 | Test Loss [MAPE]: 1144852.555 --time-- 2.3038318157196045\n",
      "Epoch 381/500 | Train Loss: 326.858 | Test Loss: 362.580 | Test Loss [MAPE]: 1180807.074 --time-- 2.305609703063965\n",
      "Epoch 382/500 | Train Loss: 346.207 | Test Loss: 365.799 | Test Loss [MAPE]: 1198010.458 --time-- 2.308788537979126\n",
      "Epoch 383/500 | Train Loss: 341.094 | Test Loss: 372.093 | Test Loss [MAPE]: 1195179.387 --time-- 2.3071322441101074\n",
      "Epoch 384/500 | Train Loss: 368.783 | Test Loss: 374.637 | Test Loss [MAPE]: 1247203.499 --time-- 2.3064990043640137\n",
      "Epoch 385/500 | Train Loss: 361.218 | Test Loss: 320.334 | Test Loss [MAPE]: 1036943.226 --time-- 2.303637742996216\n",
      "Epoch 386/500 | Train Loss: 322.862 | Test Loss: 352.967 | Test Loss [MAPE]: 1152883.416 --time-- 2.307403802871704\n",
      "Epoch 387/500 | Train Loss: 332.293 | Test Loss: 346.280 | Test Loss [MAPE]: 1085175.777 --time-- 2.306685209274292\n",
      "Epoch 388/500 | Train Loss: 355.482 | Test Loss: 381.471 | Test Loss [MAPE]: 1235052.741 --time-- 2.3057126998901367\n",
      "Epoch 389/500 | Train Loss: 344.017 | Test Loss: 374.710 | Test Loss [MAPE]: 1236680.674 --time-- 2.3032419681549072\n",
      "Epoch 390/500 | Train Loss: 341.191 | Test Loss: 359.195 | Test Loss [MAPE]: 1169859.132 --time-- 2.305755138397217\n",
      "Epoch 391/500 | Train Loss: 352.835 | Test Loss: 379.191 | Test Loss [MAPE]: 1233541.354 --time-- 2.305586099624634\n",
      "Epoch 392/500 | Train Loss: 342.813 | Test Loss: 377.711 | Test Loss [MAPE]: 1198473.839 --time-- 2.307105302810669\n",
      "Epoch 393/500 | Train Loss: 328.609 | Test Loss: 343.168 | Test Loss [MAPE]: 1132735.580 --time-- 2.30586314201355\n",
      "Epoch 394/500 | Train Loss: 354.976 | Test Loss: 345.107 | Test Loss [MAPE]: 1133723.066 --time-- 2.3075733184814453\n",
      "Epoch 395/500 | Train Loss: 344.660 | Test Loss: 356.479 | Test Loss [MAPE]: 1161354.988 --time-- 2.30757474899292\n",
      "Epoch 396/500 | Train Loss: 333.620 | Test Loss: 363.162 | Test Loss [MAPE]: 1183847.120 --time-- 2.3038930892944336\n",
      "Epoch 397/500 | Train Loss: 351.413 | Test Loss: 376.676 | Test Loss [MAPE]: 1261530.187 --time-- 2.3057680130004883\n",
      "Epoch 398/500 | Train Loss: 334.540 | Test Loss: 316.894 | Test Loss [MAPE]: 1042486.636 --time-- 2.303903818130493\n",
      "Epoch 399/500 | Train Loss: 333.527 | Test Loss: 360.697 | Test Loss [MAPE]: 1190956.754 --time-- 2.3053407669067383\n",
      "Epoch 400/500 | Train Loss: 338.277 | Test Loss: 381.910 | Test Loss [MAPE]: 1234953.833 --time-- 2.3052375316619873\n",
      "Epoch 401/500 | Train Loss: 358.966 | Test Loss: 382.825 | Test Loss [MAPE]: 1257098.684 --time-- 2.3048737049102783\n",
      "Epoch 402/500 | Train Loss: 348.777 | Test Loss: 341.863 | Test Loss [MAPE]: 1121632.693 --time-- 2.305189609527588\n",
      "Epoch 403/500 | Train Loss: 329.863 | Test Loss: 352.468 | Test Loss [MAPE]: 1137322.062 --time-- 2.3057546615600586\n",
      "Epoch 404/500 | Train Loss: 341.623 | Test Loss: 361.367 | Test Loss [MAPE]: 1168393.242 --time-- 2.306189775466919\n",
      "Epoch 405/500 | Train Loss: 349.011 | Test Loss: 385.074 | Test Loss [MAPE]: 1271964.680 --time-- 2.3054113388061523\n",
      "Epoch 406/500 | Train Loss: 348.884 | Test Loss: 351.713 | Test Loss [MAPE]: 1151492.832 --time-- 2.306685209274292\n",
      "Epoch 407/500 | Train Loss: 344.824 | Test Loss: 363.478 | Test Loss [MAPE]: 1159695.697 --time-- 2.304372549057007\n",
      "Epoch 408/500 | Train Loss: 348.806 | Test Loss: 360.918 | Test Loss [MAPE]: 1162129.470 --time-- 2.3043606281280518\n",
      "Epoch 409/500 | Train Loss: 344.538 | Test Loss: 367.293 | Test Loss [MAPE]: 1164631.416 --time-- 2.3047022819519043\n",
      "Epoch 410/500 | Train Loss: 324.303 | Test Loss: 343.757 | Test Loss [MAPE]: 1122680.094 --time-- 2.304574966430664\n",
      "Epoch 411/500 | Train Loss: 312.241 | Test Loss: 331.253 | Test Loss [MAPE]: 1104375.970 --time-- 2.356127977371216\n",
      "Epoch 412/500 | Train Loss: 339.940 | Test Loss: 413.006 | Test Loss [MAPE]: 1327374.030 --time-- 2.3563265800476074\n",
      "Epoch 413/500 | Train Loss: 362.100 | Test Loss: 365.277 | Test Loss [MAPE]: 1182580.555 --time-- 2.3585898876190186\n",
      "Epoch 414/500 | Train Loss: 330.892 | Test Loss: 353.298 | Test Loss [MAPE]: 1145937.837 --time-- 2.3586196899414062\n",
      "Epoch 415/500 | Train Loss: 332.101 | Test Loss: 348.135 | Test Loss [MAPE]: 1146876.380 --time-- 2.360095739364624\n",
      "Epoch 416/500 | Train Loss: 331.434 | Test Loss: 363.748 | Test Loss [MAPE]: 1197981.789 --time-- 2.3609070777893066\n",
      "Epoch 417/500 | Train Loss: 327.554 | Test Loss: 332.971 | Test Loss [MAPE]: 1106807.550 --time-- 2.356675863265991\n",
      "Epoch 418/500 | Train Loss: 346.941 | Test Loss: 375.192 | Test Loss [MAPE]: 1225919.171 --time-- 2.3601033687591553\n",
      "Epoch 419/500 | Train Loss: 345.515 | Test Loss: 431.126 | Test Loss [MAPE]: 1343557.069 --time-- 2.360989570617676\n",
      "Epoch 420/500 | Train Loss: 359.978 | Test Loss: 371.605 | Test Loss [MAPE]: 1231087.952 --time-- 2.3523366451263428\n",
      "Epoch 421/500 | Train Loss: 339.811 | Test Loss: 336.463 | Test Loss [MAPE]: 1102089.466 --time-- 2.3563232421875\n",
      "Epoch 422/500 | Train Loss: 327.011 | Test Loss: 348.249 | Test Loss [MAPE]: 1145060.485 --time-- 2.3057687282562256\n",
      "Epoch 423/500 | Train Loss: 332.755 | Test Loss: 331.981 | Test Loss [MAPE]: 1084864.094 --time-- 2.3066930770874023\n",
      "Epoch 424/500 | Train Loss: 343.527 | Test Loss: 374.264 | Test Loss [MAPE]: 1202034.267 --time-- 2.3064022064208984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/500 | Train Loss: 338.370 | Test Loss: 349.173 | Test Loss [MAPE]: 1148603.682 --time-- 2.30338716506958\n",
      "Epoch 426/500 | Train Loss: 330.639 | Test Loss: 344.217 | Test Loss [MAPE]: 1098307.358 --time-- 2.303645133972168\n",
      "Epoch 427/500 | Train Loss: 335.854 | Test Loss: 349.497 | Test Loss [MAPE]: 1138274.738 --time-- 2.3052005767822266\n",
      "Epoch 428/500 | Train Loss: 357.129 | Test Loss: 354.933 | Test Loss [MAPE]: 1166055.482 --time-- 2.3068811893463135\n",
      "Epoch 429/500 | Train Loss: 331.790 | Test Loss: 350.958 | Test Loss [MAPE]: 1135418.825 --time-- 2.306067705154419\n",
      "Epoch 430/500 | Train Loss: 342.111 | Test Loss: 344.333 | Test Loss [MAPE]: 1119575.932 --time-- 2.3070883750915527\n",
      "Epoch 431/500 | Train Loss: 332.392 | Test Loss: 330.999 | Test Loss [MAPE]: 1095013.346 --time-- 2.305922031402588\n",
      "Epoch 432/500 | Train Loss: 343.102 | Test Loss: 355.901 | Test Loss [MAPE]: 1162948.510 --time-- 2.306673765182495\n",
      "Epoch 433/500 | Train Loss: 330.370 | Test Loss: 365.870 | Test Loss [MAPE]: 1182128.151 --time-- 2.3026280403137207\n",
      "Epoch 434/500 | Train Loss: 348.647 | Test Loss: 333.151 | Test Loss [MAPE]: 1117466.719 --time-- 2.3035683631896973\n",
      "Epoch 435/500 | Train Loss: 332.357 | Test Loss: 372.383 | Test Loss [MAPE]: 1185143.345 --time-- 2.3054416179656982\n",
      "Epoch 436/500 | Train Loss: 337.161 | Test Loss: 353.893 | Test Loss [MAPE]: 1130047.857 --time-- 2.305919647216797\n",
      "Epoch 437/500 | Train Loss: 326.069 | Test Loss: 360.173 | Test Loss [MAPE]: 1190104.637 --time-- 2.3078038692474365\n",
      "Epoch 438/500 | Train Loss: 333.466 | Test Loss: 360.663 | Test Loss [MAPE]: 1181889.575 --time-- 2.303966522216797\n",
      "Epoch 439/500 | Train Loss: 337.683 | Test Loss: 348.574 | Test Loss [MAPE]: 1150162.875 --time-- 2.3052327632904053\n",
      "Epoch 440/500 | Train Loss: 325.480 | Test Loss: 358.357 | Test Loss [MAPE]: 1140654.638 --time-- 2.3058321475982666\n",
      "Epoch 441/500 | Train Loss: 349.311 | Test Loss: 348.869 | Test Loss [MAPE]: 1113186.518 --time-- 2.306427240371704\n",
      "Epoch 442/500 | Train Loss: 333.874 | Test Loss: 327.673 | Test Loss [MAPE]: 1083297.116 --time-- 2.3055648803710938\n",
      "Epoch 443/500 | Train Loss: 327.574 | Test Loss: 341.227 | Test Loss [MAPE]: 1114298.469 --time-- 2.3050267696380615\n",
      "Epoch 444/500 | Train Loss: 347.086 | Test Loss: 388.155 | Test Loss [MAPE]: 1303434.137 --time-- 2.3035073280334473\n",
      "Epoch 445/500 | Train Loss: 333.367 | Test Loss: 358.375 | Test Loss [MAPE]: 1185991.195 --time-- 2.306756019592285\n",
      "Epoch 446/500 | Train Loss: 341.169 | Test Loss: 365.084 | Test Loss [MAPE]: 1188891.629 --time-- 2.3035731315612793\n",
      "Epoch 447/500 | Train Loss: 335.417 | Test Loss: 334.396 | Test Loss [MAPE]: 1090675.769 --time-- 2.303743362426758\n",
      "Epoch 448/500 | Train Loss: 342.482 | Test Loss: 343.457 | Test Loss [MAPE]: 1121316.090 --time-- 2.3061585426330566\n",
      "Epoch 449/500 | Train Loss: 325.695 | Test Loss: 342.757 | Test Loss [MAPE]: 1143218.964 --time-- 2.3067846298217773\n",
      "Epoch 450/500 | Train Loss: 342.159 | Test Loss: 352.204 | Test Loss [MAPE]: 1145233.478 --time-- 2.30458402633667\n",
      "Epoch 451/500 | Train Loss: 322.420 | Test Loss: 328.058 | Test Loss [MAPE]: 1090355.533 --time-- 2.306255340576172\n",
      "Epoch 452/500 | Train Loss: 319.472 | Test Loss: 351.606 | Test Loss [MAPE]: 1127933.662 --time-- 2.3054962158203125\n",
      "Epoch 453/500 | Train Loss: 331.244 | Test Loss: 377.963 | Test Loss [MAPE]: 1259568.633 --time-- 2.3061604499816895\n",
      "Epoch 454/500 | Train Loss: 344.120 | Test Loss: 379.521 | Test Loss [MAPE]: 1269706.467 --time-- 2.306886911392212\n",
      "Epoch 455/500 | Train Loss: 333.288 | Test Loss: 373.678 | Test Loss [MAPE]: 1237927.900 --time-- 2.3060050010681152\n",
      "Epoch 456/500 | Train Loss: 342.400 | Test Loss: 333.984 | Test Loss [MAPE]: 1093639.823 --time-- 2.308018684387207\n",
      "Epoch 457/500 | Train Loss: 338.308 | Test Loss: 350.174 | Test Loss [MAPE]: 1126553.186 --time-- 2.3055436611175537\n",
      "Epoch 458/500 | Train Loss: 344.479 | Test Loss: 377.233 | Test Loss [MAPE]: 1226455.700 --time-- 2.3045971393585205\n",
      "Epoch 459/500 | Train Loss: 379.305 | Test Loss: 411.251 | Test Loss [MAPE]: 1338325.536 --time-- 2.307774305343628\n",
      "Epoch 460/500 | Train Loss: 340.379 | Test Loss: 323.044 | Test Loss [MAPE]: 1049282.123 --time-- 2.30631947517395\n",
      "Epoch 461/500 | Train Loss: 333.818 | Test Loss: 385.324 | Test Loss [MAPE]: 1199171.362 --time-- 2.305893659591675\n",
      "Epoch 462/500 | Train Loss: 345.252 | Test Loss: 339.260 | Test Loss [MAPE]: 1128684.922 --time-- 2.3038618564605713\n",
      "Epoch 463/500 | Train Loss: 344.921 | Test Loss: 392.015 | Test Loss [MAPE]: 1274175.326 --time-- 2.3053977489471436\n",
      "Epoch 464/500 | Train Loss: 334.624 | Test Loss: 335.271 | Test Loss [MAPE]: 1093765.440 --time-- 2.3073718547821045\n",
      "Epoch 465/500 | Train Loss: 319.646 | Test Loss: 331.569 | Test Loss [MAPE]: 1105037.417 --time-- 2.3064258098602295\n",
      "Epoch 466/500 | Train Loss: 341.731 | Test Loss: 334.195 | Test Loss [MAPE]: 1095636.042 --time-- 2.3047919273376465\n",
      "Epoch 467/500 | Train Loss: 343.534 | Test Loss: 362.684 | Test Loss [MAPE]: 1184684.137 --time-- 2.3042688369750977\n",
      "Epoch 468/500 | Train Loss: 329.598 | Test Loss: 370.891 | Test Loss [MAPE]: 1204270.253 --time-- 2.3071787357330322\n",
      "Epoch 469/500 | Train Loss: 349.444 | Test Loss: 362.775 | Test Loss [MAPE]: 1188561.548 --time-- 2.306936025619507\n",
      "Epoch 470/500 | Train Loss: 326.004 | Test Loss: 327.921 | Test Loss [MAPE]: 1085099.761 --time-- 2.3078083992004395\n",
      "Epoch 471/500 | Train Loss: 317.410 | Test Loss: 350.120 | Test Loss [MAPE]: 1157195.869 --time-- 2.3043015003204346\n",
      "Epoch 472/500 | Train Loss: 318.503 | Test Loss: 339.566 | Test Loss [MAPE]: 1102162.929 --time-- 2.304503917694092\n",
      "Epoch 473/500 | Train Loss: 329.920 | Test Loss: 307.795 | Test Loss [MAPE]: 1039125.003 --time-- 2.303616523742676\n",
      "Epoch 474/500 | Train Loss: 325.402 | Test Loss: 336.685 | Test Loss [MAPE]: 1104171.876 --time-- 2.3056700229644775\n",
      "Epoch 475/500 | Train Loss: 335.601 | Test Loss: 338.169 | Test Loss [MAPE]: 1077137.335 --time-- 2.3100922107696533\n",
      "Epoch 476/500 | Train Loss: 305.988 | Test Loss: 338.614 | Test Loss [MAPE]: 1097470.913 --time-- 2.3048782348632812\n",
      "Epoch 477/500 | Train Loss: 319.255 | Test Loss: 349.048 | Test Loss [MAPE]: 1147498.107 --time-- 2.3046388626098633\n",
      "Epoch 478/500 | Train Loss: 336.719 | Test Loss: 353.227 | Test Loss [MAPE]: 1152871.934 --time-- 2.3069424629211426\n",
      "Epoch 479/500 | Train Loss: 354.925 | Test Loss: 392.331 | Test Loss [MAPE]: 1270284.340 --time-- 2.3087339401245117\n",
      "Epoch 480/500 | Train Loss: 325.456 | Test Loss: 340.710 | Test Loss [MAPE]: 1116887.580 --time-- 2.3055903911590576\n",
      "Epoch 481/500 | Train Loss: 323.217 | Test Loss: 372.286 | Test Loss [MAPE]: 1181129.936 --time-- 2.3068490028381348\n",
      "Epoch 482/500 | Train Loss: 338.379 | Test Loss: 370.452 | Test Loss [MAPE]: 1191697.998 --time-- 2.3065531253814697\n",
      "Epoch 483/500 | Train Loss: 342.595 | Test Loss: 358.930 | Test Loss [MAPE]: 1171363.113 --time-- 2.3053901195526123\n",
      "Epoch 484/500 | Train Loss: 335.678 | Test Loss: 381.174 | Test Loss [MAPE]: 1263880.577 --time-- 2.3040413856506348\n",
      "Epoch 485/500 | Train Loss: 313.250 | Test Loss: 325.300 | Test Loss [MAPE]: 1070902.129 --time-- 2.3030495643615723\n",
      "Epoch 486/500 | Train Loss: 343.662 | Test Loss: 343.711 | Test Loss [MAPE]: 1136380.806 --time-- 2.307229518890381\n",
      "Epoch 487/500 | Train Loss: 325.487 | Test Loss: 349.023 | Test Loss [MAPE]: 1151230.199 --time-- 2.3044652938842773\n",
      "Epoch 488/500 | Train Loss: 321.290 | Test Loss: 351.832 | Test Loss [MAPE]: 1153442.822 --time-- 2.306250810623169\n",
      "Epoch 489/500 | Train Loss: 312.803 | Test Loss: 331.827 | Test Loss [MAPE]: 1097616.776 --time-- 2.307753562927246\n",
      "Epoch 490/500 | Train Loss: 327.047 | Test Loss: 319.876 | Test Loss [MAPE]: 1039619.300 --time-- 2.305483102798462\n",
      "Epoch 491/500 | Train Loss: 330.311 | Test Loss: 336.325 | Test Loss [MAPE]: 1124094.239 --time-- 2.3034510612487793\n",
      "Epoch 492/500 | Train Loss: 329.126 | Test Loss: 318.422 | Test Loss [MAPE]: 1062903.672 --time-- 2.305266857147217\n",
      "Epoch 493/500 | Train Loss: 316.997 | Test Loss: 318.969 | Test Loss [MAPE]: 1075066.859 --time-- 2.3047478199005127\n",
      "Epoch 494/500 | Train Loss: 321.656 | Test Loss: 340.028 | Test Loss [MAPE]: 1121992.135 --time-- 2.309661388397217\n",
      "Epoch 495/500 | Train Loss: 345.926 | Test Loss: 393.878 | Test Loss [MAPE]: 1280043.379 --time-- 2.3078653812408447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500 | Train Loss: 354.243 | Test Loss: 365.944 | Test Loss [MAPE]: 1200731.829 --time-- 2.3065826892852783\n",
      "Epoch 497/500 | Train Loss: 323.948 | Test Loss: 343.574 | Test Loss [MAPE]: 1134889.640 --time-- 2.303730010986328\n",
      "Epoch 498/500 | Train Loss: 317.824 | Test Loss: 333.267 | Test Loss [MAPE]: 1083697.598 --time-- 2.3048651218414307\n",
      "Epoch 499/500 | Train Loss: 327.478 | Test Loss: 338.874 | Test Loss [MAPE]: 1141819.057 --time-- 2.304283380508423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 03:45:16,858] Trial 35 finished with value: 434023.2482910156 and parameters: {'num_conv_layers': 4, 'kernel_size': 4, 'num_channels': 43, 'pooling_type': 'avg', 'conv_stride': 3, 'feedforward_size': 132, 'pool_stride': 2, 'learning_rate': 0.002977805494049501, 'reg_strength': 0.0027937265739764305, 'bs': 120}. Best is trial 34 with value: 425934.69303131104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500 | Train Loss: 330.679 | Test Loss: 314.298 | Test Loss [MAPE]: 1035257.981 --time-- 2.306143045425415\n",
      "1176.278112411499\n",
      "Epoch 1/500 | Train Loss: 5206.760 | Test Loss: 5162.029 | Test Loss [MAPE]: 434802.478 --time-- 1.3227918148040771\n",
      "Epoch 2/500 | Train Loss: 5106.510 | Test Loss: 5161.831 | Test Loss [MAPE]: 431304.878 --time-- 1.2268025875091553\n",
      "Epoch 3/500 | Train Loss: 5106.464 | Test Loss: 5161.746 | Test Loss [MAPE]: 419954.114 --time-- 1.225043535232544\n",
      "Epoch 4/500 | Train Loss: 5106.420 | Test Loss: 5161.797 | Test Loss [MAPE]: 424313.339 --time-- 1.2297255992889404\n",
      "Epoch 5/500 | Train Loss: 5106.523 | Test Loss: 5161.799 | Test Loss [MAPE]: 424894.990 --time-- 1.227891206741333\n",
      "Epoch 6/500 | Train Loss: 5106.468 | Test Loss: 5161.767 | Test Loss [MAPE]: 422715.970 --time-- 1.2342345714569092\n",
      "Epoch 7/500 | Train Loss: 5106.495 | Test Loss: 5161.939 | Test Loss [MAPE]: 421201.989 --time-- 1.231532096862793\n",
      "Epoch 8/500 | Train Loss: 5106.544 | Test Loss: 5161.868 | Test Loss [MAPE]: 424135.885 --time-- 1.2339246273040771\n",
      "Epoch 9/500 | Train Loss: 5106.541 | Test Loss: 5161.899 | Test Loss [MAPE]: 432427.002 --time-- 1.2296438217163086\n",
      "Epoch 10/500 | Train Loss: 5106.597 | Test Loss: 5161.882 | Test Loss [MAPE]: 428136.315 --time-- 1.2269501686096191\n",
      "Epoch 11/500 | Train Loss: 5106.550 | Test Loss: 5161.957 | Test Loss [MAPE]: 426774.518 --time-- 1.2272367477416992\n",
      "Epoch 12/500 | Train Loss: 5106.560 | Test Loss: 5161.787 | Test Loss [MAPE]: 423027.012 --time-- 1.2261631488800049\n",
      "Epoch 13/500 | Train Loss: 5106.550 | Test Loss: 5161.948 | Test Loss [MAPE]: 426369.615 --time-- 1.2330894470214844\n",
      "Epoch 14/500 | Train Loss: 5106.619 | Test Loss: 5162.004 | Test Loss [MAPE]: 420758.239 --time-- 1.2319543361663818\n",
      "Epoch 15/500 | Train Loss: 5106.570 | Test Loss: 5161.905 | Test Loss [MAPE]: 424896.958 --time-- 1.2285795211791992\n",
      "Epoch 16/500 | Train Loss: 5106.698 | Test Loss: 5162.005 | Test Loss [MAPE]: 432632.419 --time-- 1.22786283493042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 03:45:38,485] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.652 | Test Loss: 5161.906 | Test Loss [MAPE]: 423850.433 --time-- 1.2270350456237793\n",
      "Epoch 1/500 | Train Loss: 308054.449 | Test Loss: 5162.525 | Test Loss [MAPE]: 443672.266 --time-- 2.470060110092163\n",
      "Epoch 2/500 | Train Loss: 5106.949 | Test Loss: 5162.645 | Test Loss [MAPE]: 419284.945 --time-- 2.4326789379119873\n",
      "Epoch 3/500 | Train Loss: 5106.819 | Test Loss: 5161.867 | Test Loss [MAPE]: 428231.097 --time-- 2.432419538497925\n",
      "Epoch 4/500 | Train Loss: 5106.659 | Test Loss: 5162.029 | Test Loss [MAPE]: 422837.504 --time-- 2.4347033500671387\n",
      "Epoch 5/500 | Train Loss: 5106.867 | Test Loss: 5162.464 | Test Loss [MAPE]: 440978.829 --time-- 2.435241222381592\n",
      "Epoch 6/500 | Train Loss: 5106.901 | Test Loss: 5162.175 | Test Loss [MAPE]: 433566.470 --time-- 2.4361109733581543\n",
      "Epoch 7/500 | Train Loss: 5106.811 | Test Loss: 5162.084 | Test Loss [MAPE]: 434303.895 --time-- 2.4334380626678467\n",
      "Epoch 8/500 | Train Loss: 5107.780 | Test Loss: 5165.010 | Test Loss [MAPE]: 494176.156 --time-- 2.4351987838745117\n",
      "Epoch 9/500 | Train Loss: 5108.170 | Test Loss: 5162.913 | Test Loss [MAPE]: 441644.389 --time-- 2.4334495067596436\n",
      "Epoch 10/500 | Train Loss: 5107.198 | Test Loss: 5162.706 | Test Loss [MAPE]: 434416.847 --time-- 2.43412184715271\n",
      "Epoch 11/500 | Train Loss: 5107.720 | Test Loss: 5164.438 | Test Loss [MAPE]: 440828.231 --time-- 2.4357547760009766\n",
      "Epoch 12/500 | Train Loss: 5107.686 | Test Loss: 5163.343 | Test Loss [MAPE]: 447046.800 --time-- 2.433863401412964\n",
      "Epoch 13/500 | Train Loss: 5107.502 | Test Loss: 5163.905 | Test Loss [MAPE]: 451924.171 --time-- 2.433488368988037\n",
      "Epoch 14/500 | Train Loss: 5107.975 | Test Loss: 5162.843 | Test Loss [MAPE]: 438305.669 --time-- 2.437040090560913\n",
      "Epoch 15/500 | Train Loss: 5107.676 | Test Loss: 5162.975 | Test Loss [MAPE]: 454673.508 --time-- 2.4355905055999756\n",
      "Epoch 16/500 | Train Loss: 5108.233 | Test Loss: 5165.280 | Test Loss [MAPE]: 475485.490 --time-- 2.43743896484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 03:46:20,575] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5108.279 | Test Loss: 5163.721 | Test Loss [MAPE]: 443862.194 --time-- 2.434394359588623\n",
      "Epoch 1/500 | Train Loss: 5109.314 | Test Loss: 5161.754 | Test Loss [MAPE]: 423191.637 --time-- 1.7978014945983887\n",
      "Epoch 2/500 | Train Loss: 5106.371 | Test Loss: 5161.699 | Test Loss [MAPE]: 425753.541 --time-- 1.7580986022949219\n",
      "Epoch 3/500 | Train Loss: 5106.396 | Test Loss: 5161.732 | Test Loss [MAPE]: 420741.941 --time-- 1.7586841583251953\n",
      "Epoch 4/500 | Train Loss: 5106.398 | Test Loss: 5161.697 | Test Loss [MAPE]: 421226.776 --time-- 1.7589476108551025\n",
      "Epoch 5/500 | Train Loss: 5106.366 | Test Loss: 5161.696 | Test Loss [MAPE]: 420796.872 --time-- 1.7581841945648193\n",
      "Epoch 6/500 | Train Loss: 5106.356 | Test Loss: 5161.721 | Test Loss [MAPE]: 424610.706 --time-- 1.8032724857330322\n",
      "Epoch 7/500 | Train Loss: 5106.521 | Test Loss: 5161.772 | Test Loss [MAPE]: 420992.994 --time-- 1.7595367431640625\n",
      "Epoch 8/500 | Train Loss: 5106.439 | Test Loss: 5161.760 | Test Loss [MAPE]: 428603.156 --time-- 1.7561535835266113\n",
      "Epoch 9/500 | Train Loss: 5106.443 | Test Loss: 5161.885 | Test Loss [MAPE]: 416628.133 --time-- 1.7576260566711426\n",
      "Epoch 10/500 | Train Loss: 5106.445 | Test Loss: 5161.754 | Test Loss [MAPE]: 423349.503 --time-- 1.7550158500671387\n",
      "Epoch 11/500 | Train Loss: 5106.372 | Test Loss: 5161.719 | Test Loss [MAPE]: 425266.176 --time-- 1.7582082748413086\n",
      "Epoch 12/500 | Train Loss: 5106.370 | Test Loss: 5161.754 | Test Loss [MAPE]: 420101.413 --time-- 1.7577180862426758\n",
      "Epoch 13/500 | Train Loss: 5106.374 | Test Loss: 5161.852 | Test Loss [MAPE]: 436138.794 --time-- 1.758833885192871\n",
      "Epoch 14/500 | Train Loss: 5106.368 | Test Loss: 5161.727 | Test Loss [MAPE]: 429265.650 --time-- 1.7565455436706543\n",
      "Epoch 15/500 | Train Loss: 5106.374 | Test Loss: 5161.741 | Test Loss [MAPE]: 419794.655 --time-- 1.7568650245666504\n",
      "Epoch 16/500 | Train Loss: 5106.420 | Test Loss: 5161.751 | Test Loss [MAPE]: 429898.136 --time-- 1.7573862075805664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 03:46:51,148] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.367 | Test Loss: 5161.766 | Test Loss [MAPE]: 428864.396 --time-- 1.7572112083435059\n",
      "Epoch 1/500 | Train Loss: 5124.980 | Test Loss: 5162.160 | Test Loss [MAPE]: 435177.561 --time-- 1.2989370822906494\n",
      "Epoch 2/500 | Train Loss: 5106.460 | Test Loss: 5161.739 | Test Loss [MAPE]: 421633.131 --time-- 1.2664361000061035\n",
      "Epoch 3/500 | Train Loss: 5106.358 | Test Loss: 5161.689 | Test Loss [MAPE]: 423046.584 --time-- 1.2733116149902344\n",
      "Epoch 4/500 | Train Loss: 5106.399 | Test Loss: 5161.702 | Test Loss [MAPE]: 426380.119 --time-- 1.2740588188171387\n",
      "Epoch 5/500 | Train Loss: 5106.400 | Test Loss: 5161.738 | Test Loss [MAPE]: 429709.440 --time-- 1.272409439086914\n",
      "Epoch 6/500 | Train Loss: 5106.367 | Test Loss: 5161.781 | Test Loss [MAPE]: 417080.167 --time-- 1.2718298435211182\n",
      "Epoch 7/500 | Train Loss: 5106.424 | Test Loss: 5161.807 | Test Loss [MAPE]: 428819.515 --time-- 1.2776737213134766\n",
      "Epoch 8/500 | Train Loss: 5106.401 | Test Loss: 5161.730 | Test Loss [MAPE]: 420185.241 --time-- 1.272623062133789\n",
      "Epoch 9/500 | Train Loss: 5106.387 | Test Loss: 5161.790 | Test Loss [MAPE]: 431270.283 --time-- 1.2731592655181885\n",
      "Epoch 10/500 | Train Loss: 5106.503 | Test Loss: 5161.844 | Test Loss [MAPE]: 435889.867 --time-- 1.2716586589813232\n",
      "Epoch 11/500 | Train Loss: 5106.481 | Test Loss: 5161.985 | Test Loss [MAPE]: 442912.764 --time-- 1.2721452713012695\n",
      "Epoch 12/500 | Train Loss: 5106.560 | Test Loss: 5161.794 | Test Loss [MAPE]: 433837.620 --time-- 1.2693474292755127\n",
      "Epoch 13/500 | Train Loss: 5106.498 | Test Loss: 5161.771 | Test Loss [MAPE]: 430820.620 --time-- 1.2735071182250977\n",
      "Epoch 14/500 | Train Loss: 5106.504 | Test Loss: 5161.946 | Test Loss [MAPE]: 415691.662 --time-- 1.2733495235443115\n",
      "Epoch 15/500 | Train Loss: 5106.451 | Test Loss: 5161.781 | Test Loss [MAPE]: 421982.032 --time-- 1.2730510234832764\n",
      "Epoch 16/500 | Train Loss: 5106.419 | Test Loss: 5161.803 | Test Loss [MAPE]: 425974.704 --time-- 1.2729008197784424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 03:47:13,455] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.439 | Test Loss: 5162.332 | Test Loss [MAPE]: 455777.741 --time-- 1.2725043296813965\n",
      "Epoch 1/500 | Train Loss: 5171.192 | Test Loss: 5161.826 | Test Loss [MAPE]: 423897.536 --time-- 1.8138439655303955\n",
      "Epoch 2/500 | Train Loss: 5106.452 | Test Loss: 5161.786 | Test Loss [MAPE]: 425445.134 --time-- 1.7674915790557861\n",
      "Epoch 3/500 | Train Loss: 5106.530 | Test Loss: 5161.827 | Test Loss [MAPE]: 421514.294 --time-- 1.7680089473724365\n",
      "Epoch 4/500 | Train Loss: 5106.468 | Test Loss: 5161.919 | Test Loss [MAPE]: 420395.050 --time-- 1.7683954238891602\n",
      "Epoch 5/500 | Train Loss: 5106.501 | Test Loss: 5161.855 | Test Loss [MAPE]: 419359.679 --time-- 1.7668867111206055\n",
      "Epoch 6/500 | Train Loss: 5106.475 | Test Loss: 5161.791 | Test Loss [MAPE]: 425334.475 --time-- 1.7703511714935303\n",
      "Epoch 7/500 | Train Loss: 5106.449 | Test Loss: 5161.792 | Test Loss [MAPE]: 429748.589 --time-- 1.775439739227295\n",
      "Epoch 8/500 | Train Loss: 5106.485 | Test Loss: 5161.734 | Test Loss [MAPE]: 425380.550 --time-- 1.768723726272583\n",
      "Epoch 9/500 | Train Loss: 5106.455 | Test Loss: 5161.782 | Test Loss [MAPE]: 425890.656 --time-- 1.7690165042877197\n",
      "Epoch 10/500 | Train Loss: 5106.509 | Test Loss: 5161.925 | Test Loss [MAPE]: 420309.776 --time-- 1.7712883949279785\n",
      "Epoch 11/500 | Train Loss: 5106.654 | Test Loss: 5161.938 | Test Loss [MAPE]: 421008.467 --time-- 1.767190933227539\n",
      "Epoch 12/500 | Train Loss: 5106.590 | Test Loss: 5162.185 | Test Loss [MAPE]: 448712.379 --time-- 1.7675635814666748\n",
      "Epoch 13/500 | Train Loss: 5106.578 | Test Loss: 5161.936 | Test Loss [MAPE]: 419663.578 --time-- 1.7686841487884521\n",
      "Epoch 14/500 | Train Loss: 5106.633 | Test Loss: 5161.876 | Test Loss [MAPE]: 421429.214 --time-- 1.7678313255310059\n",
      "Epoch 15/500 | Train Loss: 5106.464 | Test Loss: 5161.861 | Test Loss [MAPE]: 427388.156 --time-- 1.7687437534332275\n",
      "Epoch 16/500 | Train Loss: 5106.514 | Test Loss: 5161.818 | Test Loss [MAPE]: 428408.439 --time-- 1.7672035694122314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 03:47:44,191] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.501 | Test Loss: 5161.850 | Test Loss [MAPE]: 432337.128 --time-- 1.7661230564117432\n",
      "Epoch 1/500 | Train Loss: 5382.382 | Test Loss: 5176.895 | Test Loss [MAPE]: 563589.857 --time-- 11.150890350341797\n",
      "Epoch 2/500 | Train Loss: 5105.902 | Test Loss: 5042.599 | Test Loss [MAPE]: 1313628.002 --time-- 11.168261766433716\n",
      "Epoch 3/500 | Train Loss: 4558.472 | Test Loss: 4289.314 | Test Loss [MAPE]: 2616528.111 --time-- 11.22722315788269\n",
      "Epoch 4/500 | Train Loss: 3997.126 | Test Loss: 3667.443 | Test Loss [MAPE]: 5088447.008 --time-- 11.250872611999512\n",
      "Epoch 5/500 | Train Loss: 3352.184 | Test Loss: 3054.500 | Test Loss [MAPE]: 7173708.671 --time-- 11.245505809783936\n",
      "Epoch 6/500 | Train Loss: 2923.695 | Test Loss: 2450.752 | Test Loss [MAPE]: 5610593.772 --time-- 11.245737552642822\n",
      "Epoch 7/500 | Train Loss: 2702.217 | Test Loss: 3621.015 | Test Loss [MAPE]: 6471537.500 --time-- 11.239213705062866\n",
      "Epoch 8/500 | Train Loss: 2520.815 | Test Loss: 2141.111 | Test Loss [MAPE]: 4848946.897 --time-- 11.22386884689331\n",
      "Epoch 9/500 | Train Loss: 1876.678 | Test Loss: 1617.203 | Test Loss [MAPE]: 3765613.557 --time-- 11.24406361579895\n",
      "Epoch 10/500 | Train Loss: 1608.580 | Test Loss: 2236.881 | Test Loss [MAPE]: 5096095.149 --time-- 11.244381666183472\n",
      "Epoch 11/500 | Train Loss: 1576.680 | Test Loss: 1666.116 | Test Loss [MAPE]: 4098525.197 --time-- 11.238308429718018\n",
      "Epoch 12/500 | Train Loss: 1419.594 | Test Loss: 1431.920 | Test Loss [MAPE]: 3975801.432 --time-- 11.239120483398438\n",
      "Epoch 13/500 | Train Loss: 1267.685 | Test Loss: 1207.642 | Test Loss [MAPE]: 3015556.748 --time-- 11.241505861282349\n",
      "Epoch 14/500 | Train Loss: 1161.941 | Test Loss: 1209.033 | Test Loss [MAPE]: 3181046.620 --time-- 11.240237951278687\n",
      "Epoch 15/500 | Train Loss: 1200.095 | Test Loss: 1176.807 | Test Loss [MAPE]: 2701264.780 --time-- 11.238582849502563\n",
      "Epoch 16/500 | Train Loss: 1274.513 | Test Loss: 1401.257 | Test Loss [MAPE]: 3270766.603 --time-- 11.238908767700195\n",
      "Epoch 17/500 | Train Loss: 1036.342 | Test Loss: 1177.947 | Test Loss [MAPE]: 2806728.474 --time-- 11.24378490447998\n",
      "Epoch 18/500 | Train Loss: 1114.077 | Test Loss: 1341.552 | Test Loss [MAPE]: 3000524.229 --time-- 11.232428312301636\n",
      "Epoch 19/500 | Train Loss: 941.391 | Test Loss: 997.565 | Test Loss [MAPE]: 2588099.782 --time-- 11.244860172271729\n",
      "Epoch 20/500 | Train Loss: 941.725 | Test Loss: 1006.559 | Test Loss [MAPE]: 2212495.355 --time-- 11.242175102233887\n",
      "Epoch 21/500 | Train Loss: 924.811 | Test Loss: 908.777 | Test Loss [MAPE]: 2396427.502 --time-- 11.241437673568726\n",
      "Epoch 22/500 | Train Loss: 862.524 | Test Loss: 939.524 | Test Loss [MAPE]: 2495621.940 --time-- 11.23777461051941\n",
      "Epoch 23/500 | Train Loss: 933.171 | Test Loss: 1051.529 | Test Loss [MAPE]: 2787522.641 --time-- 11.237500429153442\n",
      "Epoch 24/500 | Train Loss: 896.485 | Test Loss: 777.284 | Test Loss [MAPE]: 2067159.760 --time-- 11.240414142608643\n",
      "Epoch 25/500 | Train Loss: 813.256 | Test Loss: 888.141 | Test Loss [MAPE]: 2213184.725 --time-- 11.2392897605896\n",
      "Epoch 26/500 | Train Loss: 805.123 | Test Loss: 1238.995 | Test Loss [MAPE]: 2534691.013 --time-- 11.242173910140991\n",
      "Epoch 27/500 | Train Loss: 933.378 | Test Loss: 766.973 | Test Loss [MAPE]: 2251758.767 --time-- 11.241138935089111\n",
      "Epoch 28/500 | Train Loss: 823.239 | Test Loss: 748.356 | Test Loss [MAPE]: 2053987.166 --time-- 11.24187421798706\n",
      "Epoch 29/500 | Train Loss: 714.105 | Test Loss: 762.113 | Test Loss [MAPE]: 2023648.853 --time-- 11.240003824234009\n",
      "Epoch 30/500 | Train Loss: 817.079 | Test Loss: 761.865 | Test Loss [MAPE]: 2053129.113 --time-- 11.239532947540283\n",
      "Epoch 31/500 | Train Loss: 723.063 | Test Loss: 653.470 | Test Loss [MAPE]: 1756620.675 --time-- 11.240815162658691\n",
      "Epoch 32/500 | Train Loss: 737.291 | Test Loss: 824.102 | Test Loss [MAPE]: 2216327.108 --time-- 11.240213871002197\n",
      "Epoch 33/500 | Train Loss: 695.947 | Test Loss: 702.606 | Test Loss [MAPE]: 1866969.442 --time-- 11.242820024490356\n",
      "Epoch 34/500 | Train Loss: 707.233 | Test Loss: 783.100 | Test Loss [MAPE]: 1864564.837 --time-- 11.2427339553833\n",
      "Epoch 35/500 | Train Loss: 678.459 | Test Loss: 770.355 | Test Loss [MAPE]: 2109296.216 --time-- 11.244140625\n",
      "Epoch 36/500 | Train Loss: 739.363 | Test Loss: 716.726 | Test Loss [MAPE]: 1911542.846 --time-- 11.239114761352539\n",
      "Epoch 37/500 | Train Loss: 718.963 | Test Loss: 757.232 | Test Loss [MAPE]: 1962698.182 --time-- 11.239703893661499\n",
      "Epoch 38/500 | Train Loss: 708.663 | Test Loss: 684.413 | Test Loss [MAPE]: 1939288.096 --time-- 11.243370532989502\n",
      "Epoch 39/500 | Train Loss: 651.894 | Test Loss: 661.542 | Test Loss [MAPE]: 1714721.482 --time-- 11.241926431655884\n",
      "Epoch 40/500 | Train Loss: 642.208 | Test Loss: 684.841 | Test Loss [MAPE]: 1907936.720 --time-- 11.241939544677734\n",
      "Epoch 41/500 | Train Loss: 651.199 | Test Loss: 686.333 | Test Loss [MAPE]: 1884111.197 --time-- 11.242748498916626\n",
      "Epoch 42/500 | Train Loss: 616.758 | Test Loss: 654.656 | Test Loss [MAPE]: 1801555.777 --time-- 11.23722791671753\n",
      "Epoch 43/500 | Train Loss: 710.882 | Test Loss: 656.579 | Test Loss [MAPE]: 1742607.496 --time-- 11.240172386169434\n",
      "Epoch 44/500 | Train Loss: 600.804 | Test Loss: 610.491 | Test Loss [MAPE]: 1732544.249 --time-- 11.235827922821045\n",
      "Epoch 45/500 | Train Loss: 619.455 | Test Loss: 656.943 | Test Loss [MAPE]: 1814844.803 --time-- 11.237065076828003\n",
      "Epoch 46/500 | Train Loss: 619.694 | Test Loss: 722.116 | Test Loss [MAPE]: 1994813.379 --time-- 11.23482871055603\n",
      "Epoch 47/500 | Train Loss: 631.930 | Test Loss: 551.725 | Test Loss [MAPE]: 1543376.241 --time-- 11.232157945632935\n",
      "Epoch 48/500 | Train Loss: 677.996 | Test Loss: 684.666 | Test Loss [MAPE]: 1726872.942 --time-- 11.243807077407837\n",
      "Epoch 49/500 | Train Loss: 548.430 | Test Loss: 573.160 | Test Loss [MAPE]: 1563370.172 --time-- 11.288023710250854\n",
      "Epoch 50/500 | Train Loss: 627.976 | Test Loss: 615.089 | Test Loss [MAPE]: 1778339.237 --time-- 11.289539337158203\n",
      "Epoch 51/500 | Train Loss: 587.588 | Test Loss: 578.072 | Test Loss [MAPE]: 1605814.112 --time-- 11.282688617706299\n",
      "Epoch 52/500 | Train Loss: 621.707 | Test Loss: 619.179 | Test Loss [MAPE]: 1753025.151 --time-- 11.280220031738281\n",
      "Epoch 53/500 | Train Loss: 557.283 | Test Loss: 569.988 | Test Loss [MAPE]: 1590579.599 --time-- 11.234015226364136\n",
      "Epoch 54/500 | Train Loss: 587.716 | Test Loss: 656.679 | Test Loss [MAPE]: 1874012.978 --time-- 11.238994121551514\n",
      "Epoch 55/500 | Train Loss: 580.777 | Test Loss: 597.933 | Test Loss [MAPE]: 1654680.680 --time-- 11.234822273254395\n",
      "Epoch 56/500 | Train Loss: 586.926 | Test Loss: 606.414 | Test Loss [MAPE]: 1706180.878 --time-- 11.240500450134277\n",
      "Epoch 57/500 | Train Loss: 559.801 | Test Loss: 619.689 | Test Loss [MAPE]: 1713599.637 --time-- 11.233906745910645\n",
      "Epoch 58/500 | Train Loss: 585.204 | Test Loss: 574.192 | Test Loss [MAPE]: 1633128.506 --time-- 11.228553295135498\n",
      "Epoch 59/500 | Train Loss: 525.999 | Test Loss: 464.102 | Test Loss [MAPE]: 1306797.341 --time-- 11.228077173233032\n",
      "Epoch 60/500 | Train Loss: 511.500 | Test Loss: 590.007 | Test Loss [MAPE]: 1717436.405 --time-- 11.231963396072388\n",
      "Epoch 61/500 | Train Loss: 569.266 | Test Loss: 568.980 | Test Loss [MAPE]: 1485613.377 --time-- 11.239535093307495\n",
      "Epoch 62/500 | Train Loss: 568.338 | Test Loss: 590.082 | Test Loss [MAPE]: 1437953.359 --time-- 11.237450361251831\n",
      "Epoch 63/500 | Train Loss: 577.932 | Test Loss: 756.998 | Test Loss [MAPE]: 1725710.626 --time-- 11.231583833694458\n",
      "Epoch 64/500 | Train Loss: 568.198 | Test Loss: 531.334 | Test Loss [MAPE]: 1530633.860 --time-- 11.24672269821167\n",
      "Epoch 65/500 | Train Loss: 511.340 | Test Loss: 525.057 | Test Loss [MAPE]: 1546407.526 --time-- 11.236304998397827\n",
      "Epoch 66/500 | Train Loss: 524.441 | Test Loss: 523.648 | Test Loss [MAPE]: 1423017.964 --time-- 11.23568081855774\n",
      "Epoch 67/500 | Train Loss: 505.364 | Test Loss: 567.163 | Test Loss [MAPE]: 1617000.837 --time-- 11.237126350402832\n",
      "Epoch 68/500 | Train Loss: 502.759 | Test Loss: 497.763 | Test Loss [MAPE]: 1456922.039 --time-- 11.239821434020996\n",
      "Epoch 69/500 | Train Loss: 513.754 | Test Loss: 496.771 | Test Loss [MAPE]: 1431489.533 --time-- 11.232200860977173\n",
      "Epoch 70/500 | Train Loss: 504.659 | Test Loss: 568.992 | Test Loss [MAPE]: 1517076.440 --time-- 11.235975742340088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500 | Train Loss: 504.548 | Test Loss: 520.338 | Test Loss [MAPE]: 1507003.460 --time-- 11.234124422073364\n",
      "Epoch 72/500 | Train Loss: 463.269 | Test Loss: 549.274 | Test Loss [MAPE]: 1497037.698 --time-- 11.281527996063232\n",
      "Epoch 73/500 | Train Loss: 476.258 | Test Loss: 541.280 | Test Loss [MAPE]: 1566721.142 --time-- 11.289568662643433\n",
      "Epoch 74/500 | Train Loss: 491.666 | Test Loss: 531.715 | Test Loss [MAPE]: 1651599.905 --time-- 11.284412384033203\n",
      "Epoch 75/500 | Train Loss: 505.188 | Test Loss: 463.812 | Test Loss [MAPE]: 1373479.897 --time-- 11.245660066604614\n",
      "Epoch 76/500 | Train Loss: 458.959 | Test Loss: 499.247 | Test Loss [MAPE]: 1431846.751 --time-- 11.233423709869385\n",
      "Epoch 77/500 | Train Loss: 471.786 | Test Loss: 542.317 | Test Loss [MAPE]: 1566296.767 --time-- 11.295774698257446\n",
      "Epoch 78/500 | Train Loss: 449.610 | Test Loss: 491.689 | Test Loss [MAPE]: 1362918.861 --time-- 11.316910028457642\n",
      "Epoch 79/500 | Train Loss: 481.629 | Test Loss: 470.573 | Test Loss [MAPE]: 1379311.096 --time-- 11.30696725845337\n",
      "Epoch 80/500 | Train Loss: 501.836 | Test Loss: 505.495 | Test Loss [MAPE]: 1537738.142 --time-- 11.235126256942749\n",
      "Epoch 81/500 | Train Loss: 455.562 | Test Loss: 556.741 | Test Loss [MAPE]: 1632620.851 --time-- 11.231569528579712\n",
      "Epoch 82/500 | Train Loss: 463.235 | Test Loss: 470.545 | Test Loss [MAPE]: 1326735.313 --time-- 11.239454984664917\n",
      "Epoch 83/500 | Train Loss: 440.980 | Test Loss: 433.762 | Test Loss [MAPE]: 1321701.468 --time-- 11.233388900756836\n",
      "Epoch 84/500 | Train Loss: 412.170 | Test Loss: 481.134 | Test Loss [MAPE]: 1379429.323 --time-- 11.225472450256348\n",
      "Epoch 85/500 | Train Loss: 444.051 | Test Loss: 525.643 | Test Loss [MAPE]: 1555724.565 --time-- 11.230326652526855\n",
      "Epoch 86/500 | Train Loss: 441.041 | Test Loss: 428.287 | Test Loss [MAPE]: 1278890.760 --time-- 11.225972175598145\n",
      "Epoch 87/500 | Train Loss: 437.241 | Test Loss: 434.204 | Test Loss [MAPE]: 1308885.501 --time-- 11.243022441864014\n",
      "Epoch 88/500 | Train Loss: 436.837 | Test Loss: 517.696 | Test Loss [MAPE]: 1535555.246 --time-- 11.243983268737793\n",
      "Epoch 89/500 | Train Loss: 430.023 | Test Loss: 458.516 | Test Loss [MAPE]: 1375372.013 --time-- 11.228214263916016\n",
      "Epoch 90/500 | Train Loss: 421.726 | Test Loss: 412.187 | Test Loss [MAPE]: 1228552.031 --time-- 11.229931354522705\n",
      "Epoch 91/500 | Train Loss: 405.743 | Test Loss: 474.678 | Test Loss [MAPE]: 1420126.469 --time-- 11.224892854690552\n",
      "Epoch 92/500 | Train Loss: 420.345 | Test Loss: 470.703 | Test Loss [MAPE]: 1393180.678 --time-- 11.22689414024353\n",
      "Epoch 93/500 | Train Loss: 407.320 | Test Loss: 491.663 | Test Loss [MAPE]: 1346292.958 --time-- 11.241276025772095\n",
      "Epoch 94/500 | Train Loss: 413.373 | Test Loss: 476.038 | Test Loss [MAPE]: 1504902.557 --time-- 11.239966869354248\n",
      "Epoch 95/500 | Train Loss: 418.340 | Test Loss: 451.568 | Test Loss [MAPE]: 1282610.985 --time-- 11.23892092704773\n",
      "Epoch 96/500 | Train Loss: 430.610 | Test Loss: 443.386 | Test Loss [MAPE]: 1297007.436 --time-- 11.23673391342163\n",
      "Epoch 97/500 | Train Loss: 405.070 | Test Loss: 473.068 | Test Loss [MAPE]: 1434278.217 --time-- 11.235117435455322\n",
      "Epoch 98/500 | Train Loss: 399.987 | Test Loss: 435.091 | Test Loss [MAPE]: 1321418.502 --time-- 11.228820085525513\n",
      "Epoch 99/500 | Train Loss: 404.893 | Test Loss: 487.628 | Test Loss [MAPE]: 1389543.644 --time-- 11.23468017578125\n",
      "Epoch 100/500 | Train Loss: 419.955 | Test Loss: 439.267 | Test Loss [MAPE]: 1318772.014 --time-- 11.235317468643188\n",
      "Epoch 101/500 | Train Loss: 397.162 | Test Loss: 487.610 | Test Loss [MAPE]: 1417817.825 --time-- 11.232942342758179\n",
      "Epoch 102/500 | Train Loss: 418.191 | Test Loss: 443.941 | Test Loss [MAPE]: 1316320.870 --time-- 11.234359979629517\n",
      "Epoch 103/500 | Train Loss: 400.474 | Test Loss: 458.525 | Test Loss [MAPE]: 1416899.258 --time-- 11.233525037765503\n",
      "Epoch 104/500 | Train Loss: 377.822 | Test Loss: 452.557 | Test Loss [MAPE]: 1347973.708 --time-- 11.233341217041016\n",
      "Epoch 105/500 | Train Loss: 384.656 | Test Loss: 385.213 | Test Loss [MAPE]: 1176655.299 --time-- 11.22396993637085\n",
      "Epoch 106/500 | Train Loss: 381.150 | Test Loss: 403.355 | Test Loss [MAPE]: 1112486.563 --time-- 11.23339319229126\n",
      "Epoch 107/500 | Train Loss: 396.208 | Test Loss: 427.203 | Test Loss [MAPE]: 1330208.279 --time-- 11.236815690994263\n",
      "Epoch 108/500 | Train Loss: 383.672 | Test Loss: 366.500 | Test Loss [MAPE]: 1099500.582 --time-- 11.242412805557251\n",
      "Epoch 109/500 | Train Loss: 379.633 | Test Loss: 373.400 | Test Loss [MAPE]: 1120911.995 --time-- 11.242538928985596\n",
      "Epoch 110/500 | Train Loss: 363.043 | Test Loss: 377.818 | Test Loss [MAPE]: 1059123.360 --time-- 11.23748230934143\n",
      "Epoch 111/500 | Train Loss: 379.439 | Test Loss: 437.339 | Test Loss [MAPE]: 1313372.866 --time-- 11.228964567184448\n",
      "Epoch 112/500 | Train Loss: 374.512 | Test Loss: 392.975 | Test Loss [MAPE]: 1248290.395 --time-- 11.234115839004517\n",
      "Epoch 113/500 | Train Loss: 373.699 | Test Loss: 387.564 | Test Loss [MAPE]: 1195480.999 --time-- 11.236078977584839\n",
      "Epoch 114/500 | Train Loss: 406.943 | Test Loss: 410.819 | Test Loss [MAPE]: 1264027.002 --time-- 11.243040323257446\n",
      "Epoch 115/500 | Train Loss: 392.967 | Test Loss: 443.309 | Test Loss [MAPE]: 1354230.627 --time-- 11.245527982711792\n",
      "Epoch 116/500 | Train Loss: 379.234 | Test Loss: 377.395 | Test Loss [MAPE]: 1190110.660 --time-- 11.240127563476562\n",
      "Epoch 117/500 | Train Loss: 400.628 | Test Loss: 425.349 | Test Loss [MAPE]: 1321799.989 --time-- 11.239946842193604\n",
      "Epoch 118/500 | Train Loss: 379.009 | Test Loss: 371.373 | Test Loss [MAPE]: 1145693.507 --time-- 11.233638286590576\n",
      "Epoch 119/500 | Train Loss: 345.438 | Test Loss: 384.069 | Test Loss [MAPE]: 1152196.293 --time-- 11.241417407989502\n",
      "Epoch 120/500 | Train Loss: 370.313 | Test Loss: 367.467 | Test Loss [MAPE]: 1161118.937 --time-- 11.234741449356079\n",
      "Epoch 121/500 | Train Loss: 366.593 | Test Loss: 367.026 | Test Loss [MAPE]: 1137312.530 --time-- 11.236313819885254\n",
      "Epoch 122/500 | Train Loss: 368.409 | Test Loss: 394.330 | Test Loss [MAPE]: 1199053.028 --time-- 11.23626160621643\n",
      "Epoch 123/500 | Train Loss: 350.071 | Test Loss: 396.131 | Test Loss [MAPE]: 1238399.380 --time-- 11.234166622161865\n",
      "Epoch 124/500 | Train Loss: 375.119 | Test Loss: 423.449 | Test Loss [MAPE]: 1309843.561 --time-- 11.264994859695435\n",
      "Epoch 125/500 | Train Loss: 367.519 | Test Loss: 380.863 | Test Loss [MAPE]: 1191314.990 --time-- 11.268544912338257\n",
      "Epoch 126/500 | Train Loss: 380.365 | Test Loss: 336.883 | Test Loss [MAPE]: 1001664.947 --time-- 11.269124031066895\n",
      "Epoch 127/500 | Train Loss: 332.482 | Test Loss: 405.558 | Test Loss [MAPE]: 1259615.194 --time-- 11.240041255950928\n",
      "Epoch 128/500 | Train Loss: 362.616 | Test Loss: 374.142 | Test Loss [MAPE]: 1157115.035 --time-- 11.245494365692139\n",
      "Epoch 129/500 | Train Loss: 353.432 | Test Loss: 418.731 | Test Loss [MAPE]: 1287236.927 --time-- 11.24023985862732\n",
      "Epoch 130/500 | Train Loss: 352.954 | Test Loss: 412.551 | Test Loss [MAPE]: 1194709.977 --time-- 11.233393430709839\n",
      "Epoch 131/500 | Train Loss: 360.426 | Test Loss: 394.333 | Test Loss [MAPE]: 1186842.130 --time-- 11.23427438735962\n",
      "Epoch 132/500 | Train Loss: 391.343 | Test Loss: 434.783 | Test Loss [MAPE]: 1154110.803 --time-- 11.247827768325806\n",
      "Epoch 133/500 | Train Loss: 368.625 | Test Loss: 417.948 | Test Loss [MAPE]: 1232303.739 --time-- 11.242793560028076\n",
      "Epoch 134/500 | Train Loss: 353.797 | Test Loss: 405.827 | Test Loss [MAPE]: 1186347.987 --time-- 11.238231182098389\n",
      "Epoch 135/500 | Train Loss: 377.563 | Test Loss: 392.285 | Test Loss [MAPE]: 1224725.778 --time-- 11.245806694030762\n",
      "Epoch 136/500 | Train Loss: 357.080 | Test Loss: 358.044 | Test Loss [MAPE]: 1120456.872 --time-- 11.248328447341919\n",
      "Epoch 137/500 | Train Loss: 358.864 | Test Loss: 394.510 | Test Loss [MAPE]: 1196888.064 --time-- 11.249313116073608\n",
      "Epoch 138/500 | Train Loss: 344.726 | Test Loss: 399.876 | Test Loss [MAPE]: 1263397.524 --time-- 11.2450590133667\n",
      "Epoch 139/500 | Train Loss: 329.612 | Test Loss: 306.063 | Test Loss [MAPE]: 988269.203 --time-- 11.24781084060669\n",
      "Epoch 140/500 | Train Loss: 320.331 | Test Loss: 402.536 | Test Loss [MAPE]: 1263846.657 --time-- 11.299224376678467\n",
      "Epoch 141/500 | Train Loss: 340.367 | Test Loss: 380.674 | Test Loss [MAPE]: 1191572.576 --time-- 11.293464660644531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/500 | Train Loss: 331.106 | Test Loss: 400.539 | Test Loss [MAPE]: 1269748.848 --time-- 11.246454000473022\n",
      "Epoch 143/500 | Train Loss: 363.463 | Test Loss: 328.493 | Test Loss [MAPE]: 1023837.413 --time-- 11.244027614593506\n",
      "Epoch 144/500 | Train Loss: 342.528 | Test Loss: 441.488 | Test Loss [MAPE]: 1350348.173 --time-- 11.24906587600708\n",
      "Epoch 145/500 | Train Loss: 340.654 | Test Loss: 378.820 | Test Loss [MAPE]: 1206065.859 --time-- 11.248149156570435\n",
      "Epoch 146/500 | Train Loss: 314.995 | Test Loss: 361.500 | Test Loss [MAPE]: 1154397.749 --time-- 11.245184898376465\n",
      "Epoch 147/500 | Train Loss: 347.178 | Test Loss: 387.681 | Test Loss [MAPE]: 1216421.921 --time-- 11.242894649505615\n",
      "Epoch 148/500 | Train Loss: 333.904 | Test Loss: 316.537 | Test Loss [MAPE]: 1024687.331 --time-- 11.245588064193726\n",
      "Epoch 149/500 | Train Loss: 313.281 | Test Loss: 372.363 | Test Loss [MAPE]: 1178192.355 --time-- 11.244195222854614\n",
      "Epoch 150/500 | Train Loss: 347.684 | Test Loss: 344.979 | Test Loss [MAPE]: 1085799.824 --time-- 11.241835117340088\n",
      "Epoch 151/500 | Train Loss: 349.259 | Test Loss: 370.335 | Test Loss [MAPE]: 1167829.906 --time-- 11.246668100357056\n",
      "Epoch 152/500 | Train Loss: 335.112 | Test Loss: 384.844 | Test Loss [MAPE]: 1208238.736 --time-- 11.24680495262146\n",
      "Epoch 153/500 | Train Loss: 337.115 | Test Loss: 362.060 | Test Loss [MAPE]: 1125264.550 --time-- 11.240750551223755\n",
      "Epoch 154/500 | Train Loss: 333.882 | Test Loss: 356.464 | Test Loss [MAPE]: 1131685.750 --time-- 11.244292974472046\n",
      "Epoch 155/500 | Train Loss: 328.148 | Test Loss: 309.643 | Test Loss [MAPE]: 969648.481 --time-- 11.251487493515015\n",
      "Epoch 156/500 | Train Loss: 336.718 | Test Loss: 387.809 | Test Loss [MAPE]: 1241143.775 --time-- 11.248566389083862\n",
      "Epoch 157/500 | Train Loss: 360.306 | Test Loss: 397.524 | Test Loss [MAPE]: 1291972.083 --time-- 11.248006343841553\n",
      "Epoch 158/500 | Train Loss: 319.008 | Test Loss: 360.082 | Test Loss [MAPE]: 1104175.030 --time-- 11.251075983047485\n",
      "Epoch 159/500 | Train Loss: 341.279 | Test Loss: 472.830 | Test Loss [MAPE]: 1330629.234 --time-- 11.246950149536133\n",
      "Epoch 160/500 | Train Loss: 370.826 | Test Loss: 391.634 | Test Loss [MAPE]: 1270908.568 --time-- 11.25217890739441\n",
      "Epoch 161/500 | Train Loss: 329.735 | Test Loss: 333.152 | Test Loss [MAPE]: 1100715.474 --time-- 11.251256942749023\n",
      "Epoch 162/500 | Train Loss: 318.373 | Test Loss: 351.641 | Test Loss [MAPE]: 1117888.430 --time-- 11.24593710899353\n",
      "Epoch 163/500 | Train Loss: 332.570 | Test Loss: 353.980 | Test Loss [MAPE]: 1149394.109 --time-- 11.247189044952393\n",
      "Epoch 164/500 | Train Loss: 334.939 | Test Loss: 400.343 | Test Loss [MAPE]: 1262197.678 --time-- 11.244063138961792\n",
      "Epoch 165/500 | Train Loss: 315.626 | Test Loss: 350.163 | Test Loss [MAPE]: 1136368.046 --time-- 11.250751972198486\n",
      "Epoch 166/500 | Train Loss: 329.299 | Test Loss: 419.561 | Test Loss [MAPE]: 1364251.984 --time-- 11.25209641456604\n",
      "Epoch 167/500 | Train Loss: 336.956 | Test Loss: 357.750 | Test Loss [MAPE]: 1071645.727 --time-- 11.249994039535522\n",
      "Epoch 168/500 | Train Loss: 326.057 | Test Loss: 377.310 | Test Loss [MAPE]: 1205475.711 --time-- 11.250425815582275\n",
      "Epoch 169/500 | Train Loss: 321.618 | Test Loss: 328.714 | Test Loss [MAPE]: 941165.713 --time-- 11.24361801147461\n",
      "Epoch 170/500 | Train Loss: 329.365 | Test Loss: 346.259 | Test Loss [MAPE]: 1096309.182 --time-- 11.249156713485718\n",
      "Epoch 171/500 | Train Loss: 318.222 | Test Loss: 363.625 | Test Loss [MAPE]: 1158715.345 --time-- 11.254657506942749\n",
      "Epoch 172/500 | Train Loss: 333.620 | Test Loss: 331.263 | Test Loss [MAPE]: 1088704.283 --time-- 11.253476858139038\n",
      "Epoch 173/500 | Train Loss: 315.045 | Test Loss: 345.418 | Test Loss [MAPE]: 1127000.590 --time-- 11.251057863235474\n",
      "Epoch 174/500 | Train Loss: 302.143 | Test Loss: 323.956 | Test Loss [MAPE]: 1046065.283 --time-- 11.248456478118896\n",
      "Epoch 175/500 | Train Loss: 291.854 | Test Loss: 307.243 | Test Loss [MAPE]: 995008.262 --time-- 11.25472116470337\n",
      "Epoch 176/500 | Train Loss: 320.510 | Test Loss: 332.699 | Test Loss [MAPE]: 1091454.963 --time-- 11.249101877212524\n",
      "Epoch 177/500 | Train Loss: 324.880 | Test Loss: 329.463 | Test Loss [MAPE]: 1071246.295 --time-- 11.251332998275757\n",
      "Epoch 178/500 | Train Loss: 320.183 | Test Loss: 334.279 | Test Loss [MAPE]: 1021840.199 --time-- 11.245710134506226\n",
      "Epoch 179/500 | Train Loss: 308.852 | Test Loss: 349.022 | Test Loss [MAPE]: 1143701.050 --time-- 11.247995138168335\n",
      "Epoch 180/500 | Train Loss: 316.887 | Test Loss: 343.802 | Test Loss [MAPE]: 1061133.046 --time-- 11.249724388122559\n",
      "Epoch 181/500 | Train Loss: 324.329 | Test Loss: 310.323 | Test Loss [MAPE]: 990546.940 --time-- 11.244996309280396\n",
      "Epoch 182/500 | Train Loss: 297.227 | Test Loss: 323.253 | Test Loss [MAPE]: 1002845.105 --time-- 11.250990390777588\n",
      "Epoch 183/500 | Train Loss: 302.723 | Test Loss: 333.716 | Test Loss [MAPE]: 1083145.834 --time-- 11.244807958602905\n",
      "Epoch 184/500 | Train Loss: 307.831 | Test Loss: 320.090 | Test Loss [MAPE]: 1065786.801 --time-- 11.252601861953735\n",
      "Epoch 185/500 | Train Loss: 314.948 | Test Loss: 347.714 | Test Loss [MAPE]: 1153559.266 --time-- 11.252265453338623\n",
      "Epoch 186/500 | Train Loss: 300.674 | Test Loss: 295.067 | Test Loss [MAPE]: 937371.422 --time-- 11.249450206756592\n",
      "Epoch 187/500 | Train Loss: 300.846 | Test Loss: 329.401 | Test Loss [MAPE]: 1094522.466 --time-- 11.252562284469604\n",
      "Epoch 188/500 | Train Loss: 310.912 | Test Loss: 289.377 | Test Loss [MAPE]: 991968.165 --time-- 11.254031419754028\n",
      "Epoch 189/500 | Train Loss: 278.245 | Test Loss: 332.762 | Test Loss [MAPE]: 1081494.848 --time-- 11.250017642974854\n",
      "Epoch 190/500 | Train Loss: 304.389 | Test Loss: 343.778 | Test Loss [MAPE]: 1127991.431 --time-- 11.257651329040527\n",
      "Epoch 191/500 | Train Loss: 310.469 | Test Loss: 380.506 | Test Loss [MAPE]: 1121479.769 --time-- 11.254066467285156\n",
      "Epoch 192/500 | Train Loss: 310.371 | Test Loss: 366.245 | Test Loss [MAPE]: 1156358.101 --time-- 11.2534761428833\n",
      "Epoch 193/500 | Train Loss: 291.472 | Test Loss: 383.844 | Test Loss [MAPE]: 1252202.294 --time-- 11.253052473068237\n",
      "Epoch 194/500 | Train Loss: 319.785 | Test Loss: 353.452 | Test Loss [MAPE]: 1153815.211 --time-- 11.257978677749634\n",
      "Epoch 195/500 | Train Loss: 308.458 | Test Loss: 340.414 | Test Loss [MAPE]: 1116395.362 --time-- 11.251860857009888\n",
      "Epoch 196/500 | Train Loss: 315.246 | Test Loss: 350.416 | Test Loss [MAPE]: 1141940.622 --time-- 11.25946307182312\n",
      "Epoch 197/500 | Train Loss: 317.490 | Test Loss: 341.054 | Test Loss [MAPE]: 1142039.458 --time-- 11.250802516937256\n",
      "Epoch 198/500 | Train Loss: 298.684 | Test Loss: 330.954 | Test Loss [MAPE]: 1087915.194 --time-- 11.25809907913208\n",
      "Epoch 199/500 | Train Loss: 312.050 | Test Loss: 305.012 | Test Loss [MAPE]: 1018260.004 --time-- 11.245945453643799\n",
      "Epoch 200/500 | Train Loss: 307.534 | Test Loss: 376.870 | Test Loss [MAPE]: 994549.952 --time-- 11.250431060791016\n",
      "Epoch 201/500 | Train Loss: 287.410 | Test Loss: 298.137 | Test Loss [MAPE]: 986590.116 --time-- 11.257202386856079\n",
      "Epoch 202/500 | Train Loss: 283.897 | Test Loss: 340.243 | Test Loss [MAPE]: 1120387.708 --time-- 11.253159761428833\n",
      "Epoch 203/500 | Train Loss: 312.571 | Test Loss: 313.864 | Test Loss [MAPE]: 1020552.832 --time-- 11.254712581634521\n",
      "Epoch 204/500 | Train Loss: 294.623 | Test Loss: 338.763 | Test Loss [MAPE]: 1105774.303 --time-- 11.249523162841797\n",
      "Epoch 205/500 | Train Loss: 314.989 | Test Loss: 356.448 | Test Loss [MAPE]: 1132426.974 --time-- 11.248264789581299\n",
      "Epoch 206/500 | Train Loss: 274.257 | Test Loss: 275.256 | Test Loss [MAPE]: 947874.749 --time-- 11.259961605072021\n",
      "Epoch 207/500 | Train Loss: 270.578 | Test Loss: 354.694 | Test Loss [MAPE]: 1178074.654 --time-- 11.258321285247803\n",
      "Epoch 208/500 | Train Loss: 317.593 | Test Loss: 364.808 | Test Loss [MAPE]: 1202805.666 --time-- 11.256949424743652\n",
      "Epoch 209/500 | Train Loss: 299.107 | Test Loss: 350.408 | Test Loss [MAPE]: 1115389.024 --time-- 11.259051322937012\n",
      "Epoch 210/500 | Train Loss: 302.974 | Test Loss: 303.338 | Test Loss [MAPE]: 1004812.960 --time-- 11.257518768310547\n",
      "Epoch 211/500 | Train Loss: 312.459 | Test Loss: 314.816 | Test Loss [MAPE]: 1033163.690 --time-- 11.25869870185852\n",
      "Epoch 212/500 | Train Loss: 286.580 | Test Loss: 309.035 | Test Loss [MAPE]: 1009336.704 --time-- 11.259364128112793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/500 | Train Loss: 290.586 | Test Loss: 358.251 | Test Loss [MAPE]: 1176805.466 --time-- 11.254060506820679\n",
      "Epoch 214/500 | Train Loss: 312.910 | Test Loss: 312.243 | Test Loss [MAPE]: 999741.537 --time-- 11.255375385284424\n",
      "Epoch 215/500 | Train Loss: 299.716 | Test Loss: 318.554 | Test Loss [MAPE]: 1075792.571 --time-- 11.253131866455078\n",
      "Epoch 216/500 | Train Loss: 289.633 | Test Loss: 309.819 | Test Loss [MAPE]: 1018363.409 --time-- 11.257960796356201\n",
      "Epoch 217/500 | Train Loss: 295.242 | Test Loss: 345.047 | Test Loss [MAPE]: 1039250.401 --time-- 11.256972789764404\n",
      "Epoch 218/500 | Train Loss: 286.619 | Test Loss: 311.915 | Test Loss [MAPE]: 1049434.034 --time-- 11.253877639770508\n",
      "Epoch 219/500 | Train Loss: 293.525 | Test Loss: 336.500 | Test Loss [MAPE]: 1126287.621 --time-- 11.254891633987427\n",
      "Epoch 220/500 | Train Loss: 304.622 | Test Loss: 355.461 | Test Loss [MAPE]: 1169476.331 --time-- 11.252575874328613\n",
      "Epoch 221/500 | Train Loss: 303.260 | Test Loss: 333.981 | Test Loss [MAPE]: 1097794.028 --time-- 11.257399797439575\n",
      "Epoch 222/500 | Train Loss: 286.184 | Test Loss: 306.282 | Test Loss [MAPE]: 1007350.140 --time-- 11.255874156951904\n",
      "Epoch 223/500 | Train Loss: 309.834 | Test Loss: 349.507 | Test Loss [MAPE]: 1139312.249 --time-- 11.252103805541992\n",
      "Epoch 224/500 | Train Loss: 288.799 | Test Loss: 308.965 | Test Loss [MAPE]: 984200.289 --time-- 11.252899169921875\n",
      "Epoch 225/500 | Train Loss: 293.930 | Test Loss: 329.797 | Test Loss [MAPE]: 1046481.983 --time-- 11.25514817237854\n",
      "Epoch 226/500 | Train Loss: 303.400 | Test Loss: 312.256 | Test Loss [MAPE]: 1032019.609 --time-- 11.260483264923096\n",
      "Epoch 227/500 | Train Loss: 322.217 | Test Loss: 286.927 | Test Loss [MAPE]: 942099.584 --time-- 11.254459857940674\n",
      "Epoch 228/500 | Train Loss: 276.134 | Test Loss: 281.185 | Test Loss [MAPE]: 921321.517 --time-- 11.255759477615356\n",
      "Epoch 229/500 | Train Loss: 288.532 | Test Loss: 358.522 | Test Loss [MAPE]: 1146417.718 --time-- 11.255672454833984\n",
      "Epoch 230/500 | Train Loss: 310.813 | Test Loss: 341.045 | Test Loss [MAPE]: 1122317.496 --time-- 11.24979829788208\n",
      "Epoch 231/500 | Train Loss: 284.841 | Test Loss: 306.853 | Test Loss [MAPE]: 1035695.706 --time-- 11.251281976699829\n",
      "Epoch 232/500 | Train Loss: 269.555 | Test Loss: 354.918 | Test Loss [MAPE]: 1104660.499 --time-- 11.255438804626465\n",
      "Epoch 233/500 | Train Loss: 297.319 | Test Loss: 322.877 | Test Loss [MAPE]: 1095055.039 --time-- 11.2564115524292\n",
      "Epoch 234/500 | Train Loss: 307.365 | Test Loss: 345.281 | Test Loss [MAPE]: 1162283.545 --time-- 11.311046123504639\n",
      "Epoch 235/500 | Train Loss: 294.311 | Test Loss: 344.985 | Test Loss [MAPE]: 1024063.609 --time-- 11.310608625411987\n",
      "Epoch 236/500 | Train Loss: 302.613 | Test Loss: 322.807 | Test Loss [MAPE]: 1030217.004 --time-- 11.311057090759277\n",
      "Epoch 237/500 | Train Loss: 303.477 | Test Loss: 281.101 | Test Loss [MAPE]: 944088.054 --time-- 11.310545682907104\n",
      "Epoch 238/500 | Train Loss: 290.655 | Test Loss: 321.390 | Test Loss [MAPE]: 1084811.545 --time-- 11.30305790901184\n",
      "Epoch 239/500 | Train Loss: 275.764 | Test Loss: 319.674 | Test Loss [MAPE]: 1039490.253 --time-- 11.256717443466187\n",
      "Epoch 240/500 | Train Loss: 337.376 | Test Loss: 451.221 | Test Loss [MAPE]: 1010412.304 --time-- 11.255669593811035\n",
      "Epoch 241/500 | Train Loss: 340.746 | Test Loss: 329.584 | Test Loss [MAPE]: 1053190.221 --time-- 11.252936363220215\n",
      "Epoch 242/500 | Train Loss: 282.357 | Test Loss: 315.689 | Test Loss [MAPE]: 1026739.982 --time-- 11.260836839675903\n",
      "Epoch 243/500 | Train Loss: 273.800 | Test Loss: 332.449 | Test Loss [MAPE]: 1125223.578 --time-- 11.260262250900269\n",
      "Epoch 244/500 | Train Loss: 277.464 | Test Loss: 319.104 | Test Loss [MAPE]: 1067183.369 --time-- 11.261130332946777\n",
      "Epoch 245/500 | Train Loss: 270.427 | Test Loss: 310.366 | Test Loss [MAPE]: 1004152.654 --time-- 11.262825012207031\n",
      "Epoch 246/500 | Train Loss: 274.391 | Test Loss: 304.573 | Test Loss [MAPE]: 1014482.006 --time-- 11.25830340385437\n",
      "Epoch 247/500 | Train Loss: 283.065 | Test Loss: 315.903 | Test Loss [MAPE]: 1043973.112 --time-- 11.260517120361328\n",
      "Epoch 248/500 | Train Loss: 274.871 | Test Loss: 340.996 | Test Loss [MAPE]: 1111417.690 --time-- 11.262747049331665\n",
      "Epoch 249/500 | Train Loss: 271.740 | Test Loss: 296.330 | Test Loss [MAPE]: 987102.163 --time-- 11.311481714248657\n",
      "Epoch 250/500 | Train Loss: 264.155 | Test Loss: 303.392 | Test Loss [MAPE]: 998984.324 --time-- 11.257641553878784\n",
      "Epoch 251/500 | Train Loss: 270.298 | Test Loss: 330.486 | Test Loss [MAPE]: 1113453.060 --time-- 11.265658378601074\n",
      "Epoch 252/500 | Train Loss: 282.400 | Test Loss: 314.472 | Test Loss [MAPE]: 1016075.508 --time-- 11.254677534103394\n",
      "Epoch 253/500 | Train Loss: 274.201 | Test Loss: 332.739 | Test Loss [MAPE]: 1098734.037 --time-- 11.257043838500977\n",
      "Epoch 254/500 | Train Loss: 266.330 | Test Loss: 330.597 | Test Loss [MAPE]: 1089841.750 --time-- 11.259418725967407\n",
      "Epoch 255/500 | Train Loss: 266.204 | Test Loss: 265.502 | Test Loss [MAPE]: 895859.658 --time-- 11.262377262115479\n",
      "Epoch 256/500 | Train Loss: 269.765 | Test Loss: 299.701 | Test Loss [MAPE]: 1029845.379 --time-- 11.261589050292969\n",
      "Epoch 257/500 | Train Loss: 260.932 | Test Loss: 316.306 | Test Loss [MAPE]: 1050946.347 --time-- 11.262344121932983\n",
      "Epoch 258/500 | Train Loss: 270.273 | Test Loss: 299.391 | Test Loss [MAPE]: 960550.033 --time-- 11.26425290107727\n",
      "Epoch 259/500 | Train Loss: 260.359 | Test Loss: 322.063 | Test Loss [MAPE]: 1079270.113 --time-- 11.257079601287842\n",
      "Epoch 260/500 | Train Loss: 263.646 | Test Loss: 321.876 | Test Loss [MAPE]: 1105149.808 --time-- 11.25357437133789\n",
      "Epoch 261/500 | Train Loss: 261.039 | Test Loss: 314.726 | Test Loss [MAPE]: 1041738.234 --time-- 11.258892059326172\n",
      "Epoch 262/500 | Train Loss: 255.482 | Test Loss: 369.005 | Test Loss [MAPE]: 1143546.947 --time-- 11.263498544692993\n",
      "Epoch 263/500 | Train Loss: 291.828 | Test Loss: 299.784 | Test Loss [MAPE]: 990097.470 --time-- 11.259489297866821\n",
      "Epoch 264/500 | Train Loss: 266.078 | Test Loss: 281.808 | Test Loss [MAPE]: 939952.498 --time-- 11.259392023086548\n",
      "Epoch 265/500 | Train Loss: 294.230 | Test Loss: 377.257 | Test Loss [MAPE]: 1029004.409 --time-- 11.257154941558838\n",
      "Epoch 266/500 | Train Loss: 280.799 | Test Loss: 306.437 | Test Loss [MAPE]: 1010785.687 --time-- 11.260071039199829\n",
      "Epoch 267/500 | Train Loss: 267.477 | Test Loss: 308.547 | Test Loss [MAPE]: 1051846.696 --time-- 11.259350776672363\n",
      "Epoch 268/500 | Train Loss: 286.067 | Test Loss: 354.186 | Test Loss [MAPE]: 1167629.725 --time-- 11.259611129760742\n",
      "Epoch 269/500 | Train Loss: 282.490 | Test Loss: 320.876 | Test Loss [MAPE]: 1092282.960 --time-- 11.260992765426636\n",
      "Epoch 270/500 | Train Loss: 282.212 | Test Loss: 331.672 | Test Loss [MAPE]: 1006136.838 --time-- 11.254860639572144\n",
      "Epoch 271/500 | Train Loss: 274.099 | Test Loss: 314.359 | Test Loss [MAPE]: 1053866.887 --time-- 11.258330345153809\n",
      "Epoch 272/500 | Train Loss: 287.944 | Test Loss: 318.013 | Test Loss [MAPE]: 1056338.970 --time-- 11.260894775390625\n",
      "Epoch 273/500 | Train Loss: 271.017 | Test Loss: 297.801 | Test Loss [MAPE]: 966444.895 --time-- 11.264680624008179\n",
      "Epoch 274/500 | Train Loss: 247.007 | Test Loss: 314.044 | Test Loss [MAPE]: 1031237.436 --time-- 11.258088111877441\n",
      "Epoch 275/500 | Train Loss: 266.789 | Test Loss: 280.314 | Test Loss [MAPE]: 945546.158 --time-- 11.260722160339355\n",
      "Epoch 276/500 | Train Loss: 280.156 | Test Loss: 338.835 | Test Loss [MAPE]: 1100864.717 --time-- 11.263684272766113\n",
      "Epoch 277/500 | Train Loss: 279.076 | Test Loss: 284.193 | Test Loss [MAPE]: 930210.913 --time-- 11.26373028755188\n",
      "Epoch 278/500 | Train Loss: 250.632 | Test Loss: 303.143 | Test Loss [MAPE]: 1029027.003 --time-- 11.262214422225952\n",
      "Epoch 279/500 | Train Loss: 269.658 | Test Loss: 329.997 | Test Loss [MAPE]: 1107949.405 --time-- 11.252157926559448\n",
      "Epoch 280/500 | Train Loss: 285.847 | Test Loss: 305.020 | Test Loss [MAPE]: 1035436.861 --time-- 11.262129545211792\n",
      "Epoch 281/500 | Train Loss: 270.370 | Test Loss: 310.783 | Test Loss [MAPE]: 1057772.734 --time-- 11.26059103012085\n",
      "Epoch 282/500 | Train Loss: 262.982 | Test Loss: 259.812 | Test Loss [MAPE]: 878030.959 --time-- 11.26160979270935\n",
      "Epoch 283/500 | Train Loss: 239.895 | Test Loss: 288.362 | Test Loss [MAPE]: 937322.655 --time-- 11.260666608810425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/500 | Train Loss: 246.110 | Test Loss: 282.558 | Test Loss [MAPE]: 961720.039 --time-- 11.261909484863281\n",
      "Epoch 285/500 | Train Loss: 259.466 | Test Loss: 331.858 | Test Loss [MAPE]: 1093338.979 --time-- 11.261773586273193\n",
      "Epoch 286/500 | Train Loss: 267.357 | Test Loss: 292.816 | Test Loss [MAPE]: 975823.797 --time-- 11.253753900527954\n",
      "Epoch 287/500 | Train Loss: 271.031 | Test Loss: 308.638 | Test Loss [MAPE]: 988478.418 --time-- 11.2587730884552\n",
      "Epoch 288/500 | Train Loss: 272.322 | Test Loss: 286.002 | Test Loss [MAPE]: 922591.958 --time-- 11.259042024612427\n",
      "Epoch 289/500 | Train Loss: 246.914 | Test Loss: 293.867 | Test Loss [MAPE]: 1000358.028 --time-- 11.260480880737305\n",
      "Epoch 290/500 | Train Loss: 270.754 | Test Loss: 296.730 | Test Loss [MAPE]: 960331.777 --time-- 11.252072811126709\n",
      "Epoch 291/500 | Train Loss: 264.780 | Test Loss: 286.858 | Test Loss [MAPE]: 976770.764 --time-- 11.262101411819458\n",
      "Epoch 292/500 | Train Loss: 286.069 | Test Loss: 319.415 | Test Loss [MAPE]: 1089616.596 --time-- 11.263132095336914\n",
      "Epoch 293/500 | Train Loss: 315.428 | Test Loss: 366.685 | Test Loss [MAPE]: 1009818.685 --time-- 11.260467529296875\n",
      "Epoch 294/500 | Train Loss: 380.404 | Test Loss: 313.755 | Test Loss [MAPE]: 927543.630 --time-- 11.255185604095459\n",
      "Epoch 295/500 | Train Loss: 345.260 | Test Loss: 314.993 | Test Loss [MAPE]: 941475.713 --time-- 11.246149063110352\n",
      "Epoch 296/500 | Train Loss: 274.429 | Test Loss: 328.987 | Test Loss [MAPE]: 1080043.497 --time-- 11.257700681686401\n",
      "Epoch 297/500 | Train Loss: 299.582 | Test Loss: 315.534 | Test Loss [MAPE]: 994497.091 --time-- 11.262005805969238\n",
      "Epoch 298/500 | Train Loss: 273.171 | Test Loss: 301.735 | Test Loss [MAPE]: 987686.556 --time-- 11.26102352142334\n",
      "Epoch 299/500 | Train Loss: 254.061 | Test Loss: 334.826 | Test Loss [MAPE]: 1124485.602 --time-- 11.264379501342773\n",
      "Epoch 300/500 | Train Loss: 264.569 | Test Loss: 333.091 | Test Loss [MAPE]: 1107071.722 --time-- 11.257508993148804\n",
      "Epoch 301/500 | Train Loss: 258.649 | Test Loss: 286.010 | Test Loss [MAPE]: 968832.048 --time-- 11.253290176391602\n",
      "Epoch 302/500 | Train Loss: 253.393 | Test Loss: 303.153 | Test Loss [MAPE]: 1027336.592 --time-- 11.26127314567566\n",
      "Epoch 303/500 | Train Loss: 257.899 | Test Loss: 321.055 | Test Loss [MAPE]: 1068899.827 --time-- 11.26220154762268\n",
      "Epoch 304/500 | Train Loss: 236.151 | Test Loss: 283.369 | Test Loss [MAPE]: 957805.709 --time-- 11.266438961029053\n",
      "Epoch 305/500 | Train Loss: 244.580 | Test Loss: 300.563 | Test Loss [MAPE]: 1018088.283 --time-- 11.26349925994873\n",
      "Epoch 306/500 | Train Loss: 261.415 | Test Loss: 274.766 | Test Loss [MAPE]: 906544.740 --time-- 11.254817247390747\n",
      "Epoch 307/500 | Train Loss: 245.507 | Test Loss: 279.754 | Test Loss [MAPE]: 966964.107 --time-- 11.263387203216553\n",
      "Epoch 308/500 | Train Loss: 254.129 | Test Loss: 306.747 | Test Loss [MAPE]: 1036113.590 --time-- 11.262200832366943\n",
      "Epoch 309/500 | Train Loss: 247.553 | Test Loss: 300.235 | Test Loss [MAPE]: 926772.824 --time-- 11.259167194366455\n",
      "Epoch 310/500 | Train Loss: 260.402 | Test Loss: 278.823 | Test Loss [MAPE]: 958919.163 --time-- 11.259843587875366\n",
      "Epoch 311/500 | Train Loss: 247.683 | Test Loss: 296.776 | Test Loss [MAPE]: 1005043.205 --time-- 11.26021122932434\n",
      "Epoch 312/500 | Train Loss: 249.532 | Test Loss: 285.525 | Test Loss [MAPE]: 973207.399 --time-- 11.266914129257202\n",
      "Epoch 313/500 | Train Loss: 263.731 | Test Loss: 283.623 | Test Loss [MAPE]: 960153.507 --time-- 11.263150930404663\n",
      "Epoch 314/500 | Train Loss: 252.034 | Test Loss: 265.537 | Test Loss [MAPE]: 925737.289 --time-- 11.256356477737427\n",
      "Epoch 315/500 | Train Loss: 239.529 | Test Loss: 241.057 | Test Loss [MAPE]: 821782.813 --time-- 11.260361671447754\n",
      "Epoch 316/500 | Train Loss: 224.598 | Test Loss: 264.995 | Test Loss [MAPE]: 905227.502 --time-- 11.262458324432373\n",
      "Epoch 317/500 | Train Loss: 245.155 | Test Loss: 327.400 | Test Loss [MAPE]: 1102651.833 --time-- 11.259165048599243\n",
      "Epoch 318/500 | Train Loss: 261.524 | Test Loss: 271.464 | Test Loss [MAPE]: 921633.054 --time-- 11.264383316040039\n",
      "Epoch 319/500 | Train Loss: 251.236 | Test Loss: 290.828 | Test Loss [MAPE]: 974325.700 --time-- 11.270630598068237\n",
      "Epoch 320/500 | Train Loss: 250.901 | Test Loss: 273.810 | Test Loss [MAPE]: 926776.614 --time-- 11.265092611312866\n",
      "Epoch 321/500 | Train Loss: 271.105 | Test Loss: 314.238 | Test Loss [MAPE]: 976771.754 --time-- 11.26473617553711\n",
      "Epoch 322/500 | Train Loss: 249.413 | Test Loss: 302.176 | Test Loss [MAPE]: 1028247.821 --time-- 11.264421224594116\n",
      "Epoch 323/500 | Train Loss: 266.829 | Test Loss: 289.874 | Test Loss [MAPE]: 987255.402 --time-- 11.261673212051392\n",
      "Epoch 324/500 | Train Loss: 233.016 | Test Loss: 294.437 | Test Loss [MAPE]: 897911.731 --time-- 11.261698961257935\n",
      "Epoch 325/500 | Train Loss: 266.709 | Test Loss: 310.676 | Test Loss [MAPE]: 962621.365 --time-- 11.253530502319336\n",
      "Epoch 326/500 | Train Loss: 259.840 | Test Loss: 281.179 | Test Loss [MAPE]: 952800.815 --time-- 11.255213499069214\n",
      "Epoch 327/500 | Train Loss: 297.089 | Test Loss: 368.729 | Test Loss [MAPE]: 1120008.848 --time-- 11.25083613395691\n",
      "Epoch 328/500 | Train Loss: 287.238 | Test Loss: 279.028 | Test Loss [MAPE]: 944769.858 --time-- 11.258148908615112\n",
      "Epoch 329/500 | Train Loss: 250.991 | Test Loss: 296.751 | Test Loss [MAPE]: 992873.306 --time-- 11.258583307266235\n",
      "Epoch 330/500 | Train Loss: 251.559 | Test Loss: 274.899 | Test Loss [MAPE]: 942781.161 --time-- 11.253825664520264\n",
      "Epoch 331/500 | Train Loss: 242.176 | Test Loss: 288.984 | Test Loss [MAPE]: 971903.679 --time-- 11.263473510742188\n",
      "Epoch 332/500 | Train Loss: 245.827 | Test Loss: 355.399 | Test Loss [MAPE]: 1187323.641 --time-- 11.26478362083435\n",
      "Epoch 333/500 | Train Loss: 255.730 | Test Loss: 280.219 | Test Loss [MAPE]: 941792.066 --time-- 11.262004852294922\n",
      "Epoch 334/500 | Train Loss: 250.885 | Test Loss: 274.678 | Test Loss [MAPE]: 942708.967 --time-- 11.261763572692871\n",
      "Epoch 335/500 | Train Loss: 249.084 | Test Loss: 318.092 | Test Loss [MAPE]: 1086542.759 --time-- 11.267951726913452\n",
      "Epoch 336/500 | Train Loss: 269.417 | Test Loss: 322.490 | Test Loss [MAPE]: 1101692.708 --time-- 11.262200593948364\n",
      "Epoch 337/500 | Train Loss: 266.065 | Test Loss: 325.760 | Test Loss [MAPE]: 1083945.113 --time-- 11.265445232391357\n",
      "Epoch 338/500 | Train Loss: 298.882 | Test Loss: 286.969 | Test Loss [MAPE]: 900497.691 --time-- 11.253716468811035\n",
      "Epoch 339/500 | Train Loss: 249.494 | Test Loss: 300.068 | Test Loss [MAPE]: 970166.519 --time-- 11.292440414428711\n",
      "Epoch 340/500 | Train Loss: 240.685 | Test Loss: 258.493 | Test Loss [MAPE]: 863191.504 --time-- 11.286314725875854\n",
      "Epoch 341/500 | Train Loss: 234.314 | Test Loss: 277.481 | Test Loss [MAPE]: 962680.510 --time-- 11.25755524635315\n",
      "Epoch 342/500 | Train Loss: 231.977 | Test Loss: 237.942 | Test Loss [MAPE]: 820075.885 --time-- 11.263495683670044\n",
      "Epoch 343/500 | Train Loss: 223.445 | Test Loss: 312.117 | Test Loss [MAPE]: 951992.494 --time-- 11.26541543006897\n",
      "Epoch 344/500 | Train Loss: 259.119 | Test Loss: 306.680 | Test Loss [MAPE]: 916379.817 --time-- 11.254388809204102\n",
      "Epoch 345/500 | Train Loss: 258.957 | Test Loss: 287.905 | Test Loss [MAPE]: 960453.759 --time-- 11.252963542938232\n",
      "Epoch 346/500 | Train Loss: 246.234 | Test Loss: 294.676 | Test Loss [MAPE]: 999490.661 --time-- 11.260833978652954\n",
      "Epoch 347/500 | Train Loss: 249.163 | Test Loss: 300.063 | Test Loss [MAPE]: 1026408.724 --time-- 11.263954639434814\n",
      "Epoch 348/500 | Train Loss: 252.583 | Test Loss: 277.587 | Test Loss [MAPE]: 964898.992 --time-- 11.265703201293945\n",
      "Epoch 349/500 | Train Loss: 233.430 | Test Loss: 273.537 | Test Loss [MAPE]: 944678.713 --time-- 11.265326499938965\n",
      "Epoch 350/500 | Train Loss: 253.261 | Test Loss: 241.961 | Test Loss [MAPE]: 839965.379 --time-- 11.264143466949463\n",
      "Epoch 351/500 | Train Loss: 255.051 | Test Loss: 287.588 | Test Loss [MAPE]: 977109.020 --time-- 11.261157035827637\n",
      "Epoch 352/500 | Train Loss: 230.745 | Test Loss: 241.889 | Test Loss [MAPE]: 848512.280 --time-- 11.269535303115845\n",
      "Epoch 353/500 | Train Loss: 244.125 | Test Loss: 266.075 | Test Loss [MAPE]: 912633.994 --time-- 11.273520946502686\n",
      "Epoch 354/500 | Train Loss: 241.995 | Test Loss: 299.073 | Test Loss [MAPE]: 1048227.687 --time-- 11.280723333358765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500 | Train Loss: 255.737 | Test Loss: 315.428 | Test Loss [MAPE]: 1051924.540 --time-- 11.279552221298218\n",
      "Epoch 356/500 | Train Loss: 269.226 | Test Loss: 271.779 | Test Loss [MAPE]: 926061.420 --time-- 11.278701305389404\n",
      "Epoch 357/500 | Train Loss: 262.659 | Test Loss: 268.880 | Test Loss [MAPE]: 920139.705 --time-- 11.277857780456543\n",
      "Epoch 358/500 | Train Loss: 235.363 | Test Loss: 269.486 | Test Loss [MAPE]: 909236.580 --time-- 11.2715585231781\n",
      "Epoch 359/500 | Train Loss: 235.603 | Test Loss: 276.549 | Test Loss [MAPE]: 914767.809 --time-- 11.334757804870605\n",
      "Epoch 360/500 | Train Loss: 243.941 | Test Loss: 293.174 | Test Loss [MAPE]: 973504.932 --time-- 11.338839530944824\n",
      "Epoch 361/500 | Train Loss: 259.017 | Test Loss: 263.375 | Test Loss [MAPE]: 906776.091 --time-- 11.281673669815063\n",
      "Epoch 362/500 | Train Loss: 223.364 | Test Loss: 262.552 | Test Loss [MAPE]: 915646.261 --time-- 11.284047603607178\n",
      "Epoch 363/500 | Train Loss: 254.156 | Test Loss: 321.426 | Test Loss [MAPE]: 1074312.613 --time-- 11.354569435119629\n",
      "Epoch 364/500 | Train Loss: 252.557 | Test Loss: 289.716 | Test Loss [MAPE]: 967757.295 --time-- 11.345298767089844\n",
      "Epoch 365/500 | Train Loss: 260.906 | Test Loss: 301.679 | Test Loss [MAPE]: 1044070.225 --time-- 11.341195344924927\n",
      "Epoch 366/500 | Train Loss: 237.941 | Test Loss: 254.237 | Test Loss [MAPE]: 886769.868 --time-- 11.303711891174316\n",
      "Epoch 367/500 | Train Loss: 221.943 | Test Loss: 247.082 | Test Loss [MAPE]: 850200.247 --time-- 11.293753862380981\n",
      "Epoch 368/500 | Train Loss: 219.696 | Test Loss: 307.305 | Test Loss [MAPE]: 1009050.346 --time-- 11.292705535888672\n",
      "Epoch 369/500 | Train Loss: 245.887 | Test Loss: 305.831 | Test Loss [MAPE]: 1034068.795 --time-- 11.291422367095947\n",
      "Epoch 370/500 | Train Loss: 254.843 | Test Loss: 276.397 | Test Loss [MAPE]: 946717.520 --time-- 11.25658917427063\n",
      "Epoch 371/500 | Train Loss: 234.516 | Test Loss: 264.369 | Test Loss [MAPE]: 879451.097 --time-- 11.263750553131104\n",
      "Epoch 372/500 | Train Loss: 226.456 | Test Loss: 311.984 | Test Loss [MAPE]: 1021071.666 --time-- 11.263590097427368\n",
      "Epoch 373/500 | Train Loss: 240.192 | Test Loss: 260.484 | Test Loss [MAPE]: 895979.438 --time-- 11.283875226974487\n",
      "Epoch 374/500 | Train Loss: 234.992 | Test Loss: 281.164 | Test Loss [MAPE]: 972103.990 --time-- 11.272104263305664\n",
      "Epoch 375/500 | Train Loss: 258.593 | Test Loss: 312.271 | Test Loss [MAPE]: 1051299.144 --time-- 11.260334014892578\n",
      "Epoch 376/500 | Train Loss: 232.653 | Test Loss: 288.661 | Test Loss [MAPE]: 973018.223 --time-- 11.265873670578003\n",
      "Epoch 377/500 | Train Loss: 226.550 | Test Loss: 286.599 | Test Loss [MAPE]: 981337.368 --time-- 11.265148162841797\n",
      "Epoch 378/500 | Train Loss: 243.017 | Test Loss: 303.844 | Test Loss [MAPE]: 982165.929 --time-- 11.264461517333984\n",
      "Epoch 379/500 | Train Loss: 253.768 | Test Loss: 310.361 | Test Loss [MAPE]: 1024063.215 --time-- 11.247773170471191\n",
      "Epoch 380/500 | Train Loss: 232.015 | Test Loss: 289.938 | Test Loss [MAPE]: 938579.490 --time-- 11.256286859512329\n",
      "Epoch 381/500 | Train Loss: 292.499 | Test Loss: 422.459 | Test Loss [MAPE]: 1079611.175 --time-- 11.258375406265259\n",
      "Epoch 382/500 | Train Loss: 323.226 | Test Loss: 288.957 | Test Loss [MAPE]: 877099.437 --time-- 11.253260612487793\n",
      "Epoch 383/500 | Train Loss: 224.974 | Test Loss: 265.046 | Test Loss [MAPE]: 877770.623 --time-- 11.260108232498169\n",
      "Epoch 384/500 | Train Loss: 235.203 | Test Loss: 298.566 | Test Loss [MAPE]: 973394.150 --time-- 11.26003885269165\n",
      "Epoch 385/500 | Train Loss: 245.787 | Test Loss: 292.087 | Test Loss [MAPE]: 930386.476 --time-- 11.259468078613281\n",
      "Epoch 386/500 | Train Loss: 256.568 | Test Loss: 246.906 | Test Loss [MAPE]: 843891.476 --time-- 11.263309478759766\n",
      "Epoch 387/500 | Train Loss: 216.075 | Test Loss: 277.591 | Test Loss [MAPE]: 948297.455 --time-- 11.261898279190063\n",
      "Epoch 388/500 | Train Loss: 245.323 | Test Loss: 282.708 | Test Loss [MAPE]: 967580.372 --time-- 11.264554023742676\n",
      "Epoch 389/500 | Train Loss: 232.135 | Test Loss: 239.023 | Test Loss [MAPE]: 841833.343 --time-- 11.263294458389282\n",
      "Epoch 390/500 | Train Loss: 235.608 | Test Loss: 296.587 | Test Loss [MAPE]: 989741.298 --time-- 11.261897563934326\n",
      "Epoch 391/500 | Train Loss: 241.308 | Test Loss: 268.654 | Test Loss [MAPE]: 924569.724 --time-- 11.265149593353271\n",
      "Epoch 392/500 | Train Loss: 240.987 | Test Loss: 347.952 | Test Loss [MAPE]: 1186944.562 --time-- 11.266408205032349\n",
      "Epoch 393/500 | Train Loss: 233.265 | Test Loss: 275.626 | Test Loss [MAPE]: 901657.368 --time-- 11.264969110488892\n",
      "Epoch 394/500 | Train Loss: 239.445 | Test Loss: 277.001 | Test Loss [MAPE]: 967085.112 --time-- 11.26733660697937\n",
      "Epoch 395/500 | Train Loss: 219.136 | Test Loss: 230.586 | Test Loss [MAPE]: 797728.080 --time-- 11.25949764251709\n",
      "Epoch 396/500 | Train Loss: 220.212 | Test Loss: 313.620 | Test Loss [MAPE]: 1042955.209 --time-- 11.268977165222168\n",
      "Epoch 397/500 | Train Loss: 259.793 | Test Loss: 321.333 | Test Loss [MAPE]: 1089405.942 --time-- 11.268684148788452\n",
      "Epoch 398/500 | Train Loss: 239.191 | Test Loss: 275.878 | Test Loss [MAPE]: 958130.498 --time-- 11.268301248550415\n",
      "Epoch 399/500 | Train Loss: 229.410 | Test Loss: 285.594 | Test Loss [MAPE]: 982409.179 --time-- 11.26626706123352\n",
      "Epoch 400/500 | Train Loss: 234.861 | Test Loss: 270.674 | Test Loss [MAPE]: 934958.751 --time-- 11.26611876487732\n",
      "Epoch 401/500 | Train Loss: 227.311 | Test Loss: 287.120 | Test Loss [MAPE]: 885580.362 --time-- 11.268752336502075\n",
      "Epoch 402/500 | Train Loss: 250.325 | Test Loss: 285.835 | Test Loss [MAPE]: 965977.885 --time-- 11.260759115219116\n",
      "Epoch 403/500 | Train Loss: 271.702 | Test Loss: 246.286 | Test Loss [MAPE]: 850705.828 --time-- 11.265985488891602\n",
      "Epoch 404/500 | Train Loss: 230.415 | Test Loss: 292.668 | Test Loss [MAPE]: 1010684.259 --time-- 11.265671730041504\n",
      "Epoch 405/500 | Train Loss: 224.486 | Test Loss: 272.630 | Test Loss [MAPE]: 937787.052 --time-- 11.26175832748413\n",
      "Epoch 406/500 | Train Loss: 235.317 | Test Loss: 267.962 | Test Loss [MAPE]: 941127.921 --time-- 11.268542051315308\n",
      "Epoch 407/500 | Train Loss: 242.293 | Test Loss: 306.041 | Test Loss [MAPE]: 1046680.455 --time-- 11.265880823135376\n",
      "Epoch 408/500 | Train Loss: 233.975 | Test Loss: 259.869 | Test Loss [MAPE]: 897554.155 --time-- 11.268122673034668\n",
      "Epoch 409/500 | Train Loss: 215.104 | Test Loss: 287.632 | Test Loss [MAPE]: 975920.623 --time-- 11.26569652557373\n",
      "Epoch 410/500 | Train Loss: 225.724 | Test Loss: 272.521 | Test Loss [MAPE]: 948931.262 --time-- 11.267498254776001\n",
      "Epoch 411/500 | Train Loss: 226.466 | Test Loss: 278.196 | Test Loss [MAPE]: 925473.170 --time-- 11.263926982879639\n",
      "Epoch 412/500 | Train Loss: 226.747 | Test Loss: 277.228 | Test Loss [MAPE]: 949870.748 --time-- 11.267389059066772\n",
      "Epoch 413/500 | Train Loss: 215.880 | Test Loss: 246.672 | Test Loss [MAPE]: 857813.123 --time-- 11.267157316207886\n",
      "Epoch 414/500 | Train Loss: 238.999 | Test Loss: 287.952 | Test Loss [MAPE]: 992989.020 --time-- 11.320738792419434\n",
      "Epoch 415/500 | Train Loss: 227.869 | Test Loss: 295.392 | Test Loss [MAPE]: 1006258.280 --time-- 11.314173221588135\n",
      "Epoch 416/500 | Train Loss: 209.870 | Test Loss: 268.348 | Test Loss [MAPE]: 918809.245 --time-- 11.318417310714722\n",
      "Epoch 417/500 | Train Loss: 219.269 | Test Loss: 274.217 | Test Loss [MAPE]: 887958.319 --time-- 11.31391429901123\n",
      "Epoch 418/500 | Train Loss: 238.103 | Test Loss: 325.381 | Test Loss [MAPE]: 1001525.268 --time-- 11.319103240966797\n",
      "Epoch 419/500 | Train Loss: 230.884 | Test Loss: 281.726 | Test Loss [MAPE]: 950725.059 --time-- 11.349302053451538\n",
      "Epoch 420/500 | Train Loss: 240.477 | Test Loss: 276.576 | Test Loss [MAPE]: 944347.572 --time-- 11.330516576766968\n",
      "Epoch 421/500 | Train Loss: 236.141 | Test Loss: 291.813 | Test Loss [MAPE]: 993889.346 --time-- 11.32264232635498\n",
      "Epoch 422/500 | Train Loss: 232.557 | Test Loss: 276.043 | Test Loss [MAPE]: 951906.163 --time-- 11.320082426071167\n",
      "Epoch 423/500 | Train Loss: 239.849 | Test Loss: 271.125 | Test Loss [MAPE]: 885667.262 --time-- 11.265349626541138\n",
      "Epoch 424/500 | Train Loss: 222.863 | Test Loss: 297.384 | Test Loss [MAPE]: 962494.063 --time-- 11.263892650604248\n",
      "Epoch 425/500 | Train Loss: 251.004 | Test Loss: 289.700 | Test Loss [MAPE]: 941815.631 --time-- 11.261726379394531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500 | Train Loss: 229.415 | Test Loss: 250.558 | Test Loss [MAPE]: 878282.523 --time-- 11.291109323501587\n",
      "Epoch 427/500 | Train Loss: 209.074 | Test Loss: 262.748 | Test Loss [MAPE]: 864999.510 --time-- 11.280574083328247\n",
      "Epoch 428/500 | Train Loss: 259.202 | Test Loss: 366.201 | Test Loss [MAPE]: 952417.032 --time-- 11.263762712478638\n",
      "Epoch 429/500 | Train Loss: 282.221 | Test Loss: 257.416 | Test Loss [MAPE]: 865924.281 --time-- 11.256776809692383\n",
      "Epoch 430/500 | Train Loss: 235.820 | Test Loss: 250.649 | Test Loss [MAPE]: 864261.958 --time-- 11.259828329086304\n",
      "Epoch 431/500 | Train Loss: 222.441 | Test Loss: 280.138 | Test Loss [MAPE]: 968457.648 --time-- 11.262304306030273\n",
      "Epoch 432/500 | Train Loss: 229.385 | Test Loss: 287.030 | Test Loss [MAPE]: 959781.699 --time-- 11.263418912887573\n",
      "Epoch 433/500 | Train Loss: 235.135 | Test Loss: 300.108 | Test Loss [MAPE]: 1042674.258 --time-- 11.26472020149231\n",
      "Epoch 434/500 | Train Loss: 234.144 | Test Loss: 284.164 | Test Loss [MAPE]: 989488.295 --time-- 11.26465106010437\n",
      "Epoch 435/500 | Train Loss: 220.595 | Test Loss: 265.704 | Test Loss [MAPE]: 905494.493 --time-- 11.263211727142334\n",
      "Epoch 436/500 | Train Loss: 225.541 | Test Loss: 236.783 | Test Loss [MAPE]: 809503.138 --time-- 11.262863874435425\n",
      "Epoch 437/500 | Train Loss: 225.826 | Test Loss: 285.637 | Test Loss [MAPE]: 975405.736 --time-- 11.26160979270935\n",
      "Epoch 438/500 | Train Loss: 241.193 | Test Loss: 295.163 | Test Loss [MAPE]: 895152.399 --time-- 11.263325691223145\n",
      "Epoch 439/500 | Train Loss: 207.322 | Test Loss: 239.216 | Test Loss [MAPE]: 821016.105 --time-- 11.26314377784729\n",
      "Epoch 440/500 | Train Loss: 228.487 | Test Loss: 305.706 | Test Loss [MAPE]: 1032429.174 --time-- 11.264260530471802\n",
      "Epoch 441/500 | Train Loss: 231.384 | Test Loss: 286.651 | Test Loss [MAPE]: 937170.320 --time-- 11.264621496200562\n",
      "Epoch 442/500 | Train Loss: 225.051 | Test Loss: 306.393 | Test Loss [MAPE]: 1047873.791 --time-- 11.265910148620605\n",
      "Epoch 443/500 | Train Loss: 268.757 | Test Loss: 347.356 | Test Loss [MAPE]: 994642.543 --time-- 11.267879009246826\n",
      "Epoch 444/500 | Train Loss: 267.089 | Test Loss: 322.143 | Test Loss [MAPE]: 879533.888 --time-- 11.254398584365845\n",
      "Epoch 445/500 | Train Loss: 223.385 | Test Loss: 271.908 | Test Loss [MAPE]: 916330.338 --time-- 11.2656090259552\n",
      "Epoch 446/500 | Train Loss: 226.718 | Test Loss: 285.412 | Test Loss [MAPE]: 978825.611 --time-- 11.263181447982788\n",
      "Epoch 447/500 | Train Loss: 233.117 | Test Loss: 262.617 | Test Loss [MAPE]: 907286.435 --time-- 11.266045808792114\n",
      "Epoch 448/500 | Train Loss: 219.703 | Test Loss: 277.914 | Test Loss [MAPE]: 945000.831 --time-- 11.316894292831421\n",
      "Epoch 449/500 | Train Loss: 239.589 | Test Loss: 266.169 | Test Loss [MAPE]: 909110.828 --time-- 11.317846536636353\n",
      "Epoch 450/500 | Train Loss: 221.287 | Test Loss: 267.945 | Test Loss [MAPE]: 916401.192 --time-- 11.312532901763916\n",
      "Epoch 451/500 | Train Loss: 214.052 | Test Loss: 266.884 | Test Loss [MAPE]: 931468.117 --time-- 11.324554920196533\n",
      "Epoch 452/500 | Train Loss: 228.570 | Test Loss: 266.083 | Test Loss [MAPE]: 905744.902 --time-- 11.323157787322998\n",
      "Epoch 453/500 | Train Loss: 223.288 | Test Loss: 268.125 | Test Loss [MAPE]: 932549.063 --time-- 11.328577518463135\n",
      "Epoch 454/500 | Train Loss: 229.099 | Test Loss: 283.918 | Test Loss [MAPE]: 966839.766 --time-- 11.324172496795654\n",
      "Epoch 455/500 | Train Loss: 231.706 | Test Loss: 280.012 | Test Loss [MAPE]: 967125.113 --time-- 11.32312536239624\n",
      "Epoch 456/500 | Train Loss: 214.442 | Test Loss: 285.023 | Test Loss [MAPE]: 860947.185 --time-- 11.338964462280273\n",
      "Epoch 457/500 | Train Loss: 232.410 | Test Loss: 264.466 | Test Loss [MAPE]: 913370.384 --time-- 11.320729970932007\n",
      "Epoch 458/500 | Train Loss: 224.191 | Test Loss: 296.128 | Test Loss [MAPE]: 1004648.533 --time-- 11.320676326751709\n",
      "Epoch 459/500 | Train Loss: 226.002 | Test Loss: 307.618 | Test Loss [MAPE]: 1010085.950 --time-- 11.317016839981079\n",
      "Epoch 460/500 | Train Loss: 205.899 | Test Loss: 265.845 | Test Loss [MAPE]: 864082.497 --time-- 11.314921855926514\n",
      "Epoch 461/500 | Train Loss: 211.767 | Test Loss: 278.038 | Test Loss [MAPE]: 944792.633 --time-- 11.319920778274536\n",
      "Epoch 462/500 | Train Loss: 219.728 | Test Loss: 272.005 | Test Loss [MAPE]: 937206.529 --time-- 11.32133936882019\n",
      "Epoch 463/500 | Train Loss: 238.907 | Test Loss: 281.757 | Test Loss [MAPE]: 959502.767 --time-- 11.307271957397461\n",
      "Epoch 464/500 | Train Loss: 230.207 | Test Loss: 290.081 | Test Loss [MAPE]: 996878.909 --time-- 11.321559190750122\n",
      "Epoch 465/500 | Train Loss: 224.057 | Test Loss: 301.045 | Test Loss [MAPE]: 1028216.927 --time-- 11.31519627571106\n",
      "Epoch 466/500 | Train Loss: 266.568 | Test Loss: 311.656 | Test Loss [MAPE]: 1078480.307 --time-- 11.309282064437866\n",
      "Epoch 467/500 | Train Loss: 318.173 | Test Loss: 336.446 | Test Loss [MAPE]: 1028523.406 --time-- 11.313084840774536\n",
      "Epoch 468/500 | Train Loss: 229.724 | Test Loss: 257.241 | Test Loss [MAPE]: 887981.001 --time-- 11.313547134399414\n",
      "Epoch 469/500 | Train Loss: 212.124 | Test Loss: 261.239 | Test Loss [MAPE]: 881181.189 --time-- 11.314779281616211\n",
      "Epoch 470/500 | Train Loss: 222.539 | Test Loss: 256.751 | Test Loss [MAPE]: 898668.391 --time-- 11.320322036743164\n",
      "Epoch 471/500 | Train Loss: 206.117 | Test Loss: 227.487 | Test Loss [MAPE]: 792616.315 --time-- 11.328265190124512\n",
      "Epoch 472/500 | Train Loss: 195.383 | Test Loss: 258.265 | Test Loss [MAPE]: 898396.339 --time-- 11.321996927261353\n",
      "Epoch 473/500 | Train Loss: 202.790 | Test Loss: 266.794 | Test Loss [MAPE]: 909486.819 --time-- 11.317215919494629\n",
      "Epoch 474/500 | Train Loss: 197.472 | Test Loss: 239.811 | Test Loss [MAPE]: 834323.952 --time-- 11.320034503936768\n",
      "Epoch 475/500 | Train Loss: 208.160 | Test Loss: 232.213 | Test Loss [MAPE]: 825988.133 --time-- 11.310152292251587\n",
      "Epoch 476/500 | Train Loss: 229.385 | Test Loss: 275.405 | Test Loss [MAPE]: 917315.774 --time-- 11.315168380737305\n",
      "Epoch 477/500 | Train Loss: 283.741 | Test Loss: 266.446 | Test Loss [MAPE]: 872479.344 --time-- 11.256630659103394\n",
      "Epoch 478/500 | Train Loss: 334.777 | Test Loss: 299.705 | Test Loss [MAPE]: 819418.847 --time-- 11.254943609237671\n",
      "Epoch 479/500 | Train Loss: 370.926 | Test Loss: 303.199 | Test Loss [MAPE]: 990762.776 --time-- 11.259180068969727\n",
      "Epoch 480/500 | Train Loss: 714.109 | Test Loss: 579.883 | Test Loss [MAPE]: 1521533.691 --time-- 11.24763798713684\n",
      "Epoch 481/500 | Train Loss: 494.172 | Test Loss: 464.555 | Test Loss [MAPE]: 1232184.368 --time-- 11.271403789520264\n",
      "Epoch 482/500 | Train Loss: 304.797 | Test Loss: 257.895 | Test Loss [MAPE]: 829084.408 --time-- 11.280508995056152\n",
      "Epoch 483/500 | Train Loss: 312.182 | Test Loss: 407.228 | Test Loss [MAPE]: 1092752.476 --time-- 11.272485256195068\n",
      "Epoch 484/500 | Train Loss: 273.116 | Test Loss: 261.040 | Test Loss [MAPE]: 867958.401 --time-- 11.291837930679321\n",
      "Epoch 485/500 | Train Loss: 237.010 | Test Loss: 366.791 | Test Loss [MAPE]: 1102004.602 --time-- 11.277355432510376\n",
      "Epoch 486/500 | Train Loss: 244.342 | Test Loss: 247.388 | Test Loss [MAPE]: 836114.362 --time-- 11.269495248794556\n",
      "Epoch 487/500 | Train Loss: 214.181 | Test Loss: 295.884 | Test Loss [MAPE]: 980168.389 --time-- 11.263349056243896\n",
      "Epoch 488/500 | Train Loss: 221.829 | Test Loss: 289.771 | Test Loss [MAPE]: 966961.240 --time-- 11.265575408935547\n",
      "Epoch 489/500 | Train Loss: 231.178 | Test Loss: 283.023 | Test Loss [MAPE]: 962976.660 --time-- 11.265817880630493\n",
      "Epoch 490/500 | Train Loss: 241.360 | Test Loss: 299.121 | Test Loss [MAPE]: 1014594.973 --time-- 11.263791561126709\n",
      "Epoch 491/500 | Train Loss: 232.417 | Test Loss: 268.263 | Test Loss [MAPE]: 923458.593 --time-- 11.2666597366333\n",
      "Epoch 492/500 | Train Loss: 240.825 | Test Loss: 312.608 | Test Loss [MAPE]: 891340.281 --time-- 11.267162561416626\n",
      "Epoch 493/500 | Train Loss: 240.015 | Test Loss: 287.266 | Test Loss [MAPE]: 965955.401 --time-- 11.270738124847412\n",
      "Epoch 494/500 | Train Loss: 237.985 | Test Loss: 299.039 | Test Loss [MAPE]: 1015339.683 --time-- 11.264929294586182\n",
      "Epoch 495/500 | Train Loss: 258.315 | Test Loss: 272.412 | Test Loss [MAPE]: 931796.980 --time-- 11.264641761779785\n",
      "Epoch 496/500 | Train Loss: 253.508 | Test Loss: 300.752 | Test Loss [MAPE]: 938131.024 --time-- 11.26245927810669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/500 | Train Loss: 246.685 | Test Loss: 275.435 | Test Loss [MAPE]: 907336.571 --time-- 11.264875411987305\n",
      "Epoch 498/500 | Train Loss: 213.554 | Test Loss: 251.896 | Test Loss [MAPE]: 877354.786 --time-- 11.264353275299072\n",
      "Epoch 499/500 | Train Loss: 225.970 | Test Loss: 277.272 | Test Loss [MAPE]: 976648.338 --time-- 11.263154745101929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 05:21:44,101] Trial 41 finished with value: 563589.8567047119 and parameters: {'num_conv_layers': 4, 'kernel_size': 3, 'num_channels': 47, 'pooling_type': 'avg', 'conv_stride': 1, 'feedforward_size': 109, 'pool_stride': 2, 'learning_rate': 0.0036206043832452796, 'reg_strength': 0.0021770744986250312, 'bs': 118}. Best is trial 34 with value: 425934.69303131104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500 | Train Loss: 235.889 | Test Loss: 277.074 | Test Loss [MAPE]: 970989.150 --time-- 11.265805959701538\n",
      "5639.395282030106\n",
      "Epoch 1/500 | Train Loss: 5109.572 | Test Loss: 5161.739 | Test Loss [MAPE]: 429602.928 --time-- 2.4506070613861084\n",
      "Epoch 2/500 | Train Loss: 5106.365 | Test Loss: 5161.764 | Test Loss [MAPE]: 431065.183 --time-- 2.4275693893432617\n",
      "Epoch 3/500 | Train Loss: 5106.393 | Test Loss: 5161.769 | Test Loss [MAPE]: 418325.194 --time-- 2.4213907718658447\n",
      "Epoch 4/500 | Train Loss: 5106.386 | Test Loss: 5161.693 | Test Loss [MAPE]: 422311.585 --time-- 2.4237048625946045\n",
      "Epoch 5/500 | Train Loss: 5106.368 | Test Loss: 5161.727 | Test Loss [MAPE]: 419441.446 --time-- 2.4189682006835938\n",
      "Epoch 6/500 | Train Loss: 5106.406 | Test Loss: 5161.742 | Test Loss [MAPE]: 424242.594 --time-- 2.42065167427063\n",
      "Epoch 7/500 | Train Loss: 5106.401 | Test Loss: 5161.773 | Test Loss [MAPE]: 431093.478 --time-- 2.426013231277466\n",
      "Epoch 8/500 | Train Loss: 5106.397 | Test Loss: 5161.739 | Test Loss [MAPE]: 430475.269 --time-- 2.4229164123535156\n",
      "Epoch 9/500 | Train Loss: 5106.375 | Test Loss: 5161.736 | Test Loss [MAPE]: 431044.957 --time-- 2.4218289852142334\n",
      "Epoch 10/500 | Train Loss: 5106.353 | Test Loss: 5162.008 | Test Loss [MAPE]: 443462.293 --time-- 2.424490451812744\n",
      "Epoch 11/500 | Train Loss: 5106.431 | Test Loss: 5161.746 | Test Loss [MAPE]: 427775.916 --time-- 2.4225573539733887\n",
      "Epoch 12/500 | Train Loss: 5106.388 | Test Loss: 5161.725 | Test Loss [MAPE]: 428736.111 --time-- 2.4226057529449463\n",
      "Epoch 13/500 | Train Loss: 5106.414 | Test Loss: 5161.702 | Test Loss [MAPE]: 422666.531 --time-- 2.4213755130767822\n",
      "Epoch 14/500 | Train Loss: 5106.357 | Test Loss: 5161.836 | Test Loss [MAPE]: 437061.622 --time-- 2.422086238861084\n",
      "Epoch 15/500 | Train Loss: 5106.378 | Test Loss: 5161.734 | Test Loss [MAPE]: 427649.625 --time-- 2.4220938682556152\n",
      "Epoch 16/500 | Train Loss: 5106.370 | Test Loss: 5161.719 | Test Loss [MAPE]: 425969.826 --time-- 2.4206807613372803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 05:22:25,970] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.393 | Test Loss: 5161.788 | Test Loss [MAPE]: 418297.682 --time-- 2.4214634895324707\n",
      "Epoch 1/500 | Train Loss: 5160.313 | Test Loss: 5161.732 | Test Loss [MAPE]: 426387.071 --time-- 3.6604840755462646\n",
      "Epoch 2/500 | Train Loss: 5106.379 | Test Loss: 5161.752 | Test Loss [MAPE]: 431047.356 --time-- 3.643698215484619\n",
      "Epoch 3/500 | Train Loss: 5106.379 | Test Loss: 5161.758 | Test Loss [MAPE]: 424018.560 --time-- 3.6494860649108887\n",
      "Epoch 4/500 | Train Loss: 5106.354 | Test Loss: 5161.717 | Test Loss [MAPE]: 419314.805 --time-- 3.647984504699707\n",
      "Epoch 5/500 | Train Loss: 5117.756 | Test Loss: 5162.753 | Test Loss [MAPE]: 442456.840 --time-- 3.6447579860687256\n",
      "Epoch 6/500 | Train Loss: 5106.966 | Test Loss: 5161.724 | Test Loss [MAPE]: 422919.834 --time-- 3.6592628955841064\n",
      "Epoch 7/500 | Train Loss: 5106.378 | Test Loss: 5161.692 | Test Loss [MAPE]: 424963.661 --time-- 3.6660544872283936\n",
      "Epoch 8/500 | Train Loss: 5106.390 | Test Loss: 5161.694 | Test Loss [MAPE]: 422484.694 --time-- 3.6657817363739014\n",
      "Epoch 9/500 | Train Loss: 5106.346 | Test Loss: 5161.865 | Test Loss [MAPE]: 414664.202 --time-- 3.665738105773926\n",
      "Epoch 10/500 | Train Loss: 5106.403 | Test Loss: 5161.739 | Test Loss [MAPE]: 419637.471 --time-- 3.6658360958099365\n",
      "Epoch 11/500 | Train Loss: 5106.372 | Test Loss: 5161.715 | Test Loss [MAPE]: 426325.616 --time-- 3.6634998321533203\n",
      "Epoch 12/500 | Train Loss: 5106.386 | Test Loss: 5161.751 | Test Loss [MAPE]: 429896.354 --time-- 3.665491819381714\n",
      "Epoch 13/500 | Train Loss: 5106.427 | Test Loss: 5161.716 | Test Loss [MAPE]: 423994.205 --time-- 3.663419246673584\n",
      "Epoch 14/500 | Train Loss: 5106.380 | Test Loss: 5161.723 | Test Loss [MAPE]: 425487.546 --time-- 3.6668379306793213\n",
      "Epoch 15/500 | Train Loss: 5106.403 | Test Loss: 5161.726 | Test Loss [MAPE]: 425587.328 --time-- 3.6686179637908936\n",
      "Epoch 16/500 | Train Loss: 5106.388 | Test Loss: 5161.708 | Test Loss [MAPE]: 424850.015 --time-- 3.6635830402374268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 05:23:28,822] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.359 | Test Loss: 5161.788 | Test Loss [MAPE]: 428549.046 --time-- 3.6657280921936035\n",
      "Epoch 1/500 | Train Loss: 5110.384 | Test Loss: 5161.764 | Test Loss [MAPE]: 420319.070 --time-- 1.825913906097412\n",
      "Epoch 2/500 | Train Loss: 5076.142 | Test Loss: 4950.684 | Test Loss [MAPE]: 8526225.493 --time-- 1.782499074935913\n",
      "Epoch 3/500 | Train Loss: 4374.795 | Test Loss: 4195.396 | Test Loss [MAPE]: 2468589.635 --time-- 1.790630578994751\n",
      "Epoch 4/500 | Train Loss: 4164.297 | Test Loss: 4130.788 | Test Loss [MAPE]: 1843859.348 --time-- 1.787235975265503\n",
      "Epoch 5/500 | Train Loss: 4113.037 | Test Loss: 4126.408 | Test Loss [MAPE]: 1212662.675 --time-- 1.7825586795806885\n",
      "Epoch 6/500 | Train Loss: 4070.814 | Test Loss: 4060.207 | Test Loss [MAPE]: 1466423.414 --time-- 1.7841613292694092\n",
      "Epoch 7/500 | Train Loss: 4008.620 | Test Loss: 4005.136 | Test Loss [MAPE]: 2504292.088 --time-- 1.8137893676757812\n",
      "Epoch 8/500 | Train Loss: 3953.555 | Test Loss: 3938.422 | Test Loss [MAPE]: 2072685.641 --time-- 1.835399866104126\n",
      "Epoch 9/500 | Train Loss: 3897.329 | Test Loss: 3891.700 | Test Loss [MAPE]: 2246590.999 --time-- 1.8309357166290283\n",
      "Epoch 10/500 | Train Loss: 3852.039 | Test Loss: 3826.791 | Test Loss [MAPE]: 2903380.180 --time-- 1.8321526050567627\n",
      "Epoch 11/500 | Train Loss: 3797.120 | Test Loss: 3786.162 | Test Loss [MAPE]: 3235099.464 --time-- 1.8303651809692383\n",
      "Epoch 12/500 | Train Loss: 3730.024 | Test Loss: 3714.584 | Test Loss [MAPE]: 3359646.845 --time-- 1.832991123199463\n",
      "Epoch 13/500 | Train Loss: 3661.975 | Test Loss: 3633.891 | Test Loss [MAPE]: 3692608.506 --time-- 1.8341436386108398\n",
      "Epoch 14/500 | Train Loss: 3586.993 | Test Loss: 3558.853 | Test Loss [MAPE]: 4309196.292 --time-- 1.8325679302215576\n",
      "Epoch 15/500 | Train Loss: 3510.958 | Test Loss: 3487.231 | Test Loss [MAPE]: 4180125.519 --time-- 1.8332884311676025\n",
      "Epoch 16/500 | Train Loss: 3433.975 | Test Loss: 3391.844 | Test Loss [MAPE]: 4634275.829 --time-- 1.8306505680084229\n",
      "Epoch 17/500 | Train Loss: 3399.590 | Test Loss: 3342.797 | Test Loss [MAPE]: 4470174.799 --time-- 1.779160499572754\n",
      "Epoch 18/500 | Train Loss: 3309.378 | Test Loss: 3258.471 | Test Loss [MAPE]: 4494117.854 --time-- 1.7828404903411865\n",
      "Epoch 19/500 | Train Loss: 3242.832 | Test Loss: 3219.024 | Test Loss [MAPE]: 4280048.088 --time-- 1.7798616886138916\n",
      "Epoch 20/500 | Train Loss: 3182.977 | Test Loss: 3154.105 | Test Loss [MAPE]: 4427106.062 --time-- 1.783954381942749\n",
      "Epoch 21/500 | Train Loss: 3130.646 | Test Loss: 3106.561 | Test Loss [MAPE]: 4390995.627 --time-- 1.7824702262878418\n",
      "Epoch 22/500 | Train Loss: 3081.287 | Test Loss: 3033.936 | Test Loss [MAPE]: 4075421.217 --time-- 1.7817165851593018\n",
      "Epoch 23/500 | Train Loss: 3005.622 | Test Loss: 2971.783 | Test Loss [MAPE]: 4129765.346 --time-- 1.7816758155822754\n",
      "Epoch 24/500 | Train Loss: 2960.458 | Test Loss: 2930.574 | Test Loss [MAPE]: 3689757.235 --time-- 1.7814195156097412\n",
      "Epoch 25/500 | Train Loss: 2903.274 | Test Loss: 2905.809 | Test Loss [MAPE]: 4068618.840 --time-- 1.7847435474395752\n",
      "Epoch 26/500 | Train Loss: 2874.864 | Test Loss: 3022.128 | Test Loss [MAPE]: 2858599.202 --time-- 1.77947998046875\n",
      "Epoch 27/500 | Train Loss: 2884.946 | Test Loss: 2805.919 | Test Loss [MAPE]: 3585767.061 --time-- 1.7854957580566406\n",
      "Epoch 28/500 | Train Loss: 2779.792 | Test Loss: 2777.525 | Test Loss [MAPE]: 3157819.463 --time-- 1.7833037376403809\n",
      "Epoch 29/500 | Train Loss: 2738.305 | Test Loss: 2709.901 | Test Loss [MAPE]: 3200230.226 --time-- 1.7843480110168457\n",
      "Epoch 30/500 | Train Loss: 2722.635 | Test Loss: 2695.741 | Test Loss [MAPE]: 2913590.378 --time-- 1.7850003242492676\n",
      "Epoch 31/500 | Train Loss: 2675.278 | Test Loss: 2667.298 | Test Loss [MAPE]: 3321247.005 --time-- 1.784292221069336\n",
      "Epoch 32/500 | Train Loss: 2645.469 | Test Loss: 2628.195 | Test Loss [MAPE]: 2951229.352 --time-- 1.7833008766174316\n",
      "Epoch 33/500 | Train Loss: 2613.156 | Test Loss: 2594.912 | Test Loss [MAPE]: 2967560.561 --time-- 1.781991720199585\n",
      "Epoch 34/500 | Train Loss: 2628.680 | Test Loss: 2608.689 | Test Loss [MAPE]: 3035024.480 --time-- 1.7887468338012695\n",
      "Epoch 35/500 | Train Loss: 2573.655 | Test Loss: 2566.311 | Test Loss [MAPE]: 2875224.171 --time-- 1.7814278602600098\n",
      "Epoch 36/500 | Train Loss: 2545.481 | Test Loss: 2533.212 | Test Loss [MAPE]: 3016235.117 --time-- 1.7833821773529053\n",
      "Epoch 37/500 | Train Loss: 2524.720 | Test Loss: 2508.244 | Test Loss [MAPE]: 3078853.786 --time-- 1.7836873531341553\n",
      "Epoch 38/500 | Train Loss: 2508.615 | Test Loss: 2498.117 | Test Loss [MAPE]: 2916864.921 --time-- 1.7806549072265625\n",
      "Epoch 39/500 | Train Loss: 2482.330 | Test Loss: 2495.141 | Test Loss [MAPE]: 3147929.585 --time-- 1.7788112163543701\n",
      "Epoch 40/500 | Train Loss: 2475.759 | Test Loss: 2440.142 | Test Loss [MAPE]: 3155183.742 --time-- 1.7825560569763184\n",
      "Epoch 41/500 | Train Loss: 2429.836 | Test Loss: 2443.280 | Test Loss [MAPE]: 2923488.497 --time-- 1.7839930057525635\n",
      "Epoch 42/500 | Train Loss: 2420.242 | Test Loss: 2427.941 | Test Loss [MAPE]: 2918565.845 --time-- 1.7824516296386719\n",
      "Epoch 43/500 | Train Loss: 2411.726 | Test Loss: 2399.142 | Test Loss [MAPE]: 2873191.113 --time-- 1.7828755378723145\n",
      "Epoch 44/500 | Train Loss: 2377.178 | Test Loss: 2429.273 | Test Loss [MAPE]: 3134952.228 --time-- 1.7838211059570312\n",
      "Epoch 45/500 | Train Loss: 2364.420 | Test Loss: 2358.017 | Test Loss [MAPE]: 3005863.322 --time-- 1.7840754985809326\n",
      "Epoch 46/500 | Train Loss: 2317.729 | Test Loss: 2318.356 | Test Loss [MAPE]: 3050883.079 --time-- 1.7857515811920166\n",
      "Epoch 47/500 | Train Loss: 2293.977 | Test Loss: 2278.921 | Test Loss [MAPE]: 3180154.427 --time-- 1.7844469547271729\n",
      "Epoch 48/500 | Train Loss: 2262.469 | Test Loss: 2249.050 | Test Loss [MAPE]: 3107626.776 --time-- 1.7814137935638428\n",
      "Epoch 49/500 | Train Loss: 2245.193 | Test Loss: 2229.770 | Test Loss [MAPE]: 3171046.469 --time-- 1.782047986984253\n",
      "Epoch 50/500 | Train Loss: 2235.775 | Test Loss: 2250.164 | Test Loss [MAPE]: 3081356.180 --time-- 1.7821240425109863\n",
      "Epoch 51/500 | Train Loss: 2195.636 | Test Loss: 2182.076 | Test Loss [MAPE]: 2984463.704 --time-- 1.7836294174194336\n",
      "Epoch 52/500 | Train Loss: 2176.253 | Test Loss: 2170.691 | Test Loss [MAPE]: 2827025.050 --time-- 1.7849831581115723\n",
      "Epoch 53/500 | Train Loss: 2168.278 | Test Loss: 2155.761 | Test Loss [MAPE]: 2789905.000 --time-- 1.78391695022583\n",
      "Epoch 54/500 | Train Loss: 2140.041 | Test Loss: 2127.552 | Test Loss [MAPE]: 2895112.334 --time-- 1.7832908630371094\n",
      "Epoch 55/500 | Train Loss: 2124.160 | Test Loss: 2118.298 | Test Loss [MAPE]: 3006584.678 --time-- 1.783808946609497\n",
      "Epoch 56/500 | Train Loss: 2117.881 | Test Loss: 2123.258 | Test Loss [MAPE]: 2824616.931 --time-- 1.7818934917449951\n",
      "Epoch 57/500 | Train Loss: 2090.167 | Test Loss: 2080.623 | Test Loss [MAPE]: 2962205.316 --time-- 1.7822151184082031\n",
      "Epoch 58/500 | Train Loss: 2089.528 | Test Loss: 2076.727 | Test Loss [MAPE]: 2946875.013 --time-- 1.782987356185913\n",
      "Epoch 59/500 | Train Loss: 2063.459 | Test Loss: 2114.857 | Test Loss [MAPE]: 2801772.315 --time-- 1.7842092514038086\n",
      "Epoch 60/500 | Train Loss: 2050.247 | Test Loss: 2050.936 | Test Loss [MAPE]: 2658654.556 --time-- 1.7883806228637695\n",
      "Epoch 61/500 | Train Loss: 2054.104 | Test Loss: 2033.967 | Test Loss [MAPE]: 2780701.002 --time-- 1.7823076248168945\n",
      "Epoch 62/500 | Train Loss: 2020.240 | Test Loss: 2009.421 | Test Loss [MAPE]: 2832228.394 --time-- 1.792240858078003\n",
      "Epoch 63/500 | Train Loss: 2007.153 | Test Loss: 2025.037 | Test Loss [MAPE]: 2755246.088 --time-- 1.7914173603057861\n",
      "Epoch 64/500 | Train Loss: 2034.195 | Test Loss: 2310.864 | Test Loss [MAPE]: 3700906.322 --time-- 1.783463716506958\n",
      "Epoch 65/500 | Train Loss: 2204.270 | Test Loss: 2068.373 | Test Loss [MAPE]: 2989979.572 --time-- 1.7828338146209717\n",
      "Epoch 66/500 | Train Loss: 1988.793 | Test Loss: 1954.312 | Test Loss [MAPE]: 2675739.394 --time-- 1.7823965549468994\n",
      "Epoch 67/500 | Train Loss: 1952.382 | Test Loss: 1943.611 | Test Loss [MAPE]: 2658243.479 --time-- 1.7852342128753662\n",
      "Epoch 68/500 | Train Loss: 1942.766 | Test Loss: 1954.778 | Test Loss [MAPE]: 2700770.366 --time-- 1.7817018032073975\n",
      "Epoch 69/500 | Train Loss: 1937.543 | Test Loss: 1934.413 | Test Loss [MAPE]: 2535621.665 --time-- 1.784303903579712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500 | Train Loss: 1920.691 | Test Loss: 1933.183 | Test Loss [MAPE]: 2758224.336 --time-- 1.7816376686096191\n",
      "Epoch 71/500 | Train Loss: 1923.489 | Test Loss: 1959.589 | Test Loss [MAPE]: 2749069.380 --time-- 1.7845802307128906\n",
      "Epoch 72/500 | Train Loss: 1910.816 | Test Loss: 1909.479 | Test Loss [MAPE]: 2484418.398 --time-- 1.7807557582855225\n",
      "Epoch 73/500 | Train Loss: 1907.046 | Test Loss: 1931.492 | Test Loss [MAPE]: 2433788.125 --time-- 1.7865409851074219\n",
      "Epoch 74/500 | Train Loss: 1906.400 | Test Loss: 1927.380 | Test Loss [MAPE]: 2660983.026 --time-- 1.7843503952026367\n",
      "Epoch 75/500 | Train Loss: 1900.703 | Test Loss: 1905.389 | Test Loss [MAPE]: 2621953.622 --time-- 1.78537917137146\n",
      "Epoch 76/500 | Train Loss: 1894.830 | Test Loss: 1899.538 | Test Loss [MAPE]: 2496705.431 --time-- 1.783961534500122\n",
      "Epoch 77/500 | Train Loss: 1865.840 | Test Loss: 1873.680 | Test Loss [MAPE]: 2358969.581 --time-- 1.7879078388214111\n",
      "Epoch 78/500 | Train Loss: 1857.786 | Test Loss: 1894.646 | Test Loss [MAPE]: 2534078.421 --time-- 1.7827820777893066\n",
      "Epoch 79/500 | Train Loss: 1854.037 | Test Loss: 1883.839 | Test Loss [MAPE]: 2507903.930 --time-- 1.7856254577636719\n",
      "Epoch 80/500 | Train Loss: 1855.246 | Test Loss: 1871.765 | Test Loss [MAPE]: 2290065.956 --time-- 1.7821991443634033\n",
      "Epoch 81/500 | Train Loss: 1850.796 | Test Loss: 1877.834 | Test Loss [MAPE]: 2472533.579 --time-- 1.7874970436096191\n",
      "Epoch 82/500 | Train Loss: 1838.730 | Test Loss: 1845.079 | Test Loss [MAPE]: 2492080.248 --time-- 1.7852625846862793\n",
      "Epoch 83/500 | Train Loss: 1841.459 | Test Loss: 1839.323 | Test Loss [MAPE]: 2365071.391 --time-- 1.7813794612884521\n",
      "Epoch 84/500 | Train Loss: 1837.041 | Test Loss: 1856.677 | Test Loss [MAPE]: 2298250.489 --time-- 1.7838566303253174\n",
      "Epoch 85/500 | Train Loss: 1825.801 | Test Loss: 1810.516 | Test Loss [MAPE]: 2220960.931 --time-- 1.7870545387268066\n",
      "Epoch 86/500 | Train Loss: 1806.540 | Test Loss: 1816.772 | Test Loss [MAPE]: 2330831.158 --time-- 1.783174753189087\n",
      "Epoch 87/500 | Train Loss: 1822.451 | Test Loss: 1875.611 | Test Loss [MAPE]: 2355666.084 --time-- 1.7856757640838623\n",
      "Epoch 88/500 | Train Loss: 1830.331 | Test Loss: 1822.994 | Test Loss [MAPE]: 2192324.907 --time-- 1.7809650897979736\n",
      "Epoch 89/500 | Train Loss: 1799.935 | Test Loss: 1809.535 | Test Loss [MAPE]: 2322858.332 --time-- 1.7832896709442139\n",
      "Epoch 90/500 | Train Loss: 1794.697 | Test Loss: 1802.919 | Test Loss [MAPE]: 2336643.818 --time-- 1.783238410949707\n",
      "Epoch 91/500 | Train Loss: 1801.710 | Test Loss: 1798.884 | Test Loss [MAPE]: 2201283.738 --time-- 1.7842345237731934\n",
      "Epoch 92/500 | Train Loss: 1797.251 | Test Loss: 1809.326 | Test Loss [MAPE]: 2305806.918 --time-- 1.7833726406097412\n",
      "Epoch 93/500 | Train Loss: 1793.915 | Test Loss: 1782.665 | Test Loss [MAPE]: 2218646.726 --time-- 1.7821862697601318\n",
      "Epoch 94/500 | Train Loss: 1782.138 | Test Loss: 1793.923 | Test Loss [MAPE]: 2170359.341 --time-- 1.785740613937378\n",
      "Epoch 95/500 | Train Loss: 1777.155 | Test Loss: 1785.229 | Test Loss [MAPE]: 2215936.101 --time-- 1.783858060836792\n",
      "Epoch 96/500 | Train Loss: 1771.595 | Test Loss: 1782.463 | Test Loss [MAPE]: 2178741.288 --time-- 1.7865588665008545\n",
      "Epoch 97/500 | Train Loss: 1786.106 | Test Loss: 1785.592 | Test Loss [MAPE]: 2211379.879 --time-- 1.7864906787872314\n",
      "Epoch 98/500 | Train Loss: 1782.120 | Test Loss: 1774.363 | Test Loss [MAPE]: 2301364.164 --time-- 1.7833716869354248\n",
      "Epoch 99/500 | Train Loss: 1754.036 | Test Loss: 1775.428 | Test Loss [MAPE]: 2251758.508 --time-- 1.7810742855072021\n",
      "Epoch 100/500 | Train Loss: 1754.715 | Test Loss: 1762.601 | Test Loss [MAPE]: 2219198.409 --time-- 1.7860102653503418\n",
      "Epoch 101/500 | Train Loss: 1757.018 | Test Loss: 1774.487 | Test Loss [MAPE]: 2198847.506 --time-- 1.780961275100708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 05:26:33,368] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500 | Train Loss: 1748.315 | Test Loss: 1755.978 | Test Loss [MAPE]: 2135019.617 --time-- 1.7844922542572021\n",
      "Epoch 1/500 | Train Loss: 5127.214 | Test Loss: 5161.893 | Test Loss [MAPE]: 425519.473 --time-- 1.3915836811065674\n",
      "Epoch 2/500 | Train Loss: 5106.425 | Test Loss: 5161.807 | Test Loss [MAPE]: 421666.492 --time-- 1.3380911350250244\n",
      "Epoch 3/500 | Train Loss: 5106.432 | Test Loss: 5161.831 | Test Loss [MAPE]: 435692.179 --time-- 1.3345105648040771\n",
      "Epoch 4/500 | Train Loss: 5106.557 | Test Loss: 5161.809 | Test Loss [MAPE]: 429734.876 --time-- 1.3319981098175049\n",
      "Epoch 5/500 | Train Loss: 5106.475 | Test Loss: 5161.784 | Test Loss [MAPE]: 425262.363 --time-- 1.335015058517456\n",
      "Epoch 6/500 | Train Loss: 5106.515 | Test Loss: 5161.773 | Test Loss [MAPE]: 423105.245 --time-- 1.3332273960113525\n",
      "Epoch 7/500 | Train Loss: 5106.501 | Test Loss: 5161.795 | Test Loss [MAPE]: 420873.696 --time-- 1.3331491947174072\n",
      "Epoch 8/500 | Train Loss: 5106.501 | Test Loss: 5161.898 | Test Loss [MAPE]: 437370.232 --time-- 1.3329806327819824\n",
      "Epoch 9/500 | Train Loss: 5106.567 | Test Loss: 5161.778 | Test Loss [MAPE]: 424921.999 --time-- 1.3352179527282715\n",
      "Epoch 10/500 | Train Loss: 5106.515 | Test Loss: 5161.893 | Test Loss [MAPE]: 433308.639 --time-- 1.3343009948730469\n",
      "Epoch 11/500 | Train Loss: 5106.556 | Test Loss: 5161.947 | Test Loss [MAPE]: 423663.294 --time-- 1.3384852409362793\n",
      "Epoch 12/500 | Train Loss: 5106.505 | Test Loss: 5161.792 | Test Loss [MAPE]: 427359.779 --time-- 1.3351593017578125\n",
      "Epoch 13/500 | Train Loss: 5106.475 | Test Loss: 5161.819 | Test Loss [MAPE]: 422424.568 --time-- 1.3392245769500732\n",
      "Epoch 14/500 | Train Loss: 5106.555 | Test Loss: 5162.484 | Test Loss [MAPE]: 459092.687 --time-- 1.338660478591919\n",
      "Epoch 15/500 | Train Loss: 5106.629 | Test Loss: 5161.846 | Test Loss [MAPE]: 432296.243 --time-- 1.3343205451965332\n",
      "Epoch 16/500 | Train Loss: 5106.646 | Test Loss: 5161.910 | Test Loss [MAPE]: 431110.183 --time-- 1.3349988460540771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 05:26:56,789] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.512 | Test Loss: 5161.821 | Test Loss [MAPE]: 430791.384 --time-- 1.3345627784729004\n",
      "Epoch 1/500 | Train Loss: 5612.825 | Test Loss: 5163.775 | Test Loss [MAPE]: 470211.970 --time-- 9.836463451385498\n",
      "Epoch 2/500 | Train Loss: 5107.396 | Test Loss: 5161.797 | Test Loss [MAPE]: 429202.163 --time-- 9.875571012496948\n",
      "Epoch 3/500 | Train Loss: 5106.326 | Test Loss: 5161.666 | Test Loss [MAPE]: 421107.079 --time-- 9.875848054885864\n",
      "Epoch 4/500 | Train Loss: 5106.305 | Test Loss: 5161.667 | Test Loss [MAPE]: 421856.743 --time-- 9.878934144973755\n",
      "Epoch 5/500 | Train Loss: 5106.297 | Test Loss: 5161.661 | Test Loss [MAPE]: 424306.146 --time-- 9.88139295578003\n",
      "Epoch 6/500 | Train Loss: 5106.309 | Test Loss: 5161.662 | Test Loss [MAPE]: 424265.675 --time-- 9.881636619567871\n",
      "Epoch 7/500 | Train Loss: 5106.301 | Test Loss: 5161.659 | Test Loss [MAPE]: 421943.552 --time-- 9.878985404968262\n",
      "Epoch 8/500 | Train Loss: 5106.301 | Test Loss: 5161.665 | Test Loss [MAPE]: 424663.360 --time-- 9.879763841629028\n",
      "Epoch 9/500 | Train Loss: 5106.308 | Test Loss: 5161.676 | Test Loss [MAPE]: 422520.035 --time-- 9.879308700561523\n",
      "Epoch 10/500 | Train Loss: 5106.308 | Test Loss: 5161.678 | Test Loss [MAPE]: 421543.316 --time-- 9.884398221969604\n",
      "Epoch 11/500 | Train Loss: 5106.315 | Test Loss: 5161.665 | Test Loss [MAPE]: 421926.572 --time-- 9.878723382949829\n",
      "Epoch 12/500 | Train Loss: 5106.320 | Test Loss: 5161.673 | Test Loss [MAPE]: 425073.081 --time-- 9.880443811416626\n",
      "Epoch 13/500 | Train Loss: 5106.322 | Test Loss: 5161.700 | Test Loss [MAPE]: 419442.043 --time-- 9.881638050079346\n",
      "Epoch 14/500 | Train Loss: 5106.320 | Test Loss: 5161.692 | Test Loss [MAPE]: 423496.182 --time-- 9.877782821655273\n",
      "Epoch 15/500 | Train Loss: 5106.323 | Test Loss: 5161.704 | Test Loss [MAPE]: 428727.707 --time-- 9.878559112548828\n",
      "Epoch 16/500 | Train Loss: 5106.309 | Test Loss: 5161.682 | Test Loss [MAPE]: 419574.996 --time-- 9.880631685256958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 05:29:45,600] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.318 | Test Loss: 5161.674 | Test Loss [MAPE]: 424058.062 --time-- 9.879892587661743\n",
      "Epoch 1/500 | Train Loss: 14568.720 | Test Loss: 5163.946 | Test Loss [MAPE]: 480726.761 --time-- 7.112789869308472\n",
      "Epoch 2/500 | Train Loss: 5106.688 | Test Loss: 5161.708 | Test Loss [MAPE]: 424680.613 --time-- 7.12101411819458\n",
      "Epoch 3/500 | Train Loss: 5106.325 | Test Loss: 5161.693 | Test Loss [MAPE]: 419390.389 --time-- 7.128292083740234\n",
      "Epoch 4/500 | Train Loss: 5106.319 | Test Loss: 5161.704 | Test Loss [MAPE]: 427629.116 --time-- 7.1260905265808105\n",
      "Epoch 5/500 | Train Loss: 5106.357 | Test Loss: 5161.686 | Test Loss [MAPE]: 424669.015 --time-- 7.129514455795288\n",
      "Epoch 6/500 | Train Loss: 5106.413 | Test Loss: 5161.701 | Test Loss [MAPE]: 422684.014 --time-- 7.122553110122681\n",
      "Epoch 7/500 | Train Loss: 5106.342 | Test Loss: 5161.714 | Test Loss [MAPE]: 423797.799 --time-- 7.127466440200806\n",
      "Epoch 8/500 | Train Loss: 5106.349 | Test Loss: 5161.705 | Test Loss [MAPE]: 424022.411 --time-- 7.074569225311279\n",
      "Epoch 9/500 | Train Loss: 5106.351 | Test Loss: 5161.746 | Test Loss [MAPE]: 429609.525 --time-- 7.0762505531311035\n",
      "Epoch 10/500 | Train Loss: 5106.383 | Test Loss: 5161.960 | Test Loss [MAPE]: 441318.682 --time-- 7.074258804321289\n",
      "Epoch 11/500 | Train Loss: 5106.437 | Test Loss: 5161.737 | Test Loss [MAPE]: 428111.166 --time-- 7.077688455581665\n",
      "Epoch 12/500 | Train Loss: 5106.398 | Test Loss: 5161.724 | Test Loss [MAPE]: 422056.796 --time-- 7.075981140136719\n",
      "Epoch 13/500 | Train Loss: 5106.370 | Test Loss: 5161.737 | Test Loss [MAPE]: 423643.853 --time-- 7.0758538246154785\n",
      "Epoch 14/500 | Train Loss: 5106.367 | Test Loss: 5161.754 | Test Loss [MAPE]: 418591.278 --time-- 7.076450824737549\n",
      "Epoch 15/500 | Train Loss: 5106.384 | Test Loss: 5161.780 | Test Loss [MAPE]: 433020.662 --time-- 7.0748772621154785\n",
      "Epoch 16/500 | Train Loss: 5106.416 | Test Loss: 5161.964 | Test Loss [MAPE]: 414432.423 --time-- 7.0753748416900635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 05:31:46,936] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.458 | Test Loss: 5161.745 | Test Loss [MAPE]: 429532.805 --time-- 7.078631401062012\n",
      "Epoch 1/500 | Train Loss: 5578.285 | Test Loss: 5162.133 | Test Loss [MAPE]: 446128.353 --time-- 2.129812479019165\n",
      "Epoch 2/500 | Train Loss: 5106.480 | Test Loss: 5161.810 | Test Loss [MAPE]: 419510.965 --time-- 2.0933563709259033\n",
      "Epoch 3/500 | Train Loss: 5106.432 | Test Loss: 5161.760 | Test Loss [MAPE]: 421632.776 --time-- 2.0891594886779785\n",
      "Epoch 4/500 | Train Loss: 5106.436 | Test Loss: 5161.779 | Test Loss [MAPE]: 423878.172 --time-- 2.0884902477264404\n",
      "Epoch 5/500 | Train Loss: 5106.465 | Test Loss: 5161.770 | Test Loss [MAPE]: 425612.997 --time-- 2.0890047550201416\n",
      "Epoch 6/500 | Train Loss: 5106.449 | Test Loss: 5161.793 | Test Loss [MAPE]: 422298.588 --time-- 2.089421033859253\n",
      "Epoch 7/500 | Train Loss: 5106.561 | Test Loss: 5161.799 | Test Loss [MAPE]: 429918.103 --time-- 2.087822675704956\n",
      "Epoch 8/500 | Train Loss: 5106.490 | Test Loss: 5161.828 | Test Loss [MAPE]: 428556.308 --time-- 2.0860371589660645\n",
      "Epoch 9/500 | Train Loss: 5106.491 | Test Loss: 5161.859 | Test Loss [MAPE]: 437142.145 --time-- 2.0895233154296875\n",
      "Epoch 10/500 | Train Loss: 5106.491 | Test Loss: 5161.885 | Test Loss [MAPE]: 422168.217 --time-- 2.134859561920166\n",
      "Epoch 11/500 | Train Loss: 5106.544 | Test Loss: 5161.882 | Test Loss [MAPE]: 435271.185 --time-- 2.133059501647949\n",
      "Epoch 12/500 | Train Loss: 5106.531 | Test Loss: 5162.047 | Test Loss [MAPE]: 415968.970 --time-- 2.1352925300598145\n",
      "Epoch 13/500 | Train Loss: 5106.652 | Test Loss: 5162.084 | Test Loss [MAPE]: 442932.212 --time-- 2.138496160507202\n",
      "Epoch 14/500 | Train Loss: 5106.654 | Test Loss: 5161.785 | Test Loss [MAPE]: 421768.134 --time-- 2.0912280082702637\n",
      "Epoch 15/500 | Train Loss: 5106.653 | Test Loss: 5161.932 | Test Loss [MAPE]: 425675.157 --time-- 2.088083505630493\n",
      "Epoch 16/500 | Train Loss: 5106.550 | Test Loss: 5161.832 | Test Loss [MAPE]: 417728.407 --time-- 2.0871801376342773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 05:32:23,322] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.600 | Test Loss: 5162.038 | Test Loss [MAPE]: 416721.116 --time-- 2.090668201446533\n",
      "Epoch 1/500 | Train Loss: 5489.543 | Test Loss: 5210.829 | Test Loss [MAPE]: 698900.397 --time-- 25.66823649406433\n",
      "Epoch 2/500 | Train Loss: 5152.608 | Test Loss: 5174.687 | Test Loss [MAPE]: 866151.630 --time-- 25.593218326568604\n",
      "Epoch 3/500 | Train Loss: 5007.359 | Test Loss: 4689.557 | Test Loss [MAPE]: 2757906.639 --time-- 25.402660369873047\n",
      "Epoch 4/500 | Train Loss: 4263.711 | Test Loss: 4145.556 | Test Loss [MAPE]: 1693026.626 --time-- 25.586050748825073\n",
      "Epoch 5/500 | Train Loss: 4101.928 | Test Loss: 4083.710 | Test Loss [MAPE]: 2269153.840 --time-- 25.618129014968872\n",
      "Epoch 6/500 | Train Loss: 4024.709 | Test Loss: 3994.360 | Test Loss [MAPE]: 1942481.980 --time-- 25.628217935562134\n",
      "Epoch 7/500 | Train Loss: 3935.904 | Test Loss: 3888.335 | Test Loss [MAPE]: 3368768.083 --time-- 25.60488748550415\n",
      "Epoch 8/500 | Train Loss: 3807.977 | Test Loss: 3729.880 | Test Loss [MAPE]: 4245050.294 --time-- 25.59226703643799\n",
      "Epoch 9/500 | Train Loss: 3619.565 | Test Loss: 3484.486 | Test Loss [MAPE]: 6239379.935 --time-- 25.573682069778442\n",
      "Epoch 10/500 | Train Loss: 3269.564 | Test Loss: 3027.103 | Test Loss [MAPE]: 7576267.413 --time-- 25.552794694900513\n",
      "Epoch 11/500 | Train Loss: 2999.995 | Test Loss: 2753.707 | Test Loss [MAPE]: 7059269.301 --time-- 25.422162294387817\n",
      "Epoch 12/500 | Train Loss: 2585.312 | Test Loss: 2406.640 | Test Loss [MAPE]: 6825099.786 --time-- 25.411811351776123\n",
      "Epoch 13/500 | Train Loss: 2191.866 | Test Loss: 2015.697 | Test Loss [MAPE]: 5584536.692 --time-- 25.45381212234497\n",
      "Epoch 14/500 | Train Loss: 1799.544 | Test Loss: 1677.442 | Test Loss [MAPE]: 4711411.996 --time-- 25.40045666694641\n",
      "Epoch 15/500 | Train Loss: 1584.938 | Test Loss: 1485.291 | Test Loss [MAPE]: 3955498.251 --time-- 25.392242431640625\n",
      "Epoch 16/500 | Train Loss: 1405.560 | Test Loss: 1328.290 | Test Loss [MAPE]: 3400886.237 --time-- 25.39294934272766\n",
      "Epoch 17/500 | Train Loss: 1243.512 | Test Loss: 1179.237 | Test Loss [MAPE]: 3213201.239 --time-- 25.384033203125\n",
      "Epoch 18/500 | Train Loss: 1122.740 | Test Loss: 1096.350 | Test Loss [MAPE]: 3099574.553 --time-- 25.37483835220337\n",
      "Epoch 19/500 | Train Loss: 1143.140 | Test Loss: 1152.519 | Test Loss [MAPE]: 2756275.710 --time-- 25.35844349861145\n",
      "Epoch 20/500 | Train Loss: 1093.685 | Test Loss: 1012.450 | Test Loss [MAPE]: 2569009.187 --time-- 25.378633499145508\n",
      "Epoch 21/500 | Train Loss: 951.325 | Test Loss: 987.765 | Test Loss [MAPE]: 2511760.409 --time-- 25.384329795837402\n",
      "Epoch 22/500 | Train Loss: 913.521 | Test Loss: 871.366 | Test Loss [MAPE]: 2271493.149 --time-- 25.37892460823059\n",
      "Epoch 23/500 | Train Loss: 847.285 | Test Loss: 835.719 | Test Loss [MAPE]: 2121158.164 --time-- 25.407129049301147\n",
      "Epoch 24/500 | Train Loss: 802.884 | Test Loss: 811.783 | Test Loss [MAPE]: 1882783.689 --time-- 25.38071298599243\n",
      "Epoch 25/500 | Train Loss: 749.183 | Test Loss: 783.829 | Test Loss [MAPE]: 2071268.303 --time-- 25.410747528076172\n",
      "Epoch 26/500 | Train Loss: 719.318 | Test Loss: 707.636 | Test Loss [MAPE]: 1805238.098 --time-- 25.43439793586731\n",
      "Epoch 27/500 | Train Loss: 719.098 | Test Loss: 771.130 | Test Loss [MAPE]: 2019768.939 --time-- 25.410311222076416\n",
      "Epoch 28/500 | Train Loss: 693.890 | Test Loss: 708.195 | Test Loss [MAPE]: 1730352.815 --time-- 25.412328958511353\n",
      "Epoch 29/500 | Train Loss: 656.377 | Test Loss: 678.839 | Test Loss [MAPE]: 1588154.570 --time-- 25.40951108932495\n",
      "Epoch 30/500 | Train Loss: 647.982 | Test Loss: 686.841 | Test Loss [MAPE]: 1787516.676 --time-- 25.373432159423828\n",
      "Epoch 31/500 | Train Loss: 643.726 | Test Loss: 632.707 | Test Loss [MAPE]: 1626448.814 --time-- 25.40947723388672\n",
      "Epoch 32/500 | Train Loss: 616.700 | Test Loss: 643.355 | Test Loss [MAPE]: 1635468.551 --time-- 25.372015953063965\n",
      "Epoch 33/500 | Train Loss: 604.039 | Test Loss: 589.169 | Test Loss [MAPE]: 1472554.312 --time-- 25.372900009155273\n",
      "Epoch 34/500 | Train Loss: 596.504 | Test Loss: 567.908 | Test Loss [MAPE]: 1453796.016 --time-- 25.404162883758545\n",
      "Epoch 35/500 | Train Loss: 586.337 | Test Loss: 594.107 | Test Loss [MAPE]: 1478284.480 --time-- 25.371118545532227\n",
      "Epoch 36/500 | Train Loss: 578.768 | Test Loss: 592.960 | Test Loss [MAPE]: 1443045.220 --time-- 25.371084690093994\n",
      "Epoch 37/500 | Train Loss: 581.519 | Test Loss: 589.004 | Test Loss [MAPE]: 1525517.867 --time-- 25.370129346847534\n",
      "Epoch 38/500 | Train Loss: 582.274 | Test Loss: 569.993 | Test Loss [MAPE]: 1536715.960 --time-- 25.366069555282593\n",
      "Epoch 39/500 | Train Loss: 563.364 | Test Loss: 640.654 | Test Loss [MAPE]: 1598595.931 --time-- 25.368879079818726\n",
      "Epoch 40/500 | Train Loss: 574.820 | Test Loss: 550.876 | Test Loss [MAPE]: 1383860.860 --time-- 25.401310920715332\n",
      "Epoch 41/500 | Train Loss: 550.400 | Test Loss: 523.287 | Test Loss [MAPE]: 1331523.680 --time-- 25.40071725845337\n",
      "Epoch 42/500 | Train Loss: 531.057 | Test Loss: 525.053 | Test Loss [MAPE]: 1342849.728 --time-- 25.36869215965271\n",
      "Epoch 43/500 | Train Loss: 541.666 | Test Loss: 561.660 | Test Loss [MAPE]: 1394741.256 --time-- 25.36540699005127\n",
      "Epoch 44/500 | Train Loss: 537.548 | Test Loss: 560.873 | Test Loss [MAPE]: 1401386.963 --time-- 25.371135711669922\n",
      "Epoch 45/500 | Train Loss: 526.763 | Test Loss: 529.277 | Test Loss [MAPE]: 1303967.676 --time-- 25.37339687347412\n",
      "Epoch 46/500 | Train Loss: 543.652 | Test Loss: 560.157 | Test Loss [MAPE]: 1388327.001 --time-- 25.371139526367188\n",
      "Epoch 47/500 | Train Loss: 528.751 | Test Loss: 510.609 | Test Loss [MAPE]: 1267251.756 --time-- 25.371135473251343\n",
      "Epoch 48/500 | Train Loss: 528.125 | Test Loss: 555.345 | Test Loss [MAPE]: 1401399.262 --time-- 25.371946096420288\n",
      "Epoch 49/500 | Train Loss: 515.558 | Test Loss: 554.004 | Test Loss [MAPE]: 1490101.421 --time-- 25.401829719543457\n",
      "Epoch 50/500 | Train Loss: 546.789 | Test Loss: 552.666 | Test Loss [MAPE]: 1450352.598 --time-- 25.404388904571533\n",
      "Epoch 51/500 | Train Loss: 532.909 | Test Loss: 548.903 | Test Loss [MAPE]: 1359615.916 --time-- 25.372040271759033\n",
      "Epoch 52/500 | Train Loss: 543.396 | Test Loss: 528.230 | Test Loss [MAPE]: 1363779.792 --time-- 25.369661331176758\n",
      "Epoch 53/500 | Train Loss: 493.218 | Test Loss: 496.270 | Test Loss [MAPE]: 1187341.944 --time-- 25.40162420272827\n",
      "Epoch 54/500 | Train Loss: 510.251 | Test Loss: 514.685 | Test Loss [MAPE]: 1356286.949 --time-- 25.372882843017578\n",
      "Epoch 55/500 | Train Loss: 492.127 | Test Loss: 515.392 | Test Loss [MAPE]: 1344883.895 --time-- 25.373618125915527\n",
      "Epoch 56/500 | Train Loss: 500.114 | Test Loss: 518.984 | Test Loss [MAPE]: 1360828.498 --time-- 25.40569519996643\n",
      "Epoch 57/500 | Train Loss: 504.715 | Test Loss: 550.837 | Test Loss [MAPE]: 1460810.683 --time-- 25.374095916748047\n",
      "Epoch 58/500 | Train Loss: 540.369 | Test Loss: 564.415 | Test Loss [MAPE]: 1480788.121 --time-- 25.37485122680664\n",
      "Epoch 59/500 | Train Loss: 491.331 | Test Loss: 474.681 | Test Loss [MAPE]: 1203576.413 --time-- 25.408112287521362\n",
      "Epoch 60/500 | Train Loss: 502.501 | Test Loss: 495.325 | Test Loss [MAPE]: 1281709.693 --time-- 25.406912088394165\n",
      "Epoch 61/500 | Train Loss: 495.071 | Test Loss: 511.353 | Test Loss [MAPE]: 1294203.114 --time-- 25.374784469604492\n",
      "Epoch 62/500 | Train Loss: 501.999 | Test Loss: 491.476 | Test Loss [MAPE]: 1243276.204 --time-- 25.37638235092163\n",
      "Epoch 63/500 | Train Loss: 490.502 | Test Loss: 511.513 | Test Loss [MAPE]: 1230529.948 --time-- 25.37531614303589\n",
      "Epoch 64/500 | Train Loss: 479.009 | Test Loss: 529.735 | Test Loss [MAPE]: 1295911.451 --time-- 25.4083731174469\n",
      "Epoch 65/500 | Train Loss: 498.151 | Test Loss: 518.826 | Test Loss [MAPE]: 1275542.337 --time-- 25.407885789871216\n",
      "Epoch 66/500 | Train Loss: 494.855 | Test Loss: 496.360 | Test Loss [MAPE]: 1174564.584 --time-- 25.373905420303345\n",
      "Epoch 67/500 | Train Loss: 474.035 | Test Loss: 461.265 | Test Loss [MAPE]: 1103216.921 --time-- 25.407948970794678\n",
      "Epoch 68/500 | Train Loss: 470.802 | Test Loss: 494.402 | Test Loss [MAPE]: 1237204.718 --time-- 25.406858682632446\n",
      "Epoch 69/500 | Train Loss: 487.882 | Test Loss: 488.807 | Test Loss [MAPE]: 1221980.644 --time-- 25.373039484024048\n",
      "Epoch 70/500 | Train Loss: 475.440 | Test Loss: 486.008 | Test Loss [MAPE]: 1192594.706 --time-- 25.373936891555786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500 | Train Loss: 471.459 | Test Loss: 506.444 | Test Loss [MAPE]: 1225437.300 --time-- 25.403859615325928\n",
      "Epoch 72/500 | Train Loss: 471.498 | Test Loss: 492.066 | Test Loss [MAPE]: 1135296.192 --time-- 25.374921321868896\n",
      "Epoch 73/500 | Train Loss: 483.286 | Test Loss: 540.423 | Test Loss [MAPE]: 1269230.892 --time-- 25.377532243728638\n",
      "Epoch 74/500 | Train Loss: 483.300 | Test Loss: 523.977 | Test Loss [MAPE]: 1319761.006 --time-- 25.375189304351807\n",
      "Epoch 75/500 | Train Loss: 486.197 | Test Loss: 500.206 | Test Loss [MAPE]: 1158925.492 --time-- 25.370007514953613\n",
      "Epoch 76/500 | Train Loss: 478.784 | Test Loss: 509.562 | Test Loss [MAPE]: 1230755.219 --time-- 25.37416100502014\n",
      "Epoch 77/500 | Train Loss: 515.845 | Test Loss: 583.008 | Test Loss [MAPE]: 1457408.381 --time-- 25.35046625137329\n",
      "Epoch 78/500 | Train Loss: 490.452 | Test Loss: 492.927 | Test Loss [MAPE]: 1142542.328 --time-- 25.40374732017517\n",
      "Epoch 79/500 | Train Loss: 460.183 | Test Loss: 493.137 | Test Loss [MAPE]: 1273386.937 --time-- 25.375182628631592\n",
      "Epoch 80/500 | Train Loss: 477.867 | Test Loss: 540.150 | Test Loss [MAPE]: 1361976.808 --time-- 25.375096559524536\n",
      "Epoch 81/500 | Train Loss: 482.596 | Test Loss: 485.482 | Test Loss [MAPE]: 1227998.853 --time-- 25.372184991836548\n",
      "Epoch 82/500 | Train Loss: 468.843 | Test Loss: 483.829 | Test Loss [MAPE]: 1090591.685 --time-- 25.404803037643433\n",
      "Epoch 83/500 | Train Loss: 492.283 | Test Loss: 513.919 | Test Loss [MAPE]: 1358677.372 --time-- 25.344640970230103\n",
      "Epoch 84/500 | Train Loss: 502.541 | Test Loss: 493.111 | Test Loss [MAPE]: 1176090.789 --time-- 25.344391107559204\n",
      "Epoch 85/500 | Train Loss: 476.010 | Test Loss: 525.634 | Test Loss [MAPE]: 1299950.099 --time-- 25.370594263076782\n",
      "Epoch 86/500 | Train Loss: 473.184 | Test Loss: 500.589 | Test Loss [MAPE]: 1204780.092 --time-- 25.3736789226532\n",
      "Epoch 87/500 | Train Loss: 456.696 | Test Loss: 467.884 | Test Loss [MAPE]: 1067882.338 --time-- 25.37026619911194\n",
      "Epoch 88/500 | Train Loss: 469.543 | Test Loss: 505.964 | Test Loss [MAPE]: 1107173.591 --time-- 25.371225118637085\n",
      "Epoch 89/500 | Train Loss: 473.808 | Test Loss: 482.339 | Test Loss [MAPE]: 1232979.106 --time-- 25.375028133392334\n",
      "Epoch 90/500 | Train Loss: 474.124 | Test Loss: 523.807 | Test Loss [MAPE]: 1201153.702 --time-- 25.373738765716553\n",
      "Epoch 91/500 | Train Loss: 467.298 | Test Loss: 467.066 | Test Loss [MAPE]: 1147106.471 --time-- 25.369399547576904\n",
      "Epoch 92/500 | Train Loss: 460.355 | Test Loss: 491.383 | Test Loss [MAPE]: 1240782.290 --time-- 25.370668649673462\n",
      "Epoch 93/500 | Train Loss: 464.362 | Test Loss: 476.944 | Test Loss [MAPE]: 1184450.018 --time-- 25.40538716316223\n",
      "Epoch 94/500 | Train Loss: 452.415 | Test Loss: 497.572 | Test Loss [MAPE]: 1110276.375 --time-- 25.403391122817993\n",
      "Epoch 95/500 | Train Loss: 471.685 | Test Loss: 495.915 | Test Loss [MAPE]: 1326393.401 --time-- 25.376533269882202\n",
      "Epoch 96/500 | Train Loss: 462.219 | Test Loss: 493.212 | Test Loss [MAPE]: 1171126.186 --time-- 25.371598482131958\n",
      "Epoch 97/500 | Train Loss: 466.482 | Test Loss: 467.518 | Test Loss [MAPE]: 1111693.820 --time-- 25.370672702789307\n",
      "Epoch 98/500 | Train Loss: 446.114 | Test Loss: 509.068 | Test Loss [MAPE]: 1166824.876 --time-- 25.40109610557556\n",
      "Epoch 99/500 | Train Loss: 510.389 | Test Loss: 500.066 | Test Loss [MAPE]: 1206313.247 --time-- 25.344758987426758\n",
      "Epoch 100/500 | Train Loss: 461.536 | Test Loss: 476.256 | Test Loss [MAPE]: 1197093.331 --time-- 25.3714702129364\n",
      "Epoch 101/500 | Train Loss: 459.369 | Test Loss: 532.557 | Test Loss [MAPE]: 1182996.980 --time-- 25.37451958656311\n",
      "Epoch 102/500 | Train Loss: 473.377 | Test Loss: 449.141 | Test Loss [MAPE]: 1074509.105 --time-- 25.36877751350403\n",
      "Epoch 103/500 | Train Loss: 466.164 | Test Loss: 488.638 | Test Loss [MAPE]: 1128534.431 --time-- 25.37488603591919\n",
      "Epoch 104/500 | Train Loss: 470.930 | Test Loss: 463.953 | Test Loss [MAPE]: 1133145.115 --time-- 25.369418144226074\n",
      "Epoch 105/500 | Train Loss: 459.472 | Test Loss: 463.014 | Test Loss [MAPE]: 1115305.183 --time-- 25.375536918640137\n",
      "Epoch 106/500 | Train Loss: 461.614 | Test Loss: 471.219 | Test Loss [MAPE]: 1159897.743 --time-- 25.371553421020508\n",
      "Epoch 107/500 | Train Loss: 459.080 | Test Loss: 481.648 | Test Loss [MAPE]: 1215249.969 --time-- 25.370746612548828\n",
      "Epoch 108/500 | Train Loss: 473.644 | Test Loss: 496.722 | Test Loss [MAPE]: 1222063.949 --time-- 25.37540292739868\n",
      "Epoch 109/500 | Train Loss: 463.021 | Test Loss: 490.009 | Test Loss [MAPE]: 1127452.960 --time-- 25.373296976089478\n",
      "Epoch 110/500 | Train Loss: 450.988 | Test Loss: 461.012 | Test Loss [MAPE]: 1056492.642 --time-- 25.376038074493408\n",
      "Epoch 111/500 | Train Loss: 448.016 | Test Loss: 496.120 | Test Loss [MAPE]: 1155997.003 --time-- 25.37687039375305\n",
      "Epoch 112/500 | Train Loss: 463.088 | Test Loss: 513.256 | Test Loss [MAPE]: 1316795.200 --time-- 25.37779951095581\n",
      "Epoch 113/500 | Train Loss: 477.126 | Test Loss: 445.299 | Test Loss [MAPE]: 991830.903 --time-- 25.385774850845337\n",
      "Epoch 114/500 | Train Loss: 464.370 | Test Loss: 495.349 | Test Loss [MAPE]: 1238917.839 --time-- 25.370218753814697\n",
      "Epoch 115/500 | Train Loss: 468.286 | Test Loss: 462.380 | Test Loss [MAPE]: 1159387.952 --time-- 25.372548580169678\n",
      "Epoch 116/500 | Train Loss: 445.230 | Test Loss: 488.430 | Test Loss [MAPE]: 1119357.834 --time-- 25.37431836128235\n",
      "Epoch 117/500 | Train Loss: 459.088 | Test Loss: 524.864 | Test Loss [MAPE]: 1246055.752 --time-- 25.370814085006714\n",
      "Epoch 118/500 | Train Loss: 463.188 | Test Loss: 491.984 | Test Loss [MAPE]: 1223899.042 --time-- 25.3710458278656\n",
      "Epoch 119/500 | Train Loss: 455.542 | Test Loss: 510.355 | Test Loss [MAPE]: 1127901.765 --time-- 25.377196073532104\n",
      "Epoch 120/500 | Train Loss: 448.787 | Test Loss: 469.109 | Test Loss [MAPE]: 1138300.615 --time-- 25.371519804000854\n",
      "Epoch 121/500 | Train Loss: 458.647 | Test Loss: 512.292 | Test Loss [MAPE]: 1347905.094 --time-- 25.370396614074707\n",
      "Epoch 122/500 | Train Loss: 476.964 | Test Loss: 512.739 | Test Loss [MAPE]: 1165572.138 --time-- 25.37103796005249\n",
      "Epoch 123/500 | Train Loss: 492.495 | Test Loss: 503.734 | Test Loss [MAPE]: 1200252.911 --time-- 25.345184803009033\n",
      "Epoch 124/500 | Train Loss: 452.651 | Test Loss: 436.935 | Test Loss [MAPE]: 1001294.235 --time-- 25.40202784538269\n",
      "Epoch 125/500 | Train Loss: 451.701 | Test Loss: 495.479 | Test Loss [MAPE]: 1227730.923 --time-- 25.403550386428833\n",
      "Epoch 126/500 | Train Loss: 457.633 | Test Loss: 454.692 | Test Loss [MAPE]: 1118237.774 --time-- 25.37302255630493\n",
      "Epoch 127/500 | Train Loss: 443.615 | Test Loss: 468.406 | Test Loss [MAPE]: 1079496.456 --time-- 25.372541427612305\n",
      "Epoch 128/500 | Train Loss: 456.546 | Test Loss: 483.711 | Test Loss [MAPE]: 1177738.645 --time-- 25.371097564697266\n",
      "Epoch 129/500 | Train Loss: 459.836 | Test Loss: 475.296 | Test Loss [MAPE]: 1130740.444 --time-- 25.375967741012573\n",
      "Epoch 130/500 | Train Loss: 456.101 | Test Loss: 506.675 | Test Loss [MAPE]: 1354309.456 --time-- 25.37628698348999\n",
      "Epoch 131/500 | Train Loss: 499.209 | Test Loss: 457.671 | Test Loss [MAPE]: 1083695.991 --time-- 25.3437020778656\n",
      "Epoch 132/500 | Train Loss: 445.273 | Test Loss: 460.970 | Test Loss [MAPE]: 1101272.998 --time-- 25.375022888183594\n",
      "Epoch 133/500 | Train Loss: 467.783 | Test Loss: 497.652 | Test Loss [MAPE]: 1173596.830 --time-- 25.341933012008667\n",
      "Epoch 134/500 | Train Loss: 461.690 | Test Loss: 456.956 | Test Loss [MAPE]: 1043572.780 --time-- 25.375574350357056\n",
      "Epoch 135/500 | Train Loss: 450.680 | Test Loss: 481.418 | Test Loss [MAPE]: 1144569.837 --time-- 25.37866449356079\n",
      "Epoch 136/500 | Train Loss: 457.725 | Test Loss: 444.753 | Test Loss [MAPE]: 1049761.506 --time-- 25.377171754837036\n",
      "Epoch 137/500 | Train Loss: 452.860 | Test Loss: 480.374 | Test Loss [MAPE]: 1083524.848 --time-- 25.377341508865356\n",
      "Epoch 138/500 | Train Loss: 446.205 | Test Loss: 470.703 | Test Loss [MAPE]: 1203296.840 --time-- 25.374839305877686\n",
      "Epoch 139/500 | Train Loss: 447.389 | Test Loss: 484.342 | Test Loss [MAPE]: 1082515.291 --time-- 25.407673835754395\n",
      "Epoch 140/500 | Train Loss: 446.818 | Test Loss: 427.542 | Test Loss [MAPE]: 985451.256 --time-- 25.37609362602234\n",
      "Epoch 141/500 | Train Loss: 439.049 | Test Loss: 460.185 | Test Loss [MAPE]: 1123040.066 --time-- 25.375232934951782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/500 | Train Loss: 441.497 | Test Loss: 455.165 | Test Loss [MAPE]: 1082410.971 --time-- 25.376981258392334\n",
      "Epoch 143/500 | Train Loss: 452.863 | Test Loss: 456.248 | Test Loss [MAPE]: 1085350.331 --time-- 25.376317024230957\n",
      "Epoch 144/500 | Train Loss: 480.191 | Test Loss: 441.625 | Test Loss [MAPE]: 1100963.835 --time-- 25.347434520721436\n",
      "Epoch 145/500 | Train Loss: 426.690 | Test Loss: 456.591 | Test Loss [MAPE]: 1093742.458 --time-- 25.37570548057556\n",
      "Epoch 146/500 | Train Loss: 447.359 | Test Loss: 482.205 | Test Loss [MAPE]: 1118883.616 --time-- 25.445364236831665\n",
      "Epoch 147/500 | Train Loss: 446.830 | Test Loss: 465.771 | Test Loss [MAPE]: 1079418.089 --time-- 25.438291549682617\n",
      "Epoch 148/500 | Train Loss: 485.390 | Test Loss: 507.624 | Test Loss [MAPE]: 1314378.182 --time-- 25.351182460784912\n",
      "Epoch 149/500 | Train Loss: 486.447 | Test Loss: 468.097 | Test Loss [MAPE]: 1061611.390 --time-- 25.376670360565186\n",
      "Epoch 150/500 | Train Loss: 443.010 | Test Loss: 454.025 | Test Loss [MAPE]: 1077629.499 --time-- 25.37233328819275\n",
      "Epoch 151/500 | Train Loss: 452.165 | Test Loss: 446.041 | Test Loss [MAPE]: 1070406.721 --time-- 25.40759515762329\n",
      "Epoch 152/500 | Train Loss: 447.912 | Test Loss: 501.474 | Test Loss [MAPE]: 1172855.746 --time-- 25.37313961982727\n",
      "Epoch 153/500 | Train Loss: 446.830 | Test Loss: 457.882 | Test Loss [MAPE]: 1036889.511 --time-- 25.405922412872314\n",
      "Epoch 154/500 | Train Loss: 452.279 | Test Loss: 459.582 | Test Loss [MAPE]: 1101619.050 --time-- 25.376627445220947\n",
      "Epoch 155/500 | Train Loss: 448.564 | Test Loss: 545.882 | Test Loss [MAPE]: 1140686.349 --time-- 25.378888845443726\n",
      "Epoch 156/500 | Train Loss: 453.489 | Test Loss: 465.277 | Test Loss [MAPE]: 1155248.624 --time-- 25.375168085098267\n",
      "Epoch 157/500 | Train Loss: 454.263 | Test Loss: 473.797 | Test Loss [MAPE]: 1094863.346 --time-- 25.377251625061035\n",
      "Epoch 158/500 | Train Loss: 451.760 | Test Loss: 449.376 | Test Loss [MAPE]: 1013838.792 --time-- 25.375924825668335\n",
      "Epoch 159/500 | Train Loss: 446.752 | Test Loss: 472.879 | Test Loss [MAPE]: 1131754.375 --time-- 25.40568208694458\n",
      "Epoch 160/500 | Train Loss: 448.227 | Test Loss: 465.020 | Test Loss [MAPE]: 1170300.814 --time-- 25.370447635650635\n",
      "Epoch 161/500 | Train Loss: 427.760 | Test Loss: 453.475 | Test Loss [MAPE]: 995777.826 --time-- 25.37590765953064\n",
      "Epoch 162/500 | Train Loss: 438.034 | Test Loss: 482.492 | Test Loss [MAPE]: 1197384.280 --time-- 25.37693762779236\n",
      "Epoch 163/500 | Train Loss: 454.017 | Test Loss: 453.296 | Test Loss [MAPE]: 1087420.532 --time-- 25.374627828598022\n",
      "Epoch 164/500 | Train Loss: 431.864 | Test Loss: 467.692 | Test Loss [MAPE]: 1185077.481 --time-- 25.372979640960693\n",
      "Epoch 165/500 | Train Loss: 458.291 | Test Loss: 459.025 | Test Loss [MAPE]: 1143358.447 --time-- 25.373842000961304\n",
      "Epoch 166/500 | Train Loss: 432.987 | Test Loss: 435.553 | Test Loss [MAPE]: 1058121.184 --time-- 25.379762411117554\n",
      "Epoch 167/500 | Train Loss: 428.703 | Test Loss: 463.903 | Test Loss [MAPE]: 1109218.469 --time-- 25.410348653793335\n",
      "Epoch 168/500 | Train Loss: 443.398 | Test Loss: 485.740 | Test Loss [MAPE]: 1165187.166 --time-- 25.375866651535034\n",
      "Epoch 169/500 | Train Loss: 462.612 | Test Loss: 453.332 | Test Loss [MAPE]: 1075666.117 --time-- 25.37475275993347\n",
      "Epoch 170/500 | Train Loss: 435.059 | Test Loss: 449.980 | Test Loss [MAPE]: 1115801.139 --time-- 25.376367330551147\n",
      "Epoch 171/500 | Train Loss: 441.236 | Test Loss: 478.345 | Test Loss [MAPE]: 1208704.675 --time-- 25.37502884864807\n",
      "Epoch 172/500 | Train Loss: 460.582 | Test Loss: 467.401 | Test Loss [MAPE]: 1227696.891 --time-- 25.33948302268982\n",
      "Epoch 173/500 | Train Loss: 423.298 | Test Loss: 468.974 | Test Loss [MAPE]: 1130718.344 --time-- 25.375421285629272\n",
      "Epoch 174/500 | Train Loss: 433.806 | Test Loss: 456.725 | Test Loss [MAPE]: 1119283.977 --time-- 25.407285928726196\n",
      "Epoch 175/500 | Train Loss: 436.088 | Test Loss: 477.717 | Test Loss [MAPE]: 1042251.408 --time-- 25.373373985290527\n",
      "Epoch 176/500 | Train Loss: 442.240 | Test Loss: 464.913 | Test Loss [MAPE]: 1144047.070 --time-- 25.374835968017578\n",
      "Epoch 177/500 | Train Loss: 493.815 | Test Loss: 525.719 | Test Loss [MAPE]: 1223417.072 --time-- 25.34609627723694\n",
      "Epoch 178/500 | Train Loss: 444.888 | Test Loss: 440.959 | Test Loss [MAPE]: 1066174.783 --time-- 25.373053312301636\n",
      "Epoch 179/500 | Train Loss: 424.181 | Test Loss: 445.006 | Test Loss [MAPE]: 1093711.211 --time-- 25.370980501174927\n",
      "Epoch 180/500 | Train Loss: 429.378 | Test Loss: 447.080 | Test Loss [MAPE]: 1048259.667 --time-- 25.372039556503296\n",
      "Epoch 181/500 | Train Loss: 427.946 | Test Loss: 432.264 | Test Loss [MAPE]: 1057377.075 --time-- 25.403377294540405\n",
      "Epoch 182/500 | Train Loss: 446.082 | Test Loss: 429.144 | Test Loss [MAPE]: 1051579.082 --time-- 25.372199296951294\n",
      "Epoch 183/500 | Train Loss: 442.023 | Test Loss: 462.746 | Test Loss [MAPE]: 1071572.943 --time-- 25.37171459197998\n",
      "Epoch 184/500 | Train Loss: 446.797 | Test Loss: 487.412 | Test Loss [MAPE]: 1181753.473 --time-- 25.373130083084106\n",
      "Epoch 185/500 | Train Loss: 461.386 | Test Loss: 462.964 | Test Loss [MAPE]: 1108412.028 --time-- 25.343644857406616\n",
      "Epoch 186/500 | Train Loss: 440.606 | Test Loss: 456.347 | Test Loss [MAPE]: 1092757.738 --time-- 25.37439274787903\n",
      "Epoch 187/500 | Train Loss: 439.702 | Test Loss: 475.543 | Test Loss [MAPE]: 1190065.540 --time-- 25.427873373031616\n",
      "Epoch 188/500 | Train Loss: 442.184 | Test Loss: 452.213 | Test Loss [MAPE]: 1133258.359 --time-- 25.37589740753174\n",
      "Epoch 189/500 | Train Loss: 427.951 | Test Loss: 426.280 | Test Loss [MAPE]: 1067778.733 --time-- 25.37726378440857\n",
      "Epoch 190/500 | Train Loss: 455.209 | Test Loss: 487.392 | Test Loss [MAPE]: 1174916.157 --time-- 25.336888313293457\n",
      "Epoch 191/500 | Train Loss: 442.603 | Test Loss: 464.352 | Test Loss [MAPE]: 1128113.510 --time-- 25.38177180290222\n",
      "Epoch 192/500 | Train Loss: 437.950 | Test Loss: 461.949 | Test Loss [MAPE]: 1138734.019 --time-- 25.39537763595581\n",
      "Epoch 193/500 | Train Loss: 464.916 | Test Loss: 547.542 | Test Loss [MAPE]: 1439236.566 --time-- 25.34617590904236\n",
      "Epoch 194/500 | Train Loss: 454.683 | Test Loss: 462.516 | Test Loss [MAPE]: 1071504.781 --time-- 25.37678098678589\n",
      "Epoch 195/500 | Train Loss: 445.467 | Test Loss: 537.166 | Test Loss [MAPE]: 1380326.095 --time-- 25.342784881591797\n",
      "Epoch 196/500 | Train Loss: 455.719 | Test Loss: 481.540 | Test Loss [MAPE]: 1128653.702 --time-- 25.379785299301147\n",
      "Epoch 197/500 | Train Loss: 435.207 | Test Loss: 448.167 | Test Loss [MAPE]: 1069510.477 --time-- 25.37306237220764\n",
      "Epoch 198/500 | Train Loss: 423.399 | Test Loss: 448.522 | Test Loss [MAPE]: 1104939.982 --time-- 25.410125017166138\n",
      "Epoch 199/500 | Train Loss: 446.345 | Test Loss: 471.464 | Test Loss [MAPE]: 1101039.583 --time-- 25.375192880630493\n",
      "Epoch 200/500 | Train Loss: 446.391 | Test Loss: 440.621 | Test Loss [MAPE]: 1010447.291 --time-- 25.371312141418457\n",
      "Epoch 201/500 | Train Loss: 430.282 | Test Loss: 435.174 | Test Loss [MAPE]: 1036063.729 --time-- 25.372350454330444\n",
      "Epoch 202/500 | Train Loss: 429.519 | Test Loss: 446.115 | Test Loss [MAPE]: 1122196.534 --time-- 25.376455783843994\n",
      "Epoch 203/500 | Train Loss: 425.518 | Test Loss: 429.004 | Test Loss [MAPE]: 1025095.800 --time-- 25.371189832687378\n",
      "Epoch 204/500 | Train Loss: 434.710 | Test Loss: 455.747 | Test Loss [MAPE]: 1010906.610 --time-- 25.36878776550293\n",
      "Epoch 205/500 | Train Loss: 457.136 | Test Loss: 453.323 | Test Loss [MAPE]: 1069641.609 --time-- 25.36694836616516\n",
      "Epoch 206/500 | Train Loss: 433.651 | Test Loss: 476.797 | Test Loss [MAPE]: 1221461.994 --time-- 25.37001943588257\n",
      "Epoch 207/500 | Train Loss: 446.933 | Test Loss: 475.844 | Test Loss [MAPE]: 1193344.331 --time-- 25.37317705154419\n",
      "Epoch 208/500 | Train Loss: 431.326 | Test Loss: 447.278 | Test Loss [MAPE]: 1035145.449 --time-- 25.40333604812622\n",
      "Epoch 209/500 | Train Loss: 432.516 | Test Loss: 476.417 | Test Loss [MAPE]: 1225749.088 --time-- 25.385174989700317\n",
      "Epoch 210/500 | Train Loss: 458.524 | Test Loss: 481.427 | Test Loss [MAPE]: 1195237.831 --time-- 25.374923706054688\n",
      "Epoch 211/500 | Train Loss: 444.506 | Test Loss: 480.127 | Test Loss [MAPE]: 1166152.399 --time-- 25.372026681900024\n",
      "Epoch 212/500 | Train Loss: 454.446 | Test Loss: 458.907 | Test Loss [MAPE]: 1042375.198 --time-- 25.343284606933594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/500 | Train Loss: 435.556 | Test Loss: 440.539 | Test Loss [MAPE]: 1073928.342 --time-- 25.375584840774536\n",
      "Epoch 214/500 | Train Loss: 452.837 | Test Loss: 457.992 | Test Loss [MAPE]: 1079237.743 --time-- 25.376523733139038\n",
      "Epoch 215/500 | Train Loss: 430.450 | Test Loss: 439.176 | Test Loss [MAPE]: 1035319.822 --time-- 25.40674614906311\n",
      "Epoch 216/500 | Train Loss: 449.445 | Test Loss: 458.928 | Test Loss [MAPE]: 1100050.359 --time-- 25.373356819152832\n",
      "Epoch 217/500 | Train Loss: 438.260 | Test Loss: 445.883 | Test Loss [MAPE]: 998958.951 --time-- 25.373146772384644\n",
      "Epoch 218/500 | Train Loss: 436.715 | Test Loss: 427.572 | Test Loss [MAPE]: 1037020.479 --time-- 25.374330282211304\n",
      "Epoch 219/500 | Train Loss: 425.994 | Test Loss: 442.445 | Test Loss [MAPE]: 1031460.410 --time-- 25.376514434814453\n",
      "Epoch 220/500 | Train Loss: 441.491 | Test Loss: 480.828 | Test Loss [MAPE]: 1173750.748 --time-- 25.373721599578857\n",
      "Epoch 221/500 | Train Loss: 464.513 | Test Loss: 478.121 | Test Loss [MAPE]: 1198988.865 --time-- 25.340487003326416\n",
      "Epoch 222/500 | Train Loss: 510.574 | Test Loss: 486.875 | Test Loss [MAPE]: 1190019.553 --time-- 25.344653129577637\n",
      "Epoch 223/500 | Train Loss: 437.444 | Test Loss: 423.873 | Test Loss [MAPE]: 992723.937 --time-- 25.376413345336914\n",
      "Epoch 224/500 | Train Loss: 425.558 | Test Loss: 430.844 | Test Loss [MAPE]: 1046285.727 --time-- 25.40923523902893\n",
      "Epoch 225/500 | Train Loss: 431.370 | Test Loss: 482.211 | Test Loss [MAPE]: 1231381.285 --time-- 25.374659061431885\n",
      "Epoch 226/500 | Train Loss: 439.966 | Test Loss: 443.777 | Test Loss [MAPE]: 1074722.471 --time-- 25.373778820037842\n",
      "Epoch 227/500 | Train Loss: 423.881 | Test Loss: 466.297 | Test Loss [MAPE]: 1022882.704 --time-- 25.37714385986328\n",
      "Epoch 228/500 | Train Loss: 414.548 | Test Loss: 453.546 | Test Loss [MAPE]: 1112392.585 --time-- 25.373328685760498\n",
      "Epoch 229/500 | Train Loss: 431.797 | Test Loss: 438.576 | Test Loss [MAPE]: 1106111.467 --time-- 25.37342381477356\n",
      "Epoch 230/500 | Train Loss: 446.010 | Test Loss: 458.186 | Test Loss [MAPE]: 1150550.398 --time-- 25.362202882766724\n",
      "Epoch 231/500 | Train Loss: 445.770 | Test Loss: 476.657 | Test Loss [MAPE]: 1109752.729 --time-- 25.37613534927368\n",
      "Epoch 232/500 | Train Loss: 453.145 | Test Loss: 441.349 | Test Loss [MAPE]: 1081181.922 --time-- 25.377501010894775\n",
      "Epoch 233/500 | Train Loss: 452.351 | Test Loss: 476.409 | Test Loss [MAPE]: 1239438.155 --time-- 25.379916667938232\n",
      "Epoch 234/500 | Train Loss: 438.805 | Test Loss: 455.092 | Test Loss [MAPE]: 1083836.924 --time-- 25.378682374954224\n",
      "Epoch 235/500 | Train Loss: 435.243 | Test Loss: 472.708 | Test Loss [MAPE]: 1045375.596 --time-- 25.377506971359253\n",
      "Epoch 236/500 | Train Loss: 440.209 | Test Loss: 445.068 | Test Loss [MAPE]: 1082645.317 --time-- 25.378329038619995\n",
      "Epoch 237/500 | Train Loss: 421.569 | Test Loss: 440.371 | Test Loss [MAPE]: 1012530.933 --time-- 25.409512519836426\n",
      "Epoch 238/500 | Train Loss: 415.934 | Test Loss: 420.999 | Test Loss [MAPE]: 986721.634 --time-- 25.38157629966736\n",
      "Epoch 239/500 | Train Loss: 421.290 | Test Loss: 463.436 | Test Loss [MAPE]: 1110234.670 --time-- 25.41172957420349\n",
      "Epoch 240/500 | Train Loss: 444.557 | Test Loss: 489.724 | Test Loss [MAPE]: 1176073.807 --time-- 25.377914905548096\n",
      "Epoch 241/500 | Train Loss: 471.301 | Test Loss: 513.985 | Test Loss [MAPE]: 1306539.383 --time-- 25.37962579727173\n",
      "Epoch 242/500 | Train Loss: 452.797 | Test Loss: 476.253 | Test Loss [MAPE]: 1154784.513 --time-- 25.378281593322754\n",
      "Epoch 243/500 | Train Loss: 433.167 | Test Loss: 433.018 | Test Loss [MAPE]: 990406.855 --time-- 25.37843084335327\n",
      "Epoch 244/500 | Train Loss: 425.731 | Test Loss: 465.886 | Test Loss [MAPE]: 1152336.626 --time-- 25.376312255859375\n",
      "Epoch 245/500 | Train Loss: 440.442 | Test Loss: 450.410 | Test Loss [MAPE]: 1002689.272 --time-- 25.3801007270813\n",
      "Epoch 246/500 | Train Loss: 430.041 | Test Loss: 442.843 | Test Loss [MAPE]: 1084468.405 --time-- 25.408854246139526\n",
      "Epoch 247/500 | Train Loss: 432.213 | Test Loss: 463.458 | Test Loss [MAPE]: 1181412.926 --time-- 25.373700857162476\n",
      "Epoch 248/500 | Train Loss: 448.164 | Test Loss: 467.148 | Test Loss [MAPE]: 1101796.373 --time-- 25.377493858337402\n",
      "Epoch 249/500 | Train Loss: 445.020 | Test Loss: 456.188 | Test Loss [MAPE]: 1009134.623 --time-- 25.37302327156067\n",
      "Epoch 250/500 | Train Loss: 416.802 | Test Loss: 455.923 | Test Loss [MAPE]: 1068653.526 --time-- 25.372666358947754\n",
      "Epoch 251/500 | Train Loss: 429.914 | Test Loss: 439.426 | Test Loss [MAPE]: 1074839.000 --time-- 25.376788854599\n",
      "Epoch 252/500 | Train Loss: 479.474 | Test Loss: 449.065 | Test Loss [MAPE]: 1051805.229 --time-- 25.3438777923584\n",
      "Epoch 253/500 | Train Loss: 444.999 | Test Loss: 487.936 | Test Loss [MAPE]: 1111757.912 --time-- 25.379266262054443\n",
      "Epoch 254/500 | Train Loss: 443.714 | Test Loss: 448.898 | Test Loss [MAPE]: 1107047.486 --time-- 25.374542474746704\n",
      "Epoch 255/500 | Train Loss: 429.689 | Test Loss: 490.589 | Test Loss [MAPE]: 1170368.249 --time-- 25.376708269119263\n",
      "Epoch 256/500 | Train Loss: 433.369 | Test Loss: 443.155 | Test Loss [MAPE]: 1075221.157 --time-- 25.376842260360718\n",
      "Epoch 257/500 | Train Loss: 437.628 | Test Loss: 479.445 | Test Loss [MAPE]: 1248912.934 --time-- 25.37651777267456\n",
      "Epoch 258/500 | Train Loss: 426.677 | Test Loss: 443.765 | Test Loss [MAPE]: 1020375.779 --time-- 25.378708839416504\n",
      "Epoch 259/500 | Train Loss: 422.062 | Test Loss: 427.599 | Test Loss [MAPE]: 1022089.660 --time-- 25.3768208026886\n",
      "Epoch 260/500 | Train Loss: 429.846 | Test Loss: 451.797 | Test Loss [MAPE]: 1134138.143 --time-- 25.371866464614868\n",
      "Epoch 261/500 | Train Loss: 412.249 | Test Loss: 437.456 | Test Loss [MAPE]: 990485.855 --time-- 25.40738344192505\n",
      "Epoch 262/500 | Train Loss: 437.768 | Test Loss: 545.191 | Test Loss [MAPE]: 1130494.905 --time-- 25.349090099334717\n",
      "Epoch 263/500 | Train Loss: 455.511 | Test Loss: 466.888 | Test Loss [MAPE]: 1180198.782 --time-- 25.378376722335815\n",
      "Epoch 264/500 | Train Loss: 440.768 | Test Loss: 456.509 | Test Loss [MAPE]: 1124169.515 --time-- 25.37955141067505\n",
      "Epoch 265/500 | Train Loss: 425.181 | Test Loss: 457.079 | Test Loss [MAPE]: 1054108.181 --time-- 25.373771905899048\n",
      "Epoch 266/500 | Train Loss: 421.994 | Test Loss: 433.424 | Test Loss [MAPE]: 990859.349 --time-- 25.37699842453003\n",
      "Epoch 267/500 | Train Loss: 421.193 | Test Loss: 422.413 | Test Loss [MAPE]: 967978.674 --time-- 25.376068115234375\n",
      "Epoch 268/500 | Train Loss: 433.120 | Test Loss: 453.993 | Test Loss [MAPE]: 1139194.933 --time-- 25.3429012298584\n",
      "Epoch 269/500 | Train Loss: 418.612 | Test Loss: 453.572 | Test Loss [MAPE]: 1102398.786 --time-- 25.377474546432495\n",
      "Epoch 270/500 | Train Loss: 416.594 | Test Loss: 417.830 | Test Loss [MAPE]: 1034149.331 --time-- 25.40993857383728\n",
      "Epoch 271/500 | Train Loss: 439.495 | Test Loss: 485.679 | Test Loss [MAPE]: 1100019.273 --time-- 25.379812717437744\n",
      "Epoch 272/500 | Train Loss: 439.656 | Test Loss: 533.088 | Test Loss [MAPE]: 1546743.979 --time-- 25.350448608398438\n",
      "Epoch 273/500 | Train Loss: 473.622 | Test Loss: 442.729 | Test Loss [MAPE]: 1015450.723 --time-- 25.34734535217285\n",
      "Epoch 274/500 | Train Loss: 419.105 | Test Loss: 444.991 | Test Loss [MAPE]: 1091845.058 --time-- 25.381754398345947\n",
      "Epoch 275/500 | Train Loss: 427.697 | Test Loss: 471.640 | Test Loss [MAPE]: 1186865.370 --time-- 25.381251096725464\n",
      "Epoch 276/500 | Train Loss: 432.685 | Test Loss: 464.484 | Test Loss [MAPE]: 1200883.463 --time-- 25.37865900993347\n",
      "Epoch 277/500 | Train Loss: 424.676 | Test Loss: 426.693 | Test Loss [MAPE]: 985873.299 --time-- 25.37913727760315\n",
      "Epoch 278/500 | Train Loss: 423.922 | Test Loss: 445.631 | Test Loss [MAPE]: 1096418.762 --time-- 25.378156423568726\n",
      "Epoch 279/500 | Train Loss: 432.215 | Test Loss: 466.978 | Test Loss [MAPE]: 1117827.678 --time-- 25.382949352264404\n",
      "Epoch 280/500 | Train Loss: 433.252 | Test Loss: 455.902 | Test Loss [MAPE]: 1131674.654 --time-- 25.38076138496399\n",
      "Epoch 281/500 | Train Loss: 423.794 | Test Loss: 430.761 | Test Loss [MAPE]: 1013608.702 --time-- 25.378371953964233\n",
      "Epoch 282/500 | Train Loss: 423.062 | Test Loss: 430.607 | Test Loss [MAPE]: 1007630.943 --time-- 25.37821054458618\n",
      "Epoch 283/500 | Train Loss: 420.459 | Test Loss: 461.836 | Test Loss [MAPE]: 1117899.373 --time-- 25.379884481430054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/500 | Train Loss: 440.666 | Test Loss: 458.141 | Test Loss [MAPE]: 1132100.732 --time-- 25.374495267868042\n",
      "Epoch 285/500 | Train Loss: 426.514 | Test Loss: 427.969 | Test Loss [MAPE]: 1041683.888 --time-- 25.37666153907776\n",
      "Epoch 286/500 | Train Loss: 430.683 | Test Loss: 431.627 | Test Loss [MAPE]: 1054160.134 --time-- 25.378726482391357\n",
      "Epoch 287/500 | Train Loss: 423.770 | Test Loss: 454.151 | Test Loss [MAPE]: 1028783.820 --time-- 25.382822513580322\n",
      "Epoch 288/500 | Train Loss: 423.413 | Test Loss: 468.209 | Test Loss [MAPE]: 1082115.731 --time-- 25.414854288101196\n",
      "Epoch 289/500 | Train Loss: 436.932 | Test Loss: 486.845 | Test Loss [MAPE]: 1048182.932 --time-- 25.384461402893066\n",
      "Epoch 290/500 | Train Loss: 433.352 | Test Loss: 451.277 | Test Loss [MAPE]: 1088784.207 --time-- 25.378172397613525\n",
      "Epoch 291/500 | Train Loss: 438.808 | Test Loss: 427.537 | Test Loss [MAPE]: 996276.909 --time-- 25.37803554534912\n",
      "Epoch 292/500 | Train Loss: 448.631 | Test Loss: 453.632 | Test Loss [MAPE]: 1070955.330 --time-- 25.377107620239258\n",
      "Epoch 293/500 | Train Loss: 416.323 | Test Loss: 432.727 | Test Loss [MAPE]: 1024286.343 --time-- 25.380391359329224\n",
      "Epoch 294/500 | Train Loss: 437.704 | Test Loss: 426.329 | Test Loss [MAPE]: 1043904.211 --time-- 25.382420301437378\n",
      "Epoch 295/500 | Train Loss: 425.184 | Test Loss: 422.630 | Test Loss [MAPE]: 1038814.330 --time-- 25.380826234817505\n",
      "Epoch 296/500 | Train Loss: 408.042 | Test Loss: 424.098 | Test Loss [MAPE]: 1018282.585 --time-- 25.3784441947937\n",
      "Epoch 297/500 | Train Loss: 412.935 | Test Loss: 448.040 | Test Loss [MAPE]: 1008664.168 --time-- 25.378216981887817\n",
      "Epoch 298/500 | Train Loss: 429.159 | Test Loss: 431.147 | Test Loss [MAPE]: 1051993.252 --time-- 25.377973794937134\n",
      "Epoch 299/500 | Train Loss: 433.699 | Test Loss: 483.888 | Test Loss [MAPE]: 1067003.925 --time-- 25.381441831588745\n",
      "Epoch 300/500 | Train Loss: 439.446 | Test Loss: 423.925 | Test Loss [MAPE]: 1075241.282 --time-- 25.377858877182007\n",
      "Epoch 301/500 | Train Loss: 430.399 | Test Loss: 449.427 | Test Loss [MAPE]: 1155720.090 --time-- 25.377477884292603\n",
      "Epoch 302/500 | Train Loss: 432.433 | Test Loss: 476.002 | Test Loss [MAPE]: 1209661.788 --time-- 25.37961196899414\n",
      "Epoch 303/500 | Train Loss: 437.878 | Test Loss: 444.540 | Test Loss [MAPE]: 1038543.811 --time-- 25.37732481956482\n",
      "Epoch 304/500 | Train Loss: 428.715 | Test Loss: 437.634 | Test Loss [MAPE]: 1045235.168 --time-- 25.379931926727295\n",
      "Epoch 305/500 | Train Loss: 427.598 | Test Loss: 433.086 | Test Loss [MAPE]: 1032499.088 --time-- 25.376786708831787\n",
      "Epoch 306/500 | Train Loss: 424.173 | Test Loss: 423.477 | Test Loss [MAPE]: 935694.260 --time-- 25.374050855636597\n",
      "Epoch 307/500 | Train Loss: 421.484 | Test Loss: 448.144 | Test Loss [MAPE]: 1079634.453 --time-- 25.37518286705017\n",
      "Epoch 308/500 | Train Loss: 418.435 | Test Loss: 442.881 | Test Loss [MAPE]: 1098784.018 --time-- 25.381128787994385\n",
      "Epoch 309/500 | Train Loss: 452.347 | Test Loss: 447.403 | Test Loss [MAPE]: 1106956.487 --time-- 25.34731698036194\n",
      "Epoch 310/500 | Train Loss: 415.780 | Test Loss: 443.724 | Test Loss [MAPE]: 1080902.325 --time-- 25.37846064567566\n",
      "Epoch 311/500 | Train Loss: 411.918 | Test Loss: 457.187 | Test Loss [MAPE]: 1112119.689 --time-- 25.380582332611084\n",
      "Epoch 312/500 | Train Loss: 423.593 | Test Loss: 430.332 | Test Loss [MAPE]: 992525.853 --time-- 25.380268335342407\n",
      "Epoch 313/500 | Train Loss: 457.245 | Test Loss: 475.746 | Test Loss [MAPE]: 1106287.837 --time-- 25.35050344467163\n",
      "Epoch 314/500 | Train Loss: 436.278 | Test Loss: 431.466 | Test Loss [MAPE]: 1047567.466 --time-- 25.417174100875854\n",
      "Epoch 315/500 | Train Loss: 427.584 | Test Loss: 457.392 | Test Loss [MAPE]: 1140751.707 --time-- 25.380554676055908\n",
      "Epoch 316/500 | Train Loss: 434.874 | Test Loss: 451.781 | Test Loss [MAPE]: 1139681.726 --time-- 25.378965616226196\n",
      "Epoch 317/500 | Train Loss: 421.194 | Test Loss: 444.744 | Test Loss [MAPE]: 1042865.547 --time-- 25.378040552139282\n",
      "Epoch 318/500 | Train Loss: 437.599 | Test Loss: 460.160 | Test Loss [MAPE]: 1164195.975 --time-- 25.381406545639038\n",
      "Epoch 319/500 | Train Loss: 452.177 | Test Loss: 497.577 | Test Loss [MAPE]: 1032486.864 --time-- 25.38005232810974\n",
      "Epoch 320/500 | Train Loss: 475.374 | Test Loss: 465.620 | Test Loss [MAPE]: 1149722.730 --time-- 25.378931522369385\n",
      "Epoch 321/500 | Train Loss: 424.559 | Test Loss: 459.180 | Test Loss [MAPE]: 1075933.716 --time-- 25.37821102142334\n",
      "Epoch 322/500 | Train Loss: 414.499 | Test Loss: 423.734 | Test Loss [MAPE]: 1023513.326 --time-- 25.37761950492859\n",
      "Epoch 323/500 | Train Loss: 429.853 | Test Loss: 509.313 | Test Loss [MAPE]: 1054191.144 --time-- 25.38360023498535\n",
      "Epoch 324/500 | Train Loss: 436.900 | Test Loss: 440.888 | Test Loss [MAPE]: 1065744.453 --time-- 25.382105588912964\n",
      "Epoch 325/500 | Train Loss: 424.793 | Test Loss: 448.049 | Test Loss [MAPE]: 1117972.179 --time-- 25.381722688674927\n",
      "Epoch 326/500 | Train Loss: 419.429 | Test Loss: 462.460 | Test Loss [MAPE]: 1211812.225 --time-- 25.413102626800537\n",
      "Epoch 327/500 | Train Loss: 424.998 | Test Loss: 470.415 | Test Loss [MAPE]: 1055271.112 --time-- 25.379459857940674\n",
      "Epoch 328/500 | Train Loss: 430.133 | Test Loss: 431.541 | Test Loss [MAPE]: 1042457.454 --time-- 25.381229639053345\n",
      "Epoch 329/500 | Train Loss: 426.773 | Test Loss: 437.054 | Test Loss [MAPE]: 1037064.174 --time-- 25.37983226776123\n",
      "Epoch 330/500 | Train Loss: 411.723 | Test Loss: 437.814 | Test Loss [MAPE]: 1096582.712 --time-- 25.383074522018433\n",
      "Epoch 331/500 | Train Loss: 419.188 | Test Loss: 427.202 | Test Loss [MAPE]: 998305.402 --time-- 25.41443133354187\n",
      "Epoch 332/500 | Train Loss: 419.800 | Test Loss: 452.202 | Test Loss [MAPE]: 1146797.339 --time-- 25.38221526145935\n",
      "Epoch 333/500 | Train Loss: 413.521 | Test Loss: 427.974 | Test Loss [MAPE]: 1014466.273 --time-- 25.38183569908142\n",
      "Epoch 334/500 | Train Loss: 420.127 | Test Loss: 480.326 | Test Loss [MAPE]: 1290679.555 --time-- 25.3809015750885\n",
      "Epoch 335/500 | Train Loss: 422.314 | Test Loss: 428.984 | Test Loss [MAPE]: 1020303.773 --time-- 25.38258695602417\n",
      "Epoch 336/500 | Train Loss: 420.513 | Test Loss: 463.159 | Test Loss [MAPE]: 1105163.517 --time-- 25.3854501247406\n",
      "Epoch 337/500 | Train Loss: 425.591 | Test Loss: 438.039 | Test Loss [MAPE]: 1022531.847 --time-- 25.37822151184082\n",
      "Epoch 338/500 | Train Loss: 418.705 | Test Loss: 433.331 | Test Loss [MAPE]: 1020747.445 --time-- 25.3815176486969\n",
      "Epoch 339/500 | Train Loss: 424.937 | Test Loss: 462.459 | Test Loss [MAPE]: 1178226.180 --time-- 25.380862951278687\n",
      "Epoch 340/500 | Train Loss: 422.340 | Test Loss: 477.034 | Test Loss [MAPE]: 1220828.776 --time-- 25.381465673446655\n",
      "Epoch 341/500 | Train Loss: 434.510 | Test Loss: 451.292 | Test Loss [MAPE]: 1006103.745 --time-- 25.376290321350098\n",
      "Epoch 342/500 | Train Loss: 417.476 | Test Loss: 441.397 | Test Loss [MAPE]: 1005061.548 --time-- 25.449628829956055\n",
      "Epoch 343/500 | Train Loss: 421.752 | Test Loss: 453.687 | Test Loss [MAPE]: 1121533.127 --time-- 25.395374059677124\n",
      "Epoch 344/500 | Train Loss: 425.918 | Test Loss: 449.079 | Test Loss [MAPE]: 1094980.567 --time-- 25.380298852920532\n",
      "Epoch 345/500 | Train Loss: 410.021 | Test Loss: 459.909 | Test Loss [MAPE]: 1132541.089 --time-- 25.383103847503662\n",
      "Epoch 346/500 | Train Loss: 434.567 | Test Loss: 449.871 | Test Loss [MAPE]: 1121269.082 --time-- 25.379221439361572\n",
      "Epoch 347/500 | Train Loss: 417.327 | Test Loss: 439.035 | Test Loss [MAPE]: 1051063.117 --time-- 25.383848428726196\n",
      "Epoch 348/500 | Train Loss: 414.448 | Test Loss: 451.467 | Test Loss [MAPE]: 1148777.967 --time-- 25.379660606384277\n",
      "Epoch 349/500 | Train Loss: 426.869 | Test Loss: 463.473 | Test Loss [MAPE]: 1031450.333 --time-- 25.38289999961853\n",
      "Epoch 350/500 | Train Loss: 455.788 | Test Loss: 421.219 | Test Loss [MAPE]: 987995.535 --time-- 25.37937068939209\n",
      "Epoch 351/500 | Train Loss: 414.841 | Test Loss: 443.378 | Test Loss [MAPE]: 1107555.922 --time-- 25.38098168373108\n",
      "Epoch 352/500 | Train Loss: 410.753 | Test Loss: 404.126 | Test Loss [MAPE]: 963125.052 --time-- 25.37679362297058\n",
      "Epoch 353/500 | Train Loss: 413.704 | Test Loss: 452.491 | Test Loss [MAPE]: 1108199.503 --time-- 25.412667751312256\n",
      "Epoch 354/500 | Train Loss: 422.272 | Test Loss: 447.214 | Test Loss [MAPE]: 1096052.246 --time-- 25.37910270690918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500 | Train Loss: 418.153 | Test Loss: 431.634 | Test Loss [MAPE]: 1001364.603 --time-- 25.379066705703735\n",
      "Epoch 356/500 | Train Loss: 415.095 | Test Loss: 446.709 | Test Loss [MAPE]: 1050357.727 --time-- 25.381528615951538\n",
      "Epoch 357/500 | Train Loss: 418.481 | Test Loss: 456.822 | Test Loss [MAPE]: 1149869.304 --time-- 25.380326747894287\n",
      "Epoch 358/500 | Train Loss: 423.760 | Test Loss: 432.899 | Test Loss [MAPE]: 1027460.135 --time-- 25.38138747215271\n",
      "Epoch 359/500 | Train Loss: 420.508 | Test Loss: 472.969 | Test Loss [MAPE]: 1174432.079 --time-- 25.37997341156006\n",
      "Epoch 360/500 | Train Loss: 421.436 | Test Loss: 455.326 | Test Loss [MAPE]: 1046493.086 --time-- 25.382577896118164\n",
      "Epoch 361/500 | Train Loss: 418.982 | Test Loss: 436.868 | Test Loss [MAPE]: 998582.021 --time-- 25.384837865829468\n",
      "Epoch 362/500 | Train Loss: 419.616 | Test Loss: 439.522 | Test Loss [MAPE]: 1105440.781 --time-- 25.381781816482544\n",
      "Epoch 363/500 | Train Loss: 426.367 | Test Loss: 461.143 | Test Loss [MAPE]: 1166757.932 --time-- 25.379108428955078\n",
      "Epoch 364/500 | Train Loss: 424.429 | Test Loss: 431.326 | Test Loss [MAPE]: 1057526.057 --time-- 25.379926204681396\n",
      "Epoch 365/500 | Train Loss: 441.441 | Test Loss: 447.971 | Test Loss [MAPE]: 1031797.403 --time-- 25.383129835128784\n",
      "Epoch 366/500 | Train Loss: 439.101 | Test Loss: 476.311 | Test Loss [MAPE]: 1139442.014 --time-- 25.382251977920532\n",
      "Epoch 367/500 | Train Loss: 423.592 | Test Loss: 449.262 | Test Loss [MAPE]: 1079447.581 --time-- 25.41341280937195\n",
      "Epoch 368/500 | Train Loss: 416.076 | Test Loss: 461.561 | Test Loss [MAPE]: 1092611.129 --time-- 25.38540506362915\n",
      "Epoch 369/500 | Train Loss: 438.126 | Test Loss: 457.822 | Test Loss [MAPE]: 1115046.669 --time-- 25.379130363464355\n",
      "Epoch 370/500 | Train Loss: 419.486 | Test Loss: 432.097 | Test Loss [MAPE]: 988471.035 --time-- 25.41302180290222\n",
      "Epoch 371/500 | Train Loss: 420.474 | Test Loss: 449.974 | Test Loss [MAPE]: 1034277.830 --time-- 25.417443990707397\n",
      "Epoch 372/500 | Train Loss: 424.213 | Test Loss: 411.191 | Test Loss [MAPE]: 968743.702 --time-- 25.381881713867188\n",
      "Epoch 373/500 | Train Loss: 434.978 | Test Loss: 461.063 | Test Loss [MAPE]: 1046887.648 --time-- 25.384063482284546\n",
      "Epoch 374/500 | Train Loss: 425.669 | Test Loss: 445.039 | Test Loss [MAPE]: 1027990.838 --time-- 25.35032033920288\n",
      "Epoch 375/500 | Train Loss: 435.272 | Test Loss: 448.419 | Test Loss [MAPE]: 1135229.440 --time-- 25.40990376472473\n",
      "Epoch 376/500 | Train Loss: 417.655 | Test Loss: 452.225 | Test Loss [MAPE]: 1069202.433 --time-- 25.410125970840454\n",
      "Epoch 377/500 | Train Loss: 422.826 | Test Loss: 439.515 | Test Loss [MAPE]: 1077905.579 --time-- 25.409867525100708\n",
      "Epoch 378/500 | Train Loss: 421.235 | Test Loss: 420.146 | Test Loss [MAPE]: 987973.999 --time-- 25.4158034324646\n",
      "Epoch 379/500 | Train Loss: 411.755 | Test Loss: 423.550 | Test Loss [MAPE]: 981680.479 --time-- 25.415469884872437\n",
      "Epoch 380/500 | Train Loss: 406.590 | Test Loss: 423.021 | Test Loss [MAPE]: 1026318.212 --time-- 25.385804653167725\n",
      "Epoch 381/500 | Train Loss: 412.681 | Test Loss: 460.349 | Test Loss [MAPE]: 1143747.512 --time-- 25.382343530654907\n",
      "Epoch 382/500 | Train Loss: 420.609 | Test Loss: 445.238 | Test Loss [MAPE]: 1056382.533 --time-- 25.3800687789917\n",
      "Epoch 383/500 | Train Loss: 419.415 | Test Loss: 458.783 | Test Loss [MAPE]: 1083391.762 --time-- 25.381651401519775\n",
      "Epoch 384/500 | Train Loss: 416.748 | Test Loss: 429.818 | Test Loss [MAPE]: 1074983.953 --time-- 25.37981081008911\n",
      "Epoch 385/500 | Train Loss: 410.166 | Test Loss: 438.592 | Test Loss [MAPE]: 1124194.132 --time-- 25.415732860565186\n",
      "Epoch 386/500 | Train Loss: 421.757 | Test Loss: 440.551 | Test Loss [MAPE]: 1035544.737 --time-- 25.385265350341797\n",
      "Epoch 387/500 | Train Loss: 437.507 | Test Loss: 428.094 | Test Loss [MAPE]: 969012.254 --time-- 25.375401735305786\n",
      "Epoch 388/500 | Train Loss: 419.717 | Test Loss: 418.052 | Test Loss [MAPE]: 992452.047 --time-- 25.413935661315918\n",
      "Epoch 389/500 | Train Loss: 410.776 | Test Loss: 458.200 | Test Loss [MAPE]: 1115013.436 --time-- 25.379605293273926\n",
      "Epoch 390/500 | Train Loss: 430.328 | Test Loss: 450.809 | Test Loss [MAPE]: 1090261.500 --time-- 25.37920355796814\n",
      "Epoch 391/500 | Train Loss: 472.336 | Test Loss: 438.195 | Test Loss [MAPE]: 1034323.076 --time-- 25.345961093902588\n",
      "Epoch 392/500 | Train Loss: 416.687 | Test Loss: 427.464 | Test Loss [MAPE]: 1011455.554 --time-- 25.385607957839966\n",
      "Epoch 393/500 | Train Loss: 421.566 | Test Loss: 438.936 | Test Loss [MAPE]: 1076051.763 --time-- 25.378196001052856\n",
      "Epoch 394/500 | Train Loss: 422.377 | Test Loss: 496.916 | Test Loss [MAPE]: 1062435.652 --time-- 25.388025999069214\n",
      "Epoch 395/500 | Train Loss: 417.568 | Test Loss: 438.270 | Test Loss [MAPE]: 990234.353 --time-- 25.382711172103882\n",
      "Epoch 396/500 | Train Loss: 419.816 | Test Loss: 443.177 | Test Loss [MAPE]: 1032848.586 --time-- 25.381486177444458\n",
      "Epoch 397/500 | Train Loss: 417.158 | Test Loss: 432.125 | Test Loss [MAPE]: 1059627.260 --time-- 25.382099628448486\n",
      "Epoch 398/500 | Train Loss: 416.449 | Test Loss: 439.021 | Test Loss [MAPE]: 1135282.264 --time-- 25.37887930870056\n",
      "Epoch 399/500 | Train Loss: 419.107 | Test Loss: 485.161 | Test Loss [MAPE]: 1047612.781 --time-- 25.382847785949707\n",
      "Epoch 400/500 | Train Loss: 435.498 | Test Loss: 440.916 | Test Loss [MAPE]: 1074026.615 --time-- 25.38227367401123\n",
      "Epoch 401/500 | Train Loss: 407.081 | Test Loss: 420.319 | Test Loss [MAPE]: 995029.571 --time-- 25.37872004508972\n",
      "Epoch 402/500 | Train Loss: 412.627 | Test Loss: 441.265 | Test Loss [MAPE]: 1059317.628 --time-- 25.37930464744568\n",
      "Epoch 403/500 | Train Loss: 443.830 | Test Loss: 436.322 | Test Loss [MAPE]: 1006556.900 --time-- 25.34453320503235\n",
      "Epoch 404/500 | Train Loss: 428.046 | Test Loss: 439.524 | Test Loss [MAPE]: 1071245.282 --time-- 25.379730939865112\n",
      "Epoch 405/500 | Train Loss: 415.230 | Test Loss: 443.638 | Test Loss [MAPE]: 1104746.480 --time-- 25.375814199447632\n",
      "Epoch 406/500 | Train Loss: 418.493 | Test Loss: 429.831 | Test Loss [MAPE]: 1039603.650 --time-- 25.379781246185303\n",
      "Epoch 407/500 | Train Loss: 424.865 | Test Loss: 413.261 | Test Loss [MAPE]: 1022816.728 --time-- 25.343211889266968\n",
      "Epoch 408/500 | Train Loss: 430.221 | Test Loss: 425.650 | Test Loss [MAPE]: 1031296.471 --time-- 25.37609100341797\n",
      "Epoch 409/500 | Train Loss: 409.845 | Test Loss: 427.412 | Test Loss [MAPE]: 1033672.232 --time-- 25.37587547302246\n",
      "Epoch 410/500 | Train Loss: 417.507 | Test Loss: 449.298 | Test Loss [MAPE]: 1061850.473 --time-- 25.37876319885254\n",
      "Epoch 411/500 | Train Loss: 413.918 | Test Loss: 446.214 | Test Loss [MAPE]: 1117900.605 --time-- 25.376267910003662\n",
      "Epoch 412/500 | Train Loss: 422.784 | Test Loss: 421.114 | Test Loss [MAPE]: 1017005.665 --time-- 25.375614404678345\n",
      "Epoch 413/500 | Train Loss: 417.439 | Test Loss: 443.716 | Test Loss [MAPE]: 1142482.061 --time-- 25.377037525177002\n",
      "Epoch 414/500 | Train Loss: 423.376 | Test Loss: 558.890 | Test Loss [MAPE]: 1664301.032 --time-- 25.342073678970337\n",
      "Epoch 415/500 | Train Loss: 439.291 | Test Loss: 449.258 | Test Loss [MAPE]: 1105509.786 --time-- 25.376464366912842\n",
      "Epoch 416/500 | Train Loss: 407.792 | Test Loss: 424.418 | Test Loss [MAPE]: 996193.107 --time-- 25.378013134002686\n",
      "Epoch 417/500 | Train Loss: 422.863 | Test Loss: 458.927 | Test Loss [MAPE]: 1138143.012 --time-- 25.379683256149292\n",
      "Epoch 418/500 | Train Loss: 416.481 | Test Loss: 433.955 | Test Loss [MAPE]: 1070812.282 --time-- 25.376846075057983\n",
      "Epoch 419/500 | Train Loss: 397.542 | Test Loss: 401.542 | Test Loss [MAPE]: 939820.028 --time-- 25.381090879440308\n",
      "Epoch 420/500 | Train Loss: 408.210 | Test Loss: 459.728 | Test Loss [MAPE]: 1024982.801 --time-- 25.37960934638977\n",
      "Epoch 421/500 | Train Loss: 413.984 | Test Loss: 436.995 | Test Loss [MAPE]: 1141078.158 --time-- 25.412368297576904\n",
      "Epoch 422/500 | Train Loss: 422.476 | Test Loss: 417.274 | Test Loss [MAPE]: 1006320.556 --time-- 25.37460231781006\n",
      "Epoch 423/500 | Train Loss: 416.684 | Test Loss: 453.648 | Test Loss [MAPE]: 1090111.744 --time-- 25.37643337249756\n",
      "Epoch 424/500 | Train Loss: 420.253 | Test Loss: 444.191 | Test Loss [MAPE]: 1099190.544 --time-- 25.376920223236084\n",
      "Epoch 425/500 | Train Loss: 407.665 | Test Loss: 429.374 | Test Loss [MAPE]: 1030061.856 --time-- 25.410707712173462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500 | Train Loss: 411.368 | Test Loss: 412.504 | Test Loss [MAPE]: 987066.186 --time-- 25.379647254943848\n",
      "Epoch 427/500 | Train Loss: 422.687 | Test Loss: 466.193 | Test Loss [MAPE]: 1170531.275 --time-- 25.3734393119812\n",
      "Epoch 428/500 | Train Loss: 434.633 | Test Loss: 433.983 | Test Loss [MAPE]: 1086995.600 --time-- 25.375081777572632\n",
      "Epoch 429/500 | Train Loss: 411.168 | Test Loss: 426.274 | Test Loss [MAPE]: 1053018.840 --time-- 25.38068151473999\n",
      "Epoch 430/500 | Train Loss: 429.739 | Test Loss: 469.063 | Test Loss [MAPE]: 1180544.583 --time-- 25.37758183479309\n",
      "Epoch 431/500 | Train Loss: 430.029 | Test Loss: 451.535 | Test Loss [MAPE]: 1072404.000 --time-- 25.383652687072754\n",
      "Epoch 432/500 | Train Loss: 398.399 | Test Loss: 443.292 | Test Loss [MAPE]: 1112789.326 --time-- 25.408276557922363\n",
      "Epoch 433/500 | Train Loss: 421.019 | Test Loss: 448.665 | Test Loss [MAPE]: 1104344.390 --time-- 25.408519983291626\n",
      "Epoch 434/500 | Train Loss: 418.386 | Test Loss: 425.754 | Test Loss [MAPE]: 1005234.941 --time-- 25.377214670181274\n",
      "Epoch 435/500 | Train Loss: 420.371 | Test Loss: 434.871 | Test Loss [MAPE]: 1025433.647 --time-- 25.372701168060303\n",
      "Epoch 436/500 | Train Loss: 415.377 | Test Loss: 446.098 | Test Loss [MAPE]: 1150579.960 --time-- 25.375468015670776\n",
      "Epoch 437/500 | Train Loss: 410.831 | Test Loss: 425.365 | Test Loss [MAPE]: 994629.799 --time-- 25.380000352859497\n",
      "Epoch 438/500 | Train Loss: 406.788 | Test Loss: 418.424 | Test Loss [MAPE]: 1030477.937 --time-- 25.377218008041382\n",
      "Epoch 439/500 | Train Loss: 400.740 | Test Loss: 417.330 | Test Loss [MAPE]: 1017348.646 --time-- 25.377103090286255\n",
      "Epoch 440/500 | Train Loss: 413.182 | Test Loss: 435.993 | Test Loss [MAPE]: 1094006.369 --time-- 25.38034224510193\n",
      "Epoch 441/500 | Train Loss: 418.562 | Test Loss: 453.833 | Test Loss [MAPE]: 1113709.030 --time-- 25.37973713874817\n",
      "Epoch 442/500 | Train Loss: 422.682 | Test Loss: 454.922 | Test Loss [MAPE]: 1087081.566 --time-- 25.38396430015564\n",
      "Epoch 443/500 | Train Loss: 425.372 | Test Loss: 428.659 | Test Loss [MAPE]: 1022682.663 --time-- 25.379338264465332\n",
      "Epoch 444/500 | Train Loss: 405.539 | Test Loss: 419.137 | Test Loss [MAPE]: 1017836.635 --time-- 25.41301727294922\n",
      "Epoch 445/500 | Train Loss: 413.076 | Test Loss: 429.382 | Test Loss [MAPE]: 1060327.007 --time-- 25.378060579299927\n",
      "Epoch 446/500 | Train Loss: 425.796 | Test Loss: 437.196 | Test Loss [MAPE]: 1081079.925 --time-- 25.377586126327515\n",
      "Epoch 447/500 | Train Loss: 421.308 | Test Loss: 428.958 | Test Loss [MAPE]: 1005199.714 --time-- 25.377763271331787\n",
      "Epoch 448/500 | Train Loss: 417.146 | Test Loss: 451.108 | Test Loss [MAPE]: 1042330.543 --time-- 25.414599180221558\n",
      "Epoch 449/500 | Train Loss: 430.149 | Test Loss: 450.414 | Test Loss [MAPE]: 1071072.581 --time-- 25.414731979370117\n",
      "Epoch 450/500 | Train Loss: 411.657 | Test Loss: 428.028 | Test Loss [MAPE]: 1081783.836 --time-- 25.374075889587402\n",
      "Epoch 451/500 | Train Loss: 418.156 | Test Loss: 441.672 | Test Loss [MAPE]: 1052846.203 --time-- 25.376381874084473\n",
      "Epoch 452/500 | Train Loss: 412.631 | Test Loss: 460.106 | Test Loss [MAPE]: 1103646.120 --time-- 25.374024868011475\n",
      "Epoch 453/500 | Train Loss: 413.813 | Test Loss: 431.170 | Test Loss [MAPE]: 999765.715 --time-- 25.378023147583008\n",
      "Epoch 454/500 | Train Loss: 401.228 | Test Loss: 429.995 | Test Loss [MAPE]: 1044016.233 --time-- 25.379947900772095\n",
      "Epoch 455/500 | Train Loss: 408.804 | Test Loss: 428.038 | Test Loss [MAPE]: 1010094.059 --time-- 25.382579565048218\n",
      "Epoch 456/500 | Train Loss: 441.611 | Test Loss: 444.079 | Test Loss [MAPE]: 972079.244 --time-- 25.37985873222351\n",
      "Epoch 457/500 | Train Loss: 421.923 | Test Loss: 439.399 | Test Loss [MAPE]: 1053315.636 --time-- 25.382651329040527\n",
      "Epoch 458/500 | Train Loss: 404.948 | Test Loss: 439.645 | Test Loss [MAPE]: 1041987.945 --time-- 25.380760192871094\n",
      "Epoch 459/500 | Train Loss: 407.162 | Test Loss: 432.216 | Test Loss [MAPE]: 1046351.169 --time-- 25.37956953048706\n",
      "Epoch 460/500 | Train Loss: 403.459 | Test Loss: 454.929 | Test Loss [MAPE]: 1102542.971 --time-- 25.381933212280273\n",
      "Epoch 461/500 | Train Loss: 408.334 | Test Loss: 425.796 | Test Loss [MAPE]: 1048588.862 --time-- 25.419209957122803\n",
      "Epoch 462/500 | Train Loss: 407.815 | Test Loss: 427.546 | Test Loss [MAPE]: 1044242.179 --time-- 25.3783118724823\n",
      "Epoch 463/500 | Train Loss: 404.274 | Test Loss: 443.490 | Test Loss [MAPE]: 1135224.918 --time-- 25.376415252685547\n",
      "Epoch 464/500 | Train Loss: 446.877 | Test Loss: 437.589 | Test Loss [MAPE]: 1070618.772 --time-- 25.349143028259277\n",
      "Epoch 465/500 | Train Loss: 412.530 | Test Loss: 424.331 | Test Loss [MAPE]: 1055681.118 --time-- 25.37799859046936\n",
      "Epoch 466/500 | Train Loss: 412.901 | Test Loss: 424.223 | Test Loss [MAPE]: 1014588.908 --time-- 25.375659465789795\n",
      "Epoch 467/500 | Train Loss: 420.989 | Test Loss: 422.910 | Test Loss [MAPE]: 1033754.166 --time-- 25.373193979263306\n",
      "Epoch 468/500 | Train Loss: 411.042 | Test Loss: 441.520 | Test Loss [MAPE]: 1155173.764 --time-- 25.376659154891968\n",
      "Epoch 469/500 | Train Loss: 405.194 | Test Loss: 459.828 | Test Loss [MAPE]: 1141795.683 --time-- 25.41248893737793\n",
      "Epoch 470/500 | Train Loss: 412.193 | Test Loss: 411.632 | Test Loss [MAPE]: 979720.307 --time-- 25.380677938461304\n",
      "Epoch 471/500 | Train Loss: 402.962 | Test Loss: 420.435 | Test Loss [MAPE]: 951309.403 --time-- 25.375869274139404\n",
      "Epoch 472/500 | Train Loss: 413.393 | Test Loss: 437.382 | Test Loss [MAPE]: 1082270.148 --time-- 25.374008893966675\n",
      "Epoch 473/500 | Train Loss: 411.139 | Test Loss: 410.690 | Test Loss [MAPE]: 984165.831 --time-- 25.374134302139282\n",
      "Epoch 474/500 | Train Loss: 413.774 | Test Loss: 408.230 | Test Loss [MAPE]: 943967.057 --time-- 25.372389793395996\n",
      "Epoch 475/500 | Train Loss: 396.627 | Test Loss: 414.418 | Test Loss [MAPE]: 986847.614 --time-- 25.374266386032104\n",
      "Epoch 476/500 | Train Loss: 403.370 | Test Loss: 432.116 | Test Loss [MAPE]: 1056946.688 --time-- 25.37619376182556\n",
      "Epoch 477/500 | Train Loss: 397.650 | Test Loss: 414.346 | Test Loss [MAPE]: 1027368.530 --time-- 25.39517879486084\n",
      "Epoch 478/500 | Train Loss: 401.979 | Test Loss: 433.590 | Test Loss [MAPE]: 995802.561 --time-- 25.3817355632782\n",
      "Epoch 479/500 | Train Loss: 404.875 | Test Loss: 455.102 | Test Loss [MAPE]: 1192619.288 --time-- 25.374906539916992\n",
      "Epoch 480/500 | Train Loss: 414.207 | Test Loss: 447.556 | Test Loss [MAPE]: 1120859.932 --time-- 25.37947106361389\n",
      "Epoch 481/500 | Train Loss: 406.327 | Test Loss: 457.716 | Test Loss [MAPE]: 1159161.881 --time-- 25.379475355148315\n",
      "Epoch 482/500 | Train Loss: 410.480 | Test Loss: 449.613 | Test Loss [MAPE]: 1104509.093 --time-- 25.41352128982544\n",
      "Epoch 483/500 | Train Loss: 404.768 | Test Loss: 433.158 | Test Loss [MAPE]: 1033984.055 --time-- 25.41631531715393\n",
      "Epoch 484/500 | Train Loss: 402.677 | Test Loss: 436.380 | Test Loss [MAPE]: 1111276.159 --time-- 25.380219221115112\n",
      "Epoch 485/500 | Train Loss: 405.292 | Test Loss: 433.537 | Test Loss [MAPE]: 981257.913 --time-- 25.382992029190063\n",
      "Epoch 486/500 | Train Loss: 425.395 | Test Loss: 467.986 | Test Loss [MAPE]: 1134709.510 --time-- 25.37992548942566\n",
      "Epoch 487/500 | Train Loss: 413.172 | Test Loss: 427.738 | Test Loss [MAPE]: 1065261.326 --time-- 25.378889322280884\n",
      "Epoch 488/500 | Train Loss: 420.638 | Test Loss: 486.505 | Test Loss [MAPE]: 1256831.575 --time-- 25.377976894378662\n",
      "Epoch 489/500 | Train Loss: 418.118 | Test Loss: 420.564 | Test Loss [MAPE]: 965076.507 --time-- 25.378045082092285\n",
      "Epoch 490/500 | Train Loss: 409.455 | Test Loss: 426.156 | Test Loss [MAPE]: 978645.909 --time-- 25.408942222595215\n",
      "Epoch 491/500 | Train Loss: 418.548 | Test Loss: 441.741 | Test Loss [MAPE]: 1057920.990 --time-- 25.377498626708984\n",
      "Epoch 492/500 | Train Loss: 419.470 | Test Loss: 450.197 | Test Loss [MAPE]: 1131099.075 --time-- 25.378236770629883\n",
      "Epoch 493/500 | Train Loss: 407.095 | Test Loss: 462.590 | Test Loss [MAPE]: 1248273.328 --time-- 25.37532067298889\n",
      "Epoch 494/500 | Train Loss: 411.543 | Test Loss: 420.109 | Test Loss [MAPE]: 1006863.295 --time-- 25.37577772140503\n",
      "Epoch 495/500 | Train Loss: 407.154 | Test Loss: 431.427 | Test Loss [MAPE]: 1049572.118 --time-- 25.376083374023438\n",
      "Epoch 496/500 | Train Loss: 409.646 | Test Loss: 444.555 | Test Loss [MAPE]: 1117934.254 --time-- 25.379088878631592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/500 | Train Loss: 415.016 | Test Loss: 426.002 | Test Loss [MAPE]: 1004041.030 --time-- 25.37740421295166\n",
      "Epoch 498/500 | Train Loss: 403.056 | Test Loss: 435.002 | Test Loss [MAPE]: 1052298.176 --time-- 25.407074213027954\n",
      "Epoch 499/500 | Train Loss: 408.031 | Test Loss: 424.859 | Test Loss [MAPE]: 1009573.159 --time-- 25.378676176071167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 09:04:06,546] Trial 49 finished with value: 698900.3966064453 and parameters: {'num_conv_layers': 3, 'kernel_size': 3, 'num_channels': 43, 'pooling_type': 'avg', 'conv_stride': 1, 'feedforward_size': 107, 'pool_stride': 1, 'learning_rate': 0.0003381807679298473, 'reg_strength': 0.0033753759040194386, 'bs': 88}. Best is trial 34 with value: 425934.69303131104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500 | Train Loss: 412.874 | Test Loss: 495.402 | Test Loss [MAPE]: 1233114.944 --time-- 25.38415241241455\n",
      "12701.39466714859\n",
      "Epoch 1/500 | Train Loss: 92854.868 | Test Loss: 5169.592 | Test Loss [MAPE]: 561491.751 --time-- 1.4612054824829102\n",
      "Epoch 2/500 | Train Loss: 5346.471 | Test Loss: 5161.986 | Test Loss [MAPE]: 424473.555 --time-- 1.472055435180664\n",
      "Epoch 3/500 | Train Loss: 5106.452 | Test Loss: 5161.741 | Test Loss [MAPE]: 429535.703 --time-- 1.4754352569580078\n",
      "Epoch 4/500 | Train Loss: 5106.419 | Test Loss: 5161.775 | Test Loss [MAPE]: 429027.826 --time-- 1.5099961757659912\n",
      "Epoch 5/500 | Train Loss: 5106.406 | Test Loss: 5161.720 | Test Loss [MAPE]: 425236.648 --time-- 1.5112583637237549\n",
      "Epoch 6/500 | Train Loss: 5106.392 | Test Loss: 5161.786 | Test Loss [MAPE]: 427227.072 --time-- 1.5127005577087402\n",
      "Epoch 7/500 | Train Loss: 5106.424 | Test Loss: 5161.821 | Test Loss [MAPE]: 422149.551 --time-- 1.513481855392456\n",
      "Epoch 8/500 | Train Loss: 5106.418 | Test Loss: 5161.789 | Test Loss [MAPE]: 426332.542 --time-- 1.5134575366973877\n",
      "Epoch 9/500 | Train Loss: 5106.437 | Test Loss: 5161.808 | Test Loss [MAPE]: 422354.906 --time-- 1.509413719177246\n",
      "Epoch 10/500 | Train Loss: 5106.458 | Test Loss: 5161.791 | Test Loss [MAPE]: 428572.811 --time-- 1.5128271579742432\n",
      "Epoch 11/500 | Train Loss: 5106.434 | Test Loss: 5161.956 | Test Loss [MAPE]: 435467.764 --time-- 1.5064692497253418\n",
      "Epoch 12/500 | Train Loss: 5106.508 | Test Loss: 5161.755 | Test Loss [MAPE]: 428235.729 --time-- 1.5113282203674316\n",
      "Epoch 13/500 | Train Loss: 5106.518 | Test Loss: 5161.899 | Test Loss [MAPE]: 430535.326 --time-- 1.5119619369506836\n",
      "Epoch 14/500 | Train Loss: 5106.498 | Test Loss: 5161.860 | Test Loss [MAPE]: 433368.181 --time-- 1.510819435119629\n",
      "Epoch 15/500 | Train Loss: 5106.500 | Test Loss: 5161.752 | Test Loss [MAPE]: 429024.162 --time-- 1.5103788375854492\n",
      "Epoch 16/500 | Train Loss: 5106.554 | Test Loss: 5161.823 | Test Loss [MAPE]: 426343.566 --time-- 1.5145549774169922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 09:04:32,929] Trial 50 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.513 | Test Loss: 5162.010 | Test Loss [MAPE]: 440256.447 --time-- 1.5124626159667969\n",
      "Epoch 1/500 | Train Loss: 9917.679 | Test Loss: 5161.999 | Test Loss [MAPE]: 435209.699 --time-- 25.447187185287476\n",
      "Epoch 2/500 | Train Loss: 5106.484 | Test Loss: 5161.671 | Test Loss [MAPE]: 424460.929 --time-- 25.63803243637085\n",
      "Epoch 3/500 | Train Loss: 5106.298 | Test Loss: 5161.663 | Test Loss [MAPE]: 422372.884 --time-- 25.634684085845947\n",
      "Epoch 4/500 | Train Loss: 5106.314 | Test Loss: 5161.675 | Test Loss [MAPE]: 419658.688 --time-- 25.638362884521484\n",
      "Epoch 5/500 | Train Loss: 5106.314 | Test Loss: 5161.669 | Test Loss [MAPE]: 421547.187 --time-- 25.632649660110474\n",
      "Epoch 6/500 | Train Loss: 5106.310 | Test Loss: 5161.671 | Test Loss [MAPE]: 424808.133 --time-- 25.63348937034607\n",
      "Epoch 7/500 | Train Loss: 5106.299 | Test Loss: 5161.665 | Test Loss [MAPE]: 421714.603 --time-- 25.632133722305298\n",
      "Epoch 8/500 | Train Loss: 5106.303 | Test Loss: 5161.681 | Test Loss [MAPE]: 423649.334 --time-- 25.602783679962158\n",
      "Epoch 9/500 | Train Loss: 5106.315 | Test Loss: 5161.673 | Test Loss [MAPE]: 421307.396 --time-- 25.59528422355652\n",
      "Epoch 10/500 | Train Loss: 5106.322 | Test Loss: 5161.700 | Test Loss [MAPE]: 418790.357 --time-- 25.59791111946106\n",
      "Epoch 11/500 | Train Loss: 5106.313 | Test Loss: 5161.679 | Test Loss [MAPE]: 425504.373 --time-- 25.600716829299927\n",
      "Epoch 12/500 | Train Loss: 5106.306 | Test Loss: 5161.670 | Test Loss [MAPE]: 425567.025 --time-- 25.598253965377808\n",
      "Epoch 13/500 | Train Loss: 5106.319 | Test Loss: 5161.675 | Test Loss [MAPE]: 424060.578 --time-- 25.598427534103394\n",
      "Epoch 14/500 | Train Loss: 5106.321 | Test Loss: 5161.676 | Test Loss [MAPE]: 421104.477 --time-- 25.601508617401123\n",
      "Epoch 15/500 | Train Loss: 5106.319 | Test Loss: 5161.666 | Test Loss [MAPE]: 423234.448 --time-- 25.60537815093994\n",
      "Epoch 16/500 | Train Loss: 5106.322 | Test Loss: 5161.689 | Test Loss [MAPE]: 420663.745 --time-- 25.635754585266113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 09:11:50,297] Trial 51 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.335 | Test Loss: 5161.689 | Test Loss [MAPE]: 421728.589 --time-- 25.633748292922974\n",
      "Epoch 1/500 | Train Loss: 370400.939 | Test Loss: 5162.349 | Test Loss [MAPE]: 444655.133 --time-- 35.4474139213562\n",
      "Epoch 2/500 | Train Loss: 5106.430 | Test Loss: 5161.686 | Test Loss [MAPE]: 424325.607 --time-- 35.74941039085388\n",
      "Epoch 3/500 | Train Loss: 5106.352 | Test Loss: 5161.697 | Test Loss [MAPE]: 424657.327 --time-- 35.75472593307495\n",
      "Epoch 4/500 | Train Loss: 5106.359 | Test Loss: 5161.684 | Test Loss [MAPE]: 427280.209 --time-- 35.74887752532959\n",
      "Epoch 5/500 | Train Loss: 5106.379 | Test Loss: 5161.696 | Test Loss [MAPE]: 423942.803 --time-- 35.75466966629028\n",
      "Epoch 6/500 | Train Loss: 5106.372 | Test Loss: 5161.837 | Test Loss [MAPE]: 436593.731 --time-- 35.750914573669434\n",
      "Epoch 7/500 | Train Loss: 5106.432 | Test Loss: 5161.711 | Test Loss [MAPE]: 427093.256 --time-- 35.75222826004028\n",
      "Epoch 8/500 | Train Loss: 5106.377 | Test Loss: 5161.748 | Test Loss [MAPE]: 419751.944 --time-- 35.75099277496338\n",
      "Epoch 9/500 | Train Loss: 5106.397 | Test Loss: 5161.732 | Test Loss [MAPE]: 423690.832 --time-- 35.750771284103394\n",
      "Epoch 10/500 | Train Loss: 5106.389 | Test Loss: 5161.725 | Test Loss [MAPE]: 422961.458 --time-- 35.747164726257324\n",
      "Epoch 11/500 | Train Loss: 5106.400 | Test Loss: 5161.875 | Test Loss [MAPE]: 415737.906 --time-- 35.74450898170471\n",
      "Epoch 12/500 | Train Loss: 5106.432 | Test Loss: 5161.756 | Test Loss [MAPE]: 423811.639 --time-- 35.748210191726685\n",
      "Epoch 13/500 | Train Loss: 5106.394 | Test Loss: 5161.796 | Test Loss [MAPE]: 419569.178 --time-- 35.754382610321045\n",
      "Epoch 14/500 | Train Loss: 5106.415 | Test Loss: 5161.757 | Test Loss [MAPE]: 428646.305 --time-- 35.747416734695435\n",
      "Epoch 15/500 | Train Loss: 5106.388 | Test Loss: 5161.827 | Test Loss [MAPE]: 419283.664 --time-- 35.7526273727417\n",
      "Epoch 16/500 | Train Loss: 5106.412 | Test Loss: 5161.735 | Test Loss [MAPE]: 422370.390 --time-- 35.75318646430969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 09:21:59,926] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.432 | Test Loss: 5161.729 | Test Loss [MAPE]: 430671.320 --time-- 35.75353002548218\n",
      "Epoch 1/500 | Train Loss: 5146.416 | Test Loss: 5142.047 | Test Loss [MAPE]: 547825.003 --time-- 6.172398328781128\n",
      "Epoch 2/500 | Train Loss: 4814.111 | Test Loss: 4306.570 | Test Loss [MAPE]: 2701486.689 --time-- 6.1493611335754395\n",
      "Epoch 3/500 | Train Loss: 4175.630 | Test Loss: 4118.648 | Test Loss [MAPE]: 1835615.096 --time-- 6.148375034332275\n",
      "Epoch 4/500 | Train Loss: 4090.375 | Test Loss: 4085.173 | Test Loss [MAPE]: 1734983.574 --time-- 6.149491310119629\n",
      "Epoch 5/500 | Train Loss: 4059.134 | Test Loss: 4052.603 | Test Loss [MAPE]: 1770429.193 --time-- 6.146444320678711\n",
      "Epoch 6/500 | Train Loss: 4029.630 | Test Loss: 4024.229 | Test Loss [MAPE]: 1891621.658 --time-- 6.1463398933410645\n",
      "Epoch 7/500 | Train Loss: 3996.607 | Test Loss: 3988.648 | Test Loss [MAPE]: 2203082.515 --time-- 6.1445746421813965\n",
      "Epoch 8/500 | Train Loss: 3960.747 | Test Loss: 3948.317 | Test Loss [MAPE]: 2719270.827 --time-- 6.1498863697052\n",
      "Epoch 9/500 | Train Loss: 3914.030 | Test Loss: 3902.223 | Test Loss [MAPE]: 3154023.540 --time-- 6.146960258483887\n",
      "Epoch 10/500 | Train Loss: 3865.912 | Test Loss: 3852.632 | Test Loss [MAPE]: 3809167.699 --time-- 6.152311086654663\n",
      "Epoch 11/500 | Train Loss: 3804.881 | Test Loss: 3788.092 | Test Loss [MAPE]: 4547069.279 --time-- 6.149014234542847\n",
      "Epoch 12/500 | Train Loss: 3746.049 | Test Loss: 3723.981 | Test Loss [MAPE]: 4961798.868 --time-- 6.148114204406738\n",
      "Epoch 13/500 | Train Loss: 3686.468 | Test Loss: 3673.468 | Test Loss [MAPE]: 5539598.128 --time-- 6.152018070220947\n",
      "Epoch 14/500 | Train Loss: 3633.649 | Test Loss: 3621.664 | Test Loss [MAPE]: 6253091.418 --time-- 6.15031623840332\n",
      "Epoch 15/500 | Train Loss: 3583.773 | Test Loss: 3552.341 | Test Loss [MAPE]: 6669702.055 --time-- 6.152948379516602\n",
      "Epoch 16/500 | Train Loss: 3518.087 | Test Loss: 3496.216 | Test Loss [MAPE]: 7095524.208 --time-- 6.148833751678467\n",
      "Epoch 17/500 | Train Loss: 3461.456 | Test Loss: 3438.171 | Test Loss [MAPE]: 6507538.709 --time-- 6.17280125617981\n",
      "Epoch 18/500 | Train Loss: 3402.757 | Test Loss: 3368.993 | Test Loss [MAPE]: 6864759.045 --time-- 6.175296068191528\n",
      "Epoch 19/500 | Train Loss: 3347.057 | Test Loss: 3313.224 | Test Loss [MAPE]: 6728138.346 --time-- 6.181863069534302\n",
      "Epoch 20/500 | Train Loss: 3285.996 | Test Loss: 3254.733 | Test Loss [MAPE]: 6934428.669 --time-- 6.18064284324646\n",
      "Epoch 21/500 | Train Loss: 3233.950 | Test Loss: 3208.578 | Test Loss [MAPE]: 6964865.830 --time-- 6.177407264709473\n",
      "Epoch 22/500 | Train Loss: 3173.823 | Test Loss: 3143.427 | Test Loss [MAPE]: 6409158.846 --time-- 6.17807149887085\n",
      "Epoch 23/500 | Train Loss: 3119.280 | Test Loss: 3088.691 | Test Loss [MAPE]: 6971570.286 --time-- 6.172640800476074\n",
      "Epoch 24/500 | Train Loss: 3052.871 | Test Loss: 3027.020 | Test Loss [MAPE]: 6588295.655 --time-- 6.171631574630737\n",
      "Epoch 25/500 | Train Loss: 3004.788 | Test Loss: 2964.933 | Test Loss [MAPE]: 6300443.513 --time-- 6.1696038246154785\n",
      "Epoch 26/500 | Train Loss: 2941.778 | Test Loss: 2923.277 | Test Loss [MAPE]: 6092320.681 --time-- 6.1663124561309814\n",
      "Epoch 27/500 | Train Loss: 2902.163 | Test Loss: 2879.629 | Test Loss [MAPE]: 5645843.546 --time-- 6.163935661315918\n",
      "Epoch 28/500 | Train Loss: 2864.913 | Test Loss: 2854.037 | Test Loss [MAPE]: 5403408.839 --time-- 6.166579246520996\n",
      "Epoch 29/500 | Train Loss: 2832.634 | Test Loss: 2811.640 | Test Loss [MAPE]: 5487597.874 --time-- 6.166818380355835\n",
      "Epoch 30/500 | Train Loss: 2791.724 | Test Loss: 2781.097 | Test Loss [MAPE]: 5404232.756 --time-- 6.164443492889404\n",
      "Epoch 31/500 | Train Loss: 2765.840 | Test Loss: 2761.002 | Test Loss [MAPE]: 5321272.052 --time-- 6.165428400039673\n",
      "Epoch 32/500 | Train Loss: 2733.846 | Test Loss: 2724.282 | Test Loss [MAPE]: 4999796.028 --time-- 6.1919097900390625\n",
      "Epoch 33/500 | Train Loss: 2706.241 | Test Loss: 2722.757 | Test Loss [MAPE]: 4920923.267 --time-- 6.190218925476074\n",
      "Epoch 34/500 | Train Loss: 2676.758 | Test Loss: 2673.416 | Test Loss [MAPE]: 4558701.952 --time-- 6.189123153686523\n",
      "Epoch 35/500 | Train Loss: 2624.729 | Test Loss: 2608.621 | Test Loss [MAPE]: 4580317.773 --time-- 6.188640356063843\n",
      "Epoch 36/500 | Train Loss: 2572.923 | Test Loss: 2562.428 | Test Loss [MAPE]: 4144765.691 --time-- 6.182039976119995\n",
      "Epoch 37/500 | Train Loss: 2551.920 | Test Loss: 2543.858 | Test Loss [MAPE]: 4295573.340 --time-- 6.186993837356567\n",
      "Epoch 38/500 | Train Loss: 2523.815 | Test Loss: 2527.980 | Test Loss [MAPE]: 3931438.986 --time-- 6.185389280319214\n",
      "Epoch 39/500 | Train Loss: 2498.870 | Test Loss: 2490.521 | Test Loss [MAPE]: 3959117.070 --time-- 6.182392120361328\n",
      "Epoch 40/500 | Train Loss: 2473.140 | Test Loss: 2463.397 | Test Loss [MAPE]: 3767258.887 --time-- 6.18376350402832\n",
      "Epoch 41/500 | Train Loss: 2445.330 | Test Loss: 2428.728 | Test Loss [MAPE]: 3646890.265 --time-- 6.15111517906189\n",
      "Epoch 42/500 | Train Loss: 2374.695 | Test Loss: 2364.190 | Test Loss [MAPE]: 3385676.593 --time-- 6.1540045738220215\n",
      "Epoch 43/500 | Train Loss: 2342.176 | Test Loss: 2329.030 | Test Loss [MAPE]: 3273154.187 --time-- 6.151706695556641\n",
      "Epoch 44/500 | Train Loss: 2288.676 | Test Loss: 2269.049 | Test Loss [MAPE]: 3166639.083 --time-- 6.152626037597656\n",
      "Epoch 45/500 | Train Loss: 2262.913 | Test Loss: 2258.120 | Test Loss [MAPE]: 3194159.782 --time-- 6.149474382400513\n",
      "Epoch 46/500 | Train Loss: 2234.190 | Test Loss: 2236.142 | Test Loss [MAPE]: 3101075.763 --time-- 6.152114391326904\n",
      "Epoch 47/500 | Train Loss: 2206.625 | Test Loss: 2240.702 | Test Loss [MAPE]: 3113570.399 --time-- 6.151360750198364\n",
      "Epoch 48/500 | Train Loss: 2177.901 | Test Loss: 2196.908 | Test Loss [MAPE]: 2669357.567 --time-- 6.2347047328948975\n",
      "Epoch 49/500 | Train Loss: 2159.921 | Test Loss: 2164.956 | Test Loss [MAPE]: 2723865.194 --time-- 6.231445789337158\n",
      "Epoch 50/500 | Train Loss: 2132.316 | Test Loss: 2141.819 | Test Loss [MAPE]: 2535042.633 --time-- 6.257546663284302\n",
      "Epoch 51/500 | Train Loss: 2135.110 | Test Loss: 2146.564 | Test Loss [MAPE]: 2611701.064 --time-- 6.185777425765991\n",
      "Epoch 52/500 | Train Loss: 2103.511 | Test Loss: 2109.631 | Test Loss [MAPE]: 2399268.538 --time-- 6.188175678253174\n",
      "Epoch 53/500 | Train Loss: 2092.602 | Test Loss: 2098.663 | Test Loss [MAPE]: 2349021.973 --time-- 6.186712026596069\n",
      "Epoch 54/500 | Train Loss: 2085.017 | Test Loss: 2103.339 | Test Loss [MAPE]: 2355962.283 --time-- 6.186834096908569\n",
      "Epoch 55/500 | Train Loss: 2081.013 | Test Loss: 2108.326 | Test Loss [MAPE]: 2405817.561 --time-- 6.182313442230225\n",
      "Epoch 56/500 | Train Loss: 2075.906 | Test Loss: 2085.529 | Test Loss [MAPE]: 2379310.689 --time-- 6.179767608642578\n",
      "Epoch 57/500 | Train Loss: 2079.021 | Test Loss: 2095.362 | Test Loss [MAPE]: 2210266.345 --time-- 6.180253267288208\n",
      "Epoch 58/500 | Train Loss: 2061.604 | Test Loss: 2069.913 | Test Loss [MAPE]: 2127362.125 --time-- 6.187375068664551\n",
      "Epoch 59/500 | Train Loss: 2050.258 | Test Loss: 2081.898 | Test Loss [MAPE]: 2344052.613 --time-- 6.184427976608276\n",
      "Epoch 60/500 | Train Loss: 2052.539 | Test Loss: 2072.027 | Test Loss [MAPE]: 2223454.406 --time-- 6.18750524520874\n",
      "Epoch 61/500 | Train Loss: 2043.926 | Test Loss: 2044.294 | Test Loss [MAPE]: 1993011.664 --time-- 6.185377836227417\n",
      "Epoch 62/500 | Train Loss: 2038.469 | Test Loss: 2039.868 | Test Loss [MAPE]: 2131409.722 --time-- 6.186200141906738\n",
      "Epoch 63/500 | Train Loss: 2038.819 | Test Loss: 2059.516 | Test Loss [MAPE]: 2167373.855 --time-- 6.184272050857544\n",
      "Epoch 64/500 | Train Loss: 2043.852 | Test Loss: 2050.052 | Test Loss [MAPE]: 2162106.399 --time-- 6.187373399734497\n",
      "Epoch 65/500 | Train Loss: 2039.096 | Test Loss: 2046.822 | Test Loss [MAPE]: 1992351.657 --time-- 6.184541940689087\n",
      "Epoch 66/500 | Train Loss: 2030.255 | Test Loss: 2061.490 | Test Loss [MAPE]: 2079955.687 --time-- 6.1812424659729\n",
      "Epoch 67/500 | Train Loss: 2035.771 | Test Loss: 2051.935 | Test Loss [MAPE]: 1943631.095 --time-- 6.184820890426636\n",
      "Epoch 68/500 | Train Loss: 2026.045 | Test Loss: 2058.509 | Test Loss [MAPE]: 1998315.824 --time-- 6.151520252227783\n",
      "Epoch 69/500 | Train Loss: 2027.788 | Test Loss: 2051.473 | Test Loss [MAPE]: 1976288.742 --time-- 6.14937949180603\n",
      "Epoch 70/500 | Train Loss: 2021.499 | Test Loss: 2038.001 | Test Loss [MAPE]: 1949219.465 --time-- 6.15538215637207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500 | Train Loss: 2040.201 | Test Loss: 2062.740 | Test Loss [MAPE]: 1872411.634 --time-- 6.15636134147644\n",
      "Epoch 72/500 | Train Loss: 2021.635 | Test Loss: 2030.530 | Test Loss [MAPE]: 1934328.647 --time-- 6.1517980098724365\n",
      "Epoch 73/500 | Train Loss: 2027.453 | Test Loss: 2036.734 | Test Loss [MAPE]: 1879895.693 --time-- 6.15146541595459\n",
      "Epoch 74/500 | Train Loss: 2013.798 | Test Loss: 2054.504 | Test Loss [MAPE]: 1938973.617 --time-- 6.155268907546997\n",
      "Epoch 75/500 | Train Loss: 2023.831 | Test Loss: 2017.101 | Test Loss [MAPE]: 1876645.542 --time-- 6.154169797897339\n",
      "Epoch 76/500 | Train Loss: 2022.097 | Test Loss: 2032.145 | Test Loss [MAPE]: 2002503.993 --time-- 6.150205135345459\n",
      "Epoch 77/500 | Train Loss: 2009.814 | Test Loss: 2053.967 | Test Loss [MAPE]: 2091556.546 --time-- 6.153581380844116\n",
      "Epoch 78/500 | Train Loss: 2014.920 | Test Loss: 2037.980 | Test Loss [MAPE]: 2019142.641 --time-- 6.150638580322266\n",
      "Epoch 79/500 | Train Loss: 2011.613 | Test Loss: 2042.102 | Test Loss [MAPE]: 2196661.724 --time-- 6.154212713241577\n",
      "Epoch 80/500 | Train Loss: 2014.141 | Test Loss: 2037.052 | Test Loss [MAPE]: 2059561.178 --time-- 6.156575918197632\n",
      "Epoch 81/500 | Train Loss: 2012.641 | Test Loss: 2030.531 | Test Loss [MAPE]: 1888947.993 --time-- 6.154430866241455\n",
      "Epoch 82/500 | Train Loss: 2007.735 | Test Loss: 2031.859 | Test Loss [MAPE]: 1924538.630 --time-- 6.153364896774292\n",
      "Epoch 83/500 | Train Loss: 2009.557 | Test Loss: 2037.181 | Test Loss [MAPE]: 1849725.140 --time-- 6.157379627227783\n",
      "Epoch 84/500 | Train Loss: 2009.011 | Test Loss: 2015.523 | Test Loss [MAPE]: 1987800.278 --time-- 6.153500318527222\n",
      "Epoch 85/500 | Train Loss: 2005.805 | Test Loss: 2029.817 | Test Loss [MAPE]: 2083055.218 --time-- 6.156446933746338\n",
      "Epoch 86/500 | Train Loss: 2002.600 | Test Loss: 2014.916 | Test Loss [MAPE]: 1821316.929 --time-- 6.15117883682251\n",
      "Epoch 87/500 | Train Loss: 2011.991 | Test Loss: 2037.022 | Test Loss [MAPE]: 2013393.456 --time-- 6.154891014099121\n",
      "Epoch 88/500 | Train Loss: 2009.263 | Test Loss: 2025.025 | Test Loss [MAPE]: 1914544.135 --time-- 6.154176950454712\n",
      "Epoch 89/500 | Train Loss: 2003.341 | Test Loss: 2040.812 | Test Loss [MAPE]: 1803463.853 --time-- 6.155698776245117\n",
      "Epoch 90/500 | Train Loss: 2006.044 | Test Loss: 2024.921 | Test Loss [MAPE]: 2018649.172 --time-- 6.156455993652344\n",
      "Epoch 91/500 | Train Loss: 2010.759 | Test Loss: 2040.463 | Test Loss [MAPE]: 1964127.574 --time-- 6.158618688583374\n",
      "Epoch 92/500 | Train Loss: 2004.537 | Test Loss: 2016.823 | Test Loss [MAPE]: 2058513.702 --time-- 6.149631977081299\n",
      "Epoch 93/500 | Train Loss: 1995.430 | Test Loss: 2014.868 | Test Loss [MAPE]: 1883599.996 --time-- 6.154319763183594\n",
      "Epoch 94/500 | Train Loss: 1998.295 | Test Loss: 2002.634 | Test Loss [MAPE]: 1852999.370 --time-- 6.15437126159668\n",
      "Epoch 95/500 | Train Loss: 2006.188 | Test Loss: 2023.466 | Test Loss [MAPE]: 2039729.188 --time-- 6.152665376663208\n",
      "Epoch 96/500 | Train Loss: 2004.889 | Test Loss: 2025.467 | Test Loss [MAPE]: 1980750.458 --time-- 6.1555564403533936\n",
      "Epoch 97/500 | Train Loss: 2001.196 | Test Loss: 2022.623 | Test Loss [MAPE]: 1819018.584 --time-- 6.156254768371582\n",
      "Epoch 98/500 | Train Loss: 2001.997 | Test Loss: 2024.864 | Test Loss [MAPE]: 1829801.639 --time-- 6.152759552001953\n",
      "Epoch 99/500 | Train Loss: 1999.949 | Test Loss: 2029.057 | Test Loss [MAPE]: 1961650.272 --time-- 6.157428503036499\n",
      "Epoch 100/500 | Train Loss: 2010.623 | Test Loss: 2028.916 | Test Loss [MAPE]: 1619292.071 --time-- 6.152486085891724\n",
      "Epoch 101/500 | Train Loss: 2003.218 | Test Loss: 2013.512 | Test Loss [MAPE]: 1954032.370 --time-- 6.153058052062988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 09:32:31,240] Trial 53 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500 | Train Loss: 1989.253 | Test Loss: 2017.311 | Test Loss [MAPE]: 1836689.510 --time-- 6.153636932373047\n",
      "Epoch 1/500 | Train Loss: 194175.023 | Test Loss: 5161.745 | Test Loss [MAPE]: 426306.217 --time-- 37.58102488517761\n",
      "Epoch 2/500 | Train Loss: 5106.390 | Test Loss: 5161.749 | Test Loss [MAPE]: 431390.250 --time-- 37.86099863052368\n",
      "Epoch 3/500 | Train Loss: 5106.413 | Test Loss: 5161.789 | Test Loss [MAPE]: 417465.522 --time-- 37.85899353027344\n",
      "Epoch 4/500 | Train Loss: 5106.426 | Test Loss: 5161.828 | Test Loss [MAPE]: 424708.147 --time-- 37.85600662231445\n",
      "Epoch 5/500 | Train Loss: 5106.453 | Test Loss: 5161.809 | Test Loss [MAPE]: 429168.647 --time-- 37.86342763900757\n",
      "Epoch 6/500 | Train Loss: 5106.462 | Test Loss: 5161.811 | Test Loss [MAPE]: 430383.140 --time-- 37.88180589675903\n",
      "Epoch 7/500 | Train Loss: 5106.569 | Test Loss: 5161.896 | Test Loss [MAPE]: 430584.752 --time-- 37.8622841835022\n",
      "Epoch 8/500 | Train Loss: 5106.483 | Test Loss: 5161.929 | Test Loss [MAPE]: 417175.341 --time-- 37.859121561050415\n",
      "Epoch 9/500 | Train Loss: 5106.543 | Test Loss: 5161.826 | Test Loss [MAPE]: 427569.861 --time-- 37.86375880241394\n",
      "Epoch 10/500 | Train Loss: 5106.489 | Test Loss: 5161.896 | Test Loss [MAPE]: 420531.822 --time-- 37.8534677028656\n",
      "Epoch 11/500 | Train Loss: 5106.486 | Test Loss: 5161.876 | Test Loss [MAPE]: 433209.585 --time-- 37.86241674423218\n",
      "Epoch 12/500 | Train Loss: 5106.530 | Test Loss: 5161.831 | Test Loss [MAPE]: 419792.524 --time-- 37.86247634887695\n",
      "Epoch 13/500 | Train Loss: 5106.629 | Test Loss: 5162.350 | Test Loss [MAPE]: 452760.704 --time-- 37.862539291381836\n",
      "Epoch 14/500 | Train Loss: 5106.630 | Test Loss: 5162.111 | Test Loss [MAPE]: 418221.502 --time-- 37.8757688999176\n",
      "Epoch 15/500 | Train Loss: 5106.557 | Test Loss: 5161.827 | Test Loss [MAPE]: 422913.767 --time-- 37.874703884124756\n",
      "Epoch 16/500 | Train Loss: 5106.522 | Test Loss: 5162.112 | Test Loss [MAPE]: 419261.509 --time-- 37.9693489074707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 09:43:17,241] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.576 | Test Loss: 5161.896 | Test Loss [MAPE]: 428990.888 --time-- 37.86933636665344\n",
      "Epoch 1/500 | Train Loss: 5125.912 | Test Loss: 5171.247 | Test Loss [MAPE]: 529281.236 --time-- 4.159134149551392\n",
      "Epoch 2/500 | Train Loss: 5112.460 | Test Loss: 5165.629 | Test Loss [MAPE]: 491260.807 --time-- 4.125772714614868\n",
      "Epoch 3/500 | Train Loss: 5109.715 | Test Loss: 5164.527 | Test Loss [MAPE]: 474518.694 --time-- 4.125498056411743\n",
      "Epoch 4/500 | Train Loss: 5108.893 | Test Loss: 5163.924 | Test Loss [MAPE]: 464059.929 --time-- 4.12381649017334\n",
      "Epoch 5/500 | Train Loss: 5108.365 | Test Loss: 5163.479 | Test Loss [MAPE]: 458014.582 --time-- 4.122922658920288\n",
      "Epoch 6/500 | Train Loss: 5107.935 | Test Loss: 5163.058 | Test Loss [MAPE]: 449914.028 --time-- 4.123561143875122\n",
      "Epoch 7/500 | Train Loss: 5107.547 | Test Loss: 5162.722 | Test Loss [MAPE]: 444592.431 --time-- 4.1216161251068115\n",
      "Epoch 8/500 | Train Loss: 5107.236 | Test Loss: 5162.451 | Test Loss [MAPE]: 439923.024 --time-- 4.123310565948486\n",
      "Epoch 9/500 | Train Loss: 5106.988 | Test Loss: 5162.235 | Test Loss [MAPE]: 436317.487 --time-- 4.128381729125977\n",
      "Epoch 10/500 | Train Loss: 5106.784 | Test Loss: 5162.053 | Test Loss [MAPE]: 434795.568 --time-- 4.1258814334869385\n",
      "Epoch 11/500 | Train Loss: 5106.607 | Test Loss: 5161.919 | Test Loss [MAPE]: 428279.402 --time-- 4.125567436218262\n",
      "Epoch 12/500 | Train Loss: 5106.490 | Test Loss: 5161.802 | Test Loss [MAPE]: 429217.612 --time-- 4.123937606811523\n",
      "Epoch 13/500 | Train Loss: 5106.391 | Test Loss: 5161.716 | Test Loss [MAPE]: 426857.673 --time-- 4.12459135055542\n",
      "Epoch 14/500 | Train Loss: 5106.316 | Test Loss: 5161.661 | Test Loss [MAPE]: 427665.279 --time-- 4.123839855194092\n",
      "Epoch 15/500 | Train Loss: 5106.257 | Test Loss: 5161.624 | Test Loss [MAPE]: 423553.527 --time-- 4.121772527694702\n",
      "Epoch 16/500 | Train Loss: 5106.223 | Test Loss: 5161.573 | Test Loss [MAPE]: 423790.385 --time-- 4.125027418136597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 09:44:28,057] Trial 55 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.168 | Test Loss: 5161.512 | Test Loss [MAPE]: 423651.913 --time-- 4.125770568847656\n",
      "Epoch 1/500 | Train Loss: 5238.287 | Test Loss: 5161.718 | Test Loss [MAPE]: 426789.451 --time-- 2.5519020557403564\n",
      "Epoch 2/500 | Train Loss: 5184.644 | Test Loss: 4568.679 | Test Loss [MAPE]: 6798190.321 --time-- 2.52964186668396\n",
      "Epoch 3/500 | Train Loss: 4339.337 | Test Loss: 4219.964 | Test Loss [MAPE]: 3120747.513 --time-- 2.5415353775024414\n",
      "Epoch 4/500 | Train Loss: 4139.824 | Test Loss: 4085.482 | Test Loss [MAPE]: 2475993.728 --time-- 2.5392165184020996\n",
      "Epoch 5/500 | Train Loss: 4017.605 | Test Loss: 3972.169 | Test Loss [MAPE]: 2918694.630 --time-- 2.5429866313934326\n",
      "Epoch 6/500 | Train Loss: 3912.597 | Test Loss: 3862.027 | Test Loss [MAPE]: 2967338.317 --time-- 2.544255495071411\n",
      "Epoch 7/500 | Train Loss: 3814.632 | Test Loss: 3783.482 | Test Loss [MAPE]: 3657049.150 --time-- 2.543590784072876\n",
      "Epoch 8/500 | Train Loss: 3739.363 | Test Loss: 3718.824 | Test Loss [MAPE]: 3598168.473 --time-- 2.540773868560791\n",
      "Epoch 9/500 | Train Loss: 3667.590 | Test Loss: 3658.572 | Test Loss [MAPE]: 3778352.901 --time-- 2.5424840450286865\n",
      "Epoch 10/500 | Train Loss: 3663.744 | Test Loss: 3679.331 | Test Loss [MAPE]: 3580987.428 --time-- 2.4940385818481445\n",
      "Epoch 11/500 | Train Loss: 3578.856 | Test Loss: 3525.816 | Test Loss [MAPE]: 4089395.011 --time-- 2.497135877609253\n",
      "Epoch 12/500 | Train Loss: 3485.355 | Test Loss: 3435.160 | Test Loss [MAPE]: 3701193.140 --time-- 2.4953982830047607\n",
      "Epoch 13/500 | Train Loss: 3399.337 | Test Loss: 3461.941 | Test Loss [MAPE]: 2969964.327 --time-- 2.4952449798583984\n",
      "Epoch 14/500 | Train Loss: 3370.817 | Test Loss: 3318.049 | Test Loss [MAPE]: 3453676.678 --time-- 2.4963300228118896\n",
      "Epoch 15/500 | Train Loss: 3301.110 | Test Loss: 3396.829 | Test Loss [MAPE]: 3119960.279 --time-- 2.492266893386841\n",
      "Epoch 16/500 | Train Loss: 3311.749 | Test Loss: 3279.821 | Test Loss [MAPE]: 2730113.079 --time-- 2.4970362186431885\n",
      "Epoch 17/500 | Train Loss: 3342.481 | Test Loss: 3236.444 | Test Loss [MAPE]: 2596128.246 --time-- 2.4938547611236572\n",
      "Epoch 18/500 | Train Loss: 3203.121 | Test Loss: 3196.010 | Test Loss [MAPE]: 2754005.317 --time-- 2.4942522048950195\n",
      "Epoch 19/500 | Train Loss: 3150.548 | Test Loss: 3139.330 | Test Loss [MAPE]: 2165135.341 --time-- 2.494746208190918\n",
      "Epoch 20/500 | Train Loss: 3100.835 | Test Loss: 3087.098 | Test Loss [MAPE]: 2274260.552 --time-- 2.494666576385498\n",
      "Epoch 21/500 | Train Loss: 3072.259 | Test Loss: 3068.534 | Test Loss [MAPE]: 1700992.089 --time-- 2.4937212467193604\n",
      "Epoch 22/500 | Train Loss: 3064.000 | Test Loss: 3144.193 | Test Loss [MAPE]: 1833783.516 --time-- 2.4941794872283936\n",
      "Epoch 23/500 | Train Loss: 3045.766 | Test Loss: 3017.815 | Test Loss [MAPE]: 1840934.893 --time-- 2.490581512451172\n",
      "Epoch 24/500 | Train Loss: 3060.530 | Test Loss: 3042.689 | Test Loss [MAPE]: 1871060.980 --time-- 2.491162061691284\n",
      "Epoch 25/500 | Train Loss: 3017.846 | Test Loss: 3009.179 | Test Loss [MAPE]: 1797128.577 --time-- 2.49229097366333\n",
      "Epoch 26/500 | Train Loss: 2971.383 | Test Loss: 2976.291 | Test Loss [MAPE]: 1879013.536 --time-- 2.4874250888824463\n",
      "Epoch 27/500 | Train Loss: 2952.806 | Test Loss: 2958.873 | Test Loss [MAPE]: 1751499.803 --time-- 2.4915807247161865\n",
      "Epoch 28/500 | Train Loss: 2948.818 | Test Loss: 2989.693 | Test Loss [MAPE]: 1852518.847 --time-- 2.4898502826690674\n",
      "Epoch 29/500 | Train Loss: 2942.721 | Test Loss: 2962.660 | Test Loss [MAPE]: 1632366.744 --time-- 2.486234188079834\n",
      "Epoch 30/500 | Train Loss: 2929.632 | Test Loss: 2939.214 | Test Loss [MAPE]: 1606646.673 --time-- 2.4913644790649414\n",
      "Epoch 31/500 | Train Loss: 2920.976 | Test Loss: 2954.781 | Test Loss [MAPE]: 1952790.033 --time-- 2.4915060997009277\n",
      "Epoch 32/500 | Train Loss: 2918.681 | Test Loss: 2926.186 | Test Loss [MAPE]: 1700412.246 --time-- 2.488482713699341\n",
      "Epoch 33/500 | Train Loss: 2907.360 | Test Loss: 2906.842 | Test Loss [MAPE]: 1682062.328 --time-- 2.4875271320343018\n",
      "Epoch 34/500 | Train Loss: 2886.038 | Test Loss: 2933.868 | Test Loss [MAPE]: 1585939.382 --time-- 2.487165689468384\n",
      "Epoch 35/500 | Train Loss: 2894.784 | Test Loss: 2881.620 | Test Loss [MAPE]: 1580923.622 --time-- 2.490457057952881\n",
      "Epoch 36/500 | Train Loss: 2881.663 | Test Loss: 2892.697 | Test Loss [MAPE]: 1533733.575 --time-- 2.4914486408233643\n",
      "Epoch 37/500 | Train Loss: 2871.029 | Test Loss: 2945.872 | Test Loss [MAPE]: 1682629.252 --time-- 2.4885027408599854\n",
      "Epoch 38/500 | Train Loss: 2873.011 | Test Loss: 2883.104 | Test Loss [MAPE]: 1778687.713 --time-- 2.4893696308135986\n",
      "Epoch 39/500 | Train Loss: 2857.557 | Test Loss: 2846.899 | Test Loss [MAPE]: 1186405.680 --time-- 2.4920666217803955\n",
      "Epoch 40/500 | Train Loss: 2824.279 | Test Loss: 2825.395 | Test Loss [MAPE]: 1277858.753 --time-- 2.487241506576538\n",
      "Epoch 41/500 | Train Loss: 2833.944 | Test Loss: 2845.435 | Test Loss [MAPE]: 1459706.524 --time-- 2.486072063446045\n",
      "Epoch 42/500 | Train Loss: 2829.906 | Test Loss: 2849.981 | Test Loss [MAPE]: 1607832.530 --time-- 2.4839489459991455\n",
      "Epoch 43/500 | Train Loss: 2827.728 | Test Loss: 2840.462 | Test Loss [MAPE]: 1210029.107 --time-- 2.4857113361358643\n",
      "Epoch 44/500 | Train Loss: 2827.808 | Test Loss: 2821.392 | Test Loss [MAPE]: 1305361.426 --time-- 2.485226631164551\n",
      "Epoch 45/500 | Train Loss: 2821.236 | Test Loss: 2863.105 | Test Loss [MAPE]: 1549538.355 --time-- 2.489678382873535\n",
      "Epoch 46/500 | Train Loss: 2821.462 | Test Loss: 2836.279 | Test Loss [MAPE]: 1624258.305 --time-- 2.485903263092041\n",
      "Epoch 47/500 | Train Loss: 2817.172 | Test Loss: 2824.091 | Test Loss [MAPE]: 1243995.910 --time-- 2.490976095199585\n",
      "Epoch 48/500 | Train Loss: 2809.536 | Test Loss: 2850.440 | Test Loss [MAPE]: 1276332.292 --time-- 2.484447717666626\n",
      "Epoch 49/500 | Train Loss: 2809.341 | Test Loss: 2835.223 | Test Loss [MAPE]: 1403204.668 --time-- 2.4845149517059326\n",
      "Epoch 50/500 | Train Loss: 2814.835 | Test Loss: 2819.625 | Test Loss [MAPE]: 1287557.649 --time-- 2.484104633331299\n",
      "Epoch 51/500 | Train Loss: 2804.099 | Test Loss: 2795.796 | Test Loss [MAPE]: 1139327.579 --time-- 2.4867281913757324\n",
      "Epoch 52/500 | Train Loss: 2797.679 | Test Loss: 2808.527 | Test Loss [MAPE]: 1229705.111 --time-- 2.4879066944122314\n",
      "Epoch 53/500 | Train Loss: 2797.288 | Test Loss: 2823.789 | Test Loss [MAPE]: 1292272.426 --time-- 2.4877569675445557\n",
      "Epoch 54/500 | Train Loss: 2805.885 | Test Loss: 2812.552 | Test Loss [MAPE]: 1398758.734 --time-- 2.4850668907165527\n",
      "Epoch 55/500 | Train Loss: 2805.175 | Test Loss: 2791.546 | Test Loss [MAPE]: 1200001.729 --time-- 2.4849650859832764\n",
      "Epoch 56/500 | Train Loss: 2795.603 | Test Loss: 2796.060 | Test Loss [MAPE]: 1300573.540 --time-- 2.4864721298217773\n",
      "Epoch 57/500 | Train Loss: 2789.665 | Test Loss: 2827.057 | Test Loss [MAPE]: 1233047.037 --time-- 2.4812042713165283\n",
      "Epoch 58/500 | Train Loss: 2809.855 | Test Loss: 2890.531 | Test Loss [MAPE]: 1147264.343 --time-- 2.486455202102661\n",
      "Epoch 59/500 | Train Loss: 2810.929 | Test Loss: 2810.631 | Test Loss [MAPE]: 1224143.047 --time-- 2.486466646194458\n",
      "Epoch 60/500 | Train Loss: 2788.437 | Test Loss: 2788.817 | Test Loss [MAPE]: 1290256.912 --time-- 2.4846243858337402\n",
      "Epoch 61/500 | Train Loss: 2793.297 | Test Loss: 2831.045 | Test Loss [MAPE]: 1334126.587 --time-- 2.4842567443847656\n",
      "Epoch 62/500 | Train Loss: 2801.804 | Test Loss: 2792.200 | Test Loss [MAPE]: 1221283.821 --time-- 2.4879841804504395\n",
      "Epoch 63/500 | Train Loss: 2795.066 | Test Loss: 2816.546 | Test Loss [MAPE]: 1382063.892 --time-- 2.4841468334198\n",
      "Epoch 64/500 | Train Loss: 2800.213 | Test Loss: 2791.052 | Test Loss [MAPE]: 1197652.048 --time-- 2.485696792602539\n",
      "Epoch 65/500 | Train Loss: 2791.944 | Test Loss: 2810.984 | Test Loss [MAPE]: 1344163.936 --time-- 2.4835188388824463\n",
      "Epoch 66/500 | Train Loss: 2782.169 | Test Loss: 2792.965 | Test Loss [MAPE]: 1195507.575 --time-- 2.4791817665100098\n",
      "Epoch 67/500 | Train Loss: 2791.327 | Test Loss: 2799.411 | Test Loss [MAPE]: 1189941.040 --time-- 2.482998847961426\n",
      "Epoch 68/500 | Train Loss: 2783.555 | Test Loss: 2812.153 | Test Loss [MAPE]: 1347070.792 --time-- 2.483502149581909\n",
      "Epoch 69/500 | Train Loss: 2798.215 | Test Loss: 2799.139 | Test Loss [MAPE]: 1347729.139 --time-- 2.4848036766052246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500 | Train Loss: 2795.677 | Test Loss: 2788.160 | Test Loss [MAPE]: 1297286.504 --time-- 2.4842848777770996\n",
      "Epoch 71/500 | Train Loss: 2785.659 | Test Loss: 2820.666 | Test Loss [MAPE]: 1324444.152 --time-- 2.485116481781006\n",
      "Epoch 72/500 | Train Loss: 2783.298 | Test Loss: 2803.779 | Test Loss [MAPE]: 1317523.462 --time-- 2.4842727184295654\n",
      "Epoch 73/500 | Train Loss: 2785.540 | Test Loss: 2799.649 | Test Loss [MAPE]: 1254309.805 --time-- 2.4824376106262207\n",
      "Epoch 74/500 | Train Loss: 2794.973 | Test Loss: 2792.085 | Test Loss [MAPE]: 1257225.288 --time-- 2.488222122192383\n",
      "Epoch 75/500 | Train Loss: 2767.156 | Test Loss: 2803.673 | Test Loss [MAPE]: 1326324.174 --time-- 2.48124361038208\n",
      "Epoch 76/500 | Train Loss: 2783.083 | Test Loss: 2799.384 | Test Loss [MAPE]: 1158661.112 --time-- 2.48028564453125\n",
      "Epoch 77/500 | Train Loss: 2775.358 | Test Loss: 2799.047 | Test Loss [MAPE]: 1283220.649 --time-- 2.479917049407959\n",
      "Epoch 78/500 | Train Loss: 2780.236 | Test Loss: 2795.709 | Test Loss [MAPE]: 1169984.386 --time-- 2.4868054389953613\n",
      "Epoch 79/500 | Train Loss: 2782.680 | Test Loss: 2797.104 | Test Loss [MAPE]: 1282738.691 --time-- 2.486154317855835\n",
      "Epoch 80/500 | Train Loss: 2777.575 | Test Loss: 2813.896 | Test Loss [MAPE]: 1315859.282 --time-- 2.486802339553833\n",
      "Epoch 81/500 | Train Loss: 2786.916 | Test Loss: 2796.295 | Test Loss [MAPE]: 1187542.386 --time-- 2.486009120941162\n",
      "Epoch 82/500 | Train Loss: 2780.949 | Test Loss: 2789.597 | Test Loss [MAPE]: 1173870.634 --time-- 2.4832632541656494\n",
      "Epoch 83/500 | Train Loss: 2776.563 | Test Loss: 2817.995 | Test Loss [MAPE]: 1202109.491 --time-- 2.4852519035339355\n",
      "Epoch 84/500 | Train Loss: 2788.570 | Test Loss: 2786.881 | Test Loss [MAPE]: 1228152.146 --time-- 2.487947463989258\n",
      "Epoch 85/500 | Train Loss: 2778.948 | Test Loss: 2807.857 | Test Loss [MAPE]: 1328158.757 --time-- 2.484685182571411\n",
      "Epoch 86/500 | Train Loss: 2780.681 | Test Loss: 2798.270 | Test Loss [MAPE]: 1249123.278 --time-- 2.4871628284454346\n",
      "Epoch 87/500 | Train Loss: 2781.801 | Test Loss: 2807.086 | Test Loss [MAPE]: 1312860.822 --time-- 2.482928514480591\n",
      "Epoch 88/500 | Train Loss: 2777.099 | Test Loss: 2786.504 | Test Loss [MAPE]: 1340823.845 --time-- 2.4894843101501465\n",
      "Epoch 89/500 | Train Loss: 2780.604 | Test Loss: 2808.765 | Test Loss [MAPE]: 1281362.069 --time-- 2.4845619201660156\n",
      "Epoch 90/500 | Train Loss: 2782.412 | Test Loss: 2797.828 | Test Loss [MAPE]: 1241220.001 --time-- 2.4880053997039795\n",
      "Epoch 91/500 | Train Loss: 2773.689 | Test Loss: 2789.506 | Test Loss [MAPE]: 1164101.397 --time-- 2.484431743621826\n",
      "Epoch 92/500 | Train Loss: 2770.192 | Test Loss: 2782.730 | Test Loss [MAPE]: 1177066.171 --time-- 2.4836392402648926\n",
      "Epoch 93/500 | Train Loss: 2769.554 | Test Loss: 2778.716 | Test Loss [MAPE]: 1164030.522 --time-- 2.4822325706481934\n",
      "Epoch 94/500 | Train Loss: 2779.428 | Test Loss: 2815.216 | Test Loss [MAPE]: 1352638.499 --time-- 2.4864156246185303\n",
      "Epoch 95/500 | Train Loss: 2788.321 | Test Loss: 2801.620 | Test Loss [MAPE]: 1205555.713 --time-- 2.485018491744995\n",
      "Epoch 96/500 | Train Loss: 2776.862 | Test Loss: 2792.920 | Test Loss [MAPE]: 1254722.347 --time-- 2.49281644821167\n",
      "Epoch 97/500 | Train Loss: 2773.194 | Test Loss: 2788.726 | Test Loss [MAPE]: 1230522.583 --time-- 2.489868402481079\n",
      "Epoch 98/500 | Train Loss: 2771.092 | Test Loss: 2789.148 | Test Loss [MAPE]: 1274205.019 --time-- 2.4885551929473877\n",
      "Epoch 99/500 | Train Loss: 2787.631 | Test Loss: 2824.668 | Test Loss [MAPE]: 1389722.245 --time-- 2.4849884510040283\n",
      "Epoch 100/500 | Train Loss: 2779.790 | Test Loss: 2801.148 | Test Loss [MAPE]: 1236010.196 --time-- 2.4846765995025635\n",
      "Epoch 101/500 | Train Loss: 2772.008 | Test Loss: 2792.262 | Test Loss [MAPE]: 1230570.939 --time-- 2.487229347229004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 09:48:44,282] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500 | Train Loss: 2773.752 | Test Loss: 2794.932 | Test Loss [MAPE]: 1215771.397 --time-- 2.4827136993408203\n",
      "Epoch 1/500 | Train Loss: 5110.010 | Test Loss: 5161.770 | Test Loss [MAPE]: 421951.520 --time-- 1.9233670234680176\n",
      "Epoch 2/500 | Train Loss: 5105.549 | Test Loss: 5146.854 | Test Loss [MAPE]: 523141.284 --time-- 1.8776049613952637\n",
      "Epoch 3/500 | Train Loss: 4623.959 | Test Loss: 4355.370 | Test Loss [MAPE]: 5915559.678 --time-- 1.880925178527832\n",
      "Epoch 4/500 | Train Loss: 4193.702 | Test Loss: 4091.411 | Test Loss [MAPE]: 3062168.463 --time-- 1.8776323795318604\n",
      "Epoch 5/500 | Train Loss: 4002.858 | Test Loss: 3932.302 | Test Loss [MAPE]: 2161930.262 --time-- 1.8783752918243408\n",
      "Epoch 6/500 | Train Loss: 3854.533 | Test Loss: 3778.105 | Test Loss [MAPE]: 2590714.408 --time-- 1.881645917892456\n",
      "Epoch 7/500 | Train Loss: 3689.465 | Test Loss: 3601.836 | Test Loss [MAPE]: 3384298.116 --time-- 1.884199857711792\n",
      "Epoch 8/500 | Train Loss: 3467.029 | Test Loss: 3348.225 | Test Loss [MAPE]: 3805756.022 --time-- 1.8839313983917236\n",
      "Epoch 9/500 | Train Loss: 3228.338 | Test Loss: 3147.306 | Test Loss [MAPE]: 4574848.299 --time-- 1.8860504627227783\n",
      "Epoch 10/500 | Train Loss: 2947.760 | Test Loss: 2765.748 | Test Loss [MAPE]: 4262436.757 --time-- 1.8838109970092773\n",
      "Epoch 11/500 | Train Loss: 2622.109 | Test Loss: 2487.161 | Test Loss [MAPE]: 4085760.363 --time-- 1.8833119869232178\n",
      "Epoch 12/500 | Train Loss: 2457.274 | Test Loss: 2301.004 | Test Loss [MAPE]: 4233312.401 --time-- 1.8812291622161865\n",
      "Epoch 13/500 | Train Loss: 2248.212 | Test Loss: 2239.503 | Test Loss [MAPE]: 3619006.226 --time-- 1.886200189590454\n",
      "Epoch 14/500 | Train Loss: 2148.280 | Test Loss: 2081.799 | Test Loss [MAPE]: 3404895.130 --time-- 1.8852455615997314\n",
      "Epoch 15/500 | Train Loss: 2045.156 | Test Loss: 1994.370 | Test Loss [MAPE]: 3346752.930 --time-- 1.8834357261657715\n",
      "Epoch 16/500 | Train Loss: 1917.733 | Test Loss: 1867.741 | Test Loss [MAPE]: 3162472.440 --time-- 1.883131980895996\n",
      "Epoch 17/500 | Train Loss: 1835.181 | Test Loss: 1796.042 | Test Loss [MAPE]: 3168760.273 --time-- 1.8891091346740723\n",
      "Epoch 18/500 | Train Loss: 1780.166 | Test Loss: 1722.180 | Test Loss [MAPE]: 3226341.085 --time-- 1.8823089599609375\n",
      "Epoch 19/500 | Train Loss: 1675.143 | Test Loss: 1632.024 | Test Loss [MAPE]: 3088336.814 --time-- 1.8874647617340088\n",
      "Epoch 20/500 | Train Loss: 1600.634 | Test Loss: 1637.664 | Test Loss [MAPE]: 3197562.734 --time-- 1.886315107345581\n",
      "Epoch 21/500 | Train Loss: 1586.394 | Test Loss: 1594.221 | Test Loss [MAPE]: 3075860.583 --time-- 1.884108066558838\n",
      "Epoch 22/500 | Train Loss: 1520.680 | Test Loss: 1512.250 | Test Loss [MAPE]: 2936752.399 --time-- 1.8851814270019531\n",
      "Epoch 23/500 | Train Loss: 1471.914 | Test Loss: 1438.817 | Test Loss [MAPE]: 2810939.122 --time-- 1.8840439319610596\n",
      "Epoch 24/500 | Train Loss: 1417.588 | Test Loss: 1410.370 | Test Loss [MAPE]: 2852820.230 --time-- 1.8888816833496094\n",
      "Epoch 25/500 | Train Loss: 1417.522 | Test Loss: 1441.698 | Test Loss [MAPE]: 2914913.983 --time-- 1.8876123428344727\n",
      "Epoch 26/500 | Train Loss: 1394.183 | Test Loss: 1391.378 | Test Loss [MAPE]: 2715392.428 --time-- 1.8834972381591797\n",
      "Epoch 27/500 | Train Loss: 1339.022 | Test Loss: 1305.122 | Test Loss [MAPE]: 2520642.519 --time-- 1.886507511138916\n",
      "Epoch 28/500 | Train Loss: 1272.338 | Test Loss: 1285.091 | Test Loss [MAPE]: 2351769.853 --time-- 1.8864428997039795\n",
      "Epoch 29/500 | Train Loss: 1252.951 | Test Loss: 1311.627 | Test Loss [MAPE]: 2660141.516 --time-- 1.8847835063934326\n",
      "Epoch 30/500 | Train Loss: 1247.642 | Test Loss: 1270.314 | Test Loss [MAPE]: 2578867.155 --time-- 1.8837056159973145\n",
      "Epoch 31/500 | Train Loss: 1258.653 | Test Loss: 1277.270 | Test Loss [MAPE]: 2919490.520 --time-- 1.883674144744873\n",
      "Epoch 32/500 | Train Loss: 1187.154 | Test Loss: 1206.872 | Test Loss [MAPE]: 2322655.377 --time-- 1.8830053806304932\n",
      "Epoch 33/500 | Train Loss: 1177.113 | Test Loss: 1222.038 | Test Loss [MAPE]: 2491079.733 --time-- 1.8847322463989258\n",
      "Epoch 34/500 | Train Loss: 1161.140 | Test Loss: 1233.414 | Test Loss [MAPE]: 2485957.194 --time-- 1.88547945022583\n",
      "Epoch 35/500 | Train Loss: 1159.638 | Test Loss: 1229.612 | Test Loss [MAPE]: 2455707.192 --time-- 1.8869264125823975\n",
      "Epoch 36/500 | Train Loss: 1157.269 | Test Loss: 1151.924 | Test Loss [MAPE]: 2348691.021 --time-- 1.8852391242980957\n",
      "Epoch 37/500 | Train Loss: 1093.968 | Test Loss: 1133.051 | Test Loss [MAPE]: 2207254.481 --time-- 1.8834683895111084\n",
      "Epoch 38/500 | Train Loss: 1106.936 | Test Loss: 1157.498 | Test Loss [MAPE]: 2377296.878 --time-- 1.8826677799224854\n",
      "Epoch 39/500 | Train Loss: 1083.561 | Test Loss: 1124.956 | Test Loss [MAPE]: 2180847.157 --time-- 1.886826515197754\n",
      "Epoch 40/500 | Train Loss: 1091.638 | Test Loss: 1097.883 | Test Loss [MAPE]: 2258508.948 --time-- 1.8850715160369873\n",
      "Epoch 41/500 | Train Loss: 1076.387 | Test Loss: 1120.559 | Test Loss [MAPE]: 2267041.615 --time-- 1.8876283168792725\n",
      "Epoch 42/500 | Train Loss: 1067.748 | Test Loss: 1121.064 | Test Loss [MAPE]: 2323815.164 --time-- 1.8842341899871826\n",
      "Epoch 43/500 | Train Loss: 1063.502 | Test Loss: 1056.443 | Test Loss [MAPE]: 2041719.595 --time-- 1.8827650547027588\n",
      "Epoch 44/500 | Train Loss: 1050.848 | Test Loss: 1125.404 | Test Loss [MAPE]: 2419566.565 --time-- 1.882498025894165\n",
      "Epoch 45/500 | Train Loss: 1062.050 | Test Loss: 1066.473 | Test Loss [MAPE]: 2194035.496 --time-- 1.8843042850494385\n",
      "Epoch 46/500 | Train Loss: 1058.532 | Test Loss: 1061.929 | Test Loss [MAPE]: 2293973.138 --time-- 1.8869214057922363\n",
      "Epoch 47/500 | Train Loss: 1031.186 | Test Loss: 1058.870 | Test Loss [MAPE]: 2192609.665 --time-- 1.8832714557647705\n",
      "Epoch 48/500 | Train Loss: 1027.720 | Test Loss: 1055.962 | Test Loss [MAPE]: 2233496.495 --time-- 1.8863520622253418\n",
      "Epoch 49/500 | Train Loss: 1037.054 | Test Loss: 1050.455 | Test Loss [MAPE]: 2228303.949 --time-- 1.8842947483062744\n",
      "Epoch 50/500 | Train Loss: 1014.372 | Test Loss: 1018.910 | Test Loss [MAPE]: 2135406.717 --time-- 1.8828401565551758\n",
      "Epoch 51/500 | Train Loss: 984.190 | Test Loss: 1002.864 | Test Loss [MAPE]: 2194061.906 --time-- 1.8841609954833984\n",
      "Epoch 52/500 | Train Loss: 1005.100 | Test Loss: 1041.352 | Test Loss [MAPE]: 2310389.652 --time-- 1.890188217163086\n",
      "Epoch 53/500 | Train Loss: 1001.600 | Test Loss: 1032.831 | Test Loss [MAPE]: 2157443.642 --time-- 1.8827481269836426\n",
      "Epoch 54/500 | Train Loss: 1012.920 | Test Loss: 1053.796 | Test Loss [MAPE]: 2488456.580 --time-- 1.8864712715148926\n",
      "Epoch 55/500 | Train Loss: 997.273 | Test Loss: 1013.996 | Test Loss [MAPE]: 2271135.833 --time-- 1.8873226642608643\n",
      "Epoch 56/500 | Train Loss: 971.554 | Test Loss: 1124.413 | Test Loss [MAPE]: 2478965.732 --time-- 1.886279582977295\n",
      "Epoch 57/500 | Train Loss: 1008.003 | Test Loss: 1007.755 | Test Loss [MAPE]: 2299058.813 --time-- 1.8855092525482178\n",
      "Epoch 58/500 | Train Loss: 957.839 | Test Loss: 993.867 | Test Loss [MAPE]: 2239691.380 --time-- 1.9333364963531494\n",
      "Epoch 59/500 | Train Loss: 978.427 | Test Loss: 997.203 | Test Loss [MAPE]: 2375535.383 --time-- 1.9459517002105713\n",
      "Epoch 60/500 | Train Loss: 999.780 | Test Loss: 1116.149 | Test Loss [MAPE]: 2491665.066 --time-- 1.9386372566223145\n",
      "Epoch 61/500 | Train Loss: 972.172 | Test Loss: 971.243 | Test Loss [MAPE]: 2253243.503 --time-- 1.941157341003418\n",
      "Epoch 62/500 | Train Loss: 943.174 | Test Loss: 972.110 | Test Loss [MAPE]: 2235261.348 --time-- 1.9375965595245361\n",
      "Epoch 63/500 | Train Loss: 961.955 | Test Loss: 980.523 | Test Loss [MAPE]: 2288089.514 --time-- 1.9346106052398682\n",
      "Epoch 64/500 | Train Loss: 921.743 | Test Loss: 916.216 | Test Loss [MAPE]: 2111459.542 --time-- 1.9337828159332275\n",
      "Epoch 65/500 | Train Loss: 915.168 | Test Loss: 961.391 | Test Loss [MAPE]: 2270009.703 --time-- 1.9371912479400635\n",
      "Epoch 66/500 | Train Loss: 939.016 | Test Loss: 987.185 | Test Loss [MAPE]: 2329565.884 --time-- 1.8847200870513916\n",
      "Epoch 67/500 | Train Loss: 917.117 | Test Loss: 912.425 | Test Loss [MAPE]: 2218321.275 --time-- 1.883265495300293\n",
      "Epoch 68/500 | Train Loss: 919.334 | Test Loss: 983.137 | Test Loss [MAPE]: 2499923.036 --time-- 1.8855900764465332\n",
      "Epoch 69/500 | Train Loss: 924.392 | Test Loss: 928.298 | Test Loss [MAPE]: 2292621.925 --time-- 1.882202386856079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500 | Train Loss: 906.885 | Test Loss: 923.541 | Test Loss [MAPE]: 2293923.766 --time-- 1.8826427459716797\n",
      "Epoch 71/500 | Train Loss: 895.173 | Test Loss: 914.216 | Test Loss [MAPE]: 2327389.289 --time-- 1.8855705261230469\n",
      "Epoch 72/500 | Train Loss: 879.018 | Test Loss: 911.765 | Test Loss [MAPE]: 2362837.471 --time-- 1.8821563720703125\n",
      "Epoch 73/500 | Train Loss: 884.038 | Test Loss: 917.343 | Test Loss [MAPE]: 2347378.097 --time-- 1.8839526176452637\n",
      "Epoch 74/500 | Train Loss: 900.568 | Test Loss: 924.645 | Test Loss [MAPE]: 2239696.971 --time-- 1.8834865093231201\n",
      "Epoch 75/500 | Train Loss: 878.760 | Test Loss: 888.637 | Test Loss [MAPE]: 2288287.467 --time-- 1.8847339153289795\n",
      "Epoch 76/500 | Train Loss: 871.152 | Test Loss: 870.051 | Test Loss [MAPE]: 2194749.590 --time-- 1.8823461532592773\n",
      "Epoch 77/500 | Train Loss: 864.633 | Test Loss: 881.114 | Test Loss [MAPE]: 2327263.004 --time-- 1.8839242458343506\n",
      "Epoch 78/500 | Train Loss: 877.439 | Test Loss: 949.331 | Test Loss [MAPE]: 2447089.979 --time-- 1.8841302394866943\n",
      "Epoch 79/500 | Train Loss: 881.419 | Test Loss: 911.276 | Test Loss [MAPE]: 2381574.734 --time-- 1.8822481632232666\n",
      "Epoch 80/500 | Train Loss: 852.396 | Test Loss: 903.757 | Test Loss [MAPE]: 2359566.983 --time-- 1.8841776847839355\n",
      "Epoch 81/500 | Train Loss: 860.286 | Test Loss: 841.471 | Test Loss [MAPE]: 2166178.620 --time-- 1.8846962451934814\n",
      "Epoch 82/500 | Train Loss: 831.401 | Test Loss: 845.495 | Test Loss [MAPE]: 2191880.545 --time-- 1.8830547332763672\n",
      "Epoch 83/500 | Train Loss: 843.201 | Test Loss: 859.560 | Test Loss [MAPE]: 2309607.588 --time-- 1.883544921875\n",
      "Epoch 84/500 | Train Loss: 851.790 | Test Loss: 849.268 | Test Loss [MAPE]: 2192727.168 --time-- 1.884429931640625\n",
      "Epoch 85/500 | Train Loss: 821.176 | Test Loss: 831.781 | Test Loss [MAPE]: 2147115.355 --time-- 1.8849818706512451\n",
      "Epoch 86/500 | Train Loss: 797.087 | Test Loss: 843.841 | Test Loss [MAPE]: 2024653.645 --time-- 1.886458158493042\n",
      "Epoch 87/500 | Train Loss: 816.154 | Test Loss: 822.950 | Test Loss [MAPE]: 2193513.605 --time-- 1.883150577545166\n",
      "Epoch 88/500 | Train Loss: 827.476 | Test Loss: 870.795 | Test Loss [MAPE]: 2272373.447 --time-- 1.882986307144165\n",
      "Epoch 89/500 | Train Loss: 825.693 | Test Loss: 812.107 | Test Loss [MAPE]: 2065340.027 --time-- 1.8825159072875977\n",
      "Epoch 90/500 | Train Loss: 782.813 | Test Loss: 797.031 | Test Loss [MAPE]: 2112364.881 --time-- 1.8849189281463623\n",
      "Epoch 91/500 | Train Loss: 840.490 | Test Loss: 883.659 | Test Loss [MAPE]: 2252232.763 --time-- 1.8821122646331787\n",
      "Epoch 92/500 | Train Loss: 835.500 | Test Loss: 839.650 | Test Loss [MAPE]: 2084216.584 --time-- 1.8824398517608643\n",
      "Epoch 93/500 | Train Loss: 780.224 | Test Loss: 780.805 | Test Loss [MAPE]: 1911376.902 --time-- 1.885704517364502\n",
      "Epoch 94/500 | Train Loss: 784.418 | Test Loss: 835.419 | Test Loss [MAPE]: 2171818.417 --time-- 1.886791467666626\n",
      "Epoch 95/500 | Train Loss: 785.325 | Test Loss: 784.051 | Test Loss [MAPE]: 2054533.258 --time-- 1.8838121891021729\n",
      "Epoch 96/500 | Train Loss: 767.756 | Test Loss: 798.475 | Test Loss [MAPE]: 2095081.918 --time-- 1.8858976364135742\n",
      "Epoch 97/500 | Train Loss: 795.014 | Test Loss: 817.511 | Test Loss [MAPE]: 2184648.631 --time-- 1.8861489295959473\n",
      "Epoch 98/500 | Train Loss: 774.396 | Test Loss: 812.594 | Test Loss [MAPE]: 2166568.071 --time-- 1.9368469715118408\n",
      "Epoch 99/500 | Train Loss: 785.402 | Test Loss: 816.388 | Test Loss [MAPE]: 2220606.950 --time-- 1.9432358741760254\n",
      "Epoch 100/500 | Train Loss: 777.043 | Test Loss: 839.663 | Test Loss [MAPE]: 2160685.470 --time-- 1.9367237091064453\n",
      "Epoch 101/500 | Train Loss: 775.779 | Test Loss: 809.052 | Test Loss [MAPE]: 2195293.386 --time-- 1.9428577423095703\n",
      "Epoch 102/500 | Train Loss: 755.197 | Test Loss: 805.356 | Test Loss [MAPE]: 2173998.459 --time-- 1.93858003616333\n",
      "Epoch 103/500 | Train Loss: 800.046 | Test Loss: 803.859 | Test Loss [MAPE]: 2085044.239 --time-- 1.9372804164886475\n",
      "Epoch 104/500 | Train Loss: 750.344 | Test Loss: 789.606 | Test Loss [MAPE]: 2082128.640 --time-- 1.9414770603179932\n",
      "Epoch 105/500 | Train Loss: 744.728 | Test Loss: 782.670 | Test Loss [MAPE]: 2076195.227 --time-- 1.9326727390289307\n",
      "Epoch 106/500 | Train Loss: 763.207 | Test Loss: 876.062 | Test Loss [MAPE]: 2504994.715 --time-- 1.9392032623291016\n",
      "Epoch 107/500 | Train Loss: 810.958 | Test Loss: 784.443 | Test Loss [MAPE]: 2058593.712 --time-- 1.9402589797973633\n",
      "Epoch 108/500 | Train Loss: 730.269 | Test Loss: 738.719 | Test Loss [MAPE]: 1994641.238 --time-- 1.9448277950286865\n",
      "Epoch 109/500 | Train Loss: 716.980 | Test Loss: 775.231 | Test Loss [MAPE]: 2162293.923 --time-- 1.9362189769744873\n",
      "Epoch 110/500 | Train Loss: 714.362 | Test Loss: 743.335 | Test Loss [MAPE]: 2100425.186 --time-- 1.9354164600372314\n",
      "Epoch 111/500 | Train Loss: 748.822 | Test Loss: 813.126 | Test Loss [MAPE]: 2147434.932 --time-- 1.9443750381469727\n",
      "Epoch 112/500 | Train Loss: 755.256 | Test Loss: 754.407 | Test Loss [MAPE]: 2090463.915 --time-- 1.9053270816802979\n",
      "Epoch 113/500 | Train Loss: 717.703 | Test Loss: 753.472 | Test Loss [MAPE]: 2049772.358 --time-- 1.8847072124481201\n",
      "Epoch 114/500 | Train Loss: 736.068 | Test Loss: 737.350 | Test Loss [MAPE]: 1996064.334 --time-- 1.8839595317840576\n",
      "Epoch 115/500 | Train Loss: 714.295 | Test Loss: 771.691 | Test Loss [MAPE]: 2192127.090 --time-- 1.8872568607330322\n",
      "Epoch 116/500 | Train Loss: 763.529 | Test Loss: 761.948 | Test Loss [MAPE]: 2128816.277 --time-- 1.8883862495422363\n",
      "Epoch 117/500 | Train Loss: 709.520 | Test Loss: 722.882 | Test Loss [MAPE]: 1951989.993 --time-- 1.882319688796997\n",
      "Epoch 118/500 | Train Loss: 713.400 | Test Loss: 714.551 | Test Loss [MAPE]: 1924500.484 --time-- 1.88590407371521\n",
      "Epoch 119/500 | Train Loss: 726.642 | Test Loss: 721.763 | Test Loss [MAPE]: 1951547.853 --time-- 1.884798526763916\n",
      "Epoch 120/500 | Train Loss: 701.317 | Test Loss: 703.457 | Test Loss [MAPE]: 1910310.895 --time-- 1.8848059177398682\n",
      "Epoch 121/500 | Train Loss: 752.484 | Test Loss: 823.228 | Test Loss [MAPE]: 2170733.010 --time-- 1.8833885192871094\n",
      "Epoch 122/500 | Train Loss: 718.179 | Test Loss: 720.357 | Test Loss [MAPE]: 1964556.407 --time-- 1.88627028465271\n",
      "Epoch 123/500 | Train Loss: 707.191 | Test Loss: 722.943 | Test Loss [MAPE]: 1959293.097 --time-- 1.883413314819336\n",
      "Epoch 124/500 | Train Loss: 708.117 | Test Loss: 755.047 | Test Loss [MAPE]: 2150992.474 --time-- 1.8857316970825195\n",
      "Epoch 125/500 | Train Loss: 793.532 | Test Loss: 812.735 | Test Loss [MAPE]: 2166347.837 --time-- 1.8878746032714844\n",
      "Epoch 126/500 | Train Loss: 708.922 | Test Loss: 712.507 | Test Loss [MAPE]: 1965329.875 --time-- 1.8848786354064941\n",
      "Epoch 127/500 | Train Loss: 685.933 | Test Loss: 712.339 | Test Loss [MAPE]: 1980257.491 --time-- 1.8850672245025635\n",
      "Epoch 128/500 | Train Loss: 691.048 | Test Loss: 687.065 | Test Loss [MAPE]: 1891178.986 --time-- 1.8843536376953125\n",
      "Epoch 129/500 | Train Loss: 709.852 | Test Loss: 745.343 | Test Loss [MAPE]: 1895792.004 --time-- 1.8825318813323975\n",
      "Epoch 130/500 | Train Loss: 712.332 | Test Loss: 726.607 | Test Loss [MAPE]: 2074289.883 --time-- 1.8891644477844238\n",
      "Epoch 131/500 | Train Loss: 684.532 | Test Loss: 756.869 | Test Loss [MAPE]: 2193645.441 --time-- 1.8839764595031738\n",
      "Epoch 132/500 | Train Loss: 702.775 | Test Loss: 719.778 | Test Loss [MAPE]: 1979677.906 --time-- 1.8830840587615967\n",
      "Epoch 133/500 | Train Loss: 678.370 | Test Loss: 704.897 | Test Loss [MAPE]: 1921342.792 --time-- 1.881359338760376\n",
      "Epoch 134/500 | Train Loss: 663.001 | Test Loss: 704.939 | Test Loss [MAPE]: 2018637.566 --time-- 1.8844285011291504\n",
      "Epoch 135/500 | Train Loss: 688.998 | Test Loss: 715.798 | Test Loss [MAPE]: 2013674.412 --time-- 1.8893840312957764\n",
      "Epoch 136/500 | Train Loss: 667.731 | Test Loss: 671.286 | Test Loss [MAPE]: 1808100.253 --time-- 1.8870513439178467\n",
      "Epoch 137/500 | Train Loss: 647.058 | Test Loss: 689.114 | Test Loss [MAPE]: 2019398.921 --time-- 1.8835663795471191\n",
      "Epoch 138/500 | Train Loss: 701.755 | Test Loss: 706.768 | Test Loss [MAPE]: 2098019.494 --time-- 1.8851189613342285\n",
      "Epoch 139/500 | Train Loss: 676.143 | Test Loss: 729.019 | Test Loss [MAPE]: 2015401.634 --time-- 1.8847761154174805\n",
      "Epoch 140/500 | Train Loss: 700.750 | Test Loss: 723.682 | Test Loss [MAPE]: 2076663.756 --time-- 1.8857736587524414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/500 | Train Loss: 681.419 | Test Loss: 678.636 | Test Loss [MAPE]: 1992991.427 --time-- 1.886049747467041\n",
      "Epoch 142/500 | Train Loss: 671.435 | Test Loss: 716.351 | Test Loss [MAPE]: 2133343.041 --time-- 1.8843841552734375\n",
      "Epoch 143/500 | Train Loss: 680.257 | Test Loss: 694.180 | Test Loss [MAPE]: 2024933.397 --time-- 1.8803870677947998\n",
      "Epoch 144/500 | Train Loss: 646.946 | Test Loss: 658.539 | Test Loss [MAPE]: 1932107.125 --time-- 1.88797926902771\n",
      "Epoch 145/500 | Train Loss: 653.567 | Test Loss: 668.322 | Test Loss [MAPE]: 1983984.378 --time-- 1.8855440616607666\n",
      "Epoch 146/500 | Train Loss: 644.850 | Test Loss: 691.268 | Test Loss [MAPE]: 2116134.853 --time-- 1.8852226734161377\n",
      "Epoch 147/500 | Train Loss: 653.120 | Test Loss: 708.004 | Test Loss [MAPE]: 2068632.098 --time-- 1.8833041191101074\n",
      "Epoch 148/500 | Train Loss: 676.545 | Test Loss: 724.850 | Test Loss [MAPE]: 2135900.398 --time-- 1.885077714920044\n",
      "Epoch 149/500 | Train Loss: 659.718 | Test Loss: 671.052 | Test Loss [MAPE]: 2010699.495 --time-- 1.8817729949951172\n",
      "Epoch 150/500 | Train Loss: 641.571 | Test Loss: 652.414 | Test Loss [MAPE]: 1934905.769 --time-- 1.88447904586792\n",
      "Epoch 151/500 | Train Loss: 655.501 | Test Loss: 688.050 | Test Loss [MAPE]: 2086868.869 --time-- 1.8869099617004395\n",
      "Epoch 152/500 | Train Loss: 638.533 | Test Loss: 669.845 | Test Loss [MAPE]: 1918057.354 --time-- 1.9329564571380615\n",
      "Epoch 153/500 | Train Loss: 640.441 | Test Loss: 677.204 | Test Loss [MAPE]: 2051839.133 --time-- 1.9324893951416016\n",
      "Epoch 154/500 | Train Loss: 632.191 | Test Loss: 676.135 | Test Loss [MAPE]: 1972238.574 --time-- 1.9296150207519531\n",
      "Epoch 155/500 | Train Loss: 632.590 | Test Loss: 648.432 | Test Loss [MAPE]: 1927160.647 --time-- 1.9342150688171387\n",
      "Epoch 156/500 | Train Loss: 640.241 | Test Loss: 675.867 | Test Loss [MAPE]: 2009193.867 --time-- 1.934351921081543\n",
      "Epoch 157/500 | Train Loss: 650.605 | Test Loss: 680.391 | Test Loss [MAPE]: 2051889.181 --time-- 1.9316294193267822\n",
      "Epoch 158/500 | Train Loss: 618.605 | Test Loss: 636.078 | Test Loss [MAPE]: 1904933.821 --time-- 1.9310669898986816\n",
      "Epoch 159/500 | Train Loss: 622.440 | Test Loss: 704.026 | Test Loss [MAPE]: 2145770.398 --time-- 1.9463224411010742\n",
      "Epoch 160/500 | Train Loss: 646.977 | Test Loss: 719.359 | Test Loss [MAPE]: 2134216.084 --time-- 1.9469192028045654\n",
      "Epoch 161/500 | Train Loss: 651.553 | Test Loss: 688.679 | Test Loss [MAPE]: 2012521.316 --time-- 1.9354794025421143\n",
      "Epoch 162/500 | Train Loss: 639.229 | Test Loss: 679.197 | Test Loss [MAPE]: 1935141.921 --time-- 1.9316964149475098\n",
      "Epoch 163/500 | Train Loss: 624.098 | Test Loss: 645.626 | Test Loss [MAPE]: 1949353.126 --time-- 1.8858580589294434\n",
      "Epoch 164/500 | Train Loss: 701.175 | Test Loss: 666.307 | Test Loss [MAPE]: 1925899.772 --time-- 1.883972406387329\n",
      "Epoch 165/500 | Train Loss: 616.045 | Test Loss: 627.885 | Test Loss [MAPE]: 1902701.524 --time-- 1.885143756866455\n",
      "Epoch 166/500 | Train Loss: 633.187 | Test Loss: 718.375 | Test Loss [MAPE]: 2212304.309 --time-- 1.886976718902588\n",
      "Epoch 167/500 | Train Loss: 614.233 | Test Loss: 605.499 | Test Loss [MAPE]: 1809948.444 --time-- 1.8841326236724854\n",
      "Epoch 168/500 | Train Loss: 601.138 | Test Loss: 647.434 | Test Loss [MAPE]: 1951869.797 --time-- 1.8852617740631104\n",
      "Epoch 169/500 | Train Loss: 625.014 | Test Loss: 654.798 | Test Loss [MAPE]: 1903544.243 --time-- 1.8866758346557617\n",
      "Epoch 170/500 | Train Loss: 620.965 | Test Loss: 593.669 | Test Loss [MAPE]: 1732968.649 --time-- 1.8840258121490479\n",
      "Epoch 171/500 | Train Loss: 575.412 | Test Loss: 648.647 | Test Loss [MAPE]: 1941339.511 --time-- 1.8878898620605469\n",
      "Epoch 172/500 | Train Loss: 635.057 | Test Loss: 641.639 | Test Loss [MAPE]: 1957377.508 --time-- 1.8823821544647217\n",
      "Epoch 173/500 | Train Loss: 615.440 | Test Loss: 709.062 | Test Loss [MAPE]: 2265498.749 --time-- 1.8838250637054443\n",
      "Epoch 174/500 | Train Loss: 629.260 | Test Loss: 626.679 | Test Loss [MAPE]: 1863988.422 --time-- 1.8826375007629395\n",
      "Epoch 175/500 | Train Loss: 618.032 | Test Loss: 618.267 | Test Loss [MAPE]: 1863475.563 --time-- 1.885627269744873\n",
      "Epoch 176/500 | Train Loss: 627.988 | Test Loss: 639.117 | Test Loss [MAPE]: 1926210.594 --time-- 1.9365379810333252\n",
      "Epoch 177/500 | Train Loss: 626.424 | Test Loss: 681.225 | Test Loss [MAPE]: 1966789.700 --time-- 1.934103012084961\n",
      "Epoch 178/500 | Train Loss: 620.461 | Test Loss: 599.673 | Test Loss [MAPE]: 1774178.906 --time-- 1.9367387294769287\n",
      "Epoch 179/500 | Train Loss: 600.007 | Test Loss: 645.012 | Test Loss [MAPE]: 1945871.858 --time-- 1.9333775043487549\n",
      "Epoch 180/500 | Train Loss: 642.342 | Test Loss: 642.534 | Test Loss [MAPE]: 1934662.497 --time-- 1.9327573776245117\n",
      "Epoch 181/500 | Train Loss: 620.055 | Test Loss: 611.068 | Test Loss [MAPE]: 1838795.984 --time-- 1.9329719543457031\n",
      "Epoch 182/500 | Train Loss: 603.409 | Test Loss: 723.866 | Test Loss [MAPE]: 2154408.112 --time-- 1.9327869415283203\n",
      "Epoch 183/500 | Train Loss: 624.032 | Test Loss: 594.513 | Test Loss [MAPE]: 1731510.978 --time-- 1.9382762908935547\n",
      "Epoch 184/500 | Train Loss: 590.631 | Test Loss: 614.542 | Test Loss [MAPE]: 1875708.548 --time-- 1.930891513824463\n",
      "Epoch 185/500 | Train Loss: 600.360 | Test Loss: 629.743 | Test Loss [MAPE]: 1853905.801 --time-- 1.9327611923217773\n",
      "Epoch 186/500 | Train Loss: 611.933 | Test Loss: 606.366 | Test Loss [MAPE]: 1825954.807 --time-- 1.9340295791625977\n",
      "Epoch 187/500 | Train Loss: 599.858 | Test Loss: 697.970 | Test Loss [MAPE]: 2149460.246 --time-- 1.9345614910125732\n",
      "Epoch 188/500 | Train Loss: 611.695 | Test Loss: 620.200 | Test Loss [MAPE]: 1885967.958 --time-- 1.9333558082580566\n",
      "Epoch 189/500 | Train Loss: 585.739 | Test Loss: 631.356 | Test Loss [MAPE]: 1966022.469 --time-- 1.9326212406158447\n",
      "Epoch 190/500 | Train Loss: 601.538 | Test Loss: 620.580 | Test Loss [MAPE]: 1899259.675 --time-- 1.9316389560699463\n",
      "Epoch 191/500 | Train Loss: 621.394 | Test Loss: 631.873 | Test Loss [MAPE]: 1882886.269 --time-- 1.9301340579986572\n",
      "Epoch 192/500 | Train Loss: 628.057 | Test Loss: 673.463 | Test Loss [MAPE]: 1981084.438 --time-- 1.937992811203003\n",
      "Epoch 193/500 | Train Loss: 606.431 | Test Loss: 593.735 | Test Loss [MAPE]: 1774318.991 --time-- 1.9374947547912598\n",
      "Epoch 194/500 | Train Loss: 566.620 | Test Loss: 593.117 | Test Loss [MAPE]: 1774155.598 --time-- 1.9344608783721924\n",
      "Epoch 195/500 | Train Loss: 594.198 | Test Loss: 632.056 | Test Loss [MAPE]: 1903972.769 --time-- 1.9426648616790771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 09:55:00,139] Trial 57 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/500 | Train Loss: 586.227 | Test Loss: 1107.051 | Test Loss [MAPE]: 3878761.886 --time-- 1.935887336730957\n",
      "Epoch 1/500 | Train Loss: 37998.496 | Test Loss: 5162.321 | Test Loss [MAPE]: 422154.034 --time-- 10.905082941055298\n",
      "Epoch 2/500 | Train Loss: 5106.544 | Test Loss: 5161.703 | Test Loss [MAPE]: 423256.691 --time-- 10.958818674087524\n",
      "Epoch 3/500 | Train Loss: 5106.357 | Test Loss: 5161.766 | Test Loss [MAPE]: 421355.859 --time-- 10.959791660308838\n",
      "Epoch 4/500 | Train Loss: 5106.387 | Test Loss: 5161.839 | Test Loss [MAPE]: 434127.053 --time-- 10.91139817237854\n",
      "Epoch 5/500 | Train Loss: 5106.426 | Test Loss: 5161.812 | Test Loss [MAPE]: 430428.854 --time-- 10.956960916519165\n",
      "Epoch 6/500 | Train Loss: 5106.437 | Test Loss: 5161.812 | Test Loss [MAPE]: 417287.292 --time-- 10.882670879364014\n",
      "Epoch 7/500 | Train Loss: 5106.480 | Test Loss: 5161.850 | Test Loss [MAPE]: 416908.486 --time-- 10.881388425827026\n",
      "Epoch 8/500 | Train Loss: 5106.474 | Test Loss: 5161.824 | Test Loss [MAPE]: 418862.427 --time-- 10.881802320480347\n",
      "Epoch 9/500 | Train Loss: 5106.454 | Test Loss: 5161.854 | Test Loss [MAPE]: 419452.254 --time-- 10.880810499191284\n",
      "Epoch 10/500 | Train Loss: 5106.527 | Test Loss: 5161.799 | Test Loss [MAPE]: 429278.392 --time-- 10.882181644439697\n",
      "Epoch 11/500 | Train Loss: 5106.578 | Test Loss: 5161.862 | Test Loss [MAPE]: 424136.360 --time-- 10.882903099060059\n",
      "Epoch 12/500 | Train Loss: 5106.512 | Test Loss: 5161.909 | Test Loss [MAPE]: 432576.758 --time-- 10.879307270050049\n",
      "Epoch 13/500 | Train Loss: 5106.566 | Test Loss: 5161.897 | Test Loss [MAPE]: 419596.851 --time-- 10.884098052978516\n",
      "Epoch 14/500 | Train Loss: 5106.529 | Test Loss: 5161.835 | Test Loss [MAPE]: 430277.001 --time-- 10.890428066253662\n",
      "Epoch 15/500 | Train Loss: 5106.510 | Test Loss: 5161.981 | Test Loss [MAPE]: 416989.800 --time-- 10.880439043045044\n",
      "Epoch 16/500 | Train Loss: 5106.602 | Test Loss: 5162.336 | Test Loss [MAPE]: 455580.901 --time-- 10.881717443466187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 09:58:06,161] Trial 58 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.651 | Test Loss: 5161.807 | Test Loss [MAPE]: 423828.833 --time-- 10.88320016860962\n",
      "Epoch 1/500 | Train Loss: 44323.596 | Test Loss: 5161.749 | Test Loss [MAPE]: 421056.749 --time-- 3.8696045875549316\n",
      "Epoch 2/500 | Train Loss: 5106.381 | Test Loss: 5161.709 | Test Loss [MAPE]: 419364.641 --time-- 3.8739583492279053\n",
      "Epoch 3/500 | Train Loss: 5106.387 | Test Loss: 5161.727 | Test Loss [MAPE]: 420633.286 --time-- 3.8720126152038574\n",
      "Epoch 4/500 | Train Loss: 5106.373 | Test Loss: 5161.786 | Test Loss [MAPE]: 431721.786 --time-- 3.876999855041504\n",
      "Epoch 5/500 | Train Loss: 5106.432 | Test Loss: 5161.846 | Test Loss [MAPE]: 417511.480 --time-- 3.874502420425415\n",
      "Epoch 6/500 | Train Loss: 5106.417 | Test Loss: 5161.826 | Test Loss [MAPE]: 435754.333 --time-- 3.8706045150756836\n",
      "Epoch 7/500 | Train Loss: 5106.404 | Test Loss: 5161.727 | Test Loss [MAPE]: 423168.739 --time-- 3.869429588317871\n",
      "Epoch 8/500 | Train Loss: 5106.409 | Test Loss: 5161.747 | Test Loss [MAPE]: 426331.612 --time-- 3.873798131942749\n",
      "Epoch 9/500 | Train Loss: 5106.420 | Test Loss: 5161.755 | Test Loss [MAPE]: 420602.430 --time-- 3.870650053024292\n",
      "Epoch 10/500 | Train Loss: 5106.479 | Test Loss: 5162.072 | Test Loss [MAPE]: 443158.494 --time-- 3.8754773139953613\n",
      "Epoch 11/500 | Train Loss: 5106.449 | Test Loss: 5161.816 | Test Loss [MAPE]: 430738.183 --time-- 3.872432231903076\n",
      "Epoch 12/500 | Train Loss: 5106.476 | Test Loss: 5161.786 | Test Loss [MAPE]: 429621.376 --time-- 3.8719656467437744\n",
      "Epoch 13/500 | Train Loss: 5106.482 | Test Loss: 5161.946 | Test Loss [MAPE]: 438537.866 --time-- 3.872321128845215\n",
      "Epoch 14/500 | Train Loss: 5106.458 | Test Loss: 5161.845 | Test Loss [MAPE]: 422189.805 --time-- 3.871609687805176\n",
      "Epoch 15/500 | Train Loss: 5106.511 | Test Loss: 5161.807 | Test Loss [MAPE]: 424098.528 --time-- 3.873507261276245\n",
      "Epoch 16/500 | Train Loss: 5106.477 | Test Loss: 5161.802 | Test Loss [MAPE]: 432038.438 --time-- 3.877595901489258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 09:59:12,873] Trial 59 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.465 | Test Loss: 5161.772 | Test Loss [MAPE]: 425603.924 --time-- 3.8731448650360107\n",
      "Epoch 1/500 | Train Loss: inf | Test Loss: 5193.844 | Test Loss [MAPE]: 796712.190 --time-- 4.071003198623657\n",
      "Epoch 2/500 | Train Loss: 5115.113 | Test Loss: 5162.702 | Test Loss [MAPE]: 444118.408 --time-- 4.057260513305664\n",
      "Epoch 3/500 | Train Loss: 5106.682 | Test Loss: 5161.795 | Test Loss [MAPE]: 427256.776 --time-- 4.053861618041992\n",
      "Epoch 4/500 | Train Loss: 5106.490 | Test Loss: 5161.836 | Test Loss [MAPE]: 428864.367 --time-- 4.053895711898804\n",
      "Epoch 5/500 | Train Loss: 5106.591 | Test Loss: 5162.011 | Test Loss [MAPE]: 420778.354 --time-- 4.0531346797943115\n",
      "Epoch 6/500 | Train Loss: 5106.591 | Test Loss: 5162.037 | Test Loss [MAPE]: 417059.767 --time-- 4.055791616439819\n",
      "Epoch 7/500 | Train Loss: 5106.623 | Test Loss: 5161.947 | Test Loss [MAPE]: 420451.361 --time-- 4.054313659667969\n",
      "Epoch 8/500 | Train Loss: 5106.652 | Test Loss: 5161.994 | Test Loss [MAPE]: 422317.414 --time-- 4.056315183639526\n",
      "Epoch 9/500 | Train Loss: 5106.755 | Test Loss: 5162.003 | Test Loss [MAPE]: 425214.282 --time-- 4.057623624801636\n",
      "Epoch 10/500 | Train Loss: 5106.886 | Test Loss: 5162.196 | Test Loss [MAPE]: 423821.490 --time-- 4.052780389785767\n",
      "Epoch 11/500 | Train Loss: 5106.896 | Test Loss: 5162.086 | Test Loss [MAPE]: 439916.294 --time-- 4.0554821491241455\n",
      "Epoch 12/500 | Train Loss: 5106.792 | Test Loss: 5162.108 | Test Loss [MAPE]: 425129.729 --time-- 4.054137945175171\n",
      "Epoch 13/500 | Train Loss: 5107.116 | Test Loss: 5162.492 | Test Loss [MAPE]: 449412.768 --time-- 4.052295207977295\n",
      "Epoch 14/500 | Train Loss: 5107.593 | Test Loss: 5163.087 | Test Loss [MAPE]: 432247.715 --time-- 4.054628133773804\n",
      "Epoch 15/500 | Train Loss: 5107.183 | Test Loss: 5162.029 | Test Loss [MAPE]: 432281.919 --time-- 4.056569814682007\n",
      "Epoch 16/500 | Train Loss: 5106.969 | Test Loss: 5162.189 | Test Loss [MAPE]: 426835.071 --time-- 4.052995204925537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-02 10:00:22,522] Trial 60 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 | Train Loss: 5106.769 | Test Loss: 5162.083 | Test Loss [MAPE]: 434465.666 --time-- 4.0550923347473145\n",
      "Epoch 1/500 | Train Loss: 5251.023 | Test Loss: 5163.047 | Test Loss [MAPE]: 514526.562 --time-- 12.74380373954773\n",
      "Epoch 2/500 | Train Loss: 4805.460 | Test Loss: 4328.338 | Test Loss [MAPE]: 1385848.699 --time-- 12.723872900009155\n",
      "Epoch 3/500 | Train Loss: 4177.834 | Test Loss: 4081.738 | Test Loss [MAPE]: 2391050.030 --time-- 12.716630220413208\n",
      "Epoch 4/500 | Train Loss: 3992.950 | Test Loss: 3905.013 | Test Loss [MAPE]: 3311636.358 --time-- 12.715004920959473\n",
      "Epoch 5/500 | Train Loss: 3820.317 | Test Loss: 3747.006 | Test Loss [MAPE]: 5236569.251 --time-- 12.72046685218811\n",
      "Epoch 6/500 | Train Loss: 3700.429 | Test Loss: 3635.573 | Test Loss [MAPE]: 5798337.833 --time-- 12.720614433288574\n",
      "Epoch 7/500 | Train Loss: 3594.693 | Test Loss: 3551.831 | Test Loss [MAPE]: 6042438.919 --time-- 12.72122597694397\n",
      "Epoch 8/500 | Train Loss: 3528.476 | Test Loss: 3469.649 | Test Loss [MAPE]: 6209538.310 --time-- 12.720105171203613\n",
      "Epoch 9/500 | Train Loss: 3410.717 | Test Loss: 3401.077 | Test Loss [MAPE]: 6856901.785 --time-- 12.724900007247925\n",
      "Epoch 10/500 | Train Loss: 3327.479 | Test Loss: 3281.392 | Test Loss [MAPE]: 6535907.816 --time-- 12.728681802749634\n",
      "Epoch 11/500 | Train Loss: 3227.748 | Test Loss: 3151.290 | Test Loss [MAPE]: 5120879.203 --time-- 12.730419158935547\n",
      "Epoch 12/500 | Train Loss: 3126.011 | Test Loss: 2985.399 | Test Loss [MAPE]: 4953774.124 --time-- 12.73299527168274\n",
      "Epoch 13/500 | Train Loss: 3398.326 | Test Loss: 3091.129 | Test Loss [MAPE]: 4678910.025 --time-- 12.709891080856323\n",
      "Epoch 14/500 | Train Loss: 2912.822 | Test Loss: 2873.864 | Test Loss [MAPE]: 3931955.250 --time-- 12.722797393798828\n",
      "Epoch 15/500 | Train Loss: 2779.569 | Test Loss: 2692.657 | Test Loss [MAPE]: 3626988.078 --time-- 12.725018739700317\n",
      "Epoch 16/500 | Train Loss: 2686.188 | Test Loss: 2646.209 | Test Loss [MAPE]: 3252865.546 --time-- 12.72170376777649\n",
      "Epoch 17/500 | Train Loss: 2568.943 | Test Loss: 2529.780 | Test Loss [MAPE]: 3485169.596 --time-- 12.72443699836731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-08-02 10:04:02,724] Trial 61 failed with parameters: {'num_conv_layers': 4, 'kernel_size': 7, 'num_channels': 50, 'pooling_type': 'max', 'conv_stride': 1, 'feedforward_size': 111, 'pool_stride': 2, 'learning_rate': 0.0027529748933444393, 'reg_strength': 0.0020272022132670014, 'bs': 124} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/htjhnson/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_66682/1893709827.py\", line 87, in objective\n",
      "    running_train_loss += loss.item() * inputs.size(0)\n",
      "                          ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-08-02 10:04:02,726] Trial 61 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 148\u001b[0m\n\u001b[1;32m    143\u001b[0m storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///CNN_Optuna_ForManuscript.db\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# SQLite database as storage\u001b[39;00m\n\u001b[1;32m    144\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m,  sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m), \n\u001b[1;32m    145\u001b[0m                             study_name\u001b[38;5;241m=\u001b[39mstudy_name, storage\u001b[38;5;241m=\u001b[39mstorage,\n\u001b[1;32m    146\u001b[0m                             pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mThresholdPruner(upper\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000.0\u001b[39m))\n\u001b[0;32m--> 148\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[1;32m     63\u001b[0m             study,\n\u001b[1;32m     64\u001b[0m             func,\n\u001b[1;32m     65\u001b[0m             n_trials,\n\u001b[1;32m     66\u001b[0m             timeout,\n\u001b[1;32m     67\u001b[0m             catch,\n\u001b[1;32m     68\u001b[0m             callbacks,\n\u001b[1;32m     69\u001b[0m             gc_after_trial,\n\u001b[1;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     73\u001b[0m         )\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[8], line 87\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     85\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     86\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m accumulation_steps\n\u001b[0;32m---> 87\u001b[0m running_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     88\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Optimization function\n",
    "\n",
    "# Switch to directory for saving weights\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelOptimizations/BestWeights')\n",
    "\n",
    "# Define file name for best model weights\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "\n",
    "# Define the objective function to be minimized.\n",
    "\n",
    "def objective(trial):\n",
    "    accumulation_steps = 4\n",
    "    n_conv_layers = trial.suggest_int('num_conv_layers', 1, 4)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 3, 12)\n",
    "    num_channels = trial.suggest_int('num_channels', 5, 50)\n",
    "    pooling_type = trial.suggest_categorical('pooling_type', ['none', 'max', 'avg'])\n",
    "    conv_stride = trial.suggest_int('conv_stride', 1, 10)\n",
    "    n_fc_layers = 1  # Number of fully connected layers\n",
    "    feedforward_size = trial.suggest_int(\"feedforward_size\", 100, 250)\n",
    "    pool_kernel = 2\n",
    "    if pooling_type != 'none':\n",
    "        pool_stride = trial.suggest_int('pool_stride', 1, 2)\n",
    "\n",
    "    layers = []\n",
    "    in_channels = 1  # Assuming 1 input channel\n",
    "    in_features = 46000  # Number of input features\n",
    "    dilation = 1\n",
    "    padding = 1\n",
    "\n",
    "    for i in range(n_conv_layers):\n",
    "        out_channels = num_channels\n",
    "        layers.append(nn.Conv1d(in_channels, out_channels, kernel_size, stride=conv_stride, dilation=dilation, padding=padding))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_features = ((in_features + 2*padding - dilation*(kernel_size - 1) - 1) // conv_stride) + 1\n",
    "        in_channels = out_channels\n",
    "        \n",
    "        if pooling_type != 'none':\n",
    "            if pooling_type == 'max':\n",
    "                layers.append(nn.MaxPool1d(pool_kernel, stride=pool_stride, padding=padding))\n",
    "            else:\n",
    "                layers.append(nn.AvgPool1d(pool_kernel, stride=pool_stride, padding=padding))\n",
    "            in_features = ((in_features + 2*padding - pool_kernel) // pool_stride) + 1\n",
    "\n",
    "    layers.append(nn.Flatten())\n",
    "    \n",
    "    for _ in range(n_fc_layers):\n",
    "        layers.append(nn.Linear(in_features * in_channels, feedforward_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_features = feedforward_size\n",
    "        in_channels = 1\n",
    "\n",
    "    layers.append(nn.Linear(in_features, 44))   # For quantifying 44 metabolites\n",
    "\n",
    "    model = nn.Sequential(*layers).to(device)\n",
    "    \n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-2)\n",
    "    reg_strength = trial.suggest_float('reg_strength', 1e-6, 1e-2)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=reg_strength)\n",
    "    \n",
    "    bs = trial.suggest_int(\"bs\", 16, 128)\n",
    "    train_loader = torch.utils.data.DataLoader(datasets, batch_size=bs, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(Test_datasets, batch_size=bs, shuffle=False)\n",
    "    val_loader = torch.utils.data.DataLoader(Val_datasets, batch_size=bs, shuffle=False)\n",
    "\n",
    "    num_epochs = 500\n",
    "    criterion = QuantileLoss()\n",
    "    criterion2 = MAPELoss()\n",
    "    best_test_loss = float('inf')\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start2 = time.time()\n",
    "        running_train_loss = 0.0\n",
    "        running_test_loss = 0.0\n",
    "                \n",
    "        model.train()\n",
    "        scaler = GradScaler()\n",
    "        optimizer.zero_grad()\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss = loss / accumulation_steps\n",
    "            running_train_loss += loss.item() * inputs.size(0)\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                running_test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        running_test_loss2 = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss2 = criterion2(outputs, labels)\n",
    "                running_test_loss2 += loss2.item() * inputs.size(0)\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            end_time2 = time.time()\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} | Train Loss: {running_train_loss:.3f} | Test Loss: {running_test_loss:.3f} | Test Loss [MAPE]: {running_test_loss2:.3f}', \"--time--\", end_time2-start2)\n",
    "\n",
    "        if running_test_loss2 < best_test_loss:\n",
    "            best_test_loss = running_test_loss2\n",
    "            \n",
    "        trial.report(running_test_loss, epoch)\n",
    "        \n",
    "        '''\n",
    "        if epoch > 15 and trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        '''\n",
    "        \n",
    "        ## Double threshold pruner\n",
    "        if epoch > 15 and running_test_loss > 5000 and trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        elif epoch > 100 and running_test_loss > 1000 and trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "            \n",
    "    end_time = time.time()\n",
    "    print(end_time - start)   \n",
    "\n",
    "    return best_test_loss\n",
    "\n",
    "study_name = \"CNN_Optuna_ForManuscript\"\n",
    "storage = \"sqlite:///CNN_Optuna_ForManuscript.db\"  # SQLite database as storage\n",
    "study = optuna.create_study(direction='minimize',  sampler=optuna.samplers.TPESampler(seed=3), \n",
    "                            study_name=study_name, storage=storage,\n",
    "                            pruner=optuna.pruners.ThresholdPruner(upper=500.0))\n",
    "\n",
    "study.optimize(objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to directory for saving weights\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelOptimizations/BestWeights/')\n",
    "\n",
    "loaded_study = optuna.load_study(study_name=\"CNN_Optuna_ForManuscript\", storage=\"sqlite:///CNN_Optuna_ForManuscript.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in loaded_study.trials:\n",
    "    print(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = loaded_study.trials_dataframe()\n",
    "print(trials_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in loaded_study.trials:\n",
    "    print(f\"Trial number: {trial.number}\")\n",
    "    print(f\"  Params: {trial.params}\")\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(f\"  State: {trial.state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and best value from the study\n",
    "best_params = loaded_study.best_params\n",
    "best_value = loaded_study.best_value\n",
    "\n",
    "# Create a dictionary to store hyperparameters and best loss\n",
    "data = {\n",
    "    'Hyperparameter': list(best_params.keys()) + ['Best Loss'],\n",
    "    'Value': list(best_params.values()) + [best_value]\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_rank(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_terminator_improvement(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_timeline(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_edf(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
