{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import dependencies\n",
    "\n",
    "import numpy as np\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Set default plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (30,20)\n",
    "\n",
    "# Define number of epochs used later in training\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Transformer Encoder on dataset of 44 metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2e7a8264d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name variable used for saving model metrics, name should reflect model used, dataset used, and other information such as # of epochs\n",
    "ModelName = \"Transformer_44met_TrainingAndValidation_100bin_4heads_\" + str(num_epochs) +\"ep\"\n",
    "\n",
    "# Set the random seed\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelPerformanceMetrics/') \n",
    "seed = 1\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training and testing datasets, validation datasets, and representative example spectra \n",
    "\n",
    "# Switch to directory containing datasets\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/GeneratedDataAndVariables')\n",
    "\n",
    "# Load training data and max value from testing and training datasets\n",
    "spectra = np.load('Dataset44_Spec.npy')\n",
    "conc1 = np.load('Dataset44_Conc.npy')\n",
    "\n",
    "# Load validation dataset\n",
    "#spectraVal = np.load('Dataset44_Val_Spec.npy')\n",
    "#concVal = np.load('Dataset44_Val_Conc.npy')\n",
    "\n",
    "# Load representative validation spectra\n",
    "#ValSpectra = np.load(\"Dataset44_RepresentativeExamples_Spectra.npy\")\n",
    "#ValConc = np.load(\"Dataset44_RepresentativeExamples_Concentrations.npy\")\n",
    "#ValSpecNames = np.load(\"Dataset44_RepresentativeExamples_VariableNames.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU for training.\n"
     ]
    }
   ],
   "source": [
    "## Prepare to switch data from CPU to GPU\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # A CUDA device object\n",
    "    print(\"Using GPU for training.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")           # A CPU object\n",
    "    print(\"CUDA is not available. Using CPU for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up data for testing and training\n",
    "\n",
    "# Split into testing and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectra, conc1, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Tensorize and prepare datasets\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test).float()\n",
    "\n",
    "\n",
    "# Move the input data to the GPU device\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "#spectraVal = torch.tensor(spectraVal).float().to(device)   # Confusing names, these spectra are the 5000 spectra generated like the training dataset\n",
    "#ValSpectra = torch.tensor(ValSpectra).float().to(device)   # Confusing names, these spectra are the 10 representative example spectra\n",
    "\n",
    "# Move the target data to the GPU device\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "#concVal = torch.tensor(concVal).float().to(device)\n",
    "#ValConc = torch.tensor(ValConc).float().to(device)\n",
    "\n",
    "# More data prep?\n",
    "datasets = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "Test_datasets = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "train_iter = torch.utils.data.DataLoader(datasets, batch_size = 32, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(Test_datasets, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "del y_test\n",
    "del spectra\n",
    "del conc1\n",
    "del datasets\n",
    "del Test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        self.decoder = nn.Linear(235520, 44)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Binning\n",
    "        batch_size, seq_length = x.size()\n",
    "        num_bins = seq_length // self.input_dim\n",
    "        x = x.view(batch_size, num_bins, self.input_dim)  # (batch_size, num_bins, input_dim)\n",
    "        \n",
    "        # Embedding\n",
    "        x = self.embedding(x)  # (batch_size, num_bins, d_model)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        x = x.permute(1, 0, 2)  # (num_bins, batch_size, d_model)\n",
    "        x = self.transformer_encoder(x)  # (num_bins, batch_size, d_model)\n",
    "        x = x.permute(1, 0, 2)  # (batch_size, num_bins, d_model)\n",
    "        \n",
    "        # Reconstruct original sequence\n",
    "        x = x.reshape(batch_size, num_bins * d_model)\n",
    "        \n",
    "        # Decoding\n",
    "        x = self.decoder(x)  # (batch_size, output_dim)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Parameters\n",
    "input_dim = 100   # Size of each bin\n",
    "d_model = 512     # Embedding dimension\n",
    "nhead = 4         # Number of attention heads\n",
    "num_encoder_layers = 1  # Number of transformer encoder layers\n",
    "dim_feedforward = 2048  # Feedforward dimension\n",
    "dropout = 0.1     # Dropout rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    best_test_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:  # The last number here denotes how often to print loss metrics in terms of epochs\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                  f'Train Loss: {train_loss:.4f}, '\n",
    "                  f'Test Loss: {test_loss:.4f}')\n",
    "            \n",
    "       \n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            # Save model when test loss improves\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, save_path)\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "def train_or_load_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    is_model_trained = False  # Initialize flag\n",
    "\n",
    "    if os.path.isfile(save_path):\n",
    "        print(\"Loading pretrained model from {}\".format(save_path))\n",
    "        checkpoint = torch.load(save_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer = optim.Adam(model.parameters())  \n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print(\"No pretrained model found. Training from scratch.\")\n",
    "        #optimizer = optim.Adam(model.parameters())  \n",
    "        train_losses, test_losses = train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path)\n",
    "        is_model_trained = True  # Set flag to True after training\n",
    "        # Save losses per epoch\n",
    "        np.save(ModelName + \"_TrainLoss.npy\", train_losses)\n",
    "        np.save(ModelName + \"_TestLoss.npy\", test_losses)\n",
    "    \n",
    "    return train_losses, test_losses, is_model_trained  # Return the losses and flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/htjhnson/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrained model found. Training from scratch.\n",
      "Epoch [1/1000], Train Loss: 6579409.8516, Test Loss: 1088534.1416\n",
      "Epoch [2/1000], Train Loss: 1849301.0848, Test Loss: 65513.1890\n",
      "Epoch [3/1000], Train Loss: 205705.4717, Test Loss: 35795.2688\n",
      "Epoch [4/1000], Train Loss: 141540.0370, Test Loss: 32748.0739\n",
      "Epoch [5/1000], Train Loss: 115212.7493, Test Loss: 32810.5925\n",
      "Epoch [6/1000], Train Loss: 102464.2923, Test Loss: 28791.8987\n",
      "Epoch [7/1000], Train Loss: 93054.0812, Test Loss: 23654.8012\n",
      "Epoch [8/1000], Train Loss: 86825.9010, Test Loss: 28000.0359\n",
      "Epoch [9/1000], Train Loss: 78744.4277, Test Loss: 27289.2113\n",
      "Epoch [10/1000], Train Loss: 71558.3151, Test Loss: 21604.3311\n",
      "Epoch [11/1000], Train Loss: 66593.5241, Test Loss: 18502.0281\n",
      "Epoch [12/1000], Train Loss: 61468.0980, Test Loss: 21034.5191\n",
      "Epoch [13/1000], Train Loss: 56570.2025, Test Loss: 21304.2640\n",
      "Epoch [14/1000], Train Loss: 53075.1494, Test Loss: 22003.5441\n",
      "Epoch [15/1000], Train Loss: 50074.1410, Test Loss: 14117.9241\n",
      "Epoch [16/1000], Train Loss: 47679.8910, Test Loss: 26081.3438\n",
      "Epoch [17/1000], Train Loss: 44275.3188, Test Loss: 19212.7654\n",
      "Epoch [18/1000], Train Loss: 42519.6821, Test Loss: 12000.0957\n",
      "Epoch [19/1000], Train Loss: 41222.3536, Test Loss: 17295.8338\n",
      "Epoch [20/1000], Train Loss: 38848.3120, Test Loss: 11036.2730\n",
      "Epoch [21/1000], Train Loss: 37048.3935, Test Loss: 17026.3088\n",
      "Epoch [22/1000], Train Loss: 35938.4188, Test Loss: 19211.2862\n",
      "Epoch [23/1000], Train Loss: 1852577.8763, Test Loss: 503981.9397\n",
      "Epoch [24/1000], Train Loss: 1142640.9092, Test Loss: 146232.0341\n",
      "Epoch [25/1000], Train Loss: 633332.4581, Test Loss: 119054.6115\n",
      "Epoch [26/1000], Train Loss: 522401.5479, Test Loss: 99859.0529\n",
      "Epoch [27/1000], Train Loss: 437876.8788, Test Loss: 91305.1318\n",
      "Epoch [28/1000], Train Loss: 388105.7662, Test Loss: 86519.3729\n",
      "Epoch [29/1000], Train Loss: 350138.7919, Test Loss: 77841.5714\n",
      "Epoch [30/1000], Train Loss: 295700.2099, Test Loss: 61938.2684\n",
      "Epoch [31/1000], Train Loss: 274612.8710, Test Loss: 60588.5501\n",
      "Epoch [32/1000], Train Loss: 256493.2437, Test Loss: 57554.9240\n",
      "Epoch [33/1000], Train Loss: 221041.9647, Test Loss: 43043.1031\n",
      "Epoch [34/1000], Train Loss: 168587.7932, Test Loss: 32281.0243\n",
      "Epoch [35/1000], Train Loss: 136723.0670, Test Loss: 30684.7510\n",
      "Epoch [36/1000], Train Loss: 97279.4491, Test Loss: 25675.4473\n",
      "Epoch [37/1000], Train Loss: 74792.8091, Test Loss: 14992.3292\n",
      "Epoch [38/1000], Train Loss: 62330.8183, Test Loss: 12204.2135\n",
      "Epoch [39/1000], Train Loss: 54401.3211, Test Loss: 13516.9673\n",
      "Epoch [40/1000], Train Loss: 48741.2009, Test Loss: 11554.3991\n",
      "Epoch [41/1000], Train Loss: 45536.9182, Test Loss: 13547.7129\n",
      "Epoch [42/1000], Train Loss: 42327.4124, Test Loss: 13973.1873\n",
      "Epoch [43/1000], Train Loss: 39623.5701, Test Loss: 16062.2792\n",
      "Epoch [44/1000], Train Loss: 38223.3680, Test Loss: 17005.6441\n",
      "Epoch [45/1000], Train Loss: 35579.3949, Test Loss: 10889.0289\n",
      "Epoch [46/1000], Train Loss: 34147.7901, Test Loss: 14922.1201\n",
      "Epoch [47/1000], Train Loss: 32865.3529, Test Loss: 12297.4351\n",
      "Epoch [48/1000], Train Loss: 32135.5540, Test Loss: 10893.2681\n",
      "Epoch [49/1000], Train Loss: 29393.4127, Test Loss: 13003.7173\n",
      "Epoch [50/1000], Train Loss: 29317.9907, Test Loss: 11509.4080\n",
      "Epoch [51/1000], Train Loss: 28926.0752, Test Loss: 10916.8977\n",
      "Epoch [52/1000], Train Loss: 27005.4035, Test Loss: 13635.2999\n",
      "Epoch [53/1000], Train Loss: 25880.9691, Test Loss: 10116.3708\n",
      "Epoch [54/1000], Train Loss: 393980.9541, Test Loss: 89337.4779\n",
      "Epoch [55/1000], Train Loss: 291945.9367, Test Loss: 46465.8468\n",
      "Epoch [56/1000], Train Loss: 193452.4449, Test Loss: 37965.0066\n",
      "Epoch [57/1000], Train Loss: 151792.8235, Test Loss: 43572.0892\n",
      "Epoch [58/1000], Train Loss: 119303.2578, Test Loss: 24815.7482\n",
      "Epoch [59/1000], Train Loss: 95797.7751, Test Loss: 32128.0372\n",
      "Epoch [60/1000], Train Loss: 78868.9483, Test Loss: 22494.6624\n",
      "Epoch [61/1000], Train Loss: 66413.7927, Test Loss: 33078.4443\n",
      "Epoch [62/1000], Train Loss: 56888.1023, Test Loss: 18080.7243\n",
      "Epoch [63/1000], Train Loss: 49887.9810, Test Loss: 23839.3461\n",
      "Epoch [64/1000], Train Loss: 44131.6326, Test Loss: 11958.7811\n",
      "Epoch [65/1000], Train Loss: 40925.3724, Test Loss: 12814.3795\n",
      "Epoch [66/1000], Train Loss: 36365.3425, Test Loss: 18365.6088\n",
      "Epoch [67/1000], Train Loss: 34613.5717, Test Loss: 13148.7406\n",
      "Epoch [68/1000], Train Loss: 393613.3034, Test Loss: 126206.7609\n",
      "Epoch [69/1000], Train Loss: 248918.1822, Test Loss: 36754.2217\n",
      "Epoch [70/1000], Train Loss: 92845.1009, Test Loss: 30743.5131\n",
      "Epoch [71/1000], Train Loss: 56368.1025, Test Loss: 24668.7322\n",
      "Epoch [72/1000], Train Loss: 42184.2298, Test Loss: 22137.0833\n",
      "Epoch [73/1000], Train Loss: 39076.9586, Test Loss: 26007.9356\n",
      "Epoch [74/1000], Train Loss: 35611.9935, Test Loss: 17520.9369\n",
      "Epoch [75/1000], Train Loss: 34436.2631, Test Loss: 26658.8081\n",
      "Epoch [76/1000], Train Loss: 32284.5764, Test Loss: 14672.4407\n",
      "Epoch [77/1000], Train Loss: 30914.4115, Test Loss: 9457.0976\n",
      "Epoch [78/1000], Train Loss: 30592.7051, Test Loss: 17678.7072\n",
      "Epoch [79/1000], Train Loss: 28710.0949, Test Loss: 18600.2778\n",
      "Epoch [80/1000], Train Loss: 27558.1295, Test Loss: 16578.6749\n",
      "Epoch [81/1000], Train Loss: 25893.5750, Test Loss: 22279.6146\n",
      "Epoch [82/1000], Train Loss: 25910.3386, Test Loss: 13013.7181\n",
      "Epoch [83/1000], Train Loss: 24701.7049, Test Loss: 15936.2151\n",
      "Epoch [84/1000], Train Loss: 23821.8519, Test Loss: 17321.3241\n",
      "Epoch [85/1000], Train Loss: 22972.7669, Test Loss: 15336.5951\n",
      "Epoch [86/1000], Train Loss: 22269.9231, Test Loss: 12650.6132\n",
      "Epoch [87/1000], Train Loss: 22186.6522, Test Loss: 19075.5514\n",
      "Epoch [88/1000], Train Loss: 21588.1965, Test Loss: 13608.5335\n",
      "Epoch [89/1000], Train Loss: 21012.2490, Test Loss: 15067.9738\n",
      "Epoch [90/1000], Train Loss: 20557.6634, Test Loss: 19083.6423\n",
      "Epoch [91/1000], Train Loss: 19839.3309, Test Loss: 15571.7172\n",
      "Epoch [92/1000], Train Loss: 19346.3972, Test Loss: 10897.5042\n",
      "Epoch [93/1000], Train Loss: 18814.4506, Test Loss: 15857.7373\n",
      "Epoch [94/1000], Train Loss: 18606.1474, Test Loss: 18203.6921\n",
      "Epoch [95/1000], Train Loss: 18262.9837, Test Loss: 11367.9354\n",
      "Epoch [96/1000], Train Loss: 17743.3630, Test Loss: 14578.8127\n",
      "Epoch [97/1000], Train Loss: 17469.6174, Test Loss: 10631.9107\n",
      "Epoch [98/1000], Train Loss: 17257.0231, Test Loss: 13118.4199\n",
      "Epoch [99/1000], Train Loss: 17009.3441, Test Loss: 12581.6596\n",
      "Epoch [100/1000], Train Loss: 16611.0015, Test Loss: 14936.1355\n",
      "Epoch [101/1000], Train Loss: 16381.8632, Test Loss: 13053.9361\n",
      "Epoch [102/1000], Train Loss: 15732.3552, Test Loss: 12674.9305\n",
      "Epoch [103/1000], Train Loss: 15495.5080, Test Loss: 12800.5348\n",
      "Epoch [104/1000], Train Loss: 99912.8230, Test Loss: 15293.7418\n",
      "Epoch [105/1000], Train Loss: 23454.8722, Test Loss: 19284.2032\n",
      "Epoch [106/1000], Train Loss: 18844.3387, Test Loss: 17065.8330\n",
      "Epoch [107/1000], Train Loss: 16040.3845, Test Loss: 15864.7996\n",
      "Epoch [108/1000], Train Loss: 15228.0688, Test Loss: 14975.6132\n",
      "Epoch [109/1000], Train Loss: 14806.1504, Test Loss: 19977.9319\n",
      "Epoch [110/1000], Train Loss: 14434.9651, Test Loss: 16973.6186\n",
      "Epoch [111/1000], Train Loss: 14342.7894, Test Loss: 18626.3577\n",
      "Epoch [112/1000], Train Loss: 14214.0120, Test Loss: 16216.3766\n",
      "Epoch [113/1000], Train Loss: 14027.9991, Test Loss: 16466.9794\n",
      "Epoch [114/1000], Train Loss: 13794.4229, Test Loss: 17681.3674\n",
      "Epoch [115/1000], Train Loss: 13613.5391, Test Loss: 13657.8117\n",
      "Epoch [116/1000], Train Loss: 59275.2002, Test Loss: 17401.3589\n",
      "Epoch [117/1000], Train Loss: 14335.4321, Test Loss: 20362.2643\n",
      "Epoch [118/1000], Train Loss: 13135.4662, Test Loss: 17310.5497\n",
      "Epoch [119/1000], Train Loss: 12827.9927, Test Loss: 15920.8660\n",
      "Epoch [120/1000], Train Loss: 12807.8822, Test Loss: 17070.9902\n",
      "Epoch [121/1000], Train Loss: 12779.7222, Test Loss: 18138.9256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m save_path \u001b[38;5;241m=\u001b[39m ModelName \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Params.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m train_losses, test_losses, is_model_trained \u001b[38;5;241m=\u001b[39m train_or_load_model(model_aq, train_iter, test_iter, num_epochs, save_path)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Finish timing cell run time\u001b[39;00m\n\u001b[1;32m     25\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[8], line 63\u001b[0m, in \u001b[0;36mtrain_or_load_model\u001b[0;34m(model, train_loader, test_loader, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo pretrained model found. Training from scratch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#optimizer = optim.Adam(model.parameters())  \u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m train_losses, test_losses \u001b[38;5;241m=\u001b[39m train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path)\n\u001b[1;32m     64\u001b[0m is_model_trained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Set flag to True after training\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Save losses per epoch\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mtrain_and_save_best_model\u001b[0;34m(model, train_loader, test_loader, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 18\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Instantiate model and train\n",
    "\n",
    "# For timing cell run time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Create model\n",
    "model_aq = Transformer(input_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout)\n",
    "\n",
    "\n",
    "# Move the model to the GPU device\n",
    "model_aq.to(device)\n",
    "\n",
    "# Define the path to save and load the model parameters\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "# Call the function\n",
    "train_losses, test_losses, is_model_trained = train_or_load_model(model_aq, train_iter, test_iter, num_epochs, save_path)\n",
    "\n",
    "\n",
    "# Finish timing cell run time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "if is_model_trained:\n",
    "    np.save(ModelName + \"_ExecutionTime.npy\", execution_time)\n",
    "    print(\"Execution time:\", execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25.0269, 24.7433, 25.1693, 24.7354, 24.7865, 24.8540, 24.9547, 25.0152]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_aq(ValSpectra[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "np.save(ModelName + \"_TrainLoss.npy\", train_losses)\n",
    "np.save(ModelName + \"_TestLoss.npy\", test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot the data\n",
    "plt.plot(np.arange(num_epochs)+1, train_losses, label='Train Loss')\n",
    "plt.plot(np.arange(num_epochs)+1, test_losses, label='Test Loss')\n",
    "\n",
    "# Track the previous minimum test loss and its index\n",
    "prev_min_loss = test_losses[0]\n",
    "prev_min_index = 0\n",
    "\n",
    "# Annotate each local minimum test loss with arrows\n",
    "for idx, loss in enumerate(test_losses[1:], start=1):\n",
    "    if loss < prev_min_loss:\n",
    "        plt.annotate('Min', xy=(idx+1, loss), xytext=(idx+1, loss + 5000),\n",
    "                     arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "        prev_min_loss = loss\n",
    "        prev_min_index = idx\n",
    "        \n",
    "# Add x and y labels\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "\n",
    "# Change axis size\n",
    "plt.rcParams['axes.labelsize'] = 45  # Change label font size\n",
    "\n",
    "# Change tick size\n",
    "plt.tick_params(axis='x', labelsize=30)  # Change tick size for x-axis\n",
    "plt.tick_params(axis='y', labelsize=30)  # Change tick size for y-axis\n",
    "\n",
    "# Plot legend, and display figure\n",
    "plt.legend(fontsize = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Transformer_NonIncremental_8Met5000ep_Params.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m save_path \u001b[38;5;241m=\u001b[39m ModelName \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Params.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the entire dictionary from the saved file\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(save_path)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Instantiate the model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m model_aq \u001b[38;5;241m=\u001b[39m Transformer()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Transformer_NonIncremental_8Met5000ep_Params.pt'"
     ]
    }
   ],
   "source": [
    "## Make sure best parameters are being utilized\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Define the path where you saved your model parameters\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "# Load the entire dictionary from the saved file\n",
    "checkpoint = torch.load(save_path)\n",
    "\n",
    "# Instantiate the model\n",
    "model_aq = Transformer()\n",
    "\n",
    "# Load the model's state dictionary from the loaded dictionary\n",
    "model_aq.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Move the model to the GPU \n",
    "model_aq.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Switch to directory for saving model metrics\n",
    "\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelPerformanceMetrics')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model err:  0.049663443\n"
     ]
    }
   ],
   "source": [
    "## Test model on testing dataset and deterine RMSE\n",
    "\n",
    "outputs = model_aq(X_train) # Evaluate input spectra with MLP\n",
    "\n",
    "# Move tensors to CPU and convert to numpy arrays\n",
    "outputs_cpu = outputs.detach().cpu().numpy()\n",
    "y_train_cpu = y_train.detach().cpu().numpy()\n",
    "\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, y_train_cpu))  # Determine RMSE\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"TrainRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model err:  0.42279854\n"
     ]
    }
   ],
   "source": [
    "## Test model on testing dataset and deterine RMSE\n",
    "\n",
    "model_aq.eval() # Change to evaluation mode (maybe not needed for this model)\n",
    "outputs = model_aq(X_test) # Evaluate input spectra with MLP\n",
    "\n",
    "# Move tensors to CPU and convert to numpy arrays\n",
    "outputs_cpu = outputs.detach().cpu().numpy()\n",
    "y_test_cpu = y_test.detach().cpu().numpy()\n",
    "\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, y_test_cpu))  # Determine RMSE\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"TestRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model err:  0.37070227\n"
     ]
    }
   ],
   "source": [
    "## Test model on validation dataset and deterine RMSE\n",
    "\n",
    "model_aq.eval()  # Change to evaluation mode (maybe not needed for this model)\n",
    "outputs = model_aq(spectraVal)  # Evaluate input spectra with MLP\n",
    "\n",
    "# Move tensors to CPU and convert to numpy arrays\n",
    "outputs_cpu = outputs.detach().cpu().numpy()\n",
    "concVal_cpu = concVal.detach().cpu().numpy()\n",
    "\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, concVal_cpu))  # Determine RMSE\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"ValRMSE\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1, 46000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValSpectra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValConc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AllAq1', 'AllAq5', 'AllAq25', 'AllAq50', 'ThreeAddedSinglets',\n",
       "       'ThirtyAddedSinglets', 'ShiftedSpec', 'SineBase',\n",
       "       'HighDynamicRange', 'HalfZeros', 'Blank'], dtype='<U19')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValSpecNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ValConc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m MAPEs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     GroundTruth \u001b[38;5;241m=\u001b[39m ValConc[i]\n\u001b[1;32m      6\u001b[0m     Prediction \u001b[38;5;241m=\u001b[39m model_aq(ValSpectra[i])\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Move Prediction tensor to CPU and detach from computation graph\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ValConc' is not defined"
     ]
    }
   ],
   "source": [
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(10):\n",
    "    GroundTruth = ValConc[i]\n",
    "    Prediction = model_aq(ValSpectra[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(8):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[0][metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"ValExamples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"ValExamples_MAPEs.npy\", np.array(MAPEs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.77  -  AllAq1\n",
      "0.46  -  AllAq5\n",
      "0.1  -  AllAq25\n",
      "0.08  -  AllAq50\n",
      "1.3  -  ThreeAddedSinglets\n",
      "6.12  -  ThirtyAddedSinglets\n",
      "88.88  -  ShiftedSpec\n",
      "45.17  -  SineBase\n",
      "50.17  -  HighDynamicRange\n",
      "inf  -  HalfZeros\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(10):\n",
    "    print(round(MAPEs[i].item(), 2), \" - \",ValSpecNames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1722, 51.3610,  0.8381, 50.9899,  1.1752, 51.7818,  0.6907, 50.6754]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_aq(ValSpectra[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train transformer on dataset of 21 metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of epochs used later in training\n",
    "num_epochs = 1500\n",
    "\n",
    "# Name variable used for saving model metrics, name should reflect model used, dataset used, and other information such as # of epochs\n",
    "ModelName = \"Transformer_NonIncremental_21Met\" + str(num_epochs) +\"ep\"\n",
    "\n",
    "# Set the random seed\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelPerformanceMetrics/') \n",
    "seed = 1 \n",
    "torch.manual_seed(seed)\n",
    "np.save(ModelName + \"_Seed.npy\", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training and testing datasets, validation datasets, and representative example spectra \n",
    "\n",
    "# Switch to directory containing datasets\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/GeneratedDataAndVariables')\n",
    "\n",
    "# Load training data and max value from testing and training datasets\n",
    "spectra = np.load('Dataset21_Spec.npy')\n",
    "conc1 = np.load('Dataset21_Conc.npy')\n",
    "\n",
    "# Load validation dataset\n",
    "spectraVal = np.load('Dataset21_Val_Spec.npy')\n",
    "concVal = np.load('Dataset21_Val_Conc.npy')\n",
    "\n",
    "# Load representative validation spectra\n",
    "ValSpectra = np.load(\"Dataset21_RepresentativeExamples_Spectra.npy\")\n",
    "ValConc = np.load(\"Dataset21_RepresentativeExamples_Concentrations.npy\")\n",
    "ValSpecNames = np.load(\"Dataset21_RepresentativeExamples_VariableNames.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValConc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU for training.\n"
     ]
    }
   ],
   "source": [
    "## Prepare to switch data from CPU to GPU\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # A CUDA device object\n",
    "    print(\"Using GPU for training.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")           # A CPU object\n",
    "    print(\"CUDA is not available. Using CPU for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up data for testing and training\n",
    "\n",
    "# Split into testing and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectra, conc1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Tensorize and prepare datasets\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test).float()\n",
    "\n",
    "\n",
    "# Move the input data to the GPU device\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "spectraVal = torch.tensor(spectraVal).float().to(device)   # Confusing names, these spectra are the 5000 spectra generated like the training dataset\n",
    "ValSpectra = torch.tensor(ValSpectra).float().to(device)   # Confusing names, these spectra are the 10 representative example spectra\n",
    "\n",
    "# Move the target data to the GPU device\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "concVal = torch.tensor(concVal).float().to(device)\n",
    "ValConc = torch.tensor(ValConc).float().to(device)\n",
    "\n",
    "# More data prep?\n",
    "datasets = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "Test_datasets = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "train_iter = torch.utils.data.DataLoader(datasets, batch_size = 128, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(Test_datasets, batch_size = 128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        self.decoder = nn.Linear(23552, 21)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Binning\n",
    "        batch_size, seq_length = x.size()\n",
    "        num_bins = seq_length // self.input_dim\n",
    "        x = x.view(batch_size, num_bins, self.input_dim)  # (batch_size, num_bins, input_dim)\n",
    "        \n",
    "        # Embedding\n",
    "        x = self.embedding(x)  # (batch_size, num_bins, d_model)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        x = x.permute(1, 0, 2)  # (num_bins, batch_size, d_model)\n",
    "        x = self.transformer_encoder(x)  # (num_bins, batch_size, d_model)\n",
    "        x = x.permute(1, 0, 2)  # (batch_size, num_bins, d_model)\n",
    "        \n",
    "        # Reconstruct original sequence\n",
    "        x = x.reshape(batch_size, num_bins * d_model)\n",
    "        \n",
    "        # Decoding\n",
    "        x = self.decoder(x)  # (batch_size, output_dim)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Parameters\n",
    "input_dim = 1000  # Size of each bin\n",
    "d_model = 512     # Embedding dimension\n",
    "nhead = 1     # Number of attention heads\n",
    "num_encoder_layers = 1  # Number of transformer encoder layers\n",
    "dim_feedforward = 2048  # Feedforward dimension\n",
    "dropout = 0.0    # Dropout rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    best_test_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()          \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:  # The last number here denotes how often to print loss metrics in terms of epochs\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                  f'Train Loss: {train_loss:.4f}, '\n",
    "                  f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            # Save model when test loss improves\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, save_path)\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "def train_or_load_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    is_model_trained = False  # Initialize flag\n",
    "\n",
    "    if os.path.isfile(save_path):\n",
    "        print(\"Loading pretrained model from {}\".format(save_path))\n",
    "        checkpoint = torch.load(save_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer = optim.Adam(model.parameters())  \n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print(\"No pretrained model found. Training from scratch.\")\n",
    "        #optimizer = optim.Adam(model.parameters())  \n",
    "        train_losses, test_losses = train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path)\n",
    "        is_model_trained = True  # Set flag to True after training\n",
    "        # Save losses per epoch\n",
    "        np.save(ModelName + \"_TrainLoss.npy\", train_losses)\n",
    "        np.save(ModelName + \"_TestLoss.npy\", test_losses)\n",
    "    \n",
    "    return train_losses, test_losses, is_model_trained  # Return the losses and flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrained model found. Training from scratch.\n",
      "Epoch [1/1500], Train Loss: 3850233.0312, Test Loss: 394661.1787\n",
      "Epoch [2/1500], Train Loss: 537255.3440, Test Loss: 55201.1109\n",
      "Epoch [3/1500], Train Loss: 143933.5459, Test Loss: 28405.1501\n",
      "Epoch [4/1500], Train Loss: 86817.9731, Test Loss: 18887.2080\n",
      "Epoch [5/1500], Train Loss: 64016.0217, Test Loss: 15138.9204\n",
      "Epoch [6/1500], Train Loss: 51552.3650, Test Loss: 12596.2104\n",
      "Epoch [7/1500], Train Loss: 42403.9173, Test Loss: 10479.0137\n",
      "Epoch [8/1500], Train Loss: 35923.2150, Test Loss: 10398.7306\n",
      "Epoch [9/1500], Train Loss: 33092.2461, Test Loss: 8674.6069\n",
      "Epoch [10/1500], Train Loss: 29806.4254, Test Loss: 8021.4914\n",
      "Epoch [11/1500], Train Loss: 27120.2054, Test Loss: 7795.9153\n",
      "Epoch [12/1500], Train Loss: 24290.0662, Test Loss: 7097.3666\n",
      "Epoch [13/1500], Train Loss: 23402.0408, Test Loss: 9119.4190\n",
      "Epoch [14/1500], Train Loss: 22170.2672, Test Loss: 7512.4666\n",
      "Epoch [15/1500], Train Loss: 20024.6747, Test Loss: 6407.5211\n",
      "Epoch [16/1500], Train Loss: 18975.2304, Test Loss: 6276.6900\n",
      "Epoch [17/1500], Train Loss: 17976.4039, Test Loss: 7223.6563\n",
      "Epoch [18/1500], Train Loss: 17788.8067, Test Loss: 5574.4843\n",
      "Epoch [19/1500], Train Loss: 16950.0575, Test Loss: 5201.6178\n",
      "Epoch [20/1500], Train Loss: 16026.6301, Test Loss: 5246.4264\n",
      "Epoch [21/1500], Train Loss: 16560.5861, Test Loss: 5464.1488\n",
      "Epoch [22/1500], Train Loss: 14964.1653, Test Loss: 5110.4618\n",
      "Epoch [23/1500], Train Loss: 14649.1541, Test Loss: 5442.0722\n",
      "Epoch [24/1500], Train Loss: 14123.1938, Test Loss: 5045.7947\n",
      "Epoch [25/1500], Train Loss: 14366.1036, Test Loss: 4704.6057\n",
      "Epoch [26/1500], Train Loss: 13330.9816, Test Loss: 4256.5744\n",
      "Epoch [27/1500], Train Loss: 13678.9376, Test Loss: 4814.2140\n",
      "Epoch [28/1500], Train Loss: 13202.6347, Test Loss: 4785.0308\n",
      "Epoch [29/1500], Train Loss: 12194.0341, Test Loss: 4050.4346\n",
      "Epoch [30/1500], Train Loss: 11608.7271, Test Loss: 4263.1238\n",
      "Epoch [31/1500], Train Loss: 12470.0230, Test Loss: 3953.4248\n",
      "Epoch [32/1500], Train Loss: 11204.9175, Test Loss: 4098.2525\n",
      "Epoch [33/1500], Train Loss: 11170.7255, Test Loss: 4396.7215\n",
      "Epoch [34/1500], Train Loss: 11179.0825, Test Loss: 3868.8450\n",
      "Epoch [35/1500], Train Loss: 3961205.8250, Test Loss: 1105381.1074\n",
      "Epoch [36/1500], Train Loss: 4335545.3301, Test Loss: 1042276.0654\n",
      "Epoch [37/1500], Train Loss: 4065685.0840, Test Loss: 987719.1895\n",
      "Epoch [38/1500], Train Loss: 3887857.8926, Test Loss: 724519.2627\n",
      "Epoch [39/1500], Train Loss: 1754579.7607, Test Loss: 324675.8572\n",
      "Epoch [40/1500], Train Loss: 1117167.3008, Test Loss: 250665.2937\n",
      "Epoch [41/1500], Train Loss: 962582.0977, Test Loss: 220441.0594\n",
      "Epoch [42/1500], Train Loss: 893044.0215, Test Loss: 224376.1561\n",
      "Epoch [43/1500], Train Loss: 859298.6387, Test Loss: 205998.1436\n",
      "Epoch [44/1500], Train Loss: 801004.3213, Test Loss: 195586.7522\n",
      "Epoch [45/1500], Train Loss: 696521.9790, Test Loss: 167887.2222\n",
      "Epoch [46/1500], Train Loss: 615095.4678, Test Loss: 152215.1274\n",
      "Epoch [47/1500], Train Loss: 583402.9302, Test Loss: 143825.4479\n",
      "Epoch [48/1500], Train Loss: 557068.0037, Test Loss: 138995.6760\n",
      "Epoch [49/1500], Train Loss: 531368.2092, Test Loss: 130346.0353\n",
      "Epoch [50/1500], Train Loss: 532505.1055, Test Loss: 133553.7205\n",
      "Epoch [51/1500], Train Loss: 501930.4099, Test Loss: 127951.4916\n",
      "Epoch [52/1500], Train Loss: 494118.1995, Test Loss: 123524.6752\n",
      "Epoch [53/1500], Train Loss: 477192.5386, Test Loss: 125047.7034\n",
      "Epoch [54/1500], Train Loss: 479970.4739, Test Loss: 123799.8790\n",
      "Epoch [55/1500], Train Loss: 471410.4126, Test Loss: 119190.5913\n",
      "Epoch [56/1500], Train Loss: 450734.0637, Test Loss: 118025.4998\n",
      "Epoch [57/1500], Train Loss: 440621.1931, Test Loss: 114827.7833\n",
      "Epoch [58/1500], Train Loss: 447742.2791, Test Loss: 113894.6567\n",
      "Epoch [59/1500], Train Loss: 433499.6758, Test Loss: 116315.5891\n",
      "Epoch [60/1500], Train Loss: 431146.2458, Test Loss: 111305.7520\n",
      "Epoch [61/1500], Train Loss: 421886.6985, Test Loss: 110105.5212\n",
      "Epoch [62/1500], Train Loss: 413000.6145, Test Loss: 111142.8160\n",
      "Epoch [63/1500], Train Loss: 417128.0737, Test Loss: 107761.2386\n",
      "Epoch [64/1500], Train Loss: 413913.3162, Test Loss: 104079.5853\n",
      "Epoch [65/1500], Train Loss: 393699.2078, Test Loss: 103311.5933\n",
      "Epoch [66/1500], Train Loss: 380415.5112, Test Loss: 103080.1101\n",
      "Epoch [67/1500], Train Loss: 392311.5837, Test Loss: 103238.6674\n",
      "Epoch [68/1500], Train Loss: 381232.4553, Test Loss: 104623.7018\n",
      "Epoch [69/1500], Train Loss: 367120.4731, Test Loss: 96460.1927\n",
      "Epoch [70/1500], Train Loss: 368092.9094, Test Loss: 94149.0234\n",
      "Epoch [71/1500], Train Loss: 362956.2930, Test Loss: 96092.8759\n",
      "Epoch [72/1500], Train Loss: 353261.2751, Test Loss: 91123.2329\n",
      "Epoch [73/1500], Train Loss: 348628.8301, Test Loss: 90209.4750\n",
      "Epoch [74/1500], Train Loss: 351424.2600, Test Loss: 93434.5539\n",
      "Epoch [75/1500], Train Loss: 334652.4318, Test Loss: 87118.2491\n",
      "Epoch [76/1500], Train Loss: 328475.3625, Test Loss: 85257.5659\n",
      "Epoch [77/1500], Train Loss: 329876.1285, Test Loss: 86307.3625\n",
      "Epoch [78/1500], Train Loss: 328280.5743, Test Loss: 84405.2784\n",
      "Epoch [79/1500], Train Loss: 320518.3057, Test Loss: 82775.9361\n",
      "Epoch [80/1500], Train Loss: 321322.0562, Test Loss: 81924.6747\n",
      "Epoch [81/1500], Train Loss: 325870.8190, Test Loss: 84807.4368\n",
      "Epoch [82/1500], Train Loss: 323832.8984, Test Loss: 88046.0918\n",
      "Epoch [83/1500], Train Loss: 315918.6364, Test Loss: 83319.0278\n",
      "Epoch [84/1500], Train Loss: 305546.9269, Test Loss: 79171.7770\n",
      "Epoch [85/1500], Train Loss: 301496.4358, Test Loss: 80400.6092\n",
      "Epoch [86/1500], Train Loss: 302557.7264, Test Loss: 81055.7112\n",
      "Epoch [87/1500], Train Loss: 298701.4570, Test Loss: 83764.3115\n",
      "Epoch [88/1500], Train Loss: 314280.1914, Test Loss: 89036.3505\n",
      "Epoch [89/1500], Train Loss: 308726.0321, Test Loss: 76520.3907\n",
      "Epoch [90/1500], Train Loss: 289237.0862, Test Loss: 78380.8248\n",
      "Epoch [91/1500], Train Loss: 297894.7275, Test Loss: 79321.3217\n",
      "Epoch [92/1500], Train Loss: 299881.4224, Test Loss: 76540.3172\n",
      "Epoch [93/1500], Train Loss: 300719.7822, Test Loss: 75735.3722\n",
      "Epoch [94/1500], Train Loss: 284935.0601, Test Loss: 74849.9390\n",
      "Epoch [95/1500], Train Loss: 282143.9364, Test Loss: 76669.9659\n",
      "Epoch [96/1500], Train Loss: 272688.5980, Test Loss: 75886.5109\n",
      "Epoch [97/1500], Train Loss: 285449.2948, Test Loss: 73624.8991\n",
      "Epoch [98/1500], Train Loss: 270072.6630, Test Loss: 77292.3682\n",
      "Epoch [99/1500], Train Loss: 283413.0068, Test Loss: 75110.4072\n",
      "Epoch [100/1500], Train Loss: 278604.6525, Test Loss: 81432.9180\n",
      "Epoch [101/1500], Train Loss: 270543.3778, Test Loss: 72554.1369\n",
      "Epoch [102/1500], Train Loss: 269231.7009, Test Loss: 74741.4011\n",
      "Epoch [103/1500], Train Loss: 264119.5217, Test Loss: 70140.4914\n",
      "Epoch [104/1500], Train Loss: 293498.5760, Test Loss: 77673.5955\n",
      "Epoch [105/1500], Train Loss: 305032.0000, Test Loss: 74465.8233\n",
      "Epoch [106/1500], Train Loss: 286349.6775, Test Loss: 73033.9424\n",
      "Epoch [107/1500], Train Loss: 273041.8682, Test Loss: 72035.5527\n",
      "Epoch [108/1500], Train Loss: 260168.6189, Test Loss: 70854.9062\n",
      "Epoch [109/1500], Train Loss: 261726.6826, Test Loss: 72003.4498\n",
      "Epoch [110/1500], Train Loss: 251168.9354, Test Loss: 66262.5521\n",
      "Epoch [111/1500], Train Loss: 237704.3362, Test Loss: 62393.3120\n",
      "Epoch [112/1500], Train Loss: 240673.6791, Test Loss: 66528.6651\n",
      "Epoch [113/1500], Train Loss: 238743.3748, Test Loss: 65999.1633\n",
      "Epoch [114/1500], Train Loss: 233918.9980, Test Loss: 59119.2892\n",
      "Epoch [115/1500], Train Loss: 221847.2430, Test Loss: 60792.9811\n",
      "Epoch [116/1500], Train Loss: 220532.1434, Test Loss: 56960.9749\n",
      "Epoch [117/1500], Train Loss: 213024.4587, Test Loss: 55816.2972\n",
      "Epoch [118/1500], Train Loss: 209902.3955, Test Loss: 61614.5888\n",
      "Epoch [119/1500], Train Loss: 197776.3414, Test Loss: 53229.2946\n",
      "Epoch [120/1500], Train Loss: 185304.6416, Test Loss: 48097.1059\n",
      "Epoch [121/1500], Train Loss: 169785.2461, Test Loss: 45506.2214\n",
      "Epoch [122/1500], Train Loss: 170683.6840, Test Loss: 52300.5254\n",
      "Epoch [123/1500], Train Loss: 168353.7944, Test Loss: 65073.9388\n",
      "Epoch [124/1500], Train Loss: 162760.8120, Test Loss: 34115.2864\n",
      "Epoch [125/1500], Train Loss: 115000.8204, Test Loss: 28790.7893\n",
      "Epoch [126/1500], Train Loss: 99377.3719, Test Loss: 26943.2287\n",
      "Epoch [127/1500], Train Loss: 88006.8808, Test Loss: 24015.3080\n",
      "Epoch [128/1500], Train Loss: 79326.6458, Test Loss: 22867.9513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [129/1500], Train Loss: 73204.3742, Test Loss: 20600.7286\n",
      "Epoch [130/1500], Train Loss: 68385.0832, Test Loss: 19182.2009\n",
      "Epoch [131/1500], Train Loss: 63846.1586, Test Loss: 17482.8931\n",
      "Epoch [132/1500], Train Loss: 58561.7104, Test Loss: 17225.1740\n",
      "Epoch [133/1500], Train Loss: 57061.8846, Test Loss: 16873.6897\n",
      "Epoch [134/1500], Train Loss: 53024.0959, Test Loss: 15572.7966\n",
      "Epoch [135/1500], Train Loss: 51788.6010, Test Loss: 14503.6271\n",
      "Epoch [136/1500], Train Loss: 48632.7327, Test Loss: 14388.6948\n",
      "Epoch [137/1500], Train Loss: 46966.5381, Test Loss: 13490.1793\n",
      "Epoch [138/1500], Train Loss: 42756.4715, Test Loss: 13850.5481\n",
      "Epoch [139/1500], Train Loss: 44112.7383, Test Loss: 11689.9479\n",
      "Epoch [140/1500], Train Loss: 38274.9103, Test Loss: 11265.8175\n",
      "Epoch [141/1500], Train Loss: 35629.0549, Test Loss: 10621.6337\n",
      "Epoch [142/1500], Train Loss: 35615.1347, Test Loss: 10633.5314\n",
      "Epoch [143/1500], Train Loss: 32800.8176, Test Loss: 10012.3003\n",
      "Epoch [144/1500], Train Loss: 31211.4073, Test Loss: 9410.2911\n",
      "Epoch [145/1500], Train Loss: 29095.4621, Test Loss: 9487.3122\n",
      "Epoch [146/1500], Train Loss: 27642.3699, Test Loss: 9380.8050\n",
      "Epoch [147/1500], Train Loss: 27110.8553, Test Loss: 7789.3905\n",
      "Epoch [148/1500], Train Loss: 25125.5984, Test Loss: 7879.5425\n",
      "Epoch [149/1500], Train Loss: 24234.5492, Test Loss: 7735.1403\n",
      "Epoch [150/1500], Train Loss: 23520.6634, Test Loss: 8704.3570\n",
      "Epoch [151/1500], Train Loss: 23158.8976, Test Loss: 6953.5220\n",
      "Epoch [152/1500], Train Loss: 21733.4156, Test Loss: 6666.0482\n",
      "Epoch [153/1500], Train Loss: 21040.2789, Test Loss: 6632.7840\n",
      "Epoch [154/1500], Train Loss: 19370.7947, Test Loss: 6363.8779\n",
      "Epoch [155/1500], Train Loss: 18704.4807, Test Loss: 6630.9430\n",
      "Epoch [156/1500], Train Loss: 19381.7244, Test Loss: 6271.8774\n",
      "Epoch [157/1500], Train Loss: 18789.2071, Test Loss: 6979.3198\n",
      "Epoch [158/1500], Train Loss: 18054.9848, Test Loss: 5594.9519\n",
      "Epoch [159/1500], Train Loss: 16876.6097, Test Loss: 5828.4831\n",
      "Epoch [160/1500], Train Loss: 17201.2895, Test Loss: 5215.7931\n",
      "Epoch [161/1500], Train Loss: 16631.0552, Test Loss: 5483.4451\n",
      "Epoch [162/1500], Train Loss: 15889.9632, Test Loss: 5128.5264\n",
      "Epoch [163/1500], Train Loss: 14833.2717, Test Loss: 4959.6521\n",
      "Epoch [164/1500], Train Loss: 13980.3111, Test Loss: 5081.8517\n",
      "Epoch [165/1500], Train Loss: 13824.3063, Test Loss: 4576.5418\n",
      "Epoch [166/1500], Train Loss: 13251.3057, Test Loss: 5533.9420\n",
      "Epoch [167/1500], Train Loss: 12984.9330, Test Loss: 4939.8623\n",
      "Epoch [168/1500], Train Loss: 12687.1555, Test Loss: 4563.0286\n",
      "Epoch [169/1500], Train Loss: 13335.3371, Test Loss: 4412.3901\n",
      "Epoch [170/1500], Train Loss: 12004.5495, Test Loss: 4334.2875\n",
      "Epoch [171/1500], Train Loss: 11685.4136, Test Loss: 4652.7951\n",
      "Epoch [172/1500], Train Loss: 11754.1712, Test Loss: 4134.9387\n",
      "Epoch [173/1500], Train Loss: 11148.3845, Test Loss: 4270.4040\n",
      "Epoch [174/1500], Train Loss: 11328.6423, Test Loss: 4170.4089\n",
      "Epoch [175/1500], Train Loss: 10781.1458, Test Loss: 4139.1016\n",
      "Epoch [176/1500], Train Loss: 12137.0656, Test Loss: 4012.3574\n",
      "Epoch [177/1500], Train Loss: 10536.0347, Test Loss: 4015.4016\n",
      "Epoch [178/1500], Train Loss: 10381.4464, Test Loss: 3803.3526\n",
      "Epoch [179/1500], Train Loss: 10049.2078, Test Loss: 4130.3489\n",
      "Epoch [180/1500], Train Loss: 10053.6002, Test Loss: 3881.1561\n",
      "Epoch [181/1500], Train Loss: 11889.4951, Test Loss: 3969.9522\n",
      "Epoch [182/1500], Train Loss: 9914.2456, Test Loss: 3693.8807\n",
      "Epoch [183/1500], Train Loss: 9828.8867, Test Loss: 3669.5188\n",
      "Epoch [184/1500], Train Loss: 9826.0331, Test Loss: 3738.8965\n",
      "Epoch [185/1500], Train Loss: 9146.0172, Test Loss: 3911.3631\n",
      "Epoch [186/1500], Train Loss: 9664.0229, Test Loss: 3645.5083\n",
      "Epoch [187/1500], Train Loss: 8938.8579, Test Loss: 3629.0858\n",
      "Epoch [188/1500], Train Loss: 21540.6405, Test Loss: 184716.0630\n",
      "Epoch [189/1500], Train Loss: 4520911.7842, Test Loss: 1001986.1177\n",
      "Epoch [190/1500], Train Loss: 2657780.5083, Test Loss: 242548.4220\n",
      "Epoch [191/1500], Train Loss: 565907.0974, Test Loss: 84691.9636\n",
      "Epoch [192/1500], Train Loss: 232819.5667, Test Loss: 47339.4978\n",
      "Epoch [193/1500], Train Loss: 159588.6987, Test Loss: 38543.5781\n",
      "Epoch [194/1500], Train Loss: 132508.5648, Test Loss: 33557.7582\n",
      "Epoch [195/1500], Train Loss: 114868.7223, Test Loss: 30127.3584\n",
      "Epoch [196/1500], Train Loss: 102767.4515, Test Loss: 26983.1643\n",
      "Epoch [197/1500], Train Loss: 93171.3131, Test Loss: 24174.0943\n",
      "Epoch [198/1500], Train Loss: 83763.3381, Test Loss: 22542.5464\n",
      "Epoch [199/1500], Train Loss: 76115.9459, Test Loss: 20695.8745\n",
      "Epoch [200/1500], Train Loss: 69260.6373, Test Loss: 19000.7349\n",
      "Epoch [201/1500], Train Loss: 62920.8893, Test Loss: 17274.7666\n",
      "Epoch [202/1500], Train Loss: 56856.6581, Test Loss: 15867.3130\n",
      "Epoch [203/1500], Train Loss: 51243.2098, Test Loss: 14451.8287\n",
      "Epoch [204/1500], Train Loss: 45546.0268, Test Loss: 13534.7214\n",
      "Epoch [205/1500], Train Loss: 41990.0389, Test Loss: 11856.4197\n",
      "Epoch [206/1500], Train Loss: 37467.2005, Test Loss: 10827.2692\n",
      "Epoch [207/1500], Train Loss: 34417.4375, Test Loss: 10737.2153\n",
      "Epoch [208/1500], Train Loss: 32313.8601, Test Loss: 10181.2621\n",
      "Epoch [209/1500], Train Loss: 29272.8053, Test Loss: 8488.1950\n",
      "Epoch [210/1500], Train Loss: 27006.7274, Test Loss: 8055.9038\n",
      "Epoch [211/1500], Train Loss: 24663.2086, Test Loss: 7431.5323\n",
      "Epoch [212/1500], Train Loss: 23407.9647, Test Loss: 7086.7214\n",
      "Epoch [213/1500], Train Loss: 21775.4770, Test Loss: 6681.1707\n",
      "Epoch [214/1500], Train Loss: 20628.9453, Test Loss: 6332.2879\n",
      "Epoch [215/1500], Train Loss: 19404.9606, Test Loss: 5975.2241\n",
      "Epoch [216/1500], Train Loss: 18760.5399, Test Loss: 5687.7687\n",
      "Epoch [217/1500], Train Loss: 17583.8623, Test Loss: 5526.0999\n",
      "Epoch [218/1500], Train Loss: 16886.0771, Test Loss: 5324.3877\n",
      "Epoch [219/1500], Train Loss: 16406.3549, Test Loss: 5086.3019\n",
      "Epoch [220/1500], Train Loss: 15471.1913, Test Loss: 5005.4235\n",
      "Epoch [221/1500], Train Loss: 14976.8218, Test Loss: 4794.5277\n",
      "Epoch [222/1500], Train Loss: 14626.7569, Test Loss: 5093.2636\n",
      "Epoch [223/1500], Train Loss: 14075.3722, Test Loss: 4714.1302\n",
      "Epoch [224/1500], Train Loss: 13515.5295, Test Loss: 4465.2379\n",
      "Epoch [225/1500], Train Loss: 13214.6449, Test Loss: 4840.4885\n",
      "Epoch [226/1500], Train Loss: 12563.2877, Test Loss: 4398.7511\n",
      "Epoch [227/1500], Train Loss: 12267.5921, Test Loss: 4145.9022\n",
      "Epoch [228/1500], Train Loss: 12465.8994, Test Loss: 4324.5085\n",
      "Epoch [229/1500], Train Loss: 12150.6143, Test Loss: 4145.8624\n",
      "Epoch [230/1500], Train Loss: 12008.9964, Test Loss: 4125.2083\n",
      "Epoch [231/1500], Train Loss: 11789.1773, Test Loss: 3916.8388\n",
      "Epoch [232/1500], Train Loss: 11029.3019, Test Loss: 3873.1828\n",
      "Epoch [233/1500], Train Loss: 11453.7053, Test Loss: 3762.7174\n",
      "Epoch [234/1500], Train Loss: 10631.0284, Test Loss: 4119.6309\n",
      "Epoch [235/1500], Train Loss: 10550.8509, Test Loss: 3764.8836\n",
      "Epoch [236/1500], Train Loss: 10429.3098, Test Loss: 3676.6082\n",
      "Epoch [237/1500], Train Loss: 10122.2722, Test Loss: 3999.6562\n",
      "Epoch [238/1500], Train Loss: 10384.3523, Test Loss: 3724.0271\n",
      "Epoch [239/1500], Train Loss: 9896.7257, Test Loss: 3815.7539\n",
      "Epoch [240/1500], Train Loss: 10023.7333, Test Loss: 3552.9867\n",
      "Epoch [241/1500], Train Loss: 9555.8705, Test Loss: 3636.6170\n",
      "Epoch [242/1500], Train Loss: 9324.8433, Test Loss: 3748.6344\n",
      "Epoch [243/1500], Train Loss: 9413.5421, Test Loss: 3671.7263\n",
      "Epoch [244/1500], Train Loss: 9696.5168, Test Loss: 3452.9776\n",
      "Epoch [245/1500], Train Loss: 9870.2789, Test Loss: 3704.7810\n",
      "Epoch [246/1500], Train Loss: 9092.5872, Test Loss: 3492.0529\n",
      "Epoch [247/1500], Train Loss: 8673.1559, Test Loss: 3560.2610\n",
      "Epoch [248/1500], Train Loss: 8788.2375, Test Loss: 3321.1070\n",
      "Epoch [249/1500], Train Loss: 8527.9833, Test Loss: 3617.1135\n",
      "Epoch [250/1500], Train Loss: 8253.9222, Test Loss: 3239.1933\n",
      "Epoch [251/1500], Train Loss: 8411.1274, Test Loss: 3219.3850\n",
      "Epoch [252/1500], Train Loss: 8165.6512, Test Loss: 3291.1646\n",
      "Epoch [253/1500], Train Loss: 8330.4256, Test Loss: 3306.6480\n",
      "Epoch [254/1500], Train Loss: 8216.9259, Test Loss: 3690.9274\n",
      "Epoch [255/1500], Train Loss: 8252.2419, Test Loss: 3584.7136\n",
      "Epoch [256/1500], Train Loss: 8043.9916, Test Loss: 3382.0533\n",
      "Epoch [257/1500], Train Loss: 8194.7173, Test Loss: 3242.7837\n",
      "Epoch [258/1500], Train Loss: 8200.9495, Test Loss: 3316.1743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [259/1500], Train Loss: 7901.9187, Test Loss: 3147.1319\n",
      "Epoch [260/1500], Train Loss: 8045.7994, Test Loss: 3366.2972\n",
      "Epoch [261/1500], Train Loss: 7917.9259, Test Loss: 3396.1316\n",
      "Epoch [262/1500], Train Loss: 7849.4710, Test Loss: 3221.3397\n",
      "Epoch [263/1500], Train Loss: 7891.8313, Test Loss: 3061.3022\n",
      "Epoch [264/1500], Train Loss: 7375.2180, Test Loss: 3111.0823\n",
      "Epoch [265/1500], Train Loss: 7205.0607, Test Loss: 3212.0525\n",
      "Epoch [266/1500], Train Loss: 7492.3204, Test Loss: 3538.5541\n",
      "Epoch [267/1500], Train Loss: 7321.9975, Test Loss: 3128.3672\n",
      "Epoch [268/1500], Train Loss: 7680.1088, Test Loss: 3340.9433\n",
      "Epoch [269/1500], Train Loss: 7456.1537, Test Loss: 3279.3100\n",
      "Epoch [270/1500], Train Loss: 7536.2844, Test Loss: 3206.5304\n",
      "Epoch [271/1500], Train Loss: 6986.2179, Test Loss: 3345.1890\n",
      "Epoch [272/1500], Train Loss: 7178.4425, Test Loss: 3135.8670\n",
      "Epoch [273/1500], Train Loss: 7107.6869, Test Loss: 3214.5292\n",
      "Epoch [274/1500], Train Loss: 7035.3996, Test Loss: 3167.6862\n",
      "Epoch [275/1500], Train Loss: 6826.4322, Test Loss: 3045.2223\n",
      "Epoch [276/1500], Train Loss: 6910.8749, Test Loss: 3021.9302\n",
      "Epoch [277/1500], Train Loss: 6407.0631, Test Loss: 3119.0367\n",
      "Epoch [278/1500], Train Loss: 7336.3577, Test Loss: 3070.0584\n",
      "Epoch [279/1500], Train Loss: 6776.9244, Test Loss: 2915.2170\n",
      "Epoch [280/1500], Train Loss: 6748.6295, Test Loss: 3095.6138\n",
      "Epoch [281/1500], Train Loss: 6666.9787, Test Loss: 3047.3853\n",
      "Epoch [282/1500], Train Loss: 6652.6913, Test Loss: 3395.3076\n",
      "Epoch [283/1500], Train Loss: 6678.5531, Test Loss: 3456.2140\n",
      "Epoch [284/1500], Train Loss: 474207.5904, Test Loss: 6489.4517\n",
      "Epoch [285/1500], Train Loss: 15772.0943, Test Loss: 4342.8641\n",
      "Epoch [286/1500], Train Loss: 10946.1004, Test Loss: 3697.6231\n",
      "Epoch [287/1500], Train Loss: 9187.2749, Test Loss: 3383.1517\n",
      "Epoch [288/1500], Train Loss: 8320.0979, Test Loss: 3313.6402\n",
      "Epoch [289/1500], Train Loss: 7694.1877, Test Loss: 3116.3801\n",
      "Epoch [290/1500], Train Loss: 7203.9203, Test Loss: 3171.3361\n",
      "Epoch [291/1500], Train Loss: 7047.3968, Test Loss: 3081.6273\n",
      "Epoch [292/1500], Train Loss: 6841.9635, Test Loss: 3026.5242\n",
      "Epoch [293/1500], Train Loss: 6547.2276, Test Loss: 3057.5845\n",
      "Epoch [294/1500], Train Loss: 6551.8518, Test Loss: 2955.7363\n",
      "Epoch [295/1500], Train Loss: 6302.8723, Test Loss: 2949.9337\n",
      "Epoch [296/1500], Train Loss: 6210.6050, Test Loss: 2947.7562\n",
      "Epoch [297/1500], Train Loss: 6175.9577, Test Loss: 2884.3476\n",
      "Epoch [298/1500], Train Loss: 6068.9200, Test Loss: 3069.8130\n",
      "Epoch [299/1500], Train Loss: 6328.7248, Test Loss: 2855.3136\n",
      "Epoch [300/1500], Train Loss: 6128.9660, Test Loss: 2969.8675\n",
      "Epoch [301/1500], Train Loss: 6079.9619, Test Loss: 3081.3051\n",
      "Epoch [302/1500], Train Loss: 6180.8130, Test Loss: 2868.0152\n",
      "Epoch [303/1500], Train Loss: 5938.1828, Test Loss: 2879.4465\n",
      "Epoch [304/1500], Train Loss: 6106.5889, Test Loss: 2951.7773\n",
      "Epoch [305/1500], Train Loss: 6115.9709, Test Loss: 2848.1500\n",
      "Epoch [306/1500], Train Loss: 5684.1273, Test Loss: 2798.2504\n",
      "Epoch [307/1500], Train Loss: 5995.0027, Test Loss: 3159.0467\n",
      "Epoch [308/1500], Train Loss: 6092.2147, Test Loss: 3165.6875\n",
      "Epoch [309/1500], Train Loss: 5958.8551, Test Loss: 2802.7181\n",
      "Epoch [310/1500], Train Loss: 5852.2754, Test Loss: 2774.5004\n",
      "Epoch [311/1500], Train Loss: 5924.2218, Test Loss: 2852.0608\n",
      "Epoch [312/1500], Train Loss: 6067.6721, Test Loss: 3056.5499\n",
      "Epoch [313/1500], Train Loss: 6063.7144, Test Loss: 3164.7075\n",
      "Epoch [314/1500], Train Loss: 5979.0013, Test Loss: 2728.5325\n",
      "Epoch [315/1500], Train Loss: 5576.2307, Test Loss: 2687.1613\n",
      "Epoch [316/1500], Train Loss: 5658.5364, Test Loss: 2821.3259\n",
      "Epoch [317/1500], Train Loss: 5772.3641, Test Loss: 3238.3894\n",
      "Epoch [318/1500], Train Loss: 5821.8481, Test Loss: 2938.5297\n",
      "Epoch [319/1500], Train Loss: 5621.0256, Test Loss: 2952.4599\n",
      "Epoch [320/1500], Train Loss: 6097.7305, Test Loss: 2844.3201\n",
      "Epoch [321/1500], Train Loss: 5574.9099, Test Loss: 3080.7294\n",
      "Epoch [322/1500], Train Loss: 5652.4609, Test Loss: 2921.2889\n",
      "Epoch [323/1500], Train Loss: 5797.1289, Test Loss: 2846.7272\n",
      "Epoch [324/1500], Train Loss: 5672.3003, Test Loss: 2875.1574\n",
      "Epoch [325/1500], Train Loss: 5545.8002, Test Loss: 2972.9865\n",
      "Epoch [326/1500], Train Loss: 5803.1665, Test Loss: 2933.2714\n",
      "Epoch [327/1500], Train Loss: 5843.5486, Test Loss: 3189.3976\n",
      "Epoch [328/1500], Train Loss: 5593.7012, Test Loss: 2825.2617\n",
      "Epoch [329/1500], Train Loss: 5551.2453, Test Loss: 3004.9192\n",
      "Epoch [330/1500], Train Loss: 5414.2186, Test Loss: 2925.9494\n",
      "Epoch [331/1500], Train Loss: 5388.2450, Test Loss: 2889.9688\n",
      "Epoch [332/1500], Train Loss: 5506.2046, Test Loss: 2752.5708\n",
      "Epoch [333/1500], Train Loss: 5431.8667, Test Loss: 2692.6931\n",
      "Epoch [334/1500], Train Loss: 5457.4359, Test Loss: 2869.9045\n",
      "Epoch [335/1500], Train Loss: 5477.7040, Test Loss: 2944.0731\n",
      "Epoch [336/1500], Train Loss: 5259.9755, Test Loss: 2939.7373\n",
      "Epoch [337/1500], Train Loss: 5348.5710, Test Loss: 2957.6957\n",
      "Epoch [338/1500], Train Loss: 5482.8524, Test Loss: 2753.4831\n",
      "Epoch [339/1500], Train Loss: 5550.0685, Test Loss: 2847.4138\n",
      "Epoch [340/1500], Train Loss: 5251.5130, Test Loss: 2887.5464\n",
      "Epoch [341/1500], Train Loss: 5205.3644, Test Loss: 2706.7351\n",
      "Epoch [342/1500], Train Loss: 5241.8287, Test Loss: 2875.5849\n",
      "Epoch [343/1500], Train Loss: 5396.5578, Test Loss: 3012.0073\n",
      "Epoch [344/1500], Train Loss: 5278.0254, Test Loss: 2854.0604\n",
      "Epoch [345/1500], Train Loss: 5131.6342, Test Loss: 3038.0239\n",
      "Epoch [346/1500], Train Loss: 5162.7536, Test Loss: 3091.9359\n",
      "Epoch [347/1500], Train Loss: 5180.5187, Test Loss: 3103.7712\n",
      "Epoch [348/1500], Train Loss: 5346.5373, Test Loss: 2839.5357\n",
      "Epoch [349/1500], Train Loss: 5288.8085, Test Loss: 2685.2147\n",
      "Epoch [350/1500], Train Loss: 5241.5079, Test Loss: 2733.6344\n",
      "Epoch [351/1500], Train Loss: 5176.4694, Test Loss: 2752.4764\n",
      "Epoch [352/1500], Train Loss: 5098.1098, Test Loss: 2861.5667\n",
      "Epoch [353/1500], Train Loss: 5359.4275, Test Loss: 2966.5257\n",
      "Epoch [354/1500], Train Loss: 5238.6606, Test Loss: 2745.9030\n",
      "Epoch [355/1500], Train Loss: 5043.2242, Test Loss: 2940.1451\n",
      "Epoch [356/1500], Train Loss: 4915.0289, Test Loss: 2693.9808\n",
      "Epoch [357/1500], Train Loss: 4820.6003, Test Loss: 3074.9112\n",
      "Epoch [358/1500], Train Loss: 5211.3755, Test Loss: 2963.8087\n",
      "Epoch [359/1500], Train Loss: 5431.0326, Test Loss: 2706.3113\n",
      "Epoch [360/1500], Train Loss: 5020.1197, Test Loss: 2821.9049\n",
      "Epoch [361/1500], Train Loss: 4976.1153, Test Loss: 2653.8181\n",
      "Epoch [362/1500], Train Loss: 5163.9856, Test Loss: 2756.7171\n",
      "Epoch [363/1500], Train Loss: 5111.9216, Test Loss: 2662.4336\n",
      "Epoch [364/1500], Train Loss: 4930.9844, Test Loss: 2625.0506\n",
      "Epoch [365/1500], Train Loss: 4961.1901, Test Loss: 2810.7168\n",
      "Epoch [366/1500], Train Loss: 4898.6174, Test Loss: 2758.1885\n",
      "Epoch [367/1500], Train Loss: 4846.0804, Test Loss: 3080.6697\n",
      "Epoch [368/1500], Train Loss: 4682.9725, Test Loss: 2726.9375\n",
      "Epoch [369/1500], Train Loss: 4806.9195, Test Loss: 2762.6298\n",
      "Epoch [370/1500], Train Loss: 4787.9269, Test Loss: 2785.4237\n",
      "Epoch [371/1500], Train Loss: 4885.4346, Test Loss: 2884.7240\n",
      "Epoch [372/1500], Train Loss: 5018.7774, Test Loss: 2736.1954\n",
      "Epoch [373/1500], Train Loss: 4741.1439, Test Loss: 2632.2700\n",
      "Epoch [374/1500], Train Loss: 4667.9200, Test Loss: 2903.3247\n",
      "Epoch [375/1500], Train Loss: 5074.7326, Test Loss: 3464.9986\n",
      "Epoch [376/1500], Train Loss: 5661.1629, Test Loss: 2810.7588\n",
      "Epoch [377/1500], Train Loss: 4538.1412, Test Loss: 2854.8454\n",
      "Epoch [378/1500], Train Loss: 4664.6441, Test Loss: 2828.1996\n",
      "Epoch [379/1500], Train Loss: 4484.6026, Test Loss: 2749.4868\n",
      "Epoch [380/1500], Train Loss: 4366.6225, Test Loss: 2893.8646\n",
      "Epoch [381/1500], Train Loss: 4996.7008, Test Loss: 2996.9841\n",
      "Epoch [382/1500], Train Loss: 4850.2332, Test Loss: 2629.3694\n",
      "Epoch [383/1500], Train Loss: 4809.0089, Test Loss: 3183.4123\n",
      "Epoch [384/1500], Train Loss: 104647.4685, Test Loss: 4095.9083\n",
      "Epoch [385/1500], Train Loss: 7798.9064, Test Loss: 3020.0055\n",
      "Epoch [386/1500], Train Loss: 5738.6909, Test Loss: 2829.8435\n",
      "Epoch [387/1500], Train Loss: 5049.5205, Test Loss: 2838.6010\n",
      "Epoch [388/1500], Train Loss: 4779.0306, Test Loss: 2635.5042\n",
      "Epoch [389/1500], Train Loss: 4580.3668, Test Loss: 2705.2583\n",
      "Epoch [390/1500], Train Loss: 4482.9774, Test Loss: 2763.7236\n",
      "Epoch [391/1500], Train Loss: 4692.5607, Test Loss: 2639.3732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [392/1500], Train Loss: 4221.7159, Test Loss: 2772.2315\n",
      "Epoch [393/1500], Train Loss: 4119.6559, Test Loss: 2745.7438\n",
      "Epoch [394/1500], Train Loss: 4167.8874, Test Loss: 2578.1786\n",
      "Epoch [395/1500], Train Loss: 4006.5695, Test Loss: 2762.2809\n",
      "Epoch [396/1500], Train Loss: 4061.8644, Test Loss: 2680.6160\n",
      "Epoch [397/1500], Train Loss: 4176.2317, Test Loss: 2645.2774\n",
      "Epoch [398/1500], Train Loss: 4057.9093, Test Loss: 2746.6258\n",
      "Epoch [399/1500], Train Loss: 4021.5701, Test Loss: 2788.8830\n",
      "Epoch [400/1500], Train Loss: 3989.4039, Test Loss: 2791.8685\n",
      "Epoch [401/1500], Train Loss: 4076.2642, Test Loss: 2665.8880\n",
      "Epoch [402/1500], Train Loss: 3884.2791, Test Loss: 2731.9333\n",
      "Epoch [403/1500], Train Loss: 4010.4675, Test Loss: 2709.8582\n",
      "Epoch [404/1500], Train Loss: 4075.8998, Test Loss: 2678.8763\n",
      "Epoch [405/1500], Train Loss: 3871.6729, Test Loss: 2688.0349\n",
      "Epoch [406/1500], Train Loss: 3876.1564, Test Loss: 2654.6125\n",
      "Epoch [407/1500], Train Loss: 3747.8899, Test Loss: 2705.8908\n",
      "Epoch [408/1500], Train Loss: 3889.3683, Test Loss: 2599.1751\n",
      "Epoch [409/1500], Train Loss: 3865.2000, Test Loss: 2690.7451\n",
      "Epoch [410/1500], Train Loss: 3838.8391, Test Loss: 2625.7153\n",
      "Epoch [411/1500], Train Loss: 3936.3356, Test Loss: 2745.7029\n",
      "Epoch [412/1500], Train Loss: 4058.5970, Test Loss: 2553.6703\n",
      "Epoch [413/1500], Train Loss: 3787.8622, Test Loss: 2818.8043\n",
      "Epoch [414/1500], Train Loss: 3840.3060, Test Loss: 2608.0768\n",
      "Epoch [415/1500], Train Loss: 4038.4232, Test Loss: 2799.8266\n",
      "Epoch [416/1500], Train Loss: 3833.0279, Test Loss: 2659.0192\n",
      "Epoch [417/1500], Train Loss: 4025.2821, Test Loss: 2823.7812\n",
      "Epoch [418/1500], Train Loss: 3952.8466, Test Loss: 2688.4939\n",
      "Epoch [419/1500], Train Loss: 4048.1112, Test Loss: 2936.6505\n",
      "Epoch [420/1500], Train Loss: 4060.7424, Test Loss: 2665.7791\n",
      "Epoch [421/1500], Train Loss: 3866.9283, Test Loss: 2609.0980\n",
      "Epoch [422/1500], Train Loss: 3922.0233, Test Loss: 2635.7179\n",
      "Epoch [423/1500], Train Loss: 3782.3458, Test Loss: 2590.9435\n",
      "Epoch [424/1500], Train Loss: 3856.0679, Test Loss: 2682.6875\n",
      "Epoch [425/1500], Train Loss: 3667.0432, Test Loss: 2539.0782\n",
      "Epoch [426/1500], Train Loss: 3881.2915, Test Loss: 2729.4645\n",
      "Epoch [427/1500], Train Loss: 3826.4002, Test Loss: 2707.7048\n",
      "Epoch [428/1500], Train Loss: 3882.5708, Test Loss: 2564.6342\n",
      "Epoch [429/1500], Train Loss: 3650.2800, Test Loss: 2618.3244\n",
      "Epoch [430/1500], Train Loss: 3734.6532, Test Loss: 2670.2756\n",
      "Epoch [431/1500], Train Loss: 3939.5413, Test Loss: 2872.8508\n",
      "Epoch [432/1500], Train Loss: 3860.7203, Test Loss: 2683.3881\n",
      "Epoch [433/1500], Train Loss: 3768.4359, Test Loss: 2658.6017\n",
      "Epoch [434/1500], Train Loss: 3815.8356, Test Loss: 2614.5301\n",
      "Epoch [435/1500], Train Loss: 3959.4211, Test Loss: 2690.4112\n",
      "Epoch [436/1500], Train Loss: 5415.3422, Test Loss: 2747.9723\n",
      "Epoch [437/1500], Train Loss: 5374.0817, Test Loss: 3746.5644\n",
      "Epoch [438/1500], Train Loss: 7438.6561, Test Loss: 3609.0794\n",
      "Epoch [439/1500], Train Loss: 5324.5532, Test Loss: 3027.5766\n",
      "Epoch [440/1500], Train Loss: 4326.1301, Test Loss: 2919.2154\n",
      "Epoch [441/1500], Train Loss: 3813.0956, Test Loss: 2760.7538\n",
      "Epoch [442/1500], Train Loss: 3684.8963, Test Loss: 2649.4917\n",
      "Epoch [443/1500], Train Loss: 3619.7025, Test Loss: 2469.4668\n",
      "Epoch [444/1500], Train Loss: 3623.2243, Test Loss: 2750.1009\n",
      "Epoch [445/1500], Train Loss: 3514.1953, Test Loss: 2528.8626\n",
      "Epoch [446/1500], Train Loss: 3393.5041, Test Loss: 2626.1164\n",
      "Epoch [447/1500], Train Loss: 3450.8208, Test Loss: 2553.4351\n",
      "Epoch [448/1500], Train Loss: 3599.5134, Test Loss: 2548.2318\n",
      "Epoch [449/1500], Train Loss: 3821.2427, Test Loss: 2788.1941\n",
      "Epoch [450/1500], Train Loss: 3578.6908, Test Loss: 2625.3082\n",
      "Epoch [451/1500], Train Loss: 3466.2217, Test Loss: 2906.0796\n",
      "Epoch [452/1500], Train Loss: 3772.8139, Test Loss: 2888.4471\n",
      "Epoch [453/1500], Train Loss: 3771.8239, Test Loss: 2615.2886\n",
      "Epoch [454/1500], Train Loss: 3653.5503, Test Loss: 2619.0083\n",
      "Epoch [455/1500], Train Loss: 3322.1173, Test Loss: 2527.5781\n",
      "Epoch [456/1500], Train Loss: 3622.7319, Test Loss: 2544.3225\n",
      "Epoch [457/1500], Train Loss: 3513.0774, Test Loss: 2812.1178\n",
      "Epoch [458/1500], Train Loss: 3583.4570, Test Loss: 2641.1670\n",
      "Epoch [459/1500], Train Loss: 3303.4172, Test Loss: 2475.8629\n",
      "Epoch [460/1500], Train Loss: 3271.7665, Test Loss: 2608.5463\n",
      "Epoch [461/1500], Train Loss: 3455.9269, Test Loss: 2610.7835\n",
      "Epoch [462/1500], Train Loss: 3566.3432, Test Loss: 2568.8157\n",
      "Epoch [463/1500], Train Loss: 3523.4835, Test Loss: 2538.9617\n",
      "Epoch [464/1500], Train Loss: 3452.4060, Test Loss: 2548.7818\n",
      "Epoch [465/1500], Train Loss: 3257.6077, Test Loss: 2761.9079\n",
      "Epoch [466/1500], Train Loss: 3536.1387, Test Loss: 2579.9123\n",
      "Epoch [467/1500], Train Loss: 3414.6707, Test Loss: 2526.5085\n",
      "Epoch [468/1500], Train Loss: 3490.4128, Test Loss: 2697.3893\n",
      "Epoch [469/1500], Train Loss: 3482.6783, Test Loss: 2656.3950\n",
      "Epoch [470/1500], Train Loss: 3199.5706, Test Loss: 2658.7102\n",
      "Epoch [471/1500], Train Loss: 3249.1024, Test Loss: 2430.2078\n",
      "Epoch [472/1500], Train Loss: 3292.5254, Test Loss: 2584.1612\n",
      "Epoch [473/1500], Train Loss: 3252.9289, Test Loss: 2517.3940\n",
      "Epoch [474/1500], Train Loss: 3416.8926, Test Loss: 2673.3280\n",
      "Epoch [475/1500], Train Loss: 3319.5973, Test Loss: 2686.0108\n",
      "Epoch [476/1500], Train Loss: 3243.7633, Test Loss: 2742.9208\n",
      "Epoch [477/1500], Train Loss: 3588.8070, Test Loss: 2533.2120\n",
      "Epoch [478/1500], Train Loss: 3238.9189, Test Loss: 2701.2123\n",
      "Epoch [479/1500], Train Loss: 3377.5664, Test Loss: 2896.0812\n",
      "Epoch [480/1500], Train Loss: 3277.8819, Test Loss: 2696.2865\n",
      "Epoch [481/1500], Train Loss: 3225.4091, Test Loss: 2503.0432\n",
      "Epoch [482/1500], Train Loss: 3202.9894, Test Loss: 2502.4146\n",
      "Epoch [483/1500], Train Loss: 3646.4570, Test Loss: 2540.5405\n",
      "Epoch [484/1500], Train Loss: 3037.6574, Test Loss: 2806.5413\n",
      "Epoch [485/1500], Train Loss: 3026.9605, Test Loss: 2340.5166\n",
      "Epoch [486/1500], Train Loss: 3266.0906, Test Loss: 2784.4106\n",
      "Epoch [487/1500], Train Loss: 3420.4003, Test Loss: 2552.0310\n",
      "Epoch [488/1500], Train Loss: 2820.0999, Test Loss: 2504.5126\n",
      "Epoch [489/1500], Train Loss: 2957.0292, Test Loss: 2496.8692\n",
      "Epoch [490/1500], Train Loss: 2855.8280, Test Loss: 2480.5514\n",
      "Epoch [491/1500], Train Loss: 3016.3642, Test Loss: 2646.0263\n",
      "Epoch [492/1500], Train Loss: 3083.0533, Test Loss: 2456.8916\n",
      "Epoch [493/1500], Train Loss: 2918.4058, Test Loss: 2576.8417\n",
      "Epoch [494/1500], Train Loss: 2937.0665, Test Loss: 2579.8246\n",
      "Epoch [495/1500], Train Loss: 3200.8435, Test Loss: 2465.8626\n",
      "Epoch [496/1500], Train Loss: 2811.8720, Test Loss: 2581.3540\n",
      "Epoch [497/1500], Train Loss: 2983.5121, Test Loss: 2484.2079\n",
      "Epoch [498/1500], Train Loss: 2761.8843, Test Loss: 2512.8681\n",
      "Epoch [499/1500], Train Loss: 3389.7814, Test Loss: 2454.5942\n",
      "Epoch [500/1500], Train Loss: 2811.3596, Test Loss: 2446.3759\n",
      "Epoch [501/1500], Train Loss: 3021.8870, Test Loss: 2383.3638\n",
      "Epoch [502/1500], Train Loss: 2868.8411, Test Loss: 2492.6830\n",
      "Epoch [503/1500], Train Loss: 2890.2094, Test Loss: 2458.9117\n",
      "Epoch [504/1500], Train Loss: 2821.3135, Test Loss: 2641.0751\n",
      "Epoch [505/1500], Train Loss: 2709.3316, Test Loss: 2507.6977\n",
      "Epoch [506/1500], Train Loss: 2768.1006, Test Loss: 2532.3279\n",
      "Epoch [507/1500], Train Loss: 3839.0852, Test Loss: 2460.9194\n",
      "Epoch [508/1500], Train Loss: 2600.6035, Test Loss: 2459.0668\n",
      "Epoch [509/1500], Train Loss: 2790.0110, Test Loss: 2339.1935\n",
      "Epoch [510/1500], Train Loss: 2574.4857, Test Loss: 2633.2125\n",
      "Epoch [511/1500], Train Loss: 2541.3514, Test Loss: 2538.1560\n",
      "Epoch [512/1500], Train Loss: 2549.1505, Test Loss: 2470.8605\n",
      "Epoch [513/1500], Train Loss: 3487.2609, Test Loss: 2540.5751\n",
      "Epoch [514/1500], Train Loss: 2676.0276, Test Loss: 2408.5870\n",
      "Epoch [515/1500], Train Loss: 2791.2485, Test Loss: 2480.8843\n",
      "Epoch [516/1500], Train Loss: 3454.5695, Test Loss: 2563.4515\n",
      "Epoch [517/1500], Train Loss: 2601.2683, Test Loss: 2485.0041\n",
      "Epoch [518/1500], Train Loss: 2751.1546, Test Loss: 2498.3875\n",
      "Epoch [519/1500], Train Loss: 2752.0244, Test Loss: 2375.5162\n",
      "Epoch [520/1500], Train Loss: 2464.1218, Test Loss: 2427.8859\n",
      "Epoch [521/1500], Train Loss: 2544.0168, Test Loss: 2400.2134\n",
      "Epoch [522/1500], Train Loss: 2480.8604, Test Loss: 2350.4531\n",
      "Epoch [523/1500], Train Loss: 2792.7375, Test Loss: 2734.6410\n",
      "Epoch [524/1500], Train Loss: 2563.4762, Test Loss: 2554.0313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [525/1500], Train Loss: 2491.7772, Test Loss: 2426.0690\n",
      "Epoch [526/1500], Train Loss: 2567.0663, Test Loss: 2405.2558\n",
      "Epoch [527/1500], Train Loss: 2658.0154, Test Loss: 2537.5893\n",
      "Epoch [528/1500], Train Loss: 2623.2066, Test Loss: 2544.3265\n",
      "Epoch [529/1500], Train Loss: 2696.6750, Test Loss: 2382.6401\n",
      "Epoch [530/1500], Train Loss: 2554.9767, Test Loss: 2445.8627\n",
      "Epoch [531/1500], Train Loss: 2403.7313, Test Loss: 2368.5315\n",
      "Epoch [532/1500], Train Loss: 2961.6887, Test Loss: 2621.1281\n",
      "Epoch [533/1500], Train Loss: 3559.0238, Test Loss: 2603.1911\n",
      "Epoch [534/1500], Train Loss: 2762.8166, Test Loss: 2311.2664\n",
      "Epoch [535/1500], Train Loss: 2425.3373, Test Loss: 2431.8877\n",
      "Epoch [536/1500], Train Loss: 2645.6332, Test Loss: 2344.5294\n",
      "Epoch [537/1500], Train Loss: 2439.8075, Test Loss: 2395.8152\n",
      "Epoch [538/1500], Train Loss: 2416.7624, Test Loss: 2378.2807\n",
      "Epoch [539/1500], Train Loss: 2299.5060, Test Loss: 2400.8699\n",
      "Epoch [540/1500], Train Loss: 2430.2978, Test Loss: 2299.7822\n",
      "Epoch [541/1500], Train Loss: 2677.8946, Test Loss: 2472.4366\n",
      "Epoch [542/1500], Train Loss: 2497.7342, Test Loss: 2368.3190\n",
      "Epoch [543/1500], Train Loss: 2388.1160, Test Loss: 2505.7426\n",
      "Epoch [544/1500], Train Loss: 2871.1019, Test Loss: 2320.3325\n",
      "Epoch [545/1500], Train Loss: 2756.3450, Test Loss: 2354.1264\n",
      "Epoch [546/1500], Train Loss: 2548.2989, Test Loss: 2352.3152\n",
      "Epoch [547/1500], Train Loss: 2266.3836, Test Loss: 2392.2766\n",
      "Epoch [548/1500], Train Loss: 2106.1937, Test Loss: 2308.7051\n",
      "Epoch [549/1500], Train Loss: 2203.3312, Test Loss: 2347.7546\n",
      "Epoch [550/1500], Train Loss: 23461.0059, Test Loss: 53817.2810\n",
      "Epoch [551/1500], Train Loss: 24565.3536, Test Loss: 2622.3014\n",
      "Epoch [552/1500], Train Loss: 3043.0527, Test Loss: 2369.3466\n",
      "Epoch [553/1500], Train Loss: 2455.4331, Test Loss: 2299.8954\n",
      "Epoch [554/1500], Train Loss: 2252.4392, Test Loss: 2270.8539\n",
      "Epoch [555/1500], Train Loss: 2126.7726, Test Loss: 2322.0602\n",
      "Epoch [556/1500], Train Loss: 2055.0589, Test Loss: 2291.6201\n",
      "Epoch [557/1500], Train Loss: 1975.9592, Test Loss: 2277.1947\n",
      "Epoch [558/1500], Train Loss: 1956.2575, Test Loss: 2285.0171\n",
      "Epoch [559/1500], Train Loss: 1891.6084, Test Loss: 2337.1046\n",
      "Epoch [560/1500], Train Loss: 1956.3782, Test Loss: 2302.4724\n",
      "Epoch [561/1500], Train Loss: 2021.3333, Test Loss: 2406.9161\n",
      "Epoch [562/1500], Train Loss: 1997.3509, Test Loss: 2440.2785\n",
      "Epoch [563/1500], Train Loss: 1979.5045, Test Loss: 2314.7040\n",
      "Epoch [564/1500], Train Loss: 1859.8815, Test Loss: 2315.7819\n",
      "Epoch [565/1500], Train Loss: 1839.6668, Test Loss: 2374.7176\n",
      "Epoch [566/1500], Train Loss: 1868.9156, Test Loss: 2253.0824\n",
      "Epoch [567/1500], Train Loss: 1905.7619, Test Loss: 2276.8624\n",
      "Epoch [568/1500], Train Loss: 1856.1920, Test Loss: 2272.6571\n",
      "Epoch [569/1500], Train Loss: 1916.1272, Test Loss: 2354.2803\n",
      "Epoch [570/1500], Train Loss: 1954.2666, Test Loss: 2357.4781\n",
      "Epoch [571/1500], Train Loss: 1975.1191, Test Loss: 2334.2538\n",
      "Epoch [572/1500], Train Loss: 2012.3777, Test Loss: 2270.8450\n",
      "Epoch [573/1500], Train Loss: 1987.8852, Test Loss: 2384.8393\n",
      "Epoch [574/1500], Train Loss: 1916.0094, Test Loss: 2296.6913\n",
      "Epoch [575/1500], Train Loss: 1987.4269, Test Loss: 2241.5837\n",
      "Epoch [576/1500], Train Loss: 2015.0037, Test Loss: 2381.0796\n",
      "Epoch [577/1500], Train Loss: 2065.8478, Test Loss: 2349.2200\n",
      "Epoch [578/1500], Train Loss: 2044.3172, Test Loss: 2452.0360\n",
      "Epoch [579/1500], Train Loss: 2121.3200, Test Loss: 2371.1398\n",
      "Epoch [580/1500], Train Loss: 1899.1873, Test Loss: 2441.6135\n",
      "Epoch [581/1500], Train Loss: 2004.4679, Test Loss: 2351.8090\n",
      "Epoch [582/1500], Train Loss: 1961.8587, Test Loss: 2569.0437\n",
      "Epoch [583/1500], Train Loss: 1974.7092, Test Loss: 2445.5195\n",
      "Epoch [584/1500], Train Loss: 2267.1945, Test Loss: 2445.2344\n",
      "Epoch [585/1500], Train Loss: 2254.0732, Test Loss: 2498.3219\n",
      "Epoch [586/1500], Train Loss: 2184.7504, Test Loss: 2298.5509\n",
      "Epoch [587/1500], Train Loss: 2762.2610, Test Loss: 2765.9865\n",
      "Epoch [588/1500], Train Loss: 2388.4143, Test Loss: 2445.9043\n",
      "Epoch [589/1500], Train Loss: 2231.3423, Test Loss: 2384.7201\n",
      "Epoch [590/1500], Train Loss: 2041.9537, Test Loss: 2335.1414\n",
      "Epoch [591/1500], Train Loss: 1964.8919, Test Loss: 2339.5655\n",
      "Epoch [592/1500], Train Loss: 2076.8766, Test Loss: 2322.8096\n",
      "Epoch [593/1500], Train Loss: 2225.5177, Test Loss: 2250.4069\n",
      "Epoch [594/1500], Train Loss: 2270.0144, Test Loss: 2386.2208\n",
      "Epoch [595/1500], Train Loss: 2094.6749, Test Loss: 2415.7470\n",
      "Epoch [596/1500], Train Loss: 2340.4431, Test Loss: 2459.2836\n",
      "Epoch [597/1500], Train Loss: 2405.9410, Test Loss: 2514.9890\n",
      "Epoch [598/1500], Train Loss: 2168.2185, Test Loss: 2512.0186\n",
      "Epoch [599/1500], Train Loss: 2128.5785, Test Loss: 2326.3483\n",
      "Epoch [600/1500], Train Loss: 2076.9299, Test Loss: 2464.5444\n",
      "Epoch [601/1500], Train Loss: 2423.6706, Test Loss: 2449.5930\n",
      "Epoch [602/1500], Train Loss: 2127.8105, Test Loss: 2441.9036\n",
      "Epoch [603/1500], Train Loss: 4928.7885, Test Loss: 12167.9588\n",
      "Epoch [604/1500], Train Loss: 3579.7082, Test Loss: 2201.0750\n",
      "Epoch [605/1500], Train Loss: 1848.6169, Test Loss: 2286.0408\n",
      "Epoch [606/1500], Train Loss: 1784.9095, Test Loss: 2404.3195\n",
      "Epoch [607/1500], Train Loss: 1925.7881, Test Loss: 2298.2912\n",
      "Epoch [608/1500], Train Loss: 1976.7703, Test Loss: 2451.4079\n",
      "Epoch [609/1500], Train Loss: 1876.0900, Test Loss: 2348.1847\n",
      "Epoch [610/1500], Train Loss: 1818.2598, Test Loss: 2298.4112\n",
      "Epoch [611/1500], Train Loss: 1853.0943, Test Loss: 2378.2771\n",
      "Epoch [612/1500], Train Loss: 1972.9406, Test Loss: 2415.5019\n",
      "Epoch [613/1500], Train Loss: 2007.1841, Test Loss: 2427.6602\n",
      "Epoch [614/1500], Train Loss: 3458.3074, Test Loss: 2459.5635\n",
      "Epoch [615/1500], Train Loss: 2178.4016, Test Loss: 2424.6969\n",
      "Epoch [616/1500], Train Loss: 1793.1405, Test Loss: 2323.7360\n",
      "Epoch [617/1500], Train Loss: 1981.2792, Test Loss: 2325.6385\n",
      "Epoch [618/1500], Train Loss: 1860.1830, Test Loss: 2301.9593\n",
      "Epoch [619/1500], Train Loss: 2868.9432, Test Loss: 2381.4400\n",
      "Epoch [620/1500], Train Loss: 2244.5179, Test Loss: 2451.9387\n",
      "Epoch [621/1500], Train Loss: 2053.8769, Test Loss: 2339.8208\n",
      "Epoch [622/1500], Train Loss: 1895.0707, Test Loss: 2358.8851\n",
      "Epoch [623/1500], Train Loss: 1812.1569, Test Loss: 2446.2969\n",
      "Epoch [624/1500], Train Loss: 1806.6126, Test Loss: 2415.5490\n",
      "Epoch [625/1500], Train Loss: 1974.7045, Test Loss: 2448.8140\n",
      "Epoch [626/1500], Train Loss: 2142.7055, Test Loss: 2374.9038\n",
      "Epoch [627/1500], Train Loss: 2378.3725, Test Loss: 2588.5121\n",
      "Epoch [628/1500], Train Loss: 57359.9809, Test Loss: 5873.3659\n",
      "Epoch [629/1500], Train Loss: 6580.2281, Test Loss: 2751.3332\n",
      "Epoch [630/1500], Train Loss: 3070.0574, Test Loss: 2484.4561\n",
      "Epoch [631/1500], Train Loss: 2362.6796, Test Loss: 2393.7376\n",
      "Epoch [632/1500], Train Loss: 2065.0850, Test Loss: 2279.7081\n",
      "Epoch [633/1500], Train Loss: 1936.1232, Test Loss: 2294.6467\n",
      "Epoch [634/1500], Train Loss: 1757.4164, Test Loss: 2322.0664\n",
      "Epoch [635/1500], Train Loss: 1725.2809, Test Loss: 2294.4513\n",
      "Epoch [636/1500], Train Loss: 1668.0986, Test Loss: 2414.0846\n",
      "Epoch [637/1500], Train Loss: 1740.8916, Test Loss: 2238.2271\n",
      "Epoch [638/1500], Train Loss: 1598.1645, Test Loss: 2253.2593\n",
      "Epoch [639/1500], Train Loss: 1605.4662, Test Loss: 2285.1780\n",
      "Epoch [640/1500], Train Loss: 1566.9258, Test Loss: 2261.9370\n",
      "Epoch [641/1500], Train Loss: 1599.3805, Test Loss: 2295.7723\n",
      "Epoch [642/1500], Train Loss: 1563.6193, Test Loss: 2325.2844\n",
      "Epoch [643/1500], Train Loss: 1580.3707, Test Loss: 2266.4905\n",
      "Epoch [644/1500], Train Loss: 1547.4628, Test Loss: 2274.3489\n",
      "Epoch [645/1500], Train Loss: 1533.8347, Test Loss: 2212.1659\n",
      "Epoch [646/1500], Train Loss: 1509.2180, Test Loss: 2265.6613\n",
      "Epoch [647/1500], Train Loss: 1676.8250, Test Loss: 2236.5580\n",
      "Epoch [648/1500], Train Loss: 1615.8985, Test Loss: 2295.9741\n",
      "Epoch [649/1500], Train Loss: 1578.8120, Test Loss: 2278.1189\n",
      "Epoch [650/1500], Train Loss: 1545.0771, Test Loss: 2411.4672\n",
      "Epoch [651/1500], Train Loss: 1814.2033, Test Loss: 2246.8625\n",
      "Epoch [652/1500], Train Loss: 1650.4661, Test Loss: 2330.4009\n",
      "Epoch [653/1500], Train Loss: 1689.1976, Test Loss: 2305.8614\n",
      "Epoch [654/1500], Train Loss: 1858.6650, Test Loss: 2352.1716\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m save_path \u001b[38;5;241m=\u001b[39m ModelName \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__Params.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m train_losses, test_losses, is_model_trained \u001b[38;5;241m=\u001b[39m train_or_load_model(model_aq, train_iter, test_iter, num_epochs, save_path)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Finish timing cell run time\u001b[39;00m\n\u001b[1;32m     23\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[8], line 64\u001b[0m, in \u001b[0;36mtrain_or_load_model\u001b[0;34m(model, train_loader, test_loader, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo pretrained model found. Training from scratch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#optimizer = optim.Adam(model.parameters())  \u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m train_losses, test_losses \u001b[38;5;241m=\u001b[39m train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path)\n\u001b[1;32m     65\u001b[0m is_model_trained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Set flag to True after training\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Save losses per epoch\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mtrain_and_save_best_model\u001b[0;34m(model, train_loader, test_loader, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()          \n\u001b[0;32m---> 18\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Instantiate model and train\n",
    "\n",
    "# For timing cell run time\n",
    "start_time = time.time()\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Create model\n",
    "model_aq = Transformer(input_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout)\n",
    "\n",
    "# Move the model to the GPU device\n",
    "model_aq.to(device)\n",
    "\n",
    "# Define the path to save and load the model parameters\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "# Call the function\n",
    "train_losses, test_losses, is_model_trained = train_or_load_model(model_aq, train_iter, test_iter, num_epochs, save_path)\n",
    "\n",
    "\n",
    "# Finish timing cell run time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "if is_model_trained:\n",
    "    np.save(ModelName + \"_ExecutionTime.npy\", execution_time)\n",
    "    print(\"Execution time:\", execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embedding): Linear(in_features=1000, out_features=512, bias=True)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Linear(in_features=23552, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make sure best parameters are being utilized\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Define the path where you saved your model parameters\n",
    "save_path = ModelName + '__Params.pt'\n",
    "\n",
    "# Load the entire dictionary from the saved file\n",
    "checkpoint = torch.load(save_path)\n",
    "\n",
    "# Instantiate the model\n",
    "model_aq = Transformer(input_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout)\n",
    "\n",
    "# Load the model's state dictionary from the loaded dictionary\n",
    "model_aq.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Move the model to the GPU \n",
    "model_aq.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08 0.0\n",
      "0.05 0.0\n",
      "0.01 0.0\n",
      "2.42 2.47\n",
      "21.28 20.93\n",
      "30.99 30.96\n",
      "0.03 0.0\n",
      "-0.18 0.0\n",
      "47.84 48.5\n",
      "-0.09 0.0\n",
      "0.26 0.0\n",
      "26.09 26.29\n",
      "-0.03 0.0\n",
      "-0.05 0.0\n",
      "29.78 29.42\n",
      "0.15 0.0\n",
      "0.01 0.0\n",
      "0.19 0.0\n",
      "29.79 29.66\n",
      "29.56 31.29\n",
      "-0.14 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(21):\n",
    "    print(round(model_aq(X_test[0].unsqueeze(0))[0][i].item(),2), round(y_test[0][i].item(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.46 4.34\n",
      "20.06 20.09\n",
      "42.4 42.47\n",
      "22.93 22.97\n",
      "33.99 33.73\n",
      "24.71 24.55\n",
      "28.75 28.58\n",
      "38.48 38.62\n",
      "37.61 37.86\n",
      "43.9 43.92\n",
      "1.55 1.41\n",
      "44.5 44.67\n",
      "19.59 19.49\n",
      "38.98 39.27\n",
      "43.32 43.49\n",
      "31.85 31.65\n",
      "34.49 34.39\n",
      "18.42 18.26\n",
      "40.26 39.97\n",
      "24.22 24.1\n",
      "28.18 28.3\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(21):\n",
    "    print(round(model_aq(X_test[1].unsqueeze(0))[0][i].item(),2), round(y_test[1][i].item(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9868, 0.9588, 0.8434, 0.9074, 0.8910, 0.7418, 1.0022, 0.9341, 0.8709,\n",
       "         0.9273, 1.0179, 0.9234, 0.9249, 0.8516, 0.9768, 1.0163, 0.8761, 0.9298,\n",
       "         0.8446, 0.9940, 0.9821]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_aq(ValSpectra[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "np.save(ModelName + \"_TrainLoss.npy\", train_losses)\n",
    "np.save(ModelName + \"_TestLoss.npy\", test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1500,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(num_epochs)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, train_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(num_epochs)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, test_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Track the previous minimum test loss and its index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m   2813\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[1;32m   2814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[1;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1500,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot the data\n",
    "plt.plot(np.arange(num_epochs)+1, train_losses, label='Train Loss')\n",
    "plt.plot(np.arange(num_epochs)+1, test_losses, label='Test Loss')\n",
    "\n",
    "# Track the previous minimum test loss and its index\n",
    "prev_min_loss = test_losses[0]\n",
    "prev_min_index = 0\n",
    "\n",
    "# Annotate each local minimum test loss with arrows\n",
    "for idx, loss in enumerate(test_losses[1:], start=1):\n",
    "    if loss < prev_min_loss:\n",
    "        plt.annotate('Min', xy=(idx+1, loss), xytext=(idx+1, loss + 5000),\n",
    "                     arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "        prev_min_loss = loss\n",
    "        prev_min_index = idx\n",
    "        \n",
    "# Add x and y labels\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "\n",
    "# Change axis size\n",
    "plt.rcParams['axes.labelsize'] = 45  # Change label font size\n",
    "\n",
    "# Change tick size\n",
    "plt.tick_params(axis='x', labelsize=30)  # Change tick size for x-axis\n",
    "plt.tick_params(axis='y', labelsize=30)  # Change tick size for y-axis\n",
    "\n",
    "# Plot legend, and display figure\n",
    "plt.legend(fontsize = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Switch to directory for saving model metrics\n",
    "\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelPerformanceMetrics')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16000) must match the size of tensor b (5000) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Test model on testing dataset and deterine RMSE\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model_aq(X_train) \u001b[38;5;66;03m# Evaluate input spectra with MLP\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Move tensors to CPU and convert to numpy arrays\u001b[39;00m\n\u001b[1;32m      6\u001b[0m outputs_cpu \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)  \u001b[38;5;66;03m# (batch_size, num_bins, d_model)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Add positional encoding\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(x)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Transformer Encoder\u001b[39;00m\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (num_bins, batch_size, d_model)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mPositionalEncoding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpe[:x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), :]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16000) must match the size of tensor b (5000) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "## Test model on testing dataset and deterine RMSE\n",
    "\n",
    "outputs = model_aq(X_train) # Evaluate input spectra with MLP\n",
    "\n",
    "# Move tensors to CPU and convert to numpy arrays\n",
    "outputs_cpu = outputs.detach().cpu().numpy()\n",
    "y_train_cpu = y_train.detach().cpu().numpy()\n",
    "\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, y_train_cpu))  # Determine RMSE\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"TrainRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.40 GiB. GPU 0 has a total capacity of 23.65 GiB of which 683.31 MiB is free. Process 167179 has 11.29 GiB memory in use. Including non-PyTorch memory, this process has 11.69 GiB memory in use. Of the allocated memory 10.41 GiB is allocated by PyTorch, and 480.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Test model on testing dataset and deterine RMSE\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model_aq\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# Change to evaluation mode (maybe not needed for this model)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model_aq(X_test) \u001b[38;5;66;03m# Evaluate input spectra with MLP\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Move tensors to CPU and convert to numpy arrays\u001b[39;00m\n\u001b[1;32m      7\u001b[0m outputs_cpu \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Transformer Encoder\u001b[39;00m\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (num_bins, batch_size, d_model)\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder(x)  \u001b[38;5;66;03m# (num_bins, batch_size, d_model)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (batch_size, num_bins, d_model)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Reconstruct original sequence\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:391\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    388\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 391\u001b[0m     output \u001b[38;5;241m=\u001b[39m mod(output, src_mask\u001b[38;5;241m=\u001b[39mmask, is_causal\u001b[38;5;241m=\u001b[39mis_causal, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask_for_layers)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    394\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    714\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal))\n\u001b[0;32m--> 715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:730\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 730\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(x))))\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:1473\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 0 has a total capacity of 23.65 GiB of which 683.31 MiB is free. Process 167179 has 11.29 GiB memory in use. Including non-PyTorch memory, this process has 11.69 GiB memory in use. Of the allocated memory 10.41 GiB is allocated by PyTorch, and 480.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "## Test model on testing dataset and deterine RMSE\n",
    "\n",
    "model_aq.eval() # Change to evaluation mode (maybe not needed for this model)\n",
    "outputs = model_aq(X_test) # Evaluate input spectra with MLP\n",
    "\n",
    "# Move tensors to CPU and convert to numpy arrays\n",
    "outputs_cpu = outputs.detach().cpu().numpy()\n",
    "y_test_cpu = y_test.detach().cpu().numpy()\n",
    "\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, y_test_cpu))  # Determine RMSE\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"TestRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model err:  1.5663064\n"
     ]
    }
   ],
   "source": [
    "## Test model on validation dataset and deterine RMSE\n",
    "\n",
    "model_aq.eval()  # Change to evaluation mode (maybe not needed for this model)\n",
    "outputs = model_aq(spectraVal)  # Evaluate input spectra with MLP\n",
    "\n",
    "# Move tensors to CPU and convert to numpy arrays\n",
    "outputs_cpu = outputs.detach().cpu().numpy()\n",
    "concVal_cpu = concVal.detach().cpu().numpy()\n",
    "\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, concVal_cpu))  # Determine RMSE\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"ValRMSE\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(10):\n",
    "    GroundTruth = ValConc[i]\n",
    "    Prediction = model_aq(ValSpectra[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(21):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[0][metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"ValExamples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"ValExamples_MAPEs.npy\", np.array(MAPEs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.96  -  AllAq1\n",
      "1.4  -  AllAq5\n",
      "0.55  -  AllAq25\n",
      "1.01  -  AllAq50\n",
      "0.88  -  ThreeAddedSinglets\n",
      "3.88  -  ThirtyAddedSinglets\n",
      "86.52  -  ShiftedSpec\n",
      "17.18  -  SineBase\n",
      "137.43  -  HighDynamicRange\n",
      "inf  -  HalfZeros\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(10):\n",
    "    print(round(MAPEs[i].item(), 2), \" - \",ValSpecNames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3524, 47.4996, -1.9481, 45.4296, -3.4012, 46.9226, -0.8601, 46.3289,\n",
       "         -0.9443, 46.4953, -1.2546, 46.8707, -1.7091, 44.9939, -1.4998, 49.1510,\n",
       "         -1.1522, 48.5420, -2.6948, 48.4602, -1.4583]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_aq(ValSpectra[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
