{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import dependencies\n",
    "\n",
    "import numpy as np\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nmrglue as ng\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "# Set default plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (30,20)\n",
    "\n",
    "# Define number of epochs used later in training\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CRNN on dataset of 8 metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name variable used for saving model metrics, name should reflect model used, dataset used, and other information such as # of epochs\n",
    "ModelName = \"CRNN_NonIncremental_8Met\" + str(num_epochs) +\"ep\"\n",
    "\n",
    "# Set the random seed\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelPerformanceMetrics/') \n",
    "seed = 1 \n",
    "torch.manual_seed(seed)\n",
    "np.save(ModelName + \"_Seed.npy\", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training and testing datasets, validation datasets, and representative example spectra \n",
    "\n",
    "# Switch to directory containing datasets\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/GeneratedDataAndVariables')\n",
    "\n",
    "# Load training data and max value from testing and training datasets\n",
    "spectra = np.load('Dataset8_Spec.npy')\n",
    "conc1 = np.load('Dataset8_Conc.npy')\n",
    "\n",
    "# Load validation dataset\n",
    "spectraVal = np.load('Dataset8_Val_Spec.npy')\n",
    "concVal = np.load('Dataset8_Val_Conc.npy')\n",
    "\n",
    "# Load representative validation spectra\n",
    "ValSpectra = np.load(\"Dataset8_RepresentativeExamples_Spectra.npy\")\n",
    "ValConc = np.load(\"Dataset8_RepresentativeExamples_Concentrations.npy\")\n",
    "ValSpecNames = np.load(\"Dataset8_RepresentativeExamples_VariableNames.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU for training.\n"
     ]
    }
   ],
   "source": [
    "## Prepare to switch data from CPU to GPU\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # A CUDA device object\n",
    "    print(\"Using GPU for training.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")           # A CPU object\n",
    "    print(\"CUDA is not available. Using CPU for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up data for testing and training\n",
    "\n",
    "# Split into testing and training data\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(spectra, conc1, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Tensorize and prepare datasets\n",
    "X_train = torch.tensor(X_train1).float()\n",
    "y_train = torch.tensor(y_train1).float()\n",
    "X_test = torch.tensor(X_test1).float()\n",
    "y_test = torch.tensor(y_test1).float()\n",
    "\n",
    "\n",
    "# Move the input data to the GPU device\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "spectraVal = torch.tensor(spectraVal).float().to(device)   # Confusing names, these spectra are the 5000 spectra generated like the training dataset\n",
    "ValSpectra = torch.tensor(ValSpectra).float().to(device)   # Confusing names, these spectra are the 10 representative example spectra\n",
    "\n",
    "# Move the target data to the GPU device\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "concVal = torch.tensor(concVal).float().to(device)\n",
    "ValConc = torch.tensor(ValConc).float().to(device)\n",
    "\n",
    "# More data prep?\n",
    "datasets = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "Test_datasets = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "train_dataset_reshaped = [(data.unsqueeze(1), label) for data, label in datasets]\n",
    "test_dataset_reshaped = [(data.unsqueeze(1), label) for data, label in Test_datasets]\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset_reshaped, batch_size=128, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset_reshaped, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define NN model object, define some parameters, and instantiate model\n",
    "\n",
    "# Define some model & training parameters\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "class NMR_Model_Aq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NMR_Model_Aq, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
    "        self.mp1 = nn.MaxPool1d(3, stride=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=3, padding=1)\n",
    "        self.mp2 = nn.MaxPool1d(3, stride=2)\n",
    "        self.conv3 = nn.Conv1d(32, 32, kernel_size=3, padding=1)\n",
    "        self.mp3 = nn.MaxPool1d(3, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lstm = nn.LSTM(32 * 5749, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, 200)\n",
    "        self.fc2 = nn.Linear(200, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # permute to (batch_size, features, sequence_length)\n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.mp3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        # Reshape for LSTM\n",
    "        x = x.view(x.size(0), 1, -1)  # (batch_size, 1, flattened_features)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]  # Take the output of the last time step\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMR_Model_Aq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NMR_Model_Aq, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
    "        self.mp1 = nn.MaxPool1d(3, stride=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=3, padding=1)\n",
    "        self.mp2 = nn.MaxPool1d(3, stride=2)\n",
    "        self.conv3 = nn.Conv1d(32, 32, kernel_size=3, padding=1)\n",
    "        self.mp3 = nn.MaxPool1d(3, stride=2)\n",
    "        self.lstm = nn.LSTM(32, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, 200)\n",
    "        self.fc2 = nn.Linear(200, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # permute to (batch_size, sequence_length, features)\n",
    "        x = nn.functional.relu(self.mp1(self.conv1(x)))\n",
    "        x = nn.functional.relu(self.mp2(self.conv2(x)))\n",
    "        x = nn.functional.relu(self.mp3(self.conv3(x)))\n",
    "        x = x.permute(0, 2, 1)  # reshape for LSTM: (batch_size, features, sequence_length)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]  # Take the output of the last time step\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMR_Model_Aq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NMR_Model_Aq, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
    "        self.mp1 = nn.MaxPool1d(3, stride=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.mp2 = nn.MaxPool1d(3, stride=2)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.mp3 = nn.MaxPool1d(3, stride=2)\n",
    "        self.gru = nn.GRU(128, 64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, 200)\n",
    "        self.fc2 = nn.Linear(200, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.mp3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = x.permute(0, 2, 1)  # Reshape for GRU: (batch_size, sequence_length, features)\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:, -1, :]  # Take the output of the last time step\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    best_test_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:  # The last number here denotes how often to print loss metrics in terms of epochs\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                  f'Train Loss: {train_loss:.4f}, '\n",
    "                  f'Test Loss: {test_loss:.4f}')\n",
    "            \n",
    "        '''\n",
    "        # Save model at specific epochs\n",
    "        if epoch + 1 in [1000, 10000, 50000]:\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'{save_path}_epoch_{epoch+1}.pt')\n",
    "        '''\n",
    "\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            # Save model when test loss improves\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, save_path)\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "def train_or_load_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    is_model_trained = False  # Initialize flag\n",
    "\n",
    "    if os.path.isfile(save_path):\n",
    "        print(\"Loading pretrained model from {}\".format(save_path))\n",
    "        checkpoint = torch.load(save_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer = optim.Adam(model.parameters())  \n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print(\"No pretrained model found. Training from scratch.\")\n",
    "        #optimizer = optim.Adam(model.parameters())  \n",
    "        train_losses, test_losses = train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path)\n",
    "        is_model_trained = True  # Set flag to True after training\n",
    "        # Save losses per epoch\n",
    "        np.save(ModelName + \"_TrainLoss.npy\", train_losses)\n",
    "        np.save(ModelName + \"_TestLoss.npy\", test_losses)\n",
    "    \n",
    "    return train_losses, test_losses, is_model_trained  # Return the losses and flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrained model found. Training from scratch.\n",
      "Epoch [1/300], Train Loss: 5646645.3164, Test Loss: 1091841.8340\n",
      "Epoch [2/300], Train Loss: 4282539.5820, Test Loss: 1064087.3252\n",
      "Epoch [3/300], Train Loss: 4136648.7598, Test Loss: 1015007.3994\n",
      "Epoch [4/300], Train Loss: 3901510.4004, Test Loss: 948968.1919\n",
      "Epoch [5/300], Train Loss: 3477720.4609, Test Loss: 810045.4653\n",
      "Epoch [6/300], Train Loss: 3063922.8359, Test Loss: 759010.9697\n",
      "Epoch [7/300], Train Loss: 2923595.3145, Test Loss: 730164.3770\n",
      "Epoch [8/300], Train Loss: 2698282.0605, Test Loss: 658161.5181\n",
      "Epoch [9/300], Train Loss: 2546131.2832, Test Loss: 639778.9561\n",
      "Epoch [10/300], Train Loss: 2504713.5586, Test Loss: 638837.4302\n",
      "Epoch [11/300], Train Loss: 2469862.7559, Test Loss: 617498.6060\n",
      "Epoch [12/300], Train Loss: 2310428.5439, Test Loss: 547742.9355\n",
      "Epoch [13/300], Train Loss: 2082294.8193, Test Loss: 514527.9229\n",
      "Epoch [14/300], Train Loss: 1977951.7031, Test Loss: 483053.7922\n",
      "Epoch [15/300], Train Loss: 1763321.0273, Test Loss: 419889.5679\n",
      "Epoch [16/300], Train Loss: 1620968.4551, Test Loss: 409211.2080\n",
      "Epoch [17/300], Train Loss: 1572760.3105, Test Loss: 404145.6934\n",
      "Epoch [18/300], Train Loss: 1543580.5654, Test Loss: 394086.9426\n",
      "Epoch [19/300], Train Loss: 1521739.6953, Test Loss: 387665.0518\n",
      "Epoch [20/300], Train Loss: 1507380.5293, Test Loss: 382407.2334\n",
      "Epoch [21/300], Train Loss: 1485920.1631, Test Loss: 380507.1670\n",
      "Epoch [22/300], Train Loss: 1461897.8662, Test Loss: 368564.6462\n",
      "Epoch [23/300], Train Loss: 1461448.0586, Test Loss: 346439.9395\n",
      "Epoch [24/300], Train Loss: 1218391.0869, Test Loss: 295631.1924\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model and train\n",
    "\n",
    "# For timing cell run time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Create model\n",
    "model_aq = NMR_Model_Aq()\n",
    "\n",
    "# Move the model to the GPU device\n",
    "model_aq.to(device)\n",
    "\n",
    "# Define the path to save and load the model parameters\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "# Call the function\n",
    "train_losses, test_losses, is_model_trained = train_or_load_model(model_aq, train_iter, test_iter, num_epochs, save_path)\n",
    "\n",
    "\n",
    "# Finish timing cell run time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "if is_model_trained:\n",
    "    np.save(ModelName + \"_ExecutionTime.npy\", execution_time)\n",
    "    print(\"Execution time:\", execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "np.save(ModelName + \"_TrainLoss.npy\", train_losses)\n",
    "np.save(ModelName + \"_TestLoss.npy\", test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the data\n",
    "plt.plot(np.arange(num_epochs)+1, train_losses, label='Train Loss')\n",
    "plt.plot(np.arange(num_epochs)+1, test_losses, label='Test Loss')\n",
    "\n",
    "# Track the previous minimum test loss and its index\n",
    "prev_min_loss = test_losses[0]\n",
    "prev_min_index = 0\n",
    "\n",
    "# Annotate each local minimum test loss with arrows\n",
    "for idx, loss in enumerate(test_losses[1:], start=1):\n",
    "    if loss < prev_min_loss:\n",
    "        plt.annotate('Min', xy=(idx+1, loss), xytext=(idx+1, loss + 5000),\n",
    "                     arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "        prev_min_loss = loss\n",
    "        prev_min_index = idx\n",
    "        \n",
    "# Add x and y labels\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "\n",
    "# Change axis size\n",
    "plt.rcParams['axes.labelsize'] = 45  # Change label font size\n",
    "\n",
    "# Change tick size\n",
    "plt.tick_params(axis='x', labelsize=30)  # Change tick size for x-axis\n",
    "plt.tick_params(axis='y', labelsize=30)  # Change tick size for y-axis\n",
    "\n",
    "# Plot legend, and display figure\n",
    "plt.legend(fontsize = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure best parameters are being utilized\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Define the path where you saved your model parameters\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "# Load the entire dictionary from the saved file\n",
    "checkpoint = torch.load(save_path)\n",
    "\n",
    "# Instantiate the model\n",
    "model_aq = NMR_Model_Aq()\n",
    "\n",
    "# Load the model's state dictionary from the loaded dictionary\n",
    "model_aq.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Move the model to the GPU \n",
    "model_aq.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Switch to directory for saving model metrics\n",
    "\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelPerformanceMetrics')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMR_Model_Aq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NMR_Model_Aq, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
    "        self.mp1 = nn.MaxPool1d(3, stride=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.mp2 = nn.MaxPool1d(3, stride=2)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.mp3 = nn.MaxPool1d(3, stride=2)\n",
    "        self.gru = nn.GRU(128, 64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, 200)\n",
    "        self.fc2 = nn.Linear(200, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.mp3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = x.permute(0, 2, 1)  # Reshape for GRU: (batch_size, sequence_length, features)\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:, -1, :]  # Take the output of the last time step\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test model on training dataset and deterine RMSE\n",
    "\n",
    "# Decrease the batch size\n",
    "loader = torch.utils.data.DataLoader(X_train, batch_size=32)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Iterate over the batches in the data loader\n",
    "for batch in loader:\n",
    "    # Move the batch to the GPU if available\n",
    "    batch = batch.to(device)  # Assuming device is defined and indicates GPU\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    outputs = model_aq(batch.unsqueeze(1))  # Assuming your model takes 1D input\n",
    "    \n",
    "    # Move the outputs to CPU and append to the list\n",
    "    all_outputs.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "# Concatenate the outputs from all batches\n",
    "outputs_cpu = np.concatenate(all_outputs)\n",
    "\n",
    "# Compute RMSE\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, y_train.cpu().detach().numpy()))\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"TrainRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Test model on training dataset and deterine RMSE\n",
    "\n",
    "# Decrease the batch size\n",
    "loader = torch.utils.data.DataLoader(X_test, batch_size=32)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Iterate over the batches in the data loader\n",
    "for batch in loader:\n",
    "    # Move the batch to the GPU if available\n",
    "    batch = batch.to(device)  # Assuming device is defined and indicates GPU\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    outputs = model_aq(batch.unsqueeze(1))  # Assuming your model takes 1D input\n",
    "    \n",
    "    # Move the outputs to CPU and append to the list\n",
    "    all_outputs.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "# Concatenate the outputs from all batches\n",
    "outputs_cpu = np.concatenate(all_outputs)\n",
    "\n",
    "# Compute RMSE\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, y_test.cpu().detach().numpy()))\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"TestRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test model on validation dataset and deterine RMSE\n",
    "\n",
    "# Decrease the batch size\n",
    "loader = torch.utils.data.DataLoader(spectraVal, batch_size=32)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Iterate over the batches in the data loader\n",
    "for batch in loader:\n",
    "    # Move the batch to the GPU if available\n",
    "    batch = batch.to(device)  # Assuming device is defined and indicates GPU\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    outputs = model_aq(batch.unsqueeze(1))  # Assuming your model takes 1D input\n",
    "    \n",
    "    # Move the outputs to CPU and append to the list\n",
    "    all_outputs.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "# Concatenate the outputs from all batches\n",
    "outputs_cpu = np.concatenate(all_outputs)\n",
    "\n",
    "# Compute RMSE\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, concVal.cpu().detach().numpy()))\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"ValRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(8):\n",
    "    GroundTruth = ValConc[i]\n",
    "    Prediction = model_aq(ValSpectra[i].unsqueeze(1))\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(8):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[0][metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"ValExamples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"ValExamples_MAPEs.npy\", np.array(MAPEs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN on dataset of 21 metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of epochs used later in training\n",
    "num_epochs = 300\n",
    "\n",
    "# Name variable used for saving model metrics, name should reflect model used, dataset used, and other information such as # of epochs\n",
    "ModelName = \"CNN_NonIncremental_21Met\" + str(num_epochs) +\"ep\"\n",
    "\n",
    "# Set the random seed\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelPerformanceMetrics/') \n",
    "seed = 1 \n",
    "torch.manual_seed(seed)\n",
    "np.save(ModelName + \"_Seed.npy\", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training and testing datasets, validation datasets, and representative example spectra \n",
    "\n",
    "# Switch to directory containing datasets\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/GeneratedDataAndVariables')\n",
    "\n",
    "# Load training data and max value from testing and training datasets\n",
    "spectra = np.load('Dataset21_Spec.npy')\n",
    "conc1 = np.load('Dataset21_Conc.npy')\n",
    "\n",
    "# Load validation dataset\n",
    "spectraVal = np.load('Dataset21_Val_Spec.npy')\n",
    "concVal = np.load('Dataset21_Val_Conc.npy')\n",
    "\n",
    "# Load representative validation spectra\n",
    "ValSpectra = np.load(\"Dataset21_RepresentativeExamples_Spectra.npy\")\n",
    "ValConc = np.load(\"Dataset21_RepresentativeExamples_Concentrations.npy\")\n",
    "ValSpecNames = np.load(\"Dataset21_RepresentativeExamples_VariableNames.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare to switch data from CPU to GPU\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # A CUDA device object\n",
    "    print(\"Using GPU for training.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")           # A CPU object\n",
    "    print(\"CUDA is not available. Using CPU for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up data for testing and training\n",
    "\n",
    "# Split into testing and training data\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(spectra, conc1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Tensorize and prepare datasets\n",
    "X_train = torch.tensor(X_train1).float()\n",
    "y_train = torch.tensor(y_train1).float()\n",
    "X_test = torch.tensor(X_test1).float()\n",
    "y_test = torch.tensor(y_test1).float()\n",
    "\n",
    "\n",
    "# Move the input data to the GPU device\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "spectraVal = torch.tensor(spectraVal).float().to(device)   # Confusing names, these spectra are the 5000 spectra generated like the training dataset\n",
    "ValSpectra = torch.tensor(ValSpectra).float().to(device)   # Confusing names, these spectra are the 10 representative example spectra\n",
    "\n",
    "# Move the target data to the GPU device\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "concVal = torch.tensor(concVal).float().to(device)\n",
    "ValConc = torch.tensor(ValConc).float().to(device)\n",
    "\n",
    "# More data prep?\n",
    "datasets = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "Test_datasets = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "train_dataset_reshaped = [(data.unsqueeze(1), label) for data, label in datasets]\n",
    "test_dataset_reshaped = [(data.unsqueeze(1), label) for data, label in Test_datasets]\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset_reshaped, batch_size=128, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset_reshaped, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMR_Model_Aq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NMR_Model_Aq, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
    "        self.mp1 = nn.MaxPool1d(2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.mp2 = nn.MaxPool1d(2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.mp3 = nn.MaxPool1d(2, stride=2)\n",
    "        self.gru = nn.GRU(128, 64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, 200)\n",
    "        self.fc2 = nn.Linear(200, 21)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.mp3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = x.permute(0, 2, 1)  # Reshape for GRU: (batch_size, sequence_length, features)\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:, -1, :]  # Take the output of the last time step\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    best_test_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:  # The last number here denotes how often to print loss metrics in terms of epochs\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                  f'Train Loss: {train_loss:.4f}, '\n",
    "                  f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "        '''\n",
    "        # Save model at specific epochs\n",
    "        if epoch + 1 in [1000, 10000, 50000]:\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'{save_path}_epoch_{epoch+1}.pt')\n",
    "        '''\n",
    "\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            # Save model when test loss improves\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, save_path)\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "def train_or_load_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    is_model_trained = False  # Initialize flag\n",
    "\n",
    "    if os.path.isfile(save_path):\n",
    "        print(\"Loading pretrained model from {}\".format(save_path))\n",
    "        checkpoint = torch.load(save_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer = optim.Adam(model.parameters())  \n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print(\"No pretrained model found. Training from scratch.\")\n",
    "        #optimizer = optim.Adam(model.parameters())  \n",
    "        train_losses, test_losses = train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path)\n",
    "        is_model_trained = True  # Set flag to True after training\n",
    "        # Save losses per epoch\n",
    "        np.save(ModelName + \"_TrainLoss.npy\", train_losses)\n",
    "        np.save(ModelName + \"_TestLoss.npy\", test_losses)\n",
    "    \n",
    "    return train_losses, test_losses, is_model_trained  # Return the losses and flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate model and train\n",
    "\n",
    "# For timing cell run time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Create model\n",
    "model_aq = NMR_Model_Aq()\n",
    "\n",
    "# Move the model to the GPU device\n",
    "model_aq.to(device)\n",
    "\n",
    "# Define the path to save and load the model parameters\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "# Call the function\n",
    "train_losses, test_losses, is_model_trained = train_or_load_model(model_aq, train_iter, test_iter, num_epochs, save_path)\n",
    "\n",
    "\n",
    "# Finish timing cell run time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "if is_model_trained:\n",
    "    np.save(ModelName + \"_ExecutionTime.npy\", execution_time)\n",
    "    print(\"Execution time:\", execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "np.save(ModelName + \"_TrainLoss.npy\", train_losses)\n",
    "np.save(ModelName + \"_TestLoss.npy\", test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the data\n",
    "plt.plot(np.arange(num_epochs)+1, train_losses, label='Train Loss')\n",
    "plt.plot(np.arange(num_epochs)+1, test_losses, label='Test Loss')\n",
    "\n",
    "# Track the previous minimum test loss and its index\n",
    "prev_min_loss = test_losses[0]\n",
    "prev_min_index = 0\n",
    "\n",
    "# Annotate each local minimum test loss with arrows\n",
    "for idx, loss in enumerate(test_losses[1:], start=1):\n",
    "    if loss < prev_min_loss:\n",
    "        plt.annotate('Min', xy=(idx+1, loss), xytext=(idx+1, loss + 5000),\n",
    "                     arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "        prev_min_loss = loss\n",
    "        prev_min_index = idx\n",
    "        \n",
    "# Add x and y labels\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "\n",
    "# Change axis size\n",
    "plt.rcParams['axes.labelsize'] = 45  # Change label font size\n",
    "\n",
    "# Change tick size\n",
    "plt.tick_params(axis='x', labelsize=30)  # Change tick size for x-axis\n",
    "plt.tick_params(axis='y', labelsize=30)  # Change tick size for y-axis\n",
    "\n",
    "# Plot legend, and display figure\n",
    "plt.legend(fontsize = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure best parameters are being utilized\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Define the path where you saved your model parameters\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "# Load the entire dictionary from the saved file\n",
    "checkpoint = torch.load(save_path)\n",
    "\n",
    "# Instantiate the model\n",
    "model_aq = NMR_Model_Aq()\n",
    "\n",
    "# Load the model's state dictionary from the loaded dictionary\n",
    "model_aq.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Move the model to the GPU \n",
    "model_aq.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Switch to directory for saving model metrics\n",
    "\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelPerformanceMetrics')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMR_Model_Aq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NMR_Model_Aq, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
    "        self.mp1 = nn.MaxPool1d(2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.mp2 = nn.MaxPool1d(2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.mp3 = nn.MaxPool1d(2, stride=2)\n",
    "        self.gru = nn.GRU(128, 64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, 200)\n",
    "        self.fc2 = nn.Linear(200, 21)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.mp3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = x.permute(0, 2, 1)  # Reshape for GRU: (batch_size, sequence_length, features)\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:, -1, :]  # Take the output of the last time step\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test model on training dataset and deterine RMSE\n",
    "\n",
    "# Decrease the batch size\n",
    "loader = torch.utils.data.DataLoader(X_train, batch_size=32)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Iterate over the batches in the data loader\n",
    "for batch in loader:\n",
    "    # Move the batch to the GPU if available\n",
    "    batch = batch.to(device)  # Assuming device is defined and indicates GPU\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    outputs = model_aq(batch.unsqueeze(1))  # Assuming your model takes 1D input\n",
    "    \n",
    "    # Move the outputs to CPU and append to the list\n",
    "    all_outputs.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "# Concatenate the outputs from all batches\n",
    "outputs_cpu = np.concatenate(all_outputs)\n",
    "\n",
    "# Compute RMSE\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, y_train.cpu().detach().numpy()))\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"TrainRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test model on training dataset and deterine RMSE\n",
    "\n",
    "# Decrease the batch size\n",
    "loader = torch.utils.data.DataLoader(X_test, batch_size=32)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Iterate over the batches in the data loader\n",
    "for batch in loader:\n",
    "    # Move the batch to the GPU if available\n",
    "    batch = batch.to(device)  # Assuming device is defined and indicates GPU\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    outputs = model_aq(batch.unsqueeze(1))  # Assuming your model takes 1D input\n",
    "    \n",
    "    # Move the outputs to CPU and append to the list\n",
    "    all_outputs.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "# Concatenate the outputs from all batches\n",
    "outputs_cpu = np.concatenate(all_outputs)\n",
    "\n",
    "# Compute RMSE\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, y_test.cpu().detach().numpy()))\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"TestRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test model on validation dataset and deterine RMSE\n",
    "\n",
    "# Decrease the batch size\n",
    "loader = torch.utils.data.DataLoader(spectraVal, batch_size=32)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Iterate over the batches in the data loader\n",
    "for batch in loader:\n",
    "    # Move the batch to the GPU if available\n",
    "    batch = batch.to(device)  # Assuming device is defined and indicates GPU\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    outputs = model_aq(batch.unsqueeze(1))  # Assuming your model takes 1D input\n",
    "    \n",
    "    # Move the outputs to CPU and append to the list\n",
    "    all_outputs.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "# Concatenate the outputs from all batches\n",
    "outputs_cpu = np.concatenate(all_outputs)\n",
    "\n",
    "# Compute RMSE\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, concVal.cpu().detach().numpy()))\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"ValRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(8):\n",
    "    GroundTruth = ValConc[i]\n",
    "    Prediction = model_aq(ValSpectra[i].unsqueeze(1))\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(21):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[0][metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"ValExamples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"ValExamples_MAPEs.npy\", np.array(MAPEs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN on dataset of 58 metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of epochs used later in training\n",
    "num_epochs = 300\n",
    "\n",
    "# Name variable used for saving model metrics, name should reflect model used, dataset used, and other information such as # of epochs\n",
    "ModelName = \"CNN_NonIncremental_58Met\" + str(num_epochs) +\"ep\"\n",
    "\n",
    "# Set the random seed\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelPerformanceMetrics/') \n",
    "seed = 1 \n",
    "torch.manual_seed(seed)\n",
    "np.save(ModelName + \"_Seed.npy\", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training and testing datasets, validation datasets, and representative example spectra \n",
    "\n",
    "# Switch to directory containing datasets\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/GeneratedDataAndVariables')\n",
    "\n",
    "# Load training data and max value from testing and training datasets\n",
    "spectra = np.load('Dataset58_Spec.npy')\n",
    "conc1 = np.load('Dataset58_Conc.npy')\n",
    "\n",
    "# Load validation dataset\n",
    "spectraVal = np.load('Dataset58_Val_Spec.npy')\n",
    "concVal = np.load('Dataset58_Val_Conc.npy')\n",
    "\n",
    "# Load representative validation spectra\n",
    "ValSpectra = np.load(\"Dataset58_RepresentativeExamples_Spectra.npy\")\n",
    "ValConc = np.load(\"Dataset58_RepresentativeExamples_Concentrations.npy\")\n",
    "ValSpecNames = np.load(\"Dataset58_RepresentativeExamples_VariableNames.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare to switch data from CPU to GPU\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # A CUDA device object\n",
    "    print(\"Using GPU for training.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")           # A CPU object\n",
    "    print(\"CUDA is not available. Using CPU for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up data for testing and training\n",
    "\n",
    "# Split into testing and training data\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(spectra, conc1, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Tensorize and prepare datasets\n",
    "X_train = torch.tensor(X_train1).float()\n",
    "y_train = torch.tensor(y_train1).float()\n",
    "X_test = torch.tensor(X_test1).float()\n",
    "y_test = torch.tensor(y_test1).float()\n",
    "\n",
    "\n",
    "# Move the input data to the GPU device\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "spectraVal = torch.tensor(spectraVal).float().to(device)   # Confusing names, these spectra are the 5000 spectra generated like the training dataset\n",
    "ValSpectra = torch.tensor(ValSpectra).float().to(device)   # Confusing names, these spectra are the 10 representative example spectra\n",
    "\n",
    "# Move the target data to the GPU device\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "concVal = torch.tensor(concVal).float().to(device)\n",
    "ValConc = torch.tensor(ValConc).float().to(device)\n",
    "\n",
    "# More data prep?\n",
    "datasets = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "Test_datasets = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "train_dataset_reshaped = [(data.unsqueeze(1), label) for data, label in datasets]\n",
    "test_dataset_reshaped = [(data.unsqueeze(1), label) for data, label in Test_datasets]\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset_reshaped, batch_size=128, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset_reshaped, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define NN model object, define some parameters, and instantiate model\n",
    "\n",
    "# Define some model & training parameters\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "# Define model\n",
    "class NMR_Model_Aq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NMR_Model_Aq, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
    "        self.mp1 = nn.MaxPool1d(2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.mp2 = nn.MaxPool1d(2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.mp3 = nn.MaxPool1d(2, stride=2)\n",
    "        self.gru = nn.GRU(128, 64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, 200)\n",
    "        self.fc2 = nn.Linear(200, 58)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.mp3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = x.permute(0, 2, 1)  # Reshape for GRU: (batch_size, sequence_length, features)\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:, -1, :]  # Take the output of the last time step\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    best_test_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:  # The last number here denotes how often to print loss metrics in terms of epochs\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                  f'Train Loss: {train_loss:.4f}, '\n",
    "                  f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "        '''\n",
    "        # Save model at specific epochs\n",
    "        if epoch + 1 in [1000, 10000, 50000]:\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'{save_path}_epoch_{epoch+1}.pt')\n",
    "        '''\n",
    "\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            # Save model when test loss improves\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, save_path)\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "def train_or_load_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    is_model_trained = False  # Initialize flag\n",
    "\n",
    "    if os.path.isfile(save_path):\n",
    "        print(\"Loading pretrained model from {}\".format(save_path))\n",
    "        checkpoint = torch.load(save_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer = optim.Adam(model.parameters())  \n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print(\"No pretrained model found. Training from scratch.\")\n",
    "        #optimizer = optim.Adam(model.parameters())  \n",
    "        train_losses, test_losses = train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path)\n",
    "        is_model_trained = True  # Set flag to True after training\n",
    "        # Save losses per epoch\n",
    "        np.save(ModelName + \"_TrainLoss.npy\", train_losses)\n",
    "        np.save(ModelName + \"_TestLoss.npy\", test_losses)\n",
    "    \n",
    "    return train_losses, test_losses, is_model_trained  # Return the losses and flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate model and train\n",
    "\n",
    "# For timing cell run time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Create model\n",
    "model_aq = NMR_Model_Aq()\n",
    "\n",
    "# Move the model to the GPU device\n",
    "model_aq.to(device)\n",
    "\n",
    "# Define the path to save and load the model parameters\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "# Call the function\n",
    "train_losses, test_losses, is_model_trained = train_or_load_model(model_aq, train_iter, test_iter, num_epochs, save_path)\n",
    "\n",
    "\n",
    "# Finish timing cell run time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "if is_model_trained:\n",
    "    np.save(ModelName + \"_ExecutionTime.npy\", execution_time)\n",
    "    print(\"Execution time:\", execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "np.save(ModelName + \"_TrainLoss.npy\", train_losses)\n",
    "np.save(ModelName + \"_TestLoss.npy\", test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the data\n",
    "plt.plot(np.arange(num_epochs)+1, train_losses, label='Train Loss')\n",
    "plt.plot(np.arange(num_epochs)+1, test_losses, label='Test Loss')\n",
    "\n",
    "# Track the previous minimum test loss and its index\n",
    "prev_min_loss = test_losses[0]\n",
    "prev_min_index = 0\n",
    "\n",
    "# Annotate each local minimum test loss with arrows\n",
    "for idx, loss in enumerate(test_losses[1:], start=1):\n",
    "    if loss < prev_min_loss:\n",
    "        plt.annotate('Min', xy=(idx+1, loss), xytext=(idx+1, loss + 5000),\n",
    "                     arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "        prev_min_loss = loss\n",
    "        prev_min_index = idx\n",
    "        \n",
    "# Add x and y labels\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "\n",
    "# Change axis size\n",
    "plt.rcParams['axes.labelsize'] = 45  # Change label font size\n",
    "\n",
    "# Change tick size\n",
    "plt.tick_params(axis='x', labelsize=30)  # Change tick size for x-axis\n",
    "plt.tick_params(axis='y', labelsize=30)  # Change tick size for y-axis\n",
    "\n",
    "# Plot legend, and display figure\n",
    "plt.legend(fontsize = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure best parameters are being utilized\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Define the path where you saved your model parameters\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "# Load the entire dictionary from the saved file\n",
    "checkpoint = torch.load(save_path)\n",
    "\n",
    "# Instantiate the model\n",
    "model_aq = NMR_Model_Aq()\n",
    "\n",
    "# Load the model's state dictionary from the loaded dictionary\n",
    "model_aq.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Move the model to the GPU \n",
    "model_aq.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Switch to directory for saving model metrics\n",
    "\n",
    "os.chdir('/home/htjhnson/Desktop/DL-NMR-Optimization/ModelPerformanceMetrics')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define NN model object, define some parameters, and instantiate model\n",
    "\n",
    "# Define some model & training parameters\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "# Define model\n",
    "class NMR_Model_Aq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NMR_Model_Aq, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
    "        self.mp1 = nn.MaxPool1d(2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.mp2 = nn.MaxPool1d(2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.mp3 = nn.MaxPool1d(2, stride=2)\n",
    "        self.gru = nn.GRU(128, 64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, 200)\n",
    "        self.fc2 = nn.Linear(200, 58)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.mp3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = x.permute(0, 2, 1)  # Reshape for GRU: (batch_size, sequence_length, features)\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:, -1, :]  # Take the output of the last time step\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test model on training dataset and deterine RMSE\n",
    "\n",
    "# Decrease the batch size\n",
    "loader = torch.utils.data.DataLoader(X_train, batch_size=32)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Iterate over the batches in the data loader\n",
    "for batch in loader:\n",
    "    # Move the batch to the GPU if available\n",
    "    batch = batch.to(device)  # Assuming device is defined and indicates GPU\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    outputs = model_aq(batch.unsqueeze(1))  # Assuming your model takes 1D input\n",
    "    \n",
    "    # Move the outputs to CPU and append to the list\n",
    "    all_outputs.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "# Concatenate the outputs from all batches\n",
    "outputs_cpu = np.concatenate(all_outputs)\n",
    "\n",
    "# Compute RMSE\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, y_train.cpu().detach().numpy()))\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"TrainRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test model on training dataset and deterine RMSE\n",
    "\n",
    "# Decrease the batch size\n",
    "loader = torch.utils.data.DataLoader(X_test, batch_size=32)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Iterate over the batches in the data loader\n",
    "for batch in loader:\n",
    "    # Move the batch to the GPU if available\n",
    "    batch = batch.to(device)  # Assuming device is defined and indicates GPU\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    outputs = model_aq(batch.unsqueeze(1))  # Assuming your model takes 1D input\n",
    "    \n",
    "    # Move the outputs to CPU and append to the list\n",
    "    all_outputs.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "# Concatenate the outputs from all batches\n",
    "outputs_cpu = np.concatenate(all_outputs)\n",
    "\n",
    "# Compute RMSE\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, y_test.cpu().detach().numpy()))\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"TestRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test model on validation dataset and deterine RMSE\n",
    "\n",
    "# Decrease the batch size\n",
    "loader = torch.utils.data.DataLoader(spectraVal, batch_size=32)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Iterate over the batches in the data loader\n",
    "for batch in loader:\n",
    "    # Move the batch to the GPU if available\n",
    "    batch = batch.to(device)  # Assuming device is defined and indicates GPU\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    outputs = model_aq(batch.unsqueeze(1))  # Assuming your model takes 1D input\n",
    "    \n",
    "    # Move the outputs to CPU and append to the list\n",
    "    all_outputs.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "# Concatenate the outputs from all batches\n",
    "outputs_cpu = np.concatenate(all_outputs)\n",
    "\n",
    "# Compute RMSE\n",
    "err = np.sqrt(mean_squared_error(outputs_cpu, concVal.cpu().detach().numpy()))\n",
    "print('model err: ', err)  # Print RMSE\n",
    "\n",
    "np.save(ModelName + \"ValRMSE\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(8):\n",
    "    GroundTruth = ValConc[i]\n",
    "    Prediction = model_aq(ValSpectra[i].unsqueeze(1))\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(58):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[0][metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"ValExamples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"ValExamples_MAPEs.npy\", np.array(MAPEs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
