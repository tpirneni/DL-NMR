{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import dependencies\n",
    "\n",
    "import numpy as np\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "# Set default plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (30,20)\n",
    "\n",
    "# Define number of epochs used later in training\n",
    "num_epochs = 5000\n",
    "\n",
    "# Identification part of the filenames\n",
    "model_base_name = '250000spec_RAE_ExtendedRange_MoreLeftOut_Combined1Distribution'\n",
    "base_name = '250000spec_ExtendedRange_MoreLeftOut_Combined1Distribution'    # This is the dataset base name\n",
    "base_dir = '/path/to/base/directory'   # Set base directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP on dataset of 44 metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name variable used for saving model metrics, name should reflect model used, dataset used, and other information such as # of epochs\n",
    "ModelName = f\"MLP_44met_{model_base_name}Dist_TrainingAndValidation_ForManuscript_\" + str(num_epochs) +\"ep\"\n",
    "\n",
    "# Set the random seed\n",
    "os.chdir(base_dir+'/DL-NMR-Optimization/ModelPerformanceMetrics/') \n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.save(ModelName + \"_Seed.npy\", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU for training.\n"
     ]
    }
   ],
   "source": [
    "## Prepare to switch data from CPU to GPU\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # A CUDA device object\n",
    "    print(\"Using GPU for training.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")           # A CPU object\n",
    "    print(\"CUDA is not available. Using CPU for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to directory containing datasets\n",
    "os.chdir(base_dir+'/DL-NMR-Optimization/GeneratedDataAndVariables')\n",
    "\n",
    "# Load training data and max value from testing and training datasets\n",
    "spectra_filename = f'Dataset44_{base_name}_ForManuscript_Spec.dat'\n",
    "conc1_filename = f'Dataset44_{base_name}_ForManuscript_Conc.npy'\n",
    "\n",
    "spectra_shape = (249996, 46000)\n",
    "conc1_shape = (249996, 44)\n",
    "\n",
    "\n",
    "# Load the memmap arrays\n",
    "spectra_memmap = np.memmap(spectra_filename, dtype=np.float64, mode='r', shape=spectra_shape)\n",
    "conc1_memmap = np.load(conc1_filename)\n",
    "\n",
    "# Split into testing and training data\n",
    "X_train_indices, X_test_indices, y_train_indices, y_test_indices = train_test_split(\n",
    "    np.arange(spectra_shape[0]), np.arange(conc1_shape[0]), test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "# Create custom dataset class\n",
    "class NMRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, spectra_memmap, conc1_memmap, indices):\n",
    "        self.spectra_memmap = spectra_memmap\n",
    "        self.conc1_memmap = conc1_memmap\n",
    "        self.indices = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = self.indices[idx]\n",
    "        X = self.spectra_memmap[actual_idx]\n",
    "        y = self.conc1_memmap[actual_idx]\n",
    "        return torch.tensor(X).float().to(device), torch.tensor(y).float().to(device)\n",
    "    \n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NMRDataset(spectra_memmap, conc1_memmap, X_train_indices)\n",
    "test_dataset = NMRDataset(spectra_memmap, conc1_memmap, X_test_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 31  \n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define NN model object, define some parameters, and instantiate model\n",
    "\n",
    "## Best params from Optuna study\n",
    "#{'n_layers': 2, \n",
    "# 'activation': 'LeakyReLU', \n",
    "# 'n_units_l0': 222, \n",
    "# 'n_units_l1': 463, \n",
    "# 'learning_rate': 0.0020767074281295714, \n",
    "# 'reg_strength': 0.009375024340091184, \n",
    "# 'batch_size': 31}\n",
    "\n",
    "# Define some model & training parameters\n",
    "size_hidden1 = 222\n",
    "size_hidden2 = 463\n",
    "size_hidden3 = 44\n",
    "\n",
    "\n",
    "# Define model\n",
    "class NMR_Model_Aq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(46000, size_hidden1)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.lin2 = nn.Linear(size_hidden1, size_hidden2)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.lin3 = nn.Linear(size_hidden2, size_hidden3)\n",
    "    def forward(self, input):\n",
    "        return (self.lin3(self.relu2(self.lin2(self.relu1(self.lin1(input))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeAbsoluteError(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RelativeAbsoluteError, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Compute the mean of the true values\n",
    "        y_mean = torch.mean(y_true)\n",
    "        \n",
    "        # Compute the absolute differences\n",
    "        absolute_errors = torch.abs(y_true - y_pred)\n",
    "        mean_absolute_errors = torch.abs(y_true - y_mean)\n",
    "        \n",
    "        # Compute RAE\n",
    "        rae = torch.sum(absolute_errors) / torch.sum(mean_absolute_errors)\n",
    "        return rae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "def train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    criterion = RelativeAbsoluteError()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr = 0.0020767074281295714, weight_decay=0.009375024340091184)\n",
    "    \n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    best_test_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    patience = 50  # Set how many epochs without improvement in validation loss constitutes early stopping\n",
    "    accumulation_steps = 4\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # For timing cell run time\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        ## Training phase\n",
    "        # Instantiate the GradScaler\n",
    "        scaler = GradScaler()\n",
    "        optimizer.zero_grad()  # Only zero gradients here at the start of an epoch\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            # Move data to GPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Enable autocasting for forward and backward passes\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                # Scale the loss to account for the accumulation steps\n",
    "                loss = loss / accumulation_steps\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            # Scale the loss and perform backpropagation\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                # Step the optimizer and update the scaler\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()  # Zero gradients after accumulation_steps\n",
    "\n",
    "        # Testing phase\n",
    "        train_losses.append(train_loss)\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                # Move data to GPU\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                # Enable autocasting for forward passes\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "            test_losses.append(test_loss)\n",
    "        \n",
    "        \n",
    "            \n",
    "        if (epoch + 1) % 1 == 0:  # The last number here denotes how often to print loss metrics in terms of epochs\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                  f'Train Loss: {train_loss:.4f}, '\n",
    "                  f'Test Loss: {test_loss:.4f}')\n",
    "            \n",
    "    \n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, save_path)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            \n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping at epoch {epoch + 1}')\n",
    "            break\n",
    "        \n",
    "        end = time.time()\n",
    "        print(\"Epoch time: \",end-start)\n",
    "\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "def train_or_load_model(model, train_loader, test_loader, num_epochs, save_path):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    is_model_trained = False  # Initialize flag\n",
    "\n",
    "    if os.path.isfile(save_path):\n",
    "        print(\"Loading pretrained model from {}\".format(save_path))\n",
    "        checkpoint = torch.load(save_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer = optim.Adam(model.parameters())  \n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print(\"No pretrained model found. Training from scratch.\")\n",
    "        #optimizer = optim.Adam(model.parameters())  \n",
    "        train_losses, test_losses = train_and_save_best_model(model, train_loader, test_loader, num_epochs, save_path)\n",
    "        is_model_trained = True  # Set flag to True after training\n",
    "        # Save losses per epoch\n",
    "        np.save(ModelName + \"_TrainLoss.npy\", train_losses)\n",
    "        np.save(ModelName + \"_TestLoss.npy\", test_losses)\n",
    "    \n",
    "    return train_losses, test_losses, is_model_trained  # Return the losses and flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrained model found. Training from scratch.\n",
      "Epoch [1/5000], Train Loss: 11516.6687, Test Loss: 4037.6634\n",
      "Epoch time:  223.10972833633423\n",
      "Epoch [2/5000], Train Loss: 3259.6772, Test Loss: 3216.1201\n",
      "Epoch time:  170.7397062778473\n",
      "Epoch [3/5000], Train Loss: 2766.0713, Test Loss: 2711.2589\n",
      "Epoch time:  166.3904514312744\n",
      "Epoch [4/5000], Train Loss: 2507.5838, Test Loss: 2577.2176\n",
      "Epoch time:  177.09857368469238\n",
      "Epoch [5/5000], Train Loss: 2361.1089, Test Loss: 2115.9185\n",
      "Epoch time:  209.75669312477112\n",
      "Epoch [6/5000], Train Loss: 2244.4105, Test Loss: 2273.9289\n",
      "Epoch time:  198.27857899665833\n",
      "Epoch [7/5000], Train Loss: 2134.4084, Test Loss: 1977.3803\n",
      "Epoch time:  162.95496916770935\n",
      "Epoch [8/5000], Train Loss: 2065.1566, Test Loss: 1968.3775\n",
      "Epoch time:  167.81089067459106\n",
      "Epoch [9/5000], Train Loss: 1991.5512, Test Loss: 1923.8788\n",
      "Epoch time:  171.18137121200562\n",
      "Epoch [10/5000], Train Loss: 1934.7425, Test Loss: 1807.9324\n",
      "Epoch time:  166.04813385009766\n",
      "Epoch [11/5000], Train Loss: 1859.2670, Test Loss: 2008.2412\n",
      "Epoch time:  162.47932720184326\n",
      "Epoch [12/5000], Train Loss: 1792.7376, Test Loss: 1625.5483\n",
      "Epoch time:  173.00515961647034\n",
      "Epoch [13/5000], Train Loss: 1718.7298, Test Loss: 1805.4530\n",
      "Epoch time:  181.7284755706787\n",
      "Epoch [14/5000], Train Loss: 1644.8130, Test Loss: 1742.8560\n",
      "Epoch time:  173.0547685623169\n",
      "Epoch [15/5000], Train Loss: 1595.6532, Test Loss: 1663.2336\n",
      "Epoch time:  180.10407710075378\n",
      "Epoch [16/5000], Train Loss: 1536.4394, Test Loss: 1549.5404\n",
      "Epoch time:  167.05962586402893\n",
      "Epoch [17/5000], Train Loss: 1467.6716, Test Loss: 1253.9854\n",
      "Epoch time:  178.9418089389801\n",
      "Epoch [18/5000], Train Loss: 1420.6399, Test Loss: 1529.2363\n",
      "Epoch time:  167.5078043937683\n",
      "Epoch [19/5000], Train Loss: 1359.7060, Test Loss: 1313.4431\n",
      "Epoch time:  183.1549849510193\n",
      "Epoch [20/5000], Train Loss: 1314.7332, Test Loss: 1222.4247\n",
      "Epoch time:  180.58374118804932\n",
      "Epoch [21/5000], Train Loss: 1263.0296, Test Loss: 1154.8407\n",
      "Epoch time:  166.04158854484558\n",
      "Epoch [22/5000], Train Loss: 1235.2231, Test Loss: 1304.4439\n",
      "Epoch time:  184.52515196800232\n",
      "Epoch [23/5000], Train Loss: 1188.5279, Test Loss: 1120.3813\n",
      "Epoch time:  187.20147252082825\n",
      "Epoch [24/5000], Train Loss: 1177.5130, Test Loss: 1203.2567\n",
      "Epoch time:  183.6500768661499\n",
      "Epoch [25/5000], Train Loss: 1140.9228, Test Loss: 1075.2253\n",
      "Epoch time:  179.0031397342682\n",
      "Epoch [26/5000], Train Loss: 1117.2791, Test Loss: 1068.2039\n",
      "Epoch time:  178.96193170547485\n",
      "Epoch [27/5000], Train Loss: 1114.1265, Test Loss: 1132.1244\n",
      "Epoch time:  180.60641527175903\n",
      "Epoch [28/5000], Train Loss: 1083.5458, Test Loss: 1020.8106\n",
      "Epoch time:  176.82211136817932\n",
      "Epoch [29/5000], Train Loss: 1073.5443, Test Loss: 1248.4913\n",
      "Epoch time:  183.94039297103882\n",
      "Epoch [30/5000], Train Loss: 1066.7409, Test Loss: 1146.0947\n",
      "Epoch time:  196.5523819923401\n",
      "Epoch [31/5000], Train Loss: 1047.1783, Test Loss: 1126.5412\n",
      "Epoch time:  194.08988857269287\n",
      "Epoch [32/5000], Train Loss: 1027.6494, Test Loss: 1284.5427\n",
      "Epoch time:  196.7259979248047\n",
      "Epoch [33/5000], Train Loss: 1020.6917, Test Loss: 1074.7183\n",
      "Epoch time:  181.942129611969\n",
      "Epoch [34/5000], Train Loss: 1001.9516, Test Loss: 980.2254\n",
      "Epoch time:  181.08830738067627\n",
      "Epoch [35/5000], Train Loss: 993.1232, Test Loss: 1096.1868\n",
      "Epoch time:  180.2276861667633\n",
      "Epoch [36/5000], Train Loss: 997.0911, Test Loss: 1075.9725\n",
      "Epoch time:  180.39688634872437\n",
      "Epoch [37/5000], Train Loss: 984.5172, Test Loss: 944.2271\n",
      "Epoch time:  181.4510862827301\n",
      "Epoch [38/5000], Train Loss: 987.8454, Test Loss: 1060.1136\n",
      "Epoch time:  177.87798833847046\n",
      "Epoch [39/5000], Train Loss: 973.2862, Test Loss: 1078.1923\n",
      "Epoch time:  180.05847883224487\n",
      "Epoch [40/5000], Train Loss: 974.2711, Test Loss: 889.5703\n",
      "Epoch time:  181.3529829978943\n",
      "Epoch [41/5000], Train Loss: 967.8430, Test Loss: 1023.7460\n",
      "Epoch time:  180.7035300731659\n",
      "Epoch [42/5000], Train Loss: 955.9777, Test Loss: 867.9853\n",
      "Epoch time:  173.3438699245453\n",
      "Epoch [43/5000], Train Loss: 946.9428, Test Loss: 936.4581\n",
      "Epoch time:  185.43316268920898\n",
      "Epoch [44/5000], Train Loss: 937.0105, Test Loss: 1022.4417\n",
      "Epoch time:  185.041921377182\n",
      "Epoch [45/5000], Train Loss: 944.2986, Test Loss: 918.5225\n",
      "Epoch time:  181.6780128479004\n",
      "Epoch [46/5000], Train Loss: 936.4746, Test Loss: 997.2570\n",
      "Epoch time:  179.43332624435425\n",
      "Epoch [47/5000], Train Loss: 924.5103, Test Loss: 929.4530\n",
      "Epoch time:  173.639794588089\n",
      "Epoch [48/5000], Train Loss: 922.8644, Test Loss: 821.5199\n",
      "Epoch time:  187.88305187225342\n",
      "Epoch [49/5000], Train Loss: 913.8171, Test Loss: 1106.9288\n",
      "Epoch time:  180.47913217544556\n",
      "Epoch [50/5000], Train Loss: 909.3078, Test Loss: 858.4425\n",
      "Epoch time:  170.48340511322021\n",
      "Epoch [51/5000], Train Loss: 906.1049, Test Loss: 936.6833\n",
      "Epoch time:  175.91268467903137\n",
      "Epoch [52/5000], Train Loss: 901.5017, Test Loss: 912.2142\n",
      "Epoch time:  167.99363017082214\n",
      "Epoch [53/5000], Train Loss: 897.8358, Test Loss: 798.5883\n",
      "Epoch time:  166.0248577594757\n",
      "Epoch [54/5000], Train Loss: 890.5568, Test Loss: 965.0752\n",
      "Epoch time:  169.94367241859436\n",
      "Epoch [55/5000], Train Loss: 885.1287, Test Loss: 961.0251\n",
      "Epoch time:  167.91105675697327\n",
      "Epoch [56/5000], Train Loss: 887.5220, Test Loss: 920.9161\n",
      "Epoch time:  171.89760994911194\n",
      "Epoch [57/5000], Train Loss: 883.5167, Test Loss: 844.5555\n",
      "Epoch time:  167.299081325531\n",
      "Epoch [58/5000], Train Loss: 887.1386, Test Loss: 867.7198\n",
      "Epoch time:  170.7802813053131\n",
      "Epoch [59/5000], Train Loss: 874.0305, Test Loss: 852.8478\n",
      "Epoch time:  173.33073115348816\n",
      "Epoch [60/5000], Train Loss: 880.8879, Test Loss: 978.5302\n",
      "Epoch time:  173.2225911617279\n",
      "Epoch [61/5000], Train Loss: 883.7244, Test Loss: 833.0593\n",
      "Epoch time:  172.69597339630127\n",
      "Epoch [62/5000], Train Loss: 867.8099, Test Loss: 960.5228\n",
      "Epoch time:  172.55918312072754\n",
      "Epoch [63/5000], Train Loss: 872.4601, Test Loss: 872.7938\n",
      "Epoch time:  174.53393054008484\n",
      "Epoch [64/5000], Train Loss: 865.7576, Test Loss: 934.6638\n",
      "Epoch time:  181.61005210876465\n",
      "Epoch [65/5000], Train Loss: 848.5847, Test Loss: 745.4429\n",
      "Epoch time:  182.3518579006195\n",
      "Epoch [66/5000], Train Loss: 867.3850, Test Loss: 872.9688\n",
      "Epoch time:  178.32109212875366\n",
      "Epoch [67/5000], Train Loss: 861.7708, Test Loss: 935.7885\n",
      "Epoch time:  182.86164093017578\n",
      "Epoch [68/5000], Train Loss: 852.6975, Test Loss: 784.4946\n",
      "Epoch time:  183.06035256385803\n",
      "Epoch [69/5000], Train Loss: 855.2130, Test Loss: 826.8960\n",
      "Epoch time:  182.90664792060852\n",
      "Epoch [70/5000], Train Loss: 860.5292, Test Loss: 842.2383\n",
      "Epoch time:  183.0677490234375\n",
      "Epoch [71/5000], Train Loss: 851.6011, Test Loss: 868.5842\n",
      "Epoch time:  175.6139223575592\n",
      "Epoch [72/5000], Train Loss: 854.7879, Test Loss: 858.6839\n",
      "Epoch time:  168.18682980537415\n",
      "Epoch [73/5000], Train Loss: 850.7167, Test Loss: 857.8251\n",
      "Epoch time:  172.6025629043579\n",
      "Epoch [74/5000], Train Loss: 845.2476, Test Loss: 986.2601\n",
      "Epoch time:  182.14826440811157\n",
      "Epoch [75/5000], Train Loss: 843.9839, Test Loss: 827.1597\n",
      "Epoch time:  180.68450474739075\n",
      "Epoch [76/5000], Train Loss: 849.8748, Test Loss: 787.4204\n",
      "Epoch time:  176.79491710662842\n",
      "Epoch [77/5000], Train Loss: 840.9994, Test Loss: 830.0388\n",
      "Epoch time:  174.8170142173767\n",
      "Epoch [78/5000], Train Loss: 840.3917, Test Loss: 842.2243\n",
      "Epoch time:  175.41576075553894\n",
      "Epoch [79/5000], Train Loss: 838.6069, Test Loss: 799.8040\n",
      "Epoch time:  177.11352109909058\n",
      "Epoch [80/5000], Train Loss: 841.3598, Test Loss: 877.2992\n",
      "Epoch time:  185.5236496925354\n",
      "Epoch [81/5000], Train Loss: 837.7928, Test Loss: 929.8668\n",
      "Epoch time:  185.77372574806213\n",
      "Epoch [82/5000], Train Loss: 839.3086, Test Loss: 892.6979\n",
      "Epoch time:  167.26674890518188\n",
      "Epoch [83/5000], Train Loss: 844.5233, Test Loss: 747.3919\n",
      "Epoch time:  173.74404215812683\n",
      "Epoch [84/5000], Train Loss: 841.1792, Test Loss: 811.6112\n",
      "Epoch time:  173.79766297340393\n",
      "Epoch [85/5000], Train Loss: 830.3462, Test Loss: 769.9378\n",
      "Epoch time:  172.90707969665527\n",
      "Epoch [86/5000], Train Loss: 826.1998, Test Loss: 869.1204\n",
      "Epoch time:  165.0390830039978\n",
      "Epoch [87/5000], Train Loss: 831.5119, Test Loss: 889.5130\n",
      "Epoch time:  166.59814167022705\n",
      "Epoch [88/5000], Train Loss: 829.5689, Test Loss: 847.5183\n",
      "Epoch time:  166.94479775428772\n",
      "Epoch [89/5000], Train Loss: 830.5405, Test Loss: 895.5573\n",
      "Epoch time:  166.70722913742065\n",
      "Epoch [90/5000], Train Loss: 826.3146, Test Loss: 867.7783\n",
      "Epoch time:  176.311429977417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/5000], Train Loss: 824.5839, Test Loss: 933.9243\n",
      "Epoch time:  175.2348370552063\n",
      "Epoch [92/5000], Train Loss: 822.6803, Test Loss: 819.2042\n",
      "Epoch time:  176.30536365509033\n",
      "Epoch [93/5000], Train Loss: 816.4808, Test Loss: 890.4544\n",
      "Epoch time:  173.83223581314087\n",
      "Epoch [94/5000], Train Loss: 817.7363, Test Loss: 816.1177\n",
      "Epoch time:  167.5193293094635\n",
      "Epoch [95/5000], Train Loss: 820.0556, Test Loss: 815.6736\n",
      "Epoch time:  176.86424326896667\n",
      "Epoch [96/5000], Train Loss: 818.1094, Test Loss: 840.6561\n",
      "Epoch time:  178.41001963615417\n",
      "Epoch [97/5000], Train Loss: 812.9357, Test Loss: 820.4762\n",
      "Epoch time:  176.42156386375427\n",
      "Epoch [98/5000], Train Loss: 815.8033, Test Loss: 866.3016\n",
      "Epoch time:  182.04646682739258\n",
      "Epoch [99/5000], Train Loss: 810.2148, Test Loss: 902.5154\n",
      "Epoch time:  185.43391919136047\n",
      "Epoch [100/5000], Train Loss: 808.8743, Test Loss: 761.8294\n",
      "Epoch time:  181.29930973052979\n",
      "Epoch [101/5000], Train Loss: 816.0692, Test Loss: 742.3271\n",
      "Epoch time:  185.882639169693\n",
      "Epoch [102/5000], Train Loss: 807.4390, Test Loss: 827.5495\n",
      "Epoch time:  190.77528047561646\n",
      "Epoch [103/5000], Train Loss: 802.3762, Test Loss: 777.7467\n",
      "Epoch time:  179.84063339233398\n",
      "Epoch [104/5000], Train Loss: 806.2337, Test Loss: 782.1479\n",
      "Epoch time:  171.45326113700867\n",
      "Epoch [105/5000], Train Loss: 805.5029, Test Loss: 859.5405\n",
      "Epoch time:  180.6357078552246\n",
      "Epoch [106/5000], Train Loss: 803.3878, Test Loss: 894.8761\n",
      "Epoch time:  173.35855317115784\n",
      "Epoch [107/5000], Train Loss: 803.1587, Test Loss: 801.0898\n",
      "Epoch time:  164.62668204307556\n",
      "Epoch [108/5000], Train Loss: 800.1203, Test Loss: 763.6138\n",
      "Epoch time:  167.31171536445618\n",
      "Epoch [109/5000], Train Loss: 795.1468, Test Loss: 838.3831\n",
      "Epoch time:  162.01738214492798\n",
      "Epoch [110/5000], Train Loss: 801.2698, Test Loss: 846.9603\n",
      "Epoch time:  158.88516855239868\n",
      "Epoch [111/5000], Train Loss: 802.4658, Test Loss: 844.4114\n",
      "Epoch time:  158.64169239997864\n",
      "Epoch [112/5000], Train Loss: 799.5212, Test Loss: 752.4975\n",
      "Epoch time:  161.17810344696045\n",
      "Epoch [113/5000], Train Loss: 802.7348, Test Loss: 866.9763\n",
      "Epoch time:  151.38235545158386\n",
      "Epoch [114/5000], Train Loss: 798.0039, Test Loss: 817.1719\n",
      "Epoch time:  158.4976930618286\n",
      "Epoch [115/5000], Train Loss: 800.6794, Test Loss: 802.6002\n",
      "Epoch time:  155.85885071754456\n",
      "Epoch [116/5000], Train Loss: 790.3538, Test Loss: 763.2606\n",
      "Epoch time:  155.772718667984\n",
      "Epoch [117/5000], Train Loss: 795.1190, Test Loss: 777.7225\n",
      "Epoch time:  156.41196584701538\n",
      "Epoch [118/5000], Train Loss: 798.0701, Test Loss: 710.2749\n",
      "Epoch time:  156.76023411750793\n",
      "Epoch [119/5000], Train Loss: 801.0818, Test Loss: 816.1420\n",
      "Epoch time:  186.4490134716034\n",
      "Epoch [120/5000], Train Loss: 792.7909, Test Loss: 797.8580\n",
      "Epoch time:  183.69428062438965\n",
      "Epoch [121/5000], Train Loss: 788.8683, Test Loss: 713.1434\n",
      "Epoch time:  180.07833790779114\n",
      "Epoch [122/5000], Train Loss: 791.2195, Test Loss: 793.3998\n",
      "Epoch time:  169.51202774047852\n",
      "Epoch [123/5000], Train Loss: 793.6966, Test Loss: 751.6343\n",
      "Epoch time:  162.95007991790771\n",
      "Epoch [124/5000], Train Loss: 791.7986, Test Loss: 799.3315\n",
      "Epoch time:  161.41298532485962\n",
      "Epoch [125/5000], Train Loss: 787.6096, Test Loss: 849.3729\n",
      "Epoch time:  159.5342152118683\n",
      "Epoch [126/5000], Train Loss: 785.8438, Test Loss: 740.8101\n",
      "Epoch time:  161.31877732276917\n",
      "Epoch [127/5000], Train Loss: 783.2282, Test Loss: 780.8020\n",
      "Epoch time:  152.1947419643402\n",
      "Epoch [128/5000], Train Loss: 781.4200, Test Loss: 855.6201\n",
      "Epoch time:  166.59276914596558\n",
      "Epoch [129/5000], Train Loss: 787.1863, Test Loss: 764.8466\n",
      "Epoch time:  165.99081015586853\n",
      "Epoch [130/5000], Train Loss: 782.5516, Test Loss: 786.4643\n",
      "Epoch time:  165.84113764762878\n",
      "Epoch [131/5000], Train Loss: 787.4782, Test Loss: 732.1082\n",
      "Epoch time:  165.7769651412964\n",
      "Epoch [132/5000], Train Loss: 791.8047, Test Loss: 819.8813\n",
      "Epoch time:  163.20889234542847\n",
      "Epoch [133/5000], Train Loss: 781.0167, Test Loss: 797.5839\n",
      "Epoch time:  162.26768612861633\n",
      "Epoch [134/5000], Train Loss: 781.2976, Test Loss: 760.3721\n",
      "Epoch time:  182.44271683692932\n",
      "Epoch [135/5000], Train Loss: 785.3976, Test Loss: 732.0751\n",
      "Epoch time:  192.0252652168274\n",
      "Epoch [136/5000], Train Loss: 781.2391, Test Loss: 786.4899\n",
      "Epoch time:  187.4964165687561\n",
      "Epoch [137/5000], Train Loss: 780.6315, Test Loss: 820.5164\n",
      "Epoch time:  187.3905782699585\n",
      "Epoch [138/5000], Train Loss: 785.8506, Test Loss: 847.7571\n",
      "Epoch time:  183.4551236629486\n",
      "Epoch [139/5000], Train Loss: 774.7905, Test Loss: 752.4750\n",
      "Epoch time:  186.29750800132751\n",
      "Epoch [140/5000], Train Loss: 782.9936, Test Loss: 760.7157\n",
      "Epoch time:  181.7375133037567\n",
      "Epoch [141/5000], Train Loss: 778.2536, Test Loss: 759.3554\n",
      "Epoch time:  188.06546568870544\n",
      "Epoch [142/5000], Train Loss: 773.8745, Test Loss: 821.4759\n",
      "Epoch time:  185.59290599822998\n",
      "Epoch [143/5000], Train Loss: 783.2816, Test Loss: 705.2393\n",
      "Epoch time:  174.07767057418823\n",
      "Epoch [144/5000], Train Loss: 767.5074, Test Loss: 718.9525\n",
      "Epoch time:  191.97491765022278\n",
      "Epoch [145/5000], Train Loss: 768.4910, Test Loss: 795.0818\n",
      "Epoch time:  185.88838601112366\n",
      "Epoch [146/5000], Train Loss: 779.8036, Test Loss: 857.1201\n",
      "Epoch time:  173.0424518585205\n",
      "Epoch [147/5000], Train Loss: 775.5020, Test Loss: 817.4453\n",
      "Epoch time:  171.19741582870483\n",
      "Epoch [148/5000], Train Loss: 774.0225, Test Loss: 792.3473\n",
      "Epoch time:  153.5308108329773\n",
      "Epoch [149/5000], Train Loss: 769.8571, Test Loss: 720.4156\n",
      "Epoch time:  157.46860694885254\n",
      "Epoch [150/5000], Train Loss: 770.3089, Test Loss: 719.0001\n",
      "Epoch time:  163.76967000961304\n",
      "Epoch [151/5000], Train Loss: 770.5048, Test Loss: 976.4458\n",
      "Epoch time:  176.87018728256226\n",
      "Epoch [152/5000], Train Loss: 769.2681, Test Loss: 731.2206\n",
      "Epoch time:  163.90658688545227\n",
      "Epoch [153/5000], Train Loss: 768.9421, Test Loss: 774.3395\n",
      "Epoch time:  170.19784140586853\n",
      "Epoch [154/5000], Train Loss: 774.7067, Test Loss: 793.4268\n",
      "Epoch time:  174.18106746673584\n",
      "Epoch [155/5000], Train Loss: 761.7869, Test Loss: 858.0544\n",
      "Epoch time:  162.4026837348938\n",
      "Epoch [156/5000], Train Loss: 765.6989, Test Loss: 839.7425\n",
      "Epoch time:  161.74448132514954\n",
      "Epoch [157/5000], Train Loss: 766.8833, Test Loss: 772.6085\n",
      "Epoch time:  158.64771938323975\n",
      "Epoch [158/5000], Train Loss: 762.7940, Test Loss: 777.6746\n",
      "Epoch time:  157.45166158676147\n",
      "Epoch [159/5000], Train Loss: 765.0049, Test Loss: 723.2369\n",
      "Epoch time:  170.48547863960266\n",
      "Epoch [160/5000], Train Loss: 760.8733, Test Loss: 825.9548\n",
      "Epoch time:  181.16118049621582\n",
      "Epoch [161/5000], Train Loss: 766.6727, Test Loss: 784.5879\n",
      "Epoch time:  184.6360993385315\n",
      "Epoch [162/5000], Train Loss: 765.7343, Test Loss: 796.3561\n",
      "Epoch time:  170.52717280387878\n",
      "Epoch [163/5000], Train Loss: 765.4340, Test Loss: 816.2029\n",
      "Epoch time:  162.07356142997742\n",
      "Epoch [164/5000], Train Loss: 757.4905, Test Loss: 736.7348\n",
      "Epoch time:  161.42600631713867\n",
      "Epoch [165/5000], Train Loss: 764.5182, Test Loss: 871.4710\n",
      "Epoch time:  175.75946164131165\n",
      "Epoch [166/5000], Train Loss: 766.3577, Test Loss: 760.0533\n",
      "Epoch time:  176.70185160636902\n",
      "Epoch [167/5000], Train Loss: 756.2057, Test Loss: 834.8525\n",
      "Epoch time:  155.20058822631836\n",
      "Epoch [168/5000], Train Loss: 765.4491, Test Loss: 764.5197\n",
      "Epoch time:  145.71575903892517\n",
      "Epoch [169/5000], Train Loss: 758.2878, Test Loss: 761.2641\n",
      "Epoch time:  140.65557980537415\n",
      "Epoch [170/5000], Train Loss: 764.6064, Test Loss: 784.5221\n",
      "Epoch time:  162.10901832580566\n",
      "Epoch [171/5000], Train Loss: 753.2137, Test Loss: 766.6444\n",
      "Epoch time:  197.28633904457092\n",
      "Epoch [172/5000], Train Loss: 757.6073, Test Loss: 718.1861\n",
      "Epoch time:  293.2332227230072\n",
      "Epoch [173/5000], Train Loss: 755.2580, Test Loss: 701.9135\n",
      "Epoch time:  367.2892076969147\n",
      "Epoch [174/5000], Train Loss: 756.6515, Test Loss: 823.5284\n",
      "Epoch time:  395.83725786209106\n",
      "Epoch [175/5000], Train Loss: 755.5005, Test Loss: 736.8825\n",
      "Epoch time:  319.4706702232361\n",
      "Epoch [176/5000], Train Loss: 754.8937, Test Loss: 797.9426\n",
      "Epoch time:  301.6849718093872\n",
      "Epoch [177/5000], Train Loss: 760.6946, Test Loss: 756.3876\n",
      "Epoch time:  432.62479877471924\n",
      "Epoch [178/5000], Train Loss: 760.3416, Test Loss: 740.3846\n",
      "Epoch time:  326.75918221473694\n",
      "Epoch [179/5000], Train Loss: 752.6668, Test Loss: 803.6130\n",
      "Epoch time:  333.7388288974762\n",
      "Epoch [180/5000], Train Loss: 750.4516, Test Loss: 753.2343\n",
      "Epoch time:  420.24464440345764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/5000], Train Loss: 758.7914, Test Loss: 736.8599\n",
      "Epoch time:  438.6508238315582\n",
      "Epoch [182/5000], Train Loss: 754.9236, Test Loss: 836.8962\n",
      "Epoch time:  358.46552419662476\n",
      "Epoch [183/5000], Train Loss: 754.6211, Test Loss: 811.0079\n",
      "Epoch time:  412.30845618247986\n",
      "Epoch [184/5000], Train Loss: 754.9699, Test Loss: 801.9124\n",
      "Epoch time:  402.5807511806488\n",
      "Epoch [185/5000], Train Loss: 746.7775, Test Loss: 774.1996\n",
      "Epoch time:  424.13858103752136\n",
      "Epoch [186/5000], Train Loss: 755.8948, Test Loss: 819.3602\n",
      "Epoch time:  343.75032687187195\n",
      "Epoch [187/5000], Train Loss: 756.1132, Test Loss: 743.5790\n",
      "Epoch time:  342.78903222084045\n",
      "Epoch [188/5000], Train Loss: 759.5023, Test Loss: 773.5578\n",
      "Epoch time:  304.6649055480957\n",
      "Epoch [189/5000], Train Loss: 750.0417, Test Loss: 719.4764\n",
      "Epoch time:  360.3053934574127\n",
      "Epoch [190/5000], Train Loss: 753.7913, Test Loss: 660.9130\n",
      "Epoch time:  335.82216238975525\n",
      "Epoch [191/5000], Train Loss: 756.0675, Test Loss: 719.4111\n",
      "Epoch time:  400.6293275356293\n",
      "Epoch [192/5000], Train Loss: 749.1579, Test Loss: 789.0960\n",
      "Epoch time:  354.2647297382355\n",
      "Epoch [193/5000], Train Loss: 751.5022, Test Loss: 793.9133\n",
      "Epoch time:  362.16977882385254\n",
      "Epoch [194/5000], Train Loss: 758.4185, Test Loss: 774.0118\n",
      "Epoch time:  365.8927912712097\n",
      "Epoch [195/5000], Train Loss: 753.3706, Test Loss: 707.2266\n",
      "Epoch time:  355.28536581993103\n",
      "Epoch [196/5000], Train Loss: 761.8943, Test Loss: 768.8339\n",
      "Epoch time:  374.24531149864197\n",
      "Epoch [197/5000], Train Loss: 750.0864, Test Loss: 746.3457\n",
      "Epoch time:  387.10160398483276\n",
      "Epoch [198/5000], Train Loss: 752.3891, Test Loss: 826.6626\n",
      "Epoch time:  343.4869830608368\n",
      "Epoch [199/5000], Train Loss: 753.0035, Test Loss: 788.6157\n",
      "Epoch time:  370.88048243522644\n",
      "Epoch [200/5000], Train Loss: 754.0864, Test Loss: 785.1850\n",
      "Epoch time:  376.0080201625824\n",
      "Epoch [201/5000], Train Loss: 756.7412, Test Loss: 811.9948\n",
      "Epoch time:  320.7805223464966\n",
      "Epoch [202/5000], Train Loss: 760.9882, Test Loss: 771.3592\n",
      "Epoch time:  199.75136518478394\n",
      "Epoch [203/5000], Train Loss: 740.8536, Test Loss: 710.9317\n",
      "Epoch time:  165.38395047187805\n",
      "Epoch [204/5000], Train Loss: 744.7388, Test Loss: 745.5166\n",
      "Epoch time:  161.32118463516235\n",
      "Epoch [205/5000], Train Loss: 750.6189, Test Loss: 741.1702\n",
      "Epoch time:  166.92321753501892\n",
      "Epoch [206/5000], Train Loss: 754.2571, Test Loss: 716.6802\n",
      "Epoch time:  165.4176595211029\n",
      "Epoch [207/5000], Train Loss: 747.4395, Test Loss: 792.6257\n",
      "Epoch time:  167.14865589141846\n",
      "Epoch [208/5000], Train Loss: 746.3006, Test Loss: 804.0654\n",
      "Epoch time:  166.94350624084473\n",
      "Epoch [209/5000], Train Loss: 751.5881, Test Loss: 729.5690\n",
      "Epoch time:  164.54588413238525\n",
      "Epoch [210/5000], Train Loss: 753.2468, Test Loss: 875.1635\n",
      "Epoch time:  167.24707746505737\n",
      "Epoch [211/5000], Train Loss: 756.0849, Test Loss: 724.9161\n",
      "Epoch time:  166.7932415008545\n",
      "Epoch [212/5000], Train Loss: 744.8559, Test Loss: 826.9667\n",
      "Epoch time:  163.93618607521057\n",
      "Epoch [213/5000], Train Loss: 749.5745, Test Loss: 783.4419\n",
      "Epoch time:  167.11117148399353\n",
      "Epoch [214/5000], Train Loss: 749.5346, Test Loss: 757.0098\n",
      "Epoch time:  164.93304538726807\n",
      "Epoch [215/5000], Train Loss: 749.8340, Test Loss: 764.7032\n",
      "Epoch time:  141.2974820137024\n",
      "Epoch [216/5000], Train Loss: 746.6934, Test Loss: 757.7496\n",
      "Epoch time:  60.94235444068909\n",
      "Epoch [217/5000], Train Loss: 737.0489, Test Loss: 725.4589\n",
      "Epoch time:  60.88741731643677\n",
      "Epoch [218/5000], Train Loss: 752.4392, Test Loss: 651.4581\n",
      "Epoch time:  61.761857748031616\n",
      "Epoch [219/5000], Train Loss: 747.2489, Test Loss: 795.7452\n",
      "Epoch time:  61.0266318321228\n",
      "Epoch [220/5000], Train Loss: 750.3999, Test Loss: 835.4263\n",
      "Epoch time:  60.98202586174011\n",
      "Epoch [221/5000], Train Loss: 751.8098, Test Loss: 717.0198\n",
      "Epoch time:  60.87024688720703\n",
      "Epoch [222/5000], Train Loss: 758.2030, Test Loss: 786.5292\n",
      "Epoch time:  60.94893288612366\n",
      "Epoch [223/5000], Train Loss: 744.8879, Test Loss: 684.9219\n",
      "Epoch time:  60.88695573806763\n",
      "Epoch [224/5000], Train Loss: 744.2363, Test Loss: 768.8897\n",
      "Epoch time:  60.90263223648071\n",
      "Epoch [225/5000], Train Loss: 744.2848, Test Loss: 853.4988\n",
      "Epoch time:  60.91274571418762\n",
      "Epoch [226/5000], Train Loss: 750.3778, Test Loss: 699.2177\n",
      "Epoch time:  61.2947199344635\n",
      "Epoch [227/5000], Train Loss: 740.1135, Test Loss: 787.3773\n",
      "Epoch time:  61.32519507408142\n",
      "Epoch [228/5000], Train Loss: 745.1514, Test Loss: 741.1291\n",
      "Epoch time:  61.1336395740509\n",
      "Epoch [229/5000], Train Loss: 739.3124, Test Loss: 761.5000\n",
      "Epoch time:  61.090818881988525\n",
      "Epoch [230/5000], Train Loss: 751.6740, Test Loss: 759.1383\n",
      "Epoch time:  61.09804105758667\n",
      "Epoch [231/5000], Train Loss: 740.4485, Test Loss: 754.3023\n",
      "Epoch time:  61.16983222961426\n",
      "Epoch [232/5000], Train Loss: 749.1437, Test Loss: 764.2052\n",
      "Epoch time:  61.12830901145935\n",
      "Epoch [233/5000], Train Loss: 748.8283, Test Loss: 759.9028\n",
      "Epoch time:  61.096759557724\n",
      "Epoch [234/5000], Train Loss: 745.6996, Test Loss: 819.3220\n",
      "Epoch time:  61.13885951042175\n",
      "Epoch [235/5000], Train Loss: 745.5143, Test Loss: 757.1083\n",
      "Epoch time:  61.17519545555115\n",
      "Epoch [236/5000], Train Loss: 737.3925, Test Loss: 802.1430\n",
      "Epoch time:  61.169769048690796\n",
      "Epoch [237/5000], Train Loss: 742.3121, Test Loss: 716.0416\n",
      "Epoch time:  61.13060784339905\n",
      "Epoch [238/5000], Train Loss: 747.6406, Test Loss: 742.5696\n",
      "Epoch time:  61.02990198135376\n",
      "Epoch [239/5000], Train Loss: 741.7148, Test Loss: 813.3177\n",
      "Epoch time:  60.97350811958313\n",
      "Epoch [240/5000], Train Loss: 743.0652, Test Loss: 755.1283\n",
      "Epoch time:  60.86145734786987\n",
      "Epoch [241/5000], Train Loss: 749.7725, Test Loss: 744.2348\n",
      "Epoch time:  60.890318155288696\n",
      "Epoch [242/5000], Train Loss: 738.0201, Test Loss: 673.7416\n",
      "Epoch time:  60.84490132331848\n",
      "Epoch [243/5000], Train Loss: 742.9287, Test Loss: 743.0308\n",
      "Epoch time:  60.824342489242554\n",
      "Epoch [244/5000], Train Loss: 746.6483, Test Loss: 749.5797\n",
      "Epoch time:  60.93075108528137\n",
      "Epoch [245/5000], Train Loss: 742.3350, Test Loss: 652.1352\n",
      "Epoch time:  60.88779854774475\n",
      "Epoch [246/5000], Train Loss: 737.9781, Test Loss: 780.7569\n",
      "Epoch time:  60.8677933216095\n",
      "Epoch [247/5000], Train Loss: 745.2334, Test Loss: 714.0151\n",
      "Epoch time:  60.897382736206055\n",
      "Epoch [248/5000], Train Loss: 741.1178, Test Loss: 713.0883\n",
      "Epoch time:  60.86436152458191\n",
      "Epoch [249/5000], Train Loss: 743.8659, Test Loss: 786.3688\n",
      "Epoch time:  60.85240864753723\n",
      "Epoch [250/5000], Train Loss: 742.6316, Test Loss: 737.7068\n",
      "Epoch time:  60.828840494155884\n",
      "Epoch [251/5000], Train Loss: 741.3721, Test Loss: 829.8364\n",
      "Epoch time:  61.177929162979126\n",
      "Epoch [252/5000], Train Loss: 737.4676, Test Loss: 708.5656\n",
      "Epoch time:  61.219056606292725\n",
      "Epoch [253/5000], Train Loss: 743.6479, Test Loss: 768.2790\n",
      "Epoch time:  61.20962166786194\n",
      "Epoch [254/5000], Train Loss: 738.8986, Test Loss: 843.9226\n",
      "Epoch time:  60.89651298522949\n",
      "Epoch [255/5000], Train Loss: 742.5381, Test Loss: 789.8639\n",
      "Epoch time:  60.73962473869324\n",
      "Epoch [256/5000], Train Loss: 746.5313, Test Loss: 817.3461\n",
      "Epoch time:  60.766897439956665\n",
      "Epoch [257/5000], Train Loss: 735.5133, Test Loss: 815.0774\n",
      "Epoch time:  60.74119591712952\n",
      "Epoch [258/5000], Train Loss: 737.1628, Test Loss: 668.5443\n",
      "Epoch time:  61.1530818939209\n",
      "Epoch [259/5000], Train Loss: 737.8483, Test Loss: 770.4140\n",
      "Epoch time:  61.29188561439514\n",
      "Epoch [260/5000], Train Loss: 737.7369, Test Loss: 761.7071\n",
      "Epoch time:  61.34075450897217\n",
      "Epoch [261/5000], Train Loss: 741.5647, Test Loss: 729.5777\n",
      "Epoch time:  60.99139928817749\n",
      "Epoch [262/5000], Train Loss: 739.1878, Test Loss: 823.3866\n",
      "Epoch time:  60.927600383758545\n",
      "Epoch [263/5000], Train Loss: 740.7515, Test Loss: 798.0847\n",
      "Epoch time:  60.91019415855408\n",
      "Epoch [264/5000], Train Loss: 733.7292, Test Loss: 781.6543\n",
      "Epoch time:  60.91436958312988\n",
      "Epoch [265/5000], Train Loss: 742.2041, Test Loss: 744.2355\n",
      "Epoch time:  60.888686180114746\n",
      "Epoch [266/5000], Train Loss: 734.3251, Test Loss: 769.5452\n",
      "Epoch time:  60.91381883621216\n",
      "Epoch [267/5000], Train Loss: 740.4041, Test Loss: 671.6836\n",
      "Epoch time:  60.921448707580566\n",
      "Epoch [268/5000], Train Loss: 734.2256, Test Loss: 789.0728\n",
      "Early stopping at epoch 268\n",
      "Execution time: 46305.593807697296 seconds\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model and train\n",
    "\n",
    "# For timing cell run time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir(base_dir+'/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Create model\n",
    "model_aq = NMR_Model_Aq()\n",
    "\n",
    "# Move the model to the GPU device\n",
    "model_aq.to(device)\n",
    "\n",
    "# Define the path to save and load the model parameters\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "# Call the function\n",
    "train_losses, test_losses, is_model_trained = train_or_load_model(model_aq, train_iter, test_iter, num_epochs, save_path)\n",
    "\n",
    "\n",
    "# Finish timing cell run time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "if is_model_trained:\n",
    "    np.save(ModelName + \"_ExecutionTime.npy\", execution_time)\n",
    "    print(\"Execution time:\", execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651.4580658078194"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_losses).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training and testing datasets, validation datasets, and representative example spectra \n",
    "\n",
    "# Switch to directory containing datasets\n",
    "os.chdir(base_dir+'/DL-NMR-Optimization/GeneratedDataAndVariables')\n",
    "\n",
    "# Load validation dataset\n",
    "spectraVal = np.load(f'Dataset44_{base_name}_ForManuscript_Val_Spec.npy')\n",
    "concVal = np.load(f'Dataset44_{base_name}_ForManuscript_Val_Conc.npy')\n",
    "\n",
    "\n",
    "\n",
    "# Load representative validation spectra and concentrations\n",
    "# Load spectra of varied concentrations (all metabolites at X-mM from 0.005mm to 20mM)\n",
    "ConcSpec = np.load(f'Concentration_44met_{base_name}_ForManuscript_Spec.npy')\n",
    "ConcConc = np.load(f'Concentration_44met_{base_name}_ForManuscript_Conc.npy')  \n",
    "#  Load uniform concentration distribution validation spectra\n",
    "UniformSpec = np.load(f'UniformDist_44met_{base_name}_ForManuscript_Spec.npy')\n",
    "UniformConc = np.load(f'UniformDist_44met_{base_name}_ForManuscript_Conc.npy')  \n",
    "#  Load low concentration uniform concentration distribution validation spectra\n",
    "LowUniformSpec = np.load(f'LowUniformDist_44met_{base_name}_ForManuscript_Spec.npy')\n",
    "LowUniformConc = np.load(f'LowUniformDist_44met_{base_name}_ForManuscript_Conc.npy')\n",
    "#  Load tissue mimicking concentration distribution validation spectra\n",
    "MimicTissueRangeSpec = np.load(f'MimicTissueRange_44met_{base_name}_ForManuscript_Spec.npy')\n",
    "MimicTissueRangeConc = np.load(f'MimicTissueRange_44met_{base_name}_ForManuscript_Conc.npy')\n",
    "#  Load liver tissue mimicking concentration distribution (high relative glucose) validation spectra\n",
    "MimicTissueRangeGlucSpec = np.load(f'MimicTissueRangeGluc_44met_{base_name}_ForManuscript_Spec.npy')\n",
    "MimicTissueRangeGlucConc = np.load(f'MimicTissueRangeGluc_44met_{base_name}_ForManuscript_Conc.npy')\n",
    "#  Load high dynamic range #2 validation spectra\n",
    "HighDynamicRange2Spec = np.load(f'HighDynRange2_44met_{base_name}_ForManuscript_Spec.npy')\n",
    "HighDynamicRange2Conc = np.load(f'HighDynRange2_44met_{base_name}_ForManuscript_Conc.npy') \n",
    "#  Load varied SNR validation spectra\n",
    "SNR_Spec = np.load(f'SNR_44met_{base_name}_ForManuscript_Spec.npy')\n",
    "SNR_Conc = np.load(f'SNR_44met_{base_name}_ForManuscript_Conc.npy')\n",
    "#  Load random singlet validation spectra\n",
    "Singlet_Spec = np.load(f'Singlet_44met_{base_name}_ForManuscript_Spec.npy')\n",
    "Singlet_Conc = np.load(f'Singlet_44met_{base_name}_ForManuscript_Conc.npy')\n",
    "#  Load random qref checker validation spectra\n",
    "QrefSensSpec = np.load(f'QrefSensitivity_44met_{base_name}_ForManuscript_Spec.npy')\n",
    "QrefSensConc = np.load(f'QrefSensitivity_44met_{base_name}_ForManuscript_Conc.npy')\n",
    "#  Load other validation spectra\n",
    "OtherValSpectra = np.load(f'OtherVal_44met_{base_name}_ForManuscript_Spec.npy')\n",
    "OtherValConc = np.load(f'OtherVal_44met_{base_name}_ForManuscript_Conc.npy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Move the input data to the GPU device\n",
    "spectraVal = torch.tensor(spectraVal).float().to(device)   \n",
    "concVal = torch.tensor(concVal).float().to(device)\n",
    "ConcSpec = torch.tensor(ConcSpec).float().to(device)   \n",
    "ConcConc = torch.tensor(ConcConc).float().to(device)\n",
    "UniformSpec = torch.tensor(UniformSpec).float().to(device)   \n",
    "UniformConc = torch.tensor(UniformConc).float().to(device)\n",
    "LowUniformSpec = torch.tensor(LowUniformSpec).float().to(device)   \n",
    "LowUniformConc = torch.tensor(LowUniformConc).float().to(device)\n",
    "MimicTissueRangeSpec = torch.tensor(MimicTissueRangeSpec).float().to(device)   \n",
    "MimicTissueRangeConc = torch.tensor(MimicTissueRangeConc).float().to(device)\n",
    "MimicTissueRangeGlucSpec = torch.tensor(MimicTissueRangeGlucSpec).float().to(device)   \n",
    "MimicTissueRangeGlucConc = torch.tensor(MimicTissueRangeGlucConc).float().to(device)\n",
    "HighDynamicRange2Spec = torch.tensor(HighDynamicRange2Spec).float().to(device)   \n",
    "HighDynamicRange2Conc = torch.tensor(HighDynamicRange2Conc).float().to(device)\n",
    "SNR_Spec = torch.tensor(SNR_Spec).float().to(device)   \n",
    "SNR_Conc = torch.tensor(SNR_Conc).float().to(device)\n",
    "Singlet_Spec = torch.tensor(Singlet_Spec).float().to(device)   \n",
    "Singlet_Conc = torch.tensor(Singlet_Conc).float().to(device)\n",
    "QrefSensSpec = torch.tensor(QrefSensSpec).float().to(device)   \n",
    "QrefSensConc = torch.tensor(QrefSensConc).float().to(device)\n",
    "OtherValSpectra = torch.tensor(OtherValSpectra).float().to(device)   \n",
    "OtherValConc = torch.tensor(OtherValConc).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMR_Model_Aq(\n",
       "  (lin1): Linear(in_features=46000, out_features=222, bias=True)\n",
       "  (relu1): LeakyReLU(negative_slope=0.01)\n",
       "  (lin2): Linear(in_features=222, out_features=463, bias=True)\n",
       "  (relu2): LeakyReLU(negative_slope=0.01)\n",
       "  (lin3): Linear(in_features=463, out_features=44, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make sure best parameters are being utilized\n",
    "\n",
    "# Switch to directory for saving model parameters\n",
    "os.chdir(base_dir+'/DL-NMR-Optimization/SavedParamsAndTrainingMetrics')\n",
    "\n",
    "# Define the path where you saved your model parameters\n",
    "save_path = ModelName + '_Params.pt'\n",
    "\n",
    "# Load the entire dictionary from the saved file\n",
    "checkpoint = torch.load(save_path)\n",
    "\n",
    "# Instantiate the model\n",
    "model_aq = NMR_Model_Aq()\n",
    "\n",
    "# Load the model's state dictionary from the loaded dictionary\n",
    "model_aq.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Move the model to the GPU \n",
    "model_aq.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MAPE:  47.288815\n"
     ]
    }
   ],
   "source": [
    "## Compute absolute percent error statistics on validation set\n",
    "\n",
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(5000):\n",
    "    GroundTruth = concVal[i]\n",
    "    model_aq.eval()\n",
    "    Prediction = model_aq(spectraVal[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(44):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"ValExamples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"ValExamples_MAPEs.npy\", np.array(MAPEs))\n",
    "\n",
    "\n",
    "\n",
    "print('Overall MAPE: ',np.array(MAPEs).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MAPE:  inf\n",
      "--------------------\n",
      "inf  - Concentrations: 0.0\n",
      "73.89  - Concentrations: 0.004999999888241291\n",
      "15.99  - Concentrations: 0.02500000037252903\n",
      "3.64  - Concentrations: 0.10000000149011612\n",
      "1.92  - Concentrations: 0.25\n",
      "1.55  - Concentrations: 0.5\n",
      "1.4  - Concentrations: 1.0\n",
      "1.39  - Concentrations: 2.5\n",
      "1.37  - Concentrations: 10.0\n",
      "1.37  - Concentrations: 20.0\n"
     ]
    }
   ],
   "source": [
    "## Compute absolute percent error statistics on concentration varied validation spectra\n",
    "\n",
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(10):\n",
    "    GroundTruth = ConcConc[i]\n",
    "    model_aq.eval()\n",
    "    Prediction = model_aq(ConcSpec[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(44):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[0][metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"ConcExamples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"ConcExamples_MAPEs.npy\", np.array(MAPEs))\n",
    "\n",
    "\n",
    "\n",
    "## Output metrics\n",
    "print('Overall MAPE: ',np.array(MAPEs).mean())\n",
    "print(\"--------------------\")\n",
    "for i in np.arange(10):\n",
    "    print(round(MAPEs[i].item(), 2), \" - Concentrations:\",ConcConc[i][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MAPE:  6.5706606\n",
      "--------------------\n",
      "4.01  - Min Value: 0.6783  - Mean Value: 9.2\n",
      "32.31  - Min Value: 0.0096  - Mean Value: 10.3\n",
      "2.68  - Min Value: 0.147  - Mean Value: 10.5\n",
      "4.36  - Min Value: 0.5572  - Mean Value: 8.5\n",
      "2.71  - Min Value: 1.3567  - Mean Value: 10.6\n",
      "3.75  - Min Value: 0.6332  - Mean Value: 10.9\n",
      "3.16  - Min Value: 0.7017  - Mean Value: 11.0\n",
      "7.3  - Min Value: 0.3674  - Mean Value: 8.9\n",
      "2.76  - Min Value: 0.8387  - Mean Value: 9.8\n",
      "2.65  - Min Value: 1.0913  - Mean Value: 11.1\n"
     ]
    }
   ],
   "source": [
    "## Compute absolute percent error statistics on uniform distribution validation spectra\n",
    "\n",
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(10):\n",
    "    GroundTruth = UniformConc[i]\n",
    "    model_aq.eval()\n",
    "    Prediction = model_aq(UniformSpec[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(44):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[0][metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"UniformExamples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"UniformExamples_MAPEs.npy\", np.array(MAPEs))\n",
    "\n",
    "\n",
    "\n",
    "## Output metrics\n",
    "print('Overall MAPE: ',np.array(MAPEs).mean())\n",
    "print(\"--------------------\")\n",
    "for i in np.arange(10):\n",
    "    print(round(MAPEs[i].item(), 2), \" - Min Value:\", np.round(UniformConc[i].min().item(),4), \" - Mean Value:\", np.round(UniformConc[i].mean().item(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MAPE:  5.2225294\n",
      "--------------------\n",
      "4.44  - Min Value: 0.0111  - Mean Value: 0.1\n",
      "4.85  - Min Value: 0.0103  - Mean Value: 0.1\n",
      "5.25  - Min Value: 0.0153  - Mean Value: 0.1\n",
      "5.94  - Min Value: 0.0117  - Mean Value: 0.1\n",
      "6.31  - Min Value: 0.0089  - Mean Value: 0.1\n",
      "6.38  - Min Value: 0.0075  - Mean Value: 0.1\n",
      "5.59  - Min Value: 0.0117  - Mean Value: 0.1\n",
      "4.97  - Min Value: 0.0052  - Mean Value: 0.1\n",
      "4.36  - Min Value: 0.008  - Mean Value: 0.1\n",
      "4.13  - Min Value: 0.0134  - Mean Value: 0.1\n"
     ]
    }
   ],
   "source": [
    "## Compute absolute percent error statistics on low concentration uniform distribution validation spectra\n",
    "\n",
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(10):\n",
    "    GroundTruth = LowUniformConc[i]\n",
    "    model_aq.eval()\n",
    "    Prediction = model_aq(LowUniformSpec[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(44):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[0][metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"LowUniformExamples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"LowUniformExamples_MAPEs.npy\", np.array(MAPEs))\n",
    "\n",
    "\n",
    "\n",
    "## Output metrics\n",
    "print('Overall MAPE: ',np.array(MAPEs).mean())\n",
    "print(\"--------------------\")\n",
    "for i in np.arange(10):\n",
    "    print(round(MAPEs[i].item(), 2), \" - Min Value:\", np.round(LowUniformConc[i].min().item(),4), \" - Mean Value:\", np.round(LowUniformConc[i].mean().item(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MAPE:  15.648836\n",
      "--------------------\n",
      "25.22  - Min Value: 0.0137  - Mean Value: 1.5\n",
      "18.16  - Min Value: 0.0231  - Mean Value: 0.9\n",
      "10.28  - Min Value: 0.006  - Mean Value: 0.5\n",
      "14.98  - Min Value: 0.0167  - Mean Value: 0.9\n",
      "13.64  - Min Value: 0.0104  - Mean Value: 0.6\n",
      "10.81  - Min Value: 0.0116  - Mean Value: 0.4\n",
      "10.77  - Min Value: 0.0194  - Mean Value: 0.9\n",
      "28.32  - Min Value: 0.0058  - Mean Value: 0.8\n",
      "11.8  - Min Value: 0.0123  - Mean Value: 0.9\n",
      "12.52  - Min Value: 0.0118  - Mean Value: 0.5\n"
     ]
    }
   ],
   "source": [
    "## Compute absolute percent error statistics on tissue mimicking distribution validation spectra\n",
    "\n",
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(10):\n",
    "    GroundTruth = MimicTissueRangeConc[i]\n",
    "    model_aq.eval()\n",
    "    Prediction = model_aq(MimicTissueRangeSpec[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(44):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[0][metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"MimicTissueRangeExamples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"MimicTissueRangeExamples_MAPEs.npy\", np.array(MAPEs))\n",
    "\n",
    "\n",
    "\n",
    "## Output metrics\n",
    "print('Overall MAPE: ',np.array(MAPEs).mean())\n",
    "print(\"--------------------\")\n",
    "for i in np.arange(10):\n",
    "    print(round(MAPEs[i].item(), 2), \" - Min Value:\", np.round(MimicTissueRangeConc[i].min().item(),4), \" - Mean Value:\", np.round(MimicTissueRangeConc[i].mean().item(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MAPE:  17.143198\n",
      "--------------------\n",
      "24.16  - Min Value: 0.0139  - Mean Value: 0.9\n",
      "13.75  - Min Value: 0.0139  - Mean Value: 0.7\n",
      "13.71  - Min Value: 0.0139  - Mean Value: 0.6\n",
      "14.99  - Min Value: 0.0139  - Mean Value: 1.1\n",
      "33.92  - Min Value: 0.0139  - Mean Value: 1.0\n",
      "18.39  - Min Value: 0.0139  - Mean Value: 0.9\n",
      "14.19  - Min Value: 0.0139  - Mean Value: 0.5\n",
      "11.56  - Min Value: 0.0139  - Mean Value: 0.7\n",
      "17.82  - Min Value: 0.0139  - Mean Value: 0.7\n",
      "8.94  - Min Value: 0.0139  - Mean Value: 0.5\n"
     ]
    }
   ],
   "source": [
    "## Compute absolute percent error statistics on tissue mimicking distribution validation spectra (high relative glucose concentration)\n",
    "\n",
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(10):\n",
    "    GroundTruth = MimicTissueRangeGlucConc[i]\n",
    "    model_aq.eval()\n",
    "    Prediction = model_aq(MimicTissueRangeGlucSpec[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(44):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[0][metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"MimicTissueRangeGlucExamples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"MimicTissueRangeGlucExamples_MAPEs.npy\", np.array(MAPEs))\n",
    "\n",
    "\n",
    "\n",
    "## Output metrics\n",
    "print('Overall MAPE: ',np.array(MAPEs).mean())\n",
    "print(\"--------------------\")\n",
    "for i in np.arange(10):\n",
    "    print(round(MAPEs[i].item(), 2), \" - Min Value:\", np.round(MimicTissueRangeGlucConc[i].min().item(),4), \" - Mean Value:\", np.round(MimicTissueRangeGlucConc[i].mean().item(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MAPE:  93.535446\n",
      "--------------------\n",
      "105.28  - Min Value: 0.0139  - Mean Value: 0.9\n",
      "117.92  - Min Value: 0.0139  - Mean Value: 0.7\n",
      "70.55  - Min Value: 0.0139  - Mean Value: 0.6\n",
      "71.95  - Min Value: 0.0139  - Mean Value: 1.1\n",
      "111.26  - Min Value: 0.0139  - Mean Value: 1.0\n",
      "52.34  - Min Value: 0.0139  - Mean Value: 0.9\n",
      "45.47  - Min Value: 0.0139  - Mean Value: 0.5\n",
      "179.0  - Min Value: 0.0139  - Mean Value: 0.7\n",
      "65.92  - Min Value: 0.0139  - Mean Value: 0.7\n",
      "115.66  - Min Value: 0.0139  - Mean Value: 0.5\n"
     ]
    }
   ],
   "source": [
    "## Compute absolute percent error statistics on a further high dynamic range dataset\n",
    "\n",
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(10):\n",
    "    GroundTruth = HighDynamicRange2Conc[i]\n",
    "    model_aq.eval()\n",
    "    Prediction = model_aq(HighDynamicRange2Spec[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(44):\n",
    "        per_err = 100*(GroundTruth[metabolite] - Prediction_cpu[0][metabolite]) / GroundTruth[metabolite]\n",
    "        APE.append(abs(per_err.cpu()))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"HighDynamicRange2Examples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"HighDynamicRange2Examples_MAPEs.npy\", np.array(MAPEs))\n",
    "\n",
    "\n",
    "\n",
    "## Output metrics\n",
    "print('Overall MAPE: ',np.array(MAPEs).mean())\n",
    "print(\"--------------------\")\n",
    "for i in np.arange(10):\n",
    "    print(round(MAPEs[i].item(), 2), \" - Min Value:\", np.round(MimicTissueRangeGlucConc[i].min().item(),4), \" - Mean Value:\", np.round(MimicTissueRangeGlucConc[i].mean().item(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x53500 and 46000x222)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m GroundTruth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.43\u001b[39m\n\u001b[1;32m      8\u001b[0m model_aq\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 9\u001b[0m Prediction \u001b[38;5;241m=\u001b[39m model_aq(SNR_Spec[i])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Move Prediction tensor to CPU and detach from computation graph\u001b[39;00m\n\u001b[1;32m     12\u001b[0m Prediction_cpu \u001b[38;5;241m=\u001b[39m Prediction\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36mNMR_Model_Aq.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(\u001b[38;5;28minput\u001b[39m))))))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x53500 and 46000x222)"
     ]
    }
   ],
   "source": [
    "## Compute absolute percent error statistics on a examples of varying SNR\n",
    "\n",
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(10):\n",
    "    GroundTruth = 0.43\n",
    "    model_aq.eval()\n",
    "    Prediction = model_aq(SNR_Spec[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(44):\n",
    "        per_err = 100*(GroundTruth - Prediction_cpu[0][metabolite]) / GroundTruth\n",
    "        APE.append(abs(per_err))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"SNR_Examples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"SNR_Examples_MAPEs.npy\", np.array(MAPEs))\n",
    "\n",
    "\n",
    "\n",
    "## Output metrics\n",
    "print('Overall MAPE: ',np.array(MAPEs).mean())\n",
    "print(\"--------------------\")\n",
    "for i in np.arange(10):\n",
    "    print(round(MAPEs[i].item(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute absolute percent error statistics on a examples of varying SNR\n",
    "\n",
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(10):\n",
    "    GroundTruth = 0.43\n",
    "    model_aq.eval()\n",
    "    Prediction = model_aq(Singlet_Spec[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(44):\n",
    "        per_err = 100*(GroundTruth - Prediction_cpu[0][metabolite]) / GroundTruth\n",
    "        APE.append(abs(per_err))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"Singlet_Examples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"Singlet_Examples_MAPEs.npy\", np.array(MAPEs))\n",
    "\n",
    "\n",
    "\n",
    "## Output metrics\n",
    "print('Overall MAPE: ',np.array(MAPEs).mean())\n",
    "print(\"--------------------\")\n",
    "for i in np.arange(10):\n",
    "    print(round(MAPEs[i].item(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute absolute percent error statistics on a examples of varying SNR\n",
    "\n",
    "APEs = []\n",
    "MAPEs = []\n",
    "\n",
    "for i in np.arange(10):\n",
    "    GroundTruth = 0.43\n",
    "    model_aq.eval()\n",
    "    Prediction = model_aq(QrefSensSpec[i])\n",
    "\n",
    "    # Move Prediction tensor to CPU and detach from computation graph\n",
    "    Prediction_cpu = Prediction.detach().cpu().numpy()\n",
    "\n",
    "    APE = []\n",
    "\n",
    "    for metabolite in range(44):\n",
    "        per_err = 100*(GroundTruth - Prediction_cpu[0][metabolite]) / GroundTruth\n",
    "        APE.append(abs(per_err))\n",
    "\n",
    "    MAPE = sum(APE) / len(APE)\n",
    "\n",
    "    APEs.append(APE)\n",
    "    MAPEs.append(MAPE)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays and save\n",
    "np.save(ModelName + \"_\" + \"QrefSensitivity_Examples_APEs.npy\", np.array(APEs))\n",
    "np.save(ModelName + \"_\" + \"QrefSensitivity_Examples_MAPEs.npy\", np.array(MAPEs))\n",
    "\n",
    "\n",
    "\n",
    "## Output metrics\n",
    "print('Overall MAPE: ',np.array(MAPEs).mean())\n",
    "print(\"--------------------\")\n",
    "for i in np.arange(10):\n",
    "    print(round(MAPEs[i].item(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = model_aq(OtherValSpectra[0])\n",
    "Pred[0][Pred[0] < 0] = 0\n",
    "print(\"Sinusoidal Baseline 1\")\n",
    "print(Pred[0])\n",
    "print(\"___________\")\n",
    "print(\"___________\")\n",
    "\n",
    "Pred = model_aq(OtherValSpectra[1])\n",
    "Pred[0][Pred[0] < 0] = 0\n",
    "print(\"Sinusoidal Baseline 2\")\n",
    "print(Pred[0])\n",
    "print(\"___________\")\n",
    "print(\"___________\")\n",
    "\n",
    "Pred = model_aq(OtherValSpectra[2])\n",
    "Pred[0][Pred[0] < 0] = 0\n",
    "print(\"HD-Range 1 - 0.01s and 20s\")\n",
    "print(Pred[0])\n",
    "\n",
    "Pred = model_aq(OtherValSpectra[3])\n",
    "Pred[0][Pred[0] < 0] = 0\n",
    "print(\"HD-Range 2 - 0s and 20s\")\n",
    "print(Pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
